{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (2.14.5)\n",
      "Requirement already satisfied: evaluate in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: transformers in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (4.28.1)\n",
      "Requirement already satisfied: seqeval in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: git-lfs in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (1.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: multiprocess in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: xxhash in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: pandas in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipywidgets) (8.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: backcall in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: decorator in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pure-eval in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/liuyinjia/miniconda3/envs/torch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets evaluate transformers seqeval ipywidgets git-lfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "label_names = ['O', 'B-MethodName', 'I-MethodName', 'B-HyperparameterName', 'I-HyperparameterName', 'B-HyperparameterValue', 'I-HyperparameterValue',\n",
    "               'B-MetricName', 'I-MetricName', 'B-MetricValue', 'I-MetricValue', 'B-TaskName', 'I-TaskName', 'B-DatasetName', 'I-DatasetName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build raw dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# TODO: use real data\n",
    "data_list = [{'tokens': ['EU',\n",
    "  'rejects',\n",
    "  'German',\n",
    "  'call',\n",
    "  'to',\n",
    "  'boycott',\n",
    "  'British',\n",
    "  'lamb',\n",
    "  '.'],\n",
    " 'tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}]\n",
    "data_list = data_list * 10\n",
    "raw_dataset = Dataset.from_list(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be43e6ec33934a56afa273e3a40ca23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build tokenized dataset\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  7270,\n",
       "  22961,\n",
       "  1528,\n",
       "  1840,\n",
       "  1106,\n",
       "  21423,\n",
       "  1418,\n",
       "  2495,\n",
       "  12913,\n",
       "  119,\n",
       "  102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  7270,\n",
       "  22961,\n",
       "  1528,\n",
       "  1840,\n",
       "  1106,\n",
       "  21423,\n",
       "  1418,\n",
       "  2495,\n",
       "  12913,\n",
       "  119,\n",
       "  102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'HyperparameterName',\n",
       "  'score': 0.7368197,\n",
       "  'word': 'EU',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity_group': 'MetricName',\n",
       "  'score': 0.95823604,\n",
       "  'word': 'German',\n",
       "  'start': 11,\n",
       "  'end': 17},\n",
       " {'entity_group': 'MetricName',\n",
       "  'score': 0.95853364,\n",
       "  'word': 'British',\n",
       "  'start': 34,\n",
       "  'end': 41}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"bert-finetuned-ner/checkpoint-20/\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(\"EU rejects German call to boycott British lamb .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
