-DOCSTART-	O
We	O
use	O
the	O
2018	O
Duolingo	O
Shared	O
Task	O
on	O
Second	O
Language	O
Acquisition	O
Modeling	O
(	O
Settles	O
et	O
al	O
.	O
,	O
2018	O
)	O
dataset	O
,	O
which	O
contains	O
questions	O
and	O
responses	O
for	O
Duolingo	O
users	O
over	O
the	O
first	O
30	O
days	O
of	O
learning	O
a	O
second	O
language	O
.	O
While	O
the	O
original	O
task	O
's	O
goal	O
was	O
to	O
identify	O
token	O
-	O
level	O
mistakes	O
,	O
we	O
collapse	O
these	O
errors	O
into	O
binary	O
(	O
correct	O
/	O
incorrect	O
)	O
per	O
-	O
question	O
labels	O
.	O
We	O
use	O
the	O
provided	O
train	O
/	O
dev	O
/	O
test	O
splits	O
for	O
users	O
learning	O
Spanish	O
and	O
French	O
.	O
We	O
create	O
separate	O
held	O
-	O
out	O
sets	O
from	O
the	O
test	O
set	O
to	O
evaluate	O
the	O
LM	O
-	O
KT	O
and	O
question	O
generation	O
models	O
.	O
For	O
both	O
models	O
,	O
we	O
finetune	O
separate	O
GPT-2	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O

In	O
Table	O
2	O
,	O
we	O
observe	O
that	O
lexical	O
alignment	O
is	O
more	O
beneficial	O
for	O
En	B-MethodName
-	O
Mk	O
.	O
This	O
can	O
be	O
explained	O
by	O
the	O
limited	O
vocabulary	O
overlap	O
of	O
the	O
two	O
languages	O
,	O
which	O
does	O
not	O
provide	O
sufficient	O
crosslingual	O
signal	O
for	O
the	O
training	O
of	O
MLM	O
.	O
By	O
contrast	O
,	O
initializing	O
an	O
MLM	O
with	O
pretrained	O
embeddings	O
largely	O
improves	O
performance	O
,	O
even	O
for	O
a	O
higherperforming	O
model	O
,	O
such	O
as	O
RE	O
-	O
LM	O
.	O
In	O
En	O
-	O
Sq	O
,	O
the	O
effect	O
of	O
our	O
approach	O
is	O
smaller	O
yet	O
consistent	O
.	O
This	O
can	O
be	O
attributed	O
to	O
the	O
fact	O
that	O
the	O
two	O
languages	O
use	O
the	O
same	O
script	O
.	O

ISA	O
on	O
fine	O
-	O
grained	O
VL	O
phenomena	O
In	O
ISA	O
tasks	O
,	O
models	O
are	O
typically	O
confronted	O
with	O
highly	O
discrepant	O
negative	O
samples	O
(	O
non	O
-	O
matching	O
imagecaptions	O
)	O
.	O
To	O
evaluate	O
VL	O
models	O
in	O
a	O
more	O
finegrained	O
manner	O
,	O
we	O
examine	O
their	O
MM	O
score	O
on	O
the	O
VALSE	B-MethodName
benchmark	O
(	O
Parcalabescu	O
et	O
al	O
.	O
,	O
2022	O
)	O
,	O
where	O
foiled	O
captions	O
were	O
created	O
by	O
altering	O
phrases	O
pertaining	O
to	O
6	O
specific	O
linguistic	O
phenomena	O
:	O
existence	O
,	O
counting	O
,	O
plurality	O
,	O
spatial	O
relations	O
,	O
actions	O
,	O
and	O
coreference	O
,	O
such	O
that	O
image	O
and	O
foiled	O
caption	O
do	O
not	O
match	O
.	O
For	O
completeness	O
,	O
we	O
also	O
test	O
on	O
noun	O
phrase	O
foils	O
as	O
introduced	O
in	O
the	O
FOILit	O
!	O
dataset	O
(	O
Shekhar	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O

For	O
the	O
relation	O
recognition	O
procedure	O
in	O
S	O
1	O
(	O
see	O
Section	O
3.2	O
and	O
Figure	O
4	O
)	O
,	O
we	O
empirically	O
set	O
the	O
Both	O
numbers	O
are	O
the	O
50	O
percentiles	O
of	O
the	O
corresponding	O
similarity	O
scores	O
calculated	O
from	O
the	O
reduced	O
segment	O
pair	O
set	O
(	O
T	O
)	O
.	O
Note	O
that	O
,	O
in	O
this	O
work	O
,	O
we	O
adopt	O
a	O
rule	O
-	O
based	O
heuristic	O
method	O
for	O
recognizing	O
relations	O
using	O
similarity	O
functions	O
with	O
hard	O
thresholds	O
.	O
We	O
leave	O
the	O
exploration	O
of	O
other	O
similarity	O
functions	O
,	O
thresholds	O
,	O
and	O
approaches	O
to	O
future	O
work	O
.	O

LAMBADA	B-MethodName
starts	O
by	O
calling	O
the	O
Fact	O
Check	O
module	O
on	O
the	O
goal	O
which	O
fails	O
to	O
prove	O
or	O
disprove	O
it	O
.	O
So	O
Rule	O
Selection	O
is	O
called	O
which	O
identifies	O
two	O
rules	O
that	O
can	O
be	O
applied	O
:	O
Rule3	O
and	O
Rule6	O
.	O
Since	O
Rule6	O
is	O
shorter	O
,	O
the	O
reranker	O
ranks	O
it	O
higher	O
;	O
LAM	B-MethodName
-	I-MethodName
BADA	I-MethodName
starts	O
with	O
this	O
rule	O
and	O
calls	O
the	O
Goal	O
Decomposition	O
module	O
which	O
breaks	O
the	O
goal	O
into	O
two	O
sub	O
-	O
goals	O
:	O
"	O
Dave	O
is	O
nice	O
.	O
"	O
and	O
"	O
Dave	O
is	O
kind	O
.	O
"	O
.	O
Starting	O
with	O
the	O
first	O
sub	O
-	O
goal	O
,	O
Face	O
Check	O
fails	O
on	O
it	O
so	O
Rule	O
Selection	O
is	O
called	O
which	O
selects	O
Rule2	O
and	O
Goal	O
Decomposition	O
decomposes	O
the	O
sub	O
-	O
goal	O
into	O
"	O
Dave	O
is	O
green	O
.	O
"	O
.	O

•	O
A	O
novel	O
dataset	O
of	O
US	O
computing	O
curricula	O
and	O
relevant	O
programs	O
from	O
Latin	O
America	O
.	O
•	O
An	O
examination	O
of	O
attention	O
,	O
metric	O
learning	O
,	O
and	O
BERT	B-MethodName
modules	O
to	O
generate	O
more	O
intuitive	O
embedding	O
representations	O
.	O
•	O
An	O
application	O
that	O
compares	O
a	O
computing	O
curriculum	O
to	O
international	O
standards	O
.	O

Due	O
to	O
space	O
limitations	O
we	O
omit	O
high	O
-	O
level	O
discussions	O
on	O
benchmarking	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
sentence	O
-	O
level	O
probing	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2018a	O
)	O
,	O
and	O
focus	O
on	O
the	O
recent	O
findings	O
related	O
to	O
the	O
representation	O
of	O
linguistic	O
structure	O
in	O
BERT	B-MethodName
.	O
Surface	O
-	O
level	O
information	O
generally	O
tends	O
to	O
be	O
represented	O
in	O
the	O
lower	O
layers	O
of	O
deep	O
encoders	O
,	O
while	O
higher	O
layers	O
store	O
hierarchical	O
and	O
semantic	O
information	O
(	O
Belinkov	O
et	O
al	O
.	O
,	O
2017;Lin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
show	O
that	O
the	O
abstraction	O
strategy	O
applied	O
by	O
the	O
English	O
pre	O
-	O
trained	O
BERT	B-MethodName
encoder	O
follows	O
the	O
order	O
of	O
the	O
classical	O
NLP	O
pipeline	O
.	O
Strengthening	O
the	O
claim	O
about	O
linguistic	O
capabilities	O
of	O
BERT	B-MethodName
,	O
Hewitt	O
and	O
Manning	O
(	O
2019	O
)	O
demonstrate	O
that	O
BERT	B-MethodName
implicitly	O
learns	O
syntax	O
,	O
and	O
Reif	O
et	O
al	O
.	O
(	O
2019	O
)	O
show	O
that	O
it	O
encodes	O
fine	O
-	O
grained	O
lexicalsemantic	O
distinctions	O
.	O
Rogers	O
et	O
al	O
.	O
(	O
2020	O
)	O
provide	O
a	O
comprehensive	O
overview	O
of	O
BERT	B-MethodName
's	O
properties	O
discovered	O
to	O
date	O
.	O

1	O
.	O
Initialize	O
the	O
loss	O
as	O

This	O
paper	O
presented	O
WinoQueer	O
,	O
a	O
new	O
bias	O
benchmark	O
for	O
measuring	O
anti	O
-	O
queer	O
and	O
anti	O
-	O
trans	O
bias	O
in	O
large	O
language	O
models	O
.	O
WinoQueer	O
was	O
developed	O
via	O
a	O
large	O
survey	O
of	O
LGBTQ+	O
individuals	O
,	O
meaning	O
it	O
is	O
grounded	O
in	O
real	O
-	O
world	O
harms	O
and	O
based	O
on	O
the	O
experiences	O
of	O
actual	O
queer	O
people	O
.	O
We	O
detail	O
our	O
method	O
for	O
participatory	O
benchmark	O
development	O
,	O
and	O
we	O
hope	O
that	O
this	O
method	O
will	O
be	O
extensible	O
to	O
developing	O
community	O
-	O
in	O
-	O
the	O
-	O
loop	O
benchmarks	O
for	O
LLM	O
bias	O
against	O
other	O
marginalized	O
communities	O
.	O

This	O
section	O
describes	O
the	O
data	O
collection	O
and	O
preprocessing	O
for	O
the	O
argument	O
generation	O
pipeline	O
.	O

deepQuest	O
:	O
deepQuest	O
(	O
I	O
ve	O
et	O
al	O
.	O
,	O
2018	O
)	O
is	O
a	O
neural	O
-	O
based	O
framework	O
that	O
provides	O
state	O
-	O
of	O
-	O
theart	O
models	O
for	O
multi	O
-	O
level	O
QE	O
.	O
We	O
use	O
the	O
BiRNN	B-MethodName
model	O
,	O
a	O
light	O
-	O
weight	O
architecture	O
which	O
can	O
be	O
trained	O
at	O
either	O
sentence	O
or	O
document	O
level	O
.	O

There	O
was	O
no	O
significant	O
trend	O
in	O
the	O
learners	O
'	O
frequency	O
of	O
consulting	O
the	O
additional	O
resources	O
concerning	O
language	O
and	O
types	O
of	O
additional	O
resources	O
.	O
Still	O
,	O
learners	O
of	O
all	O
languages	O
replied	O
that	O
the	O
dictionary	O
setting	O
was	O
more	O
helpful	O
for	O
data	O
annotation	O
than	O
the	O
translation	O
setting	O
.	O
and	O
SA	O
was	O
the	O
easiest	O
.	O
This	O
result	O
looks	O
awkward	O
considering	O
that	O
language	O
learners	O
achieved	O
the	O
highest	O
accuracy	O
in	O
NER	O
.	O

Parallel	O
Data	O
for	O
Post	O
-	O
Pretraining	O

As	O
described	O
in	O
the	O
previous	O
section	O
,	O
the	O
teacher	O
model	O
is	O
trained	O
using	O
a	O
direct	O
transfer	O
approach	O
:	O
it	O
learns	O
to	O
generate	O
language	O
-	O
independent	O
representations	O
from	O
the	O
labeled	O
source	O
-	O
language	O
data	O
so	O
that	O
it	O
can	O
be	O
directly	O
applied	O
to	O
unlabeled	O
targetlanguage	O
data	O
.	O
However	O
,	O
in	O
our	O
proposed	O
hybrid	O
knowledge	O
transfer	O
approach	O
,	O
we	O
expect	O
the	O
student	O
model	O
to	O
reap	O
the	O
benefits	O
of	O
the	O
data	O
transfer	O
paradigm	O
.	O
Hence	O
,	O
we	O
train	O
the	O
student	O
model	O
using	O
target	O
-	O
language	O
data	O
so	O
that	O
it	O
may	O
learn	O
from	O
syntactical	O
features	O
and	O
word	O
/	O
label	O
relations	O
.	O

•	O
Base	O
:	O
The	O
original	O
NMT	B-MethodName
models	O
without	O
finetuning	O
on	O
the	O
schema	O
dataset	O
.	O
•	O
H2H	O
:	O
The	O
NMT	B-MethodName
models	O
that	O
are	O
fine	O
-	O
tuned	O
on	O
our	O
schema	O
translation	O
dataset	O
in	O
a	O
headerto	O
-	O
header	O
manner	O
.	O
•	O
H2H+CXT	O
:	O
The	O
NMT	B-MethodName
models	O
are	O
fine	O
-	O
tuned	O
by	O
concatenating	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
input	O
and	O
translating	O
the	O
target	O
header	O
.	O
•	O
H2H+CXT+ExtL	O
:	O
The	O
NMT	B-MethodName
models	O
with	O
two	O
extra	O
Transformers	O
layers	O
at	O
the	O
end	O
of	O
the	O
encoder	O
,	O
and	O
are	O
fine	O
-	O
tuned	O
with	O
the	O
same	O
setting	O
as	O
H2H+CXT	O
.	O

In	O
this	O
section	O
,	O
we	O
conduct	O
class	O
-	O
specific	O
lexical	O
analysis	O
to	O
identify	O
the	O
clinical	O
and	O
domainagnostic	O
characteristics	O
of	O
annotation	O
artifacts	O
associated	O
with	O
each	O
set	O
of	O
hypotheses	O
in	O
MedNLI	O
.	O

We	O
treat	O
these	O
as	O
hyper	O
-	O
parameters	O
.	O
We	O
represent	O
the	O
position	O
as	O
k	O
,	O
where	O
k	O
corresponds	O
to	O
a	O
fraction	O
of	O
the	O
conversation	O
,	O
as	O
defined	O
earlier	O
.	O
For	O
example	O
,	O
the	O
word	O
"	O
house	O
"	O
spoken	O
by	O
the	O
seller	O
in	O
the	O
first	O
10	O
%	O
of	O
turns	O
in	O
a	O
negotiation	O
would	O
be	O
tokenized	O
as	O
"	O
s1	O
-	O
house	O
"	O
.	O
In	O
the	O
LED	O
experiments	O
,	O
we	O
omit	O
the	O
inner	O
cross	O
validation	O
and	O
use	O
a	O
batch	O
size	O
of	O
4	O
,	O
the	O
largest	O
possible	O
batch	O
size	O
given	O
our	O
memory	O
constraints	O
.	O
5	O
We	O
select	O
the	O
best	O
performing	O
learning	O
rate	O
out	O
of	O
{	O
5e	O
−	O
5	O
,	O
3e	O
−	O
4	O
,	O
3e	O
−	O
3	O
}	O
and	O
early	O
stop	O
based	O
on	O
training	O
loss	O
convergence	O
.	O

However	O
,	O
linking	O
to	O
unseen	O
KBs	O
requires	O
handling	O
entities	O
with	O
an	O
arbitrary	O
number	O
and	O
type	O
of	O
attributes	O
.	O
The	O
same	O
entity	O
(	O
Douglas	O
Adams	O
)	O
can	O
be	O
represented	O
in	O
a	O
different	O
KB	O
using	O
attributes	O
such	O
as	O
"	O
name	O
"	O
,	O
"	O
place	O
of	O
birth	O
"	O
,	O
etc	O
.	O
(	O
top	O
of	O
Figure	O
1	O
)	O
.	O
This	O
raises	O
the	O
question	O
of	O
whether	O
such	O
models	O
,	O
that	O
harness	O
the	O
power	O
of	O
pre	O
-	O
trained	O
language	O
models	O
,	O
generalize	O
to	O
linking	O
mentions	O
to	O
unseen	O
KBs	O
,	O
including	O
those	O
without	O
such	O
textual	O
descriptions	O
.	O
This	O
section	O
presents	O
multiple	O
ideas	O
to	O
this	O
end	O
.	O

In	O
particular	O
,	O
τ	O
=	O
0	O
refers	O
to	O
the	O
original	O
Transformer	B-MethodName
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
τ	O
=	O
H	O
means	O
that	O
XL	O
PE	I-MethodName
will	O
propagate	O
over	O
all	O
attention	O
heads	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
1	O
.	O
Electric	O
scores	O
better	O
than	O
BERT	B-MethodName
,	O
showing	O
the	O
energy	O
-	O
based	O
formulation	O
improves	O
cloze	O
model	O
pre	O
-	O
training	O
.	O
However	O
,	O
Electric	O
scores	O
slightly	O
lower	O
than	O
ELECTRA	B-MethodName
.	O
One	O
possible	O
explanation	O
is	O
that	O
Electric	O
's	O
noise	O
distribution	O
is	O
worse	O
because	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
is	O
less	O
expressive	O
than	O
a	O
masked	O
LM	O
.	O
We	O
tested	O
this	O
hypothesis	O
by	O
training	O
ELECTRA	B-MethodName
with	O
the	O
same	O
two	O
-	O
tower	O
noise	O
model	O
as	O
Electric	O
.	O
Performance	O
did	O
indeed	O
go	O
down	O
,	O
but	O
it	O
only	O
explained	O
about	O
half	O
the	O
gap	O
.	O
The	O
surprising	O
drop	O
in	O
performance	O
suggests	O
that	O
learning	O
the	O
difference	O
between	O
the	O
data	O
and	O
generations	O
from	O
a	O
low	O
-	O
capacity	O
model	O
leads	O
to	O
better	O
representations	O
than	O
only	O
learning	O
the	O
data	O
distribution	O
,	O
but	O
we	O
believe	O
further	O
research	O
is	O
needed	O
to	O
fully	O
understand	O
the	O
discrepancy	O
.	O

In	O
this	O
section	O
,	O
we	O
describe	O
the	O
heuristic	O
used	O
for	O
selecting	O
the	O
languages	O
.	O
As	O
a	O
first	O
step	O
,	O
we	O
take	O
a	O
quantitative	O
stance	O
and	O
choose	O
30	O
languages	O
(	O
L30	O
)	O
roughly	O
based	O
on	O
their	O
percent	O
of	O
web	O
content	O
2	O
.	O
As	O
a	O
second	O
step	O
,	O
we	O
consider	O
an	O
additional	O
five	O
languages	O
(	O
L5	O
)	O
3	O
to	O
cover	O
low	O
-	O
resource	O
languages	O
with	O
ish	O
(	O
da	O
)	O
,	O
Dutch	O
(	O
nl	O
)	O
,	O
Filipino	O
(	O
fil	O
)	O
,	O
Finnish	O
(	O
fi	O
)	O
,	O
French	O
(	O
fr	O
)	O
,	O
German	O
(	O
de	O
)	O
,	O
Greek	O
(	O
el	O
)	O
,	O
Hebrew	O
(	O
he	O
)	O
,	O
Hindi	O
(	O
hi	O
)	O
,	O
Hungarian	O
(	O
hu	O
)	O
,	O
Indonesian	O
(	O
i	O
d	O
)	O
,	O
Italian	O
(	O
it	O
)	O
,	O
Japanese	O
(	O
ja	O
)	O
,	O
Korean	O
(	O
ko	O
)	O
,	O
Norwegian	O
(	O
no	O
)	O
,	O
Persian	O
(	O
fa	O
)	O
,	O
Polish	O
(	O
pl	O
)	O
,	O
Portuguese	O
(	O
pt	O
)	O
,	O
Romanian	O
(	O
ro	O
)	O
,	O
Russian	O
(	O
ru	O
)	O
,	O
Spanish	O
(	O
es	O
)	O
,	O
Swedish	O
(	O
sv	O
)	O
,	O
Thai	O
(	O
th	O
)	O
,	O
Turkish	O
(	O
tr	O
)	O
,	O
Ukrainian	O
(	O
uk	O
)	O
,	O
Vietnamese	O
(	O
vi	O
)	O
.	O

Glancing	O
Training	O
.	O
According	O
to	O
previous	O
studies	O
,	O
glancing	O
training	O
(	O
Qian	O
et	O
al	O
.	O
,	O
2021	O
)	O
can	O
considerably	O
improve	O
the	O
translation	O
quality	O
of	O
non	O
-	O
iterative	O
NAR	B-MethodName
models	O
.	O
We	O
apply	O
glancing	O
training	O
technique	O
to	O
our	O
method	O
.	O
More	O
specifically	O
,	O
we	O
first	O
randomly	O
sample	O
reference	O
tokens	O
as	O
NAR	B-MethodName
decoder	O
inputs	O
like	O
Qian	O
et	O
al	O
.	O
(	O
2021	O
)	O
,	O
and	O
then	O
let	O
the	O
weak	O
AR	O
decoder	O
make	O
predictions	O
based	O
on	O
the	O
NAR	B-MethodName
decoder	O
hidden	O
states	O
.	O

B4	O
.	O
Did	O
you	O
discuss	O
the	O
steps	O
taken	O
to	O
check	O
whether	O
the	O
data	O
that	O
was	O
collected	O
/	O
used	O
contains	O
any	O
information	O
that	O
names	O
or	O
uniquely	O
identifies	O
individual	O
people	O
or	O
offensive	O
content	O
,	O
and	O
the	O
steps	O
taken	O
to	O
protect	O
/	O
anonymize	O
it	O
?	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O

SEMBLEU	B-MethodName
BLEU	I-MethodName
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
,	O
which	O
assesses	O
text	O
quality	O
by	O
comparing	O
n	O
-	O
grams	O
,	O
is	O
frequently	O
adopted	O
in	O
machine	O
translation	O
evaluation	O
.	O
To	O
extend	O
BLEU	B-MethodName
for	O
matching	O
AMR	O
graphs	O
,	O
SEM	B-MethodName
-	I-MethodName
BLEU	I-MethodName
(	O
Song	O
and	O
Gildea	O
,	O
2019	O
)	O
linearizes	O
AMR	O
graphs	O
through	O
breadth	O
-	O
first	O
traversal	O
and	O
extracts	O
n	O
-	O
gram	O
for	O
comparison	O
.	O
The	O
metric	O
is	O
alignmentfree	O
and	O
thus	O
computationally	O
efficient	O
.	O
Experimental	O
results	O
show	O
that	O
SEMBLEU	B-MethodName
achieved	O
slightly	O
higher	O
consistency	O
with	O
human	O
judgment	O
than	O
SMATCH	O
.	O

Baseline	O
Models	O
As	O
described	O
in	O
Section	O
5	O
,	O
the	O
baseline	O
models	O
provided	O
for	O
bgGLUE	O
include	O
fairly	O
small	O
encoder	O
-	O
only	O
Transformer	O
architectures	O
.	O
We	O
leave	O
for	O
future	O
work	O
other	O
modeling	O
architectures	O
and	O
modeling	O
techniques	O
that	O
are	O
known	O
for	O
improving	O
the	O
efficiency	O
and	O
the	O
computational	O
requirements	O
of	O
the	O
used	O
models	O
,	O
e.g.	O
,	O
few	O
-	O
shot	O
and	O
zero	O
-	O
shot	O
in	O
-	O
context	O
learning	O
and	O
instruction	O
-	O
based	O
evaluation	O
,	O
multi	O
-	O
task	O
learning	O
,	O
etc	O
.	O

The	O
lower	O
these	O
metrics	O
are	O
,	O
the	O
less	O
biases	O
the	O
model	O
has	O
.	O
4	O
We	O
also	O
conducted	O
the	O
same	O
experiments	O
here	O
with	O
bidirectional	O
LSTM	O
networks	O
(	O
BiLSTMs	O
)	O
which	O
required	O
a	O
different	O
way	O
to	O
generate	O
the	O
word	O
clouds	O
(	O
see	O
Appendix	O
C	O
)	O
.	O
The	O
results	O
on	O
BiLSTMs	B-MethodName
,	O
however	O
,	O
are	O
not	O
as	O
promising	O
as	O
on	O
CNNs	O
.	O
This	O
might	O
be	O
because	O
the	O
way	O
we	O
created	O
word	O
clouds	O
for	O
each	O
BiLSTM	B-MethodName
feature	O
was	O
not	O
an	O
accurate	O
way	O
to	O
reveal	O
its	O
behavior	O
.	O
Unlike	O
for	O
CNNs	O
,	O
understanding	O
recurrent	O
neural	O
network	O
features	O
for	O
text	O
classification	O
is	O
still	O
an	O
open	O
problem	O
.	O

Since	O
the	O
two	O
findings	O
are	O
more	O
or	O
less	O
surprising	O
,	O
some	O
study	O
is	O
necessary	O
to	O
reveal	O
the	O
underlying	O
reasons	O
behind	O
the	O
findings	O
.	O
We	O
hope	O
the	O
study	O
helps	O
to	O
discover	O
better	O
metrics	O
for	O
paraphrase	O
generation	O
.	O
In	O
-	O
depth	O
analysis	O
to	O
the	O
two	O
findings	O
are	O
shown	O
in	O
Sec	O
3	O
and	O
Sec	O
4	O
respectively	O
.	O

Additionally	O
,	O
we	O
propose	O
and	O
experiment	O
with	O
BERT	B-MethodName
-	I-MethodName
BiRNN	I-MethodName
,	O
a	O
variant	O
of	O
the	O
BiRNN	B-MethodName
model	O
.	O
Rather	O
than	O
training	O
the	O
token	O
embeddings	O
with	O
the	O
task	O
at	O
hand	O
,	O
we	O
use	O
large	O
-	O
scale	O
pre	O
-	O
trained	O
token	O
-	O
level	O
representations	O
from	O
the	O
multilingual	O
cased	O
base	O
BERT	B-MethodName
model	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
During	O
training	O
,	O
the	O
BERT	B-MethodName
model	O
is	O
fine	O
-	O
tuned	O
by	O
unfreezing	O
the	O
weights	O
of	O
the	O
last	O
four	O
hidden	O
layers	O
along	O
with	O
the	O
token	O
embedding	O
layer	O
.	O
This	O
performs	O
comparably	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
predictorestimator	O
neural	O
model	O
in	O
Kepler	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

We	O
examine	O
whether	O
our	O
model	O
learns	O
effective	O
embeddings	O
for	O
rare	O
entities	O
using	O
the	O
CoNLL	B-MethodName
dataset	O
.	O
Following	O
Ganea	O
and	O
Hofmann	O
(	O
2017	O
)	O
,	O
we	O
use	O
the	O
mentions	O
of	O
which	O
entity	O
candidates	O
contain	O
their	O
gold	O
entities	O
and	O
measure	O
the	O
performance	O
by	O
dividing	O
the	O
mentions	O
based	O
on	O
the	O
frequency	O
of	O
their	O
entities	O
in	O
the	O
Wikipedia	O
annotations	O
used	O
to	O
train	O
the	O
embeddings	O
.	O

The	O
observations	O
from	O
this	O
informal	O
survey	O
might	O
be	O
surprising	O
to	O
researchers	O
,	O
who	O
typically	O
consider	O
language	O
technology	O
to	O
be	O
broadly	O
useful	O
and	O
beneficial	O
to	O
all	O
people	O
.	O
An	O
awareness	O
that	O
is	O
lacking	O
in	O
the	O
research	O
field	O
,	O
however	O
,	O
is	O
that	O
the	O
purpose	O
of	O
language	O
technologies	O
and	O
their	O
development	O
process	O
might	O
vary	O
significantly	O
when	O
applied	O
to	O
indigenous	O
and	O
endangered	O
languages	O
.	O
For	O
many	O
of	O
these	O
languages	O
,	O
the	O
priorities	O
of	O
the	O
speech	O
communities	O
are	O
how	O
to	O
more	O
effectively	O
document	O
,	O
teach	O
,	O
and	O
reclaim	O
their	O
language	O
;	O
how	O
to	O
save	O
the	O
cultural	O
heritage	O
passed	O
down	O
from	O
the	O
elders	O
;	O
and	O
how	O
to	O
let	O
their	O
language	O
have	O
a	O
voice	O
among	O
other	O
widely	O
-	O
spoken	O
or	O
dominant	O
languages	O
.	O

We	O
treat	O
the	O
annotation	O
task	O
as	O
identifying	O
instances	O
of	O
a	O
semantic	O
frame	O
(	O
Fillmore	O
,	O
1976	O
)	O
that	O
represents	O
SOFC	O
-	O
related	O
experiments	O
.	O
We	O
include	O
(	O
1	O
)	O
cases	O
that	O
introduce	O
novel	O
content	O
;	O
(	O
2	O
)	O
descriptions	O
of	O
specific	O
previous	O
work	O
;	O
(	O
3	O
)	O
general	O
knowledge	O
that	O
one	O
could	O
find	O
in	O
a	O
textbook	O
or	O
survey	O
;	O
and	O
also	O
(	O
4	O
)	O
suggestions	O
for	O
future	O
work	O
.	O

MLQA	O
Table	O
4	O
shows	O
results	O
on	O
MLQA	B-MethodName
measured	O
by	O
F1	O
score	O
.	O
We	O
notice	O
the	O
mBERT	O
baseline	O
from	O
the	O
original	O
MLQA	O
paper	O
is	O
significantly	O
lower	O
than	O
that	O
from	O
,	O
so	O
we	O
use	O
the	O
latter	O
as	O
our	O
baseline	O
.	O
Our	O
2	O
M	O
model	O
outperforms	O
the	O
baseline	O
by	O
2.3	O
%	O
for	O
zero	O
-	O
shot	O
and	O
is	O
also	O
0.2	O
%	O
better	O
than	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
Base	I-MethodName
,	O
which	O
uses	O
57	O
%	O
more	O
model	O
parameters	O
than	O
mBERT	O
as	O
Table	O
3	O
shows	O
.	O
For	O
translate	O
-	O
train	O
,	O
our	O
250k	O
model	O
is	O
1.3	O
%	O
better	O
than	O
the	O
baseline	O
.	O

The	O
design	O
of	O
new	O
experiments	O
in	O
scientific	O
domains	O
heavily	O
depends	O
on	O
domain	O
knowledge	O
as	O
well	O
as	O
on	O
previous	O
studies	O
and	O
their	O
findings	O
.	O
However	O
,	O
the	O
amount	O
of	O
publications	O
available	O
is	O
typically	O
very	O
large	O
,	O
making	O
it	O
hard	O
or	O
even	O
impossible	O
to	O
keep	O
track	O
of	O
all	O
experiments	O
conducted	O
for	O
a	O
particular	O
research	O
question	O
.	O
Since	O
scientific	O
experiments	O
are	O
often	O
time	O
-	O
consuming	O
and	O
expensive	O
,	O
effective	O
knowledge	O
base	O
population	O
methods	O
for	O
finding	O
promising	O
settings	O
based	O
on	O
the	O
published	O
research	O
would	O
be	O
of	O
great	O
value	O
(	O
e.g.	O
,	O
Auer	O
et	O
al	O
.	O
,	O
2018;Manica	O
et	O
al	O
.	O
,	O
2019;Mrdjenovich	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
While	O
such	O
real	O
-	O
life	O
information	O
extraction	O
tasks	O
have	O
received	O
consid-	O
erable	O
attention	O
in	O
the	O
biomedical	O
domain	O
(	O
e.g.	O
,	O
Cohen	O
et	O
al	O
.	O
,	O
2017;Demner	O
-	O
Fushman	O
et	O
al	O
.	O
,	O
2018	O
,	O
there	O
has	O
been	O
little	O
work	O
in	O
other	O
domains	O
(	O
Nastase	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
including	O
materials	O
science	O
(	O
with	O
the	O
notable	O
exception	O
of	O
the	O
work	O
by	O
Mysore	O
et	O
al	O
.	O
,	O
2017Mysore	O
et	O
al	O
.	O
,	O
,	O
2019	O
.	O

We	O
take	O
the	O
edge	O
probing	O
setup	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
as	O
our	O
starting	O
point	O
.	O
Edge	O
probing	O
aims	O
to	O
predict	O
a	O
label	O
given	O
a	O
pair	O
of	O
contextualized	O
span	O
or	O
word	O
encodings	O
.	O
More	O
formally	O
,	O
we	O
encode	O
a	O
WP	O
-	O
tokenized	O
sentence	O
[	O
wp	O
1	O
,	O
wp	O
2	O
,	O
...	O
wp	O
k	O
]	O
with	O
a	O
frozen	O
pre	O
-	O
trained	O
model	O
,	O
producing	O
contextual	O
embeddings	O
[	O
e	O
1	O
,	O
e	O
2	O
,	O
...	O
e	O
k	O
]	O
,	O
each	O
of	O
which	O
is	O
a	O
layered	O
representation	O
over	O
L	O
=	O
{	O
l	O
0	O
,	O
l	O
1	O
,	O
...	O
l	O
m	O
}	O
layers	O
,	O
with	O
encoding	O
at	O
layer	O
l	O
n	O
for	O
the	O
wordpiece	O
wp	O
i	O
further	O
denoted	O
as	O
e	O
n	O
i	O
.	O
A	O
trainable	O
scalar	O
mix	O
is	O
applied	O
to	O
the	O
layered	O
representation	O
to	O
produce	O
the	O
final	O
encoding	O
given	O
the	O
per	O
-	O
layer	O
mixing	O
weights	O
{	O
a	O
0	O
,	O
a	O
1	O
..	O
a	O
m	O
}	O
and	O
a	O
scaling	O
parameter	O
γ	O
:	O

W	O
s	O
∈	O
R	O
3×d	O
and	O
b	O
s	O
are	O
the	O
trainable	O
weight	O
and	O
bias	O
,	O
respectively	O
.	O
The	O
cross	O
entropy	O
loss	O
L	O
S	O
for	O
the	O
sentiment	O
classification	O
is	O
then	O
given	O
as	O
follows	O
:	O

It	O
can	O
benefit	O
the	O
scenarios	O
when	O
communications	O
become	O
a	O
bottleneck	O
,	O
such	O
as	O
federal	O
learning	O
,	O
distributed	O
training	O
,	O
and	O
edge	O
computing	O
.	O
However	O
,	O
since	O
we	O
do	O
not	O
apply	O
explicit	O
differentiable	O
privacy	O
methods	O
to	O
these	O
updated	O
parameters	O
,	O
the	O
method	O
can	O
be	O
vulnerable	O
to	O
specific	O
attacks	O
(	O
e.g.	O
,	O
man	O
-	O
inthe	O
-	O
middle	O
attack	O
)	O
.	O

Future	O
work	O
includes	O
comparing	O
our	O
method	O
to	O
other	O
question	O
generation	O
methods	O
(	O
including	O
supervised	O
methods	O
:	O
,	O
Puri	O
et	O
al	O
.	O
(	O
2020	O
)	O
)	O
in	O
order	O
to	O
assess	O
the	O
effect	O
of	O
both	O
the	O
generation	O
method	O
and	O
the	O
questions	O
quality	O
on	O
the	O
final	O
performances	O
of	O
our	O
models	O
.	O
Also	O
,	O
we	O
will	O
further	O
compare	O
different	O
variations	O
of	O
our	O
question	O
generation	O
and	O
distractor	O
refining	O
methods	O
in	O
order	O
to	O
more	O
thoroughly	O
understand	O
the	O
effect	O
of	O
hyper	O
-	O
parameters	O
such	O
as	O
the	O
number	O
of	O
candidate	O
distractors	O
.	O

We	O
refer	O
the	O
reader	O
to	O
Appendix	O
A	O
for	O
an	O
overview	O
of	O
the	O
dataset	O
licenses	O
.	O
We	O
also	O
refer	O
the	O
reader	O
to	O
Appendix	O
B	O
for	O
an	O
overview	O
of	O
the	O
computatinal	O
resources	O
.	O

Because	O
our	O
aim	O
was	O
to	O
obtain	O
overall	O
accuracy	O
estimates	O
for	O
each	O
condition	O
,	O
we	O
did	O
not	O
require	O
judgements	O
for	O
every	O
individual	O
annotation	O
and	O
context	O
in	O
the	O
test	O
set	O
.	O
However	O
,	O
we	O
were	O
able	O
to	O
ensure	O
good	O
coverage	O
of	O
the	O
dataset	O
,	O
including	O
annotations	O
from	O
all	O
125	O
tangrams	O
and	O
over	O
600	O
unique	O
descriptions	O
in	O
each	O
condition	O
.	O

For	O
the	O
implementation	O
of	O
the	O
transformer	O
and	O
convolutional	O
sequence	O
-	O
to	O
-	O
sequence	O
models	O
,	O
we	O
built	O
on	O
the	O
PyTorch	O
(	O
Paszke	O
et	O
al	O
.	O
,	O
2019	O
)	O
library	O
fairseq	O
(	O
Ott	O
et	O
al	O
.	O
,	O
2019	O
)	O
by	O
Facebook	O
AI	O
Research	O
.	O
Since	O
,	O
as	O
depicted	O
in	O
the	O
evaluation	O
,	O
the	O
perplexity	O
does	O
not	O
properly	O
reflect	O
the	O
accuracy	O
,	O
we	O
extended	O
fairseq	O
by	O
an	O
option	O
to	O
measure	O
the	O
quality	O
of	O
models	O
with	O
an	O
exact	O
match	O
accuracy	O
and	O
the	O
Levenshtein	O
distance	O
.	O

As	O
shown	O
in	O
Section	O
4.3	O
,	O
the	O
simple	O
architecture	O
and	O
high	O
efficiency	O
enable	O
DecT	B-MethodName
to	O
scale	O
on	O
more	O
training	O
data	O
,	O
while	O
baseline	O
methods	O
struggle	O
to	O
finish	O
training	O
within	O
acceptable	O
time	O
limits	O
.	O
To	O
explore	O
the	O
scalability	O
of	O
DecT	B-MethodName
beyond	O
the	O
few	O
-	O
shot	O
setting	O
,	O
we	O
conduct	O
experiments	O
with	O
increased	O
training	O
data	O
(	O
n	O
=	O
64	O
and	O
256	O
)	O
.	O
For	O
reference	O
,	O
we	O
compare	O
DecT	B-MethodName
with	O
fine	O
-	O
tuning	O
,	O
the	O
strongest	O
baseline	O
which	O
update	O
full	O
model	O
parameters	O
.	O

ED	O
as	O
sequential	O
decision	O
task	O
.	O
Past	O
studies	O
Fang	O
et	O
al	O
.	O
,	O
2019	O
)	O
have	O
solved	O
ED	O
by	O
casting	O
it	O
as	O
a	O
sequential	O
decision	O
task	O
to	O
capture	O
global	O
contextual	O
information	O
.	O
We	O
adopt	O
a	O
similar	O
method	O
with	O
an	O
enhanced	O
Transformer	B-MethodName
architecture	O
,	O
a	O
training	O
task	O
,	O
and	O
an	O
inference	O
method	O
to	O
implement	O
the	O
global	O
ED	O
model	O
based	O
on	O
BERT	B-MethodName
.	O

•	O
annot	O
-the	O
visual	O
feature	O
vector	O
is	O
used	O
after	O
the	O
encoding	O
of	O
the	O
two	O
input	O
sentences	O
by	O
the	O
two	O
bi	O
-	O
directional	O
RNNs	O
;	O
•	O
last	O
-the	O
visual	O
feature	O
vector	O
is	O
used	O
just	O
before	O
the	O
last	O
layer	O
.	O

•	O
QQP	O
:	O
Quora	O
Question	O
Pairs	O
(	O
Iyer	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
The	O
task	O
is	O
to	O
determine	O
whether	O
a	O
pair	O
of	O
questions	O
are	O
semantically	O
equivalent	O
.	O
The	O
dataset	O
contains	O
364k	O
train	O
examples	O
from	O
the	O
community	O
question	O
-	O
answering	O
website	O
Quora	O
.	O

Chosen	O
Metrics	O
We	O
select	O
the	O
following	O
well	O
known	O
metrics	O
:	O
BLEU	B-MethodName
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
,	O
ROUGE	B-MethodName
(	O
Lin	O
,	O
2004	O
)	O
,	O
METEOR	B-MethodName
(	O
Banerjee	O
and	O
Lavie	O
,	O
2005	O
)	O
,	O
BERTScore	B-MethodName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
andBARTScore	O
(	O
Yuan	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Specifically	O
,	O
we	O
consider	O
two	O
variants	O
of	O
BERTScore	B-MethodName
:	O
BERTScore	B-MethodName
(	O
B	O
)	O
and	O
BERTScore	B-MethodName
(	O
R	O
)	O
,	O
based	O
on	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
respectively	O
.	O
For	O
each	O
metric	O
M	O
,	O
we	O
consider	O
its	O
two	O
variants	O
,	O
i.e.	O
,	O
a	O
reference	O
-	O
based	O
version	O
and	O
a	O
reference	O
-	O
free	O
version	O
'	O
M	O
.Free	O
'	O
.	O
In	O
the	O
reference	O
-	O
free	O
version	O
,	O
the	O
quality	O
of	O
a	O
candidate	O
C	O
is	O
estimated	O
by	O
M	O
(	O
C	O
,	O
X	O
)	O
,	O
where	O
X	O
is	O
the	O
input	O
.	O
Similarly	O
,	O
in	O
the	O
reference	O
-	O
based	O
version	O
,	O
the	O
formula	O
is	O
M	O
(	O
C	O
,	O
R	O
)	O
,	O
where	O
R	O
is	O
the	O
reference	O
.	O

Our	O
results	O
reveal	O
a	O
gap	O
between	O
AI	O
and	O
humanlevel	O
humor	O
"	O
understanding	O
.	O
"	O
In	O
the	O
from	O
pixels	O
setting	O
,	O
our	O
best	O
multimodal	O
model	O
(	O
fine	O
-	O
tuned	O
CLIP	B-MethodName
ViT	I-MethodName
-	I-MethodName
L	I-MethodName
/	I-MethodName
14	I-MethodName
(	O
Radford	O
et	O
al	O
.	O
,	O
2021	O
)	O
)	O
achieves	O
62	O
%	O
accuracy	O
on	O
a	O
5	O
-	O
way	O
multiple	O
choice	O
task	O
,	O
but	O
humans	O
achieve	O
94	O
%	O
in	O
the	O
same	O
setting	O
.	O
Even	O
with	O
significant	O
manual	O
annotation	O
of	O
the	O
cartoons	O
in	O
the	O
from	O
description	O
setting	O
(	O
and	O
despite	O
significant	O
improvements	O
in	O
language	O
modeling	O
performance	O
since	O
this	O
work	O
's	O
submission	O
2	O
)	O
large	O
language	O
models	O
still	O
fall	O
short	O
:	O
human	O
explanations	O
are	O
still	O
preferred	O
in	O
more	O
than	O
two	O
-	O
thirds	O
of	O
cases	O
compared	O
to	O
our	O
best	O
explanation	O
model	O
,	O
5	O
-	O
shot	O
GPT-4	O
.	O

Finally	O
,	O
we	O
integrate	O
the	O
prediction	O
layer	O
distillation	O
and	O
the	O
intermediate	O
layer	O
distillation	O
.	O
Let	O
T	O
denote	O
the	O
set	O
of	O
the	O
student	O
's	O
layer	O
indexes	O
,	O
the	O
whole	O
training	O
loss	O
of	O
the	O
student	O
model	O
is	O
the	O
summation	O
of	O
losses	O
w.r.t	O
.	O
all	O
sentences	O
in	O
D	O
in	O
:	O

To	O
facilitate	O
multilingual	O
experiments	O
,	O
we	O
use	O
the	O
multilingual	O
BERT	B-MethodName
-	O
base	I-MethodName
(	O
mBERT	O
)	O
published	O
by	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
Although	O
several	O
recent	O
encoders	O
have	O
outperformed	O
BERT	B-MethodName
on	O
benchmarks	O
Lan	O
et	O
al	O
.	O
,	O
2019;Raffel	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
we	O
use	O
the	O
original	O
BERT	B-MethodName
architecture	O
,	O
since	O
it	O
allows	O
us	O
to	O
inherit	O
the	O
probing	O
methodology	O
and	O
to	O
build	O
upon	O
the	O
related	O
findings	O
.	O

This	O
work	O
was	O
supported	O
by	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
No	O
.	O
61976051	O
)	O
,	O
the	O
Major	O
Key	O
Project	O
of	O
PCL	B-MethodName
(	O
No	O
.	O
PCL2021A09	O
,	O
PCL2021A02	O
,	O
PCL2022A03	O
)	O
,	O
and	O
Guangdong	O
Provincial	O
Key	O
Laboratory	O
of	O
Novel	O
Security	O
Intelligence	O
Technologies	O
(	O
2022B1212010005	O
)	O
.	O

The	O
prompt	O
template	O
used	O
to	O
evaluate	O
our	O
models	O
MMLU	B-MethodName
is	O
the	O
prompt	O
template	O
from	O
the	O
AI2	O
Reasoning	O
Challenge	O
(	O
AI2	B-MethodName
-	I-MethodName
ARC	I-MethodName
)	O
concatenated	O
with	O
5	O
passages	O
in	O
MS	O
MARCO	I-MethodName
(	O
Nguyen	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
These	O
5	O
passages	O
are	O
selected	O
via	O
dense	O
retrival	O
using	O
T5	B-MethodName
-	I-MethodName
ANCE	I-MethodName
(	O
Ge	O
et	O
al	O
.	O
,	O
2023	O
;	O
Ni	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
which	O
maps	O
a	O
query	O
to	O
a	O
single	O
vector	O
to	O
retrieve	O
similar	O
passage	O
from	O
the	O
corpus	O
.	O
Adding	O
densely	O
-	O
retrieved	O
passages	O
to	O
prompts	O
is	O
a	O
standard	O
approach	O
to	O
enhance	O
LM	O
's	O
performance	O
on	O
zero	O
-	O
shot	O
prompting	O
.	O
This	O
approach	O
is	O
named	O
retrieval	O
augmentation	O
.	O
All	O
T0	B-MethodName
and	O
METRO	B-MethodName
-	I-MethodName
T0	I-MethodName
results	O
reported	O
in	O
Table	O
3	O
are	O
evaluated	O
using	O
this	O
prompt	O
template	O
with	O
retrieval	O
augmentation	O
.	O

Our	O
evaluation	O
shows	O
that	O
the	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
is	O
able	O
to	O
produce	O
aspect	O
-	O
specific	O
,	O
high	O
-	O
quality	O
arguments	O
,	O
applicable	O
to	O
automatic	O
counter	O
-	O
argument	O
generation	O
.	O
The	O
contributions	O
are	O
as	O
follows	O
:	O
(	O
i	O
)	O
We	O
adapt	O
and	O
fine	O
-	O
tune	O
the	O
CTRL	B-MethodName
for	O
aspect	O
-	O
controlled	O
neural	O
argument	O
generation	O
.	O
(	O
ii	O
)	O
We	O
show	O
that	O
detecting	O
argument	O
aspects	O
and	O
conditioning	O
the	O
generation	O
model	O
on	O
them	O
are	O
necessary	O
steps	O
to	O
control	O
the	O
model	O
's	O
training	O
process	O
and	O
its	O
perspective	O
while	O
generating	O
.	O
(	O
iii	O
)	O
We	O
propose	O
several	O
methods	O
to	O
analyze	O
and	O
evaluate	O
the	O
quality	O
of	O
(	O
controllable	O
)	O
argument	O
generation	O
models	O
.	O
(	O
iv	O
)	O
We	O
develop	O
a	O
new	O
scheme	O
to	O
annotate	O
argument	O
aspects	O
and	O
release	O
a	O
dataset	O
with	O
5,032	O
samples	O
.	O

Hypernym	O
Heuristic	O
This	O
heuristic	O
applies	O
when	O
the	O
premise	O
contains	O
clinical	O
condition(s	O
)	O
,	O
medication(s	O
)	O
,	O
finding(s	O
)	O
,	O
procedure(s	O
)	O
or	O
event(s	O
)	O
,	O
the	O
target	O
class	O
is	O
entailment	O
,	O
and	O
the	O
generated	O
hypothesis	O
contains	O
term(s	O
)	O
that	O
can	O
be	O
interpreted	O
as	O
super	O
-	O
types	O
for	O
a	O
subset	O
of	O
elements	O
in	O
the	O
premise	O
(	O
e.g.	O
,	O
clindamycin	O
<	O
:	O
antibiotic	O
)	O
.	O

2	O
Related	O
Work	O
2.1	O
QA	O
over	O
Text	O
and	O
KB	O
Over	O
time	O
,	O
the	O
QA	O
task	O
has	O
evolved	O
into	O
two	O
main	O
streams	O
:	O
1	O
)	O
QA	O
over	O
unstructured	O
data	O
(	O
e.g.	O
,	O
freetext	O
corpora	O
like	O
Wikipedia	O
)	O
;	O
2	O
)	O
QA	O
over	O
structured	O
data	O
(	O
e.g.	O
,	O
large	O
structured	O
KBs	O
like	O
DBpedia	O
(	O
Lehmann	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
Wikidata	O
(	O
Vrandecic	O
and	O
Krötzsch	O
,	O
2014	O
)	O
)	O
.	O
As	O
structured	O
and	O
unstructured	O
data	O
are	O
intuitively	O
complementary	O
information	O
sources	O
(	O
Oguz	O
et	O
al	O
.	O
,	O
2022	O
)	O
,	O
several	O
attempts	O
have	O
been	O
made	O
to	O
combines	O
the	O
best	O
of	O
both	O
worlds	O
.	O

Zero	O
-	O
shot	O
We	O
fine	O
-	O
tuned	O
the	O
BERT	B-MethodName
-	O
base	O
model	O
on	O
the	O
e	O
-	O
SNLI	O
c	O
training	O
set	O
with	O
the	O
binary	O
token	O
classification	O
cross	O
-	O
entropy	O
objective	O
(	O
See	O
Section	O
3.3	O
for	O
details	O
)	O
and	O
used	O
this	O
as	O
a	O
zero	O
-	O
shot	O
approach	O
for	O
financial	O
signal	O
highlighting	O
.	O

•	O
Define	O
a	O
binary	O
classifier	O
D	O
that	O
estimates	O
the	O
probability	O
of	O
a	O
data	O
point	O
being	O
positive	O
as	O

To	O
investigate	O
how	O
global	O
contextual	O
information	O
helps	O
our	O
model	O
to	O
improve	O
performance	O
,	O
we	O
manually	O
analyze	O
the	O
difference	O
between	O
the	O
predictions	O
of	O
the	O
local	O
,	O
natural	O
-	O
order	O
,	O
and	O
confidence	O
-	O
order	O
models	O
.	O
We	O
use	O
the	O
fine	O
-	O
tuned	O
model	O
using	O
the	O
CoNLL	B-MethodName
dataset	O
with	O
the	O
YAGO+KB	B-MethodName
candidates	O
.	O
Although	O
all	O
models	O
perform	O
well	O
on	O
most	O
mentions	O
,	O
the	O
local	O
model	O
often	O
fails	O
to	O
resolve	O
mentions	O
of	O
common	O
names	O
referring	O
to	O
specific	O
entities	O
(	O
e.g.	O
,	O
"	O
New	O
York	O
"	O
referring	O
to	O
New	O
York	O
Knicks	O
)	O
.	O
Global	O
models	O
are	O
generally	O
better	O
to	O
resolve	O
such	O
difficult	O
cases	O
because	O
of	O
the	O
presence	O
of	O
strong	O
global	O
contextual	O
information	O
(	O
e.g.	O
,	O
mentions	O
refer	O
-	O
ring	O
to	O
basketball	O
teams	O
)	O
.	O

Mostly	O
agree	O
:	O
Although	O
the	O
machine	O
explanation	O
refers	O
to	O
documents	O
that	O
are	O
not	O
explicitly	O
evident	O
,	O
the	O
human	O
explanation	O
assumes	O
a	O
less	O
likely	O
interpretation	O
of	O
"	O
delicious	O
"	O
.	O

Similarly	O
to	O
most	O
of	O
the	O
recent	O
*	O
ACL	O
conferences	O
,	O
we	O
implemented	O
the	O
author	O
response	O
period	O
:	O
a	O
week	O
during	O
which	O
the	O
authors	O
have	O
the	O
opportunity	O
to	O
read	O
the	O
reviews	O
and	O
send	O
their	O
response	O
.	O
The	O
goal	O
of	O
this	O
process	O
is	O
improving	O
the	O
quality	O
of	O
the	O
reviews	O
,	O
and	O
we	O
supplemented	O
that	O
goal	O
with	O
the	O
above	O
new	O
option	O
for	O
the	O
authors	O
to	O
flag	O
specific	O
types	O
of	O
review	O
issues	O
(	O
§	O
5.3	O
)	O
.	O
The	O
authors	O
could	O
(	O
but	O
did	O
n't	O
have	O
to	O
)	O
provide	O
a	O
response	O
and	O
flag	O
review	O
issues	O
;	O
this	O
was	O
done	O
for	O
88.3	O
%	O
of	O
reviewed	O
submissions	O
.	O
In	O
57.3	O
%	O
review	O
forms	O
the	O
reviewers	O
indicated	O
that	O
they	O
read	O
the	O
response	O
(	O
it	O
is	O
possible	O
that	O
more	O
did	O
read	O
the	O
response	O
but	O
did	O
not	O
fill	O
in	O
the	O
form	O
)	O
.	O

To	O
address	O
the	O
need	O
for	O
a	O
dataset	O
for	O
the	O
new	O
schema	O
translation	O
task	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
schema	O
translation	O
dataset	O
.	O
It	O
consists	O
of	O
3,158	O
tables	O
with	O
11,979	O
headers	O
written	O
in	O
six	O
different	O
languages	O
,	O
including	O
English	O
,	O
Chinese	O
,	O
French	O
,	O
German	O
,	O
Spanish	O
,	O
and	O
Japanese	O
.	O
In	O
this	O
section	O
,	O
we	O
will	O
first	O
introduce	O
our	O
construction	O
methodology	O
and	O
then	O
analyze	O
the	O
characteristics	O
of	O
our	O
dataset	O
.	O

The	O
hyper	O
-	O
parameters	O
used	O
in	O
the	O
fine	O
-	O
tuning	O
on	O
the	O
CoNLL	B-MethodName
dataset	O
are	O
detailed	O
in	O
Table	O
5	O
.	O
We	O
select	O
these	O
hyper	O
-	O
parameters	O
from	O
the	O
search	O
space	O
described	O
in	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
based	O
on	O
the	O
accuracy	O
on	O
the	O
development	O
set	O
of	O
the	O
CoNLL	B-MethodName
dataset	O
.	O

In	O
this	O
section	O
,	O
we	O
conduct	O
a	O
qualitative	O
analysis	O
on	O
the	O
effectiveness	O
of	O
CAST	B-MethodName
based	O
on	O
M2M-100	O
for	O
three	O
types	O
of	O
headers	O
:	O
headers	O
with	O
special	O
tokenization	O
,	O
abbreviation	O
headers	O
,	O
and	O
polysemy	O
headers	O
.	O
We	O
list	O
some	O
of	O
the	O
example	O
translations	O
in	O
Table	O
7	O
.	O

ViLT	B-MethodName
uses	O
a	O
single	O
encoder	O
that	O
takes	O
as	O
input	O
both	O
the	O
text	O
and	O
image	O
inputs	O
together	O
.	O
ViLT	B-MethodName
pre	O
-	O
training	O
also	O
uses	O
aligned	O
image	O
-	O
text	O
data	O
,	O
but	O
from	O
existing	O
benchmarks	O
(	O
Lin	O
et	O
al	O
.	O
,	O
2014	O
;	O
Krishna	O
et	O
al	O
.	O
,	O
2016	O
;	O
Ordonez	O
et	O
al	O
.	O
,	O
2011	O
;	O
Sharma	O
a	O
person	O
wearing	O
a	O
robe	O
a	O
person	O
wearing	O
a	O
robe	O
with	O
a	O
head	O
,	O
a	O
collar	O
,	O
and	O
a	O
body	O
Figure	O
6	O
:	O
Illustration	O
of	O
the	O
language	O
and	O
vision	O
modalities	O
under	O
the	O
different	O
experimental	O
conditions	O
.	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
It	O
is	O
pre	O
-	O
trained	O
using	O
multiple	O
selfsupervised	O
objectives	O
,	O
including	O
image	O
-	O
text	O
matching	O
via	O
a	O
binary	O
classification	O
head	O
,	O
which	O
is	O
suitable	O
for	O
our	O
task	O
out	O
of	O
the	O
box	O
.	O
We	O
implement	O
f	O
using	O
this	O
classification	O
head	O
.	O
Given	O
a	O
textx	O
and	O
an	O
image	O
I	O
∈	O
I	O
,	O
we	O
compute	O
their	O
similarity	O
using	O
the	O
matching	O
classification	O
head	O
.	O

The	O
evidence	O
of	O
this	O
argument	O
is	O
based	O
upon	O
the	O
two	O
underlined	O
aspects	O
.	O
While	O
these	O
aspects	O
encode	O
a	O
negative	O
stance	O
towards	O
the	O
topic	O
of	O
"	O
Nuclear	O
Energy	O
"	O
,	O
the	O
topic	O
itself	O
is	O
not	O
mentioned	O
explicitly	O
in	O
the	O
argument	O
.	O

Controllable	O
Text	O
Generation	O
aims	O
to	O
steer	O

We	O
apply	O
the	O
concept	O
of	O
controlled	O
neural	O
text	O
generation	O
to	O
the	O
domain	O
of	O
argument	O
generation	O
.	O
Our	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
is	O
conditioned	O
on	O
topics	O
,	O
stances	O
,	O
and	O
aspects	O
and	O
can	O
reliably	O
create	O
arguments	O
using	O
these	O
control	O
codes	O
.	O
We	O
show	O
that	O
arguments	O
generated	O
with	O
our	O
approach	O
are	O
genuine	O
and	O
of	O
high	O
argumentative	O
and	O
grammatical	O
quality	O
in	O
general	O
.	O
Moreover	O
,	O
we	O
show	O
that	O
our	O
approach	O
can	O
be	O
used	O
to	O
generate	O
counter	O
-	O
arguments	O
in	O
a	O
transparent	O
and	O
interpretable	O
way	O
.	O
We	O
fine	O
-	O
tune	O
the	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
on	O
two	O
different	O
data	O
sources	O
and	O
find	O
that	O
using	O
mixed	O
data	O
from	O
Common	O
-	O
Crawl	O
results	O
in	O
a	O
higher	O
quality	O
of	O
generated	O
arguments	O
than	O
using	O
user	O
discussions	O
from	O
Reddit	O
-	O
Comments	O
.	O
Further	O
,	O
we	O
define	O
argument	O
aspect	O
detection	O
for	O
controlled	O
argument	O
generation	O
and	O
introduce	O
a	O
novel	O
annotation	O
scheme	O
to	O
crowdsource	O
argument	O
aspect	O
annotations	O
,	O
resulting	O
in	O
a	O
high	O
-	O
quality	O
dataset	O
.	O
We	O
publish	O
the	O
model	O
weights	O
,	O
data	O
,	O
and	O
all	O
code	O
necessary	O
to	O
train	O
the	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
.	O

Accuracy	O
of	O
rationale	O
generation	O
.	O
To	O
evaluate	O
the	O
performance	O
of	O
the	O
generation	O
,	O
we	O
adopt	O
ROUGE	B-MethodName
and	O
BLEU	B-MethodName
as	O
the	O
metrics	O
.	O
ROUGE	B-MethodName
5	I-MethodName
is	O
a	O
commonly	O
used	O
metric	O
in	O
the	O
NLP	O
task	O
.	O
We	O
keep	O
the	O
results	O
of	O
ROUGE-1	B-MethodName
,	O
ROUGE-2	B-MethodName
,	O
and	O
ROUGE	B-MethodName
-	I-MethodName
L.	I-MethodName
BLEU	I-MethodName
6	I-MethodName
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
is	O
an	O
automatic	O
evaluation	O
for	O
text	O
generation	O
tasks	O
that	O
highly	O
correlates	O
with	O
human	O
evaluation	O
.	O
We	O
keep	O
the	O
result	O
of	O
BLEU-1	B-MethodName
and	O
BLEU	B-MethodName
-	I-MethodName
N	I-MethodName
(	O
an	O
average	O
of	O
BLEU-1	B-MethodName
,	O
BLEU2	B-MethodName
,	O
BLEU-3	B-MethodName
,	O
and	O
BLEU-4	B-MethodName
)	O
.	O

Entity	O
Extraction	O
Evaluation	O
on	O
the	O
Synthesis	O
Procedures	O
Dataset	O

-DOCSTART-	O
Pre	O
-	O
Training	O
Transformers	O
as	O
Energy	O
-	O
Based	O
Cloze	O
Models	O

to	O
significant	O
degeneration	O
of	O
the	O
generalization	O
performance	O
for	O
text	O
generation	O
tasks	O
(	O
Cheng	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Table	O
1	O
provides	O
a	O
typical	O
example	O
to	O
show	O
the	O
vulnerability	O
of	O
the	O
model	O
to	O
perturbations	O
.	O
We	O
can	O
see	O
that	O
the	O
words	O
"	O
aeroplane	O
"	O
and	O
"	O
injuries	O
"	O
in	O
the	O
original	O
text	O
are	O
revised	O
as	O
"	O
aeroplanes	O
"	O
and	O
"	O
accident	O
"	O
respectively	O
,	O
which	O
do	O
not	O
alter	O
the	O
meaning	O
of	O
the	O
input	O
.	O
However	O
,	O
the	O
output	O
generated	O
by	O
BART	B-MethodName
obviously	O
hallucinates	O
the	O
input	O
.	O

All	O
prompting	O
methods	O
are	O
trying	O
to	O
extract	O
knowledge	O
from	O
the	O
Large	O
Language	O
Models	O
(	O
LLMs	O
)	O
.	O

Special	O
tokens	O
When	O
computing	O
token	O
-	O
wise	O
contributions	O
,	O
we	O
do	O
not	O
take	O
[	O
SEP	O
]	O
and	O
[	O
CLS	O
]	O
tokens	O
into	O
account	O
(	O
i.e.	O
,	O
they	O
are	O
always	O
assigned	O
zero	O
contribution	O
)	O
,	O
since	O
their	O
functionality	O
is	O
to	O
aggregate	O
cross	O
-	O
modal	O
information	O
,	O
e.g.	O
for	O
classification	O
,	O
and	O
hence	O
they	O
can	O
not	O
be	O
attributed	O
to	O
one	O
modality	O
exclusively	O
.	O

The	O
cloze	O
task	O
(	O
Taylor	O
,	O
1953	O
)	O
of	O
predicting	O
the	O
identity	O
of	O
a	O
token	O
given	O
its	O
surrounding	O
context	O
has	O
proven	O
highly	O
effective	O
for	O
representation	O
learning	O
over	O
text	O
.	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
implements	O
the	O
cloze	O
task	O
by	O
replacing	O
input	O
tokens	O
with	O
[	O
MASK	O
]	O
,	O
but	O
this	O
approach	O
incurs	O
drawbacks	O
in	O
efficiency	O
(	O
only	O
15	O
%	O
of	O
tokens	O
are	O
masked	O
out	O
at	O
a	O
time	O
)	O
and	O
introduces	O
a	O
pre	O
-	O
train	O
/	O
fine	O
-	O
tune	O
mismatch	O
where	O
BERT	B-MethodName
sees	O
[	O
MASK	O
]	O
tokens	O
in	O
training	O
but	O
not	O
in	O
fine	O
-	O
tuning	O
.	O
ELECTRA	B-MethodName
(	O
Clark	O
et	O
al	O
.	O
,	O
2020	O
)	O
uses	O
a	O
different	O
pre	O
-	O
training	O
task	O
that	O
alleviates	O
these	O
disadvantages	O
.	O
Instead	O
of	O
masking	O
tokens	O
,	O
ELECTRA	B-MethodName
replaces	O
some	O
input	O
tokens	O
with	O
fakes	O
sampled	O
from	O
a	O
small	O
generator	O
network	O
.	O
The	O
pre	O
-	O
training	O
task	O
is	O
then	O
to	O
distinguish	O
the	O
original	O
vs.	O
replaced	O
tokens	O
.	O
While	O
on	O
the	O
surface	O
it	O
appears	O
quite	O
different	O
from	O
BERT	B-MethodName
,	O
in	O
this	O
paper	O
we	O
elucidate	O
a	O
close	O
connection	O
between	O
ELECTRA	O
and	O
cloze	O
modeling	O
.	O
In	O
particular	O
,	O
we	O
develop	O
a	O
new	O
way	O
of	O
implementing	O
the	O
cloze	O
task	O
using	O
an	O
energy	O
-	O
based	O
model	O
(	O
EBM	O
)	O
.	O
Then	O
we	O
show	O
the	O
resulting	O
model	O
,	O
which	O
we	O
call	O
Electric	O
,	O
is	O
closely	O
related	O
to	O
ELECTRA	B-MethodName
,	O
as	O
well	O
as	O
being	O
useful	O
in	O
its	O
own	O
right	O
for	O
some	O
applications	O
.	O
1	O
EBMs	O
learn	O
an	O
energy	O
function	O
that	O
assigns	O
low	O
energy	O
values	O
to	O
inputs	O
in	O
the	O
data	O
distribution	O
and	O
high	O
energy	O
values	O
to	O
other	O
inputs	O
.	O
They	O
are	O
flexible	O
because	O
they	O
do	O
not	O
have	O
to	O
compute	O
normalized	O
probabilities	O
.	O
For	O
example	O
,	O
Electric	O
does	O
not	O
use	O
masking	O
or	O
an	O
output	O
softmax	O
,	O
instead	O
producing	O
a	O
scalar	O
energy	O
score	O
for	O
each	O
token	O
where	O
a	O
low	O
energy	O
indicates	O
the	O
token	O
is	O
likely	O
given	O
its	O
context	O
.	O
Unlike	O
with	O
BERT	B-MethodName
,	O
these	O
likelihood	O
scores	O
can	O
be	O
computed	O
simultaneously	O
for	O
all	O
input	O
tokens	O
rather	O
than	O
only	O
for	O
a	O
small	O
masked	O
-	O
out	O
subset	O
.	O
We	O
propose	O
a	O
training	O
algorithm	O
for	O
Electric	O
that	O
efficiently	O
approximates	O
a	O
loss	O
based	O
on	O
noise	O
-	O
contrastive	O
estimation	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010	O
)	O
.	O
Then	O
we	O
show	O
that	O
this	O
training	O
algorithm	O
is	O
closely	O
related	O
to	O
ELECTRA	O
;	O
in	O
fact	O
,	O
ELECTRA	O
can	O
be	O
viewed	O
as	O
a	O
variant	O
of	O
Electric	O
using	O
negative	O
sampling	O
instead	O
of	O
noise	O
-	O
contrastive	O
estimation	O
.	O

Reference	O
Summary	O
:	O
The	O
Royal	B-MethodName
Mail	I-MethodName
has	O
painted	O
a	O
postbox	O
gold	O
in	O
the	O
Oxford	O
-	O
shire	O
town	O
of	O
Henley	O
-	O
on	O
-	O
Thames	O
-in	O
recognition	O
of	O
its	O
medal	O
winning	O
rowing	O
club	O
.	O

Local	O
-	O
global	O
-	O
combined	O
approaches	O
(	O
or	O
hybrid	O
approaches	O
)	O
can	O
be	O
seen	O
as	O
an	O
improvement	O
on	O
local	O
ones	O
.	O
The	O
method	O
HMCN	B-MethodName
(	O
Hierarchical	O
Multilabel	O
Classification	I-MethodName
Networks	I-MethodName
)	O
(	O
Wehrmann	O
et	O
al	O
.	O
,	O
2018	O
)	O
is	O
probably	O
the	O
first	O
hybrid	O
model	O
.	O
In	O
HMCN	B-MethodName
,	O
local	O
classifiers	O
are	O
arranged	O
in	O
series	O
and	O
global	O
classification	O
is	O
conducted	O
to	O
coordinate	O
these	O
local	O
classifiers	O
.	O
The	O
method	O
HARNN	B-MethodName
(	O
Hierarchical	O
Attention	O
-	O
based	O
Recurrent	O
Neural	O
Network	I-MethodName
)	O
(	O
Huang	O
et	O
al	O
.	O
,	O
2019	O
)	O
is	O
another	O
typical	O
hybrid	O
model	O
.	O
It	O
shares	O
a	O
similar	O
architecture	O
with	O
HMCN	B-MethodName
,	O
but	O
uses	O
the	O
multi	O
-	O
label	O
attention	O
mechanism	O
to	O
extract	O
label	O
-	O
wise	O
text	O
features	O
.	O
However	O
,	O
since	O
errors	O
in	O
the	O
prediction	O
of	O
higher	O
-	O
level	O
categories	O
may	O
provide	O
misleading	O
information	O
for	O
lower	O
levels	O
,	O
these	O
hybrid	O
approaches	O
might	O
suffer	O
from	O
error	O
propagation	O
(	O
Rojas	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

With	O
the	O
aim	O
of	O
fostering	O
research	O
on	O
challenging	O
information	O
extraction	O
tasks	O
in	O
the	O
scientific	O
domain	O
,	O
we	O
target	O
the	O
domain	O
of	O
SOFC	O
-	O
related	O
experiments	O
as	O
a	O
starting	O
point	O
.	O
Our	O
findings	O
based	O
on	O
this	O
sample	O
use	O
case	O
are	O
transferable	O
to	O
similar	O
experimental	O
domains	O
,	O
which	O
we	O
illustrate	O
by	O
applying	O
our	O
best	O
model	O
configurations	O
to	O
a	O
previously	O
existing	O
related	O
corpus	O
(	O
Mysore	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O

For	O
IMDb	B-MethodName
dataset	O
and	O
AGNews	B-MethodName
dataset	O
,	O
we	O
leave	O
10	O
%	O
of	O
the	O
training	O
set	O
as	O
validation	O
data	O
,	O
and	O
others	O
as	O
training	O
data	O
.	O
For	O
the	O
AGNews	B-MethodName
dataset	O
,	O
we	O
use	O
the	O
description	O
for	O
text	O
generation	O
and	O
wrote	O
a	O
script	O
to	O
resolve	O
HTML	O
tags	O
.	O
For	O
Jigsaw	O
dataset	O
,	O
we	O
apply	O
a	O
binary	O
setting	O
where	O
we	O
keep	O
the	O
"	O
nontoxic	O
"	O
class	O
unchanged	O
and	O
group	O
all	O
other	O
classes	O
into	O
"	O
toxic	O
"	O
class	O
.	O

In	O
Section	O
3.2	O
,	O
we	O
propose	O
the	O
following	O
embedding	O
learning	O
objective	O
:	O
J	O
=	O
d∈D	O
w	O
i	O
∈d	O
w	O
j	O
∈C	O
(	O
w	O
i	O
,	O
h	O
)	O
exp	O
(	O
u	O
T	O
w	O
i	O
vw	O
j	O
)	O

•	O
Experiments	O
on	O
our	O
proposed	O
dataset	O
demonstrate	O
that	O
our	O
approach	O
significantly	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
in	O
schema	O
translation	O
.	O

|x|	O
)	O
is	O
the	O
entire	O
sequence	O
tokens	O
corresponding	O
to	O
student	O
s	O
j	O
,	O
consisting	O
of	O
all	O
their	O
past	O
questions	O
and	O
answers	O
.	O
Using	O
the	O
softmax	O
output	O
of	O
the	O
LM	O
-	I-MethodName
KT	I-MethodName
model	O
(	O
p	O
θ	O
KT	O
)	O
,	O
we	O
estimate	O
a	O
student	O
's	O
(	O
inverse	O
)	O
difficulty	O
in	O
answering	O
a	O
specific	O
question	O
as	O
d	O
qs	O
=	O
p	O
θ	O
KT	O
(	O
<	O
Y>|s	O
,	O
q	O
)	O
.	O
We	O
find	O
that	O
p	O
θ	O
KT	O
is	O
well	O
-	O
calibrated	O
(	O
Section	O
4.2	O
)	O
,	O
yielding	O
a	O
good	O
proxy	O
for	O
the	O
true	O
question	O
difficulty	O
.	O

As	O
mentioned	O
in	O
the	O
results	O
section	O
of	O
the	O
main	O
paper	O
,	O
we	O
vary	O
the	O
latency	O
weight	O
hyperparameter	O
(	O
λ	O
)	O
to	O
train	O
different	O
models	O
to	O
obtain	O
different	O
latency	O
regimes	O
.	O
We	O
also	O
vary	O
the	O
step	O
-	O
size	O
/	O
speech	O
segment	O
size	O
during	O
inference	O
.	O
In	O
total	O
,	O
we	O
obtain	O
18	O
different	O
data	O
points	O
corresponding	O
to	O
each	O
model	O
.	O
In	O
Table	O
3	O
,	O
we	O
compare	O
the	O
results	O
obtained	O
using	O
MMA	B-MethodName
,	O
MMA	B-MethodName
-	I-MethodName
XLM	I-MethodName
and	O
MMA	B-MethodName
-	I-MethodName
SLM	I-MethodName
under	O
similar	O
hyperparameter	O
settings	O
.	O
It	O
will	O
help	O
the	O
reader	O
to	O
quantify	O
the	O
benefits	O
obtained	O
from	O
our	O
proposed	O
approach	O
.	O

Results	O
Table	O
4	O
shows	O
accuracy	O
for	O
15	O
languages	O
.	O
We	O
observe	O
that	O
the	O
differences	O
between	O
variants	O
are	O
relatively	O
small	O
compared	O
with	O
retrieval	O
and	O
mining	O
tasks	O
.	O
We	O
think	O
this	O
is	O
because	O
judging	O
the	O
relationship	O
between	O
two	O
sentences	O
does	O
not	O
rely	O
on	O
cosine	O
similarity	O
,	O
so	O
the	O
pre	O
-	O
training	O
can	O
not	O
be	O
directly	O
transferred	O
to	O
the	O
downstream	O
task	O
.	O
mBERT	B-MethodName
variants	O
all	O
show	O
positive	O
results	O
and	O
DAP	B-MethodName
has	O
the	O
largest	O
improvement	O
.	O
But	O
for	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
variants	O
,	O
only	O
DAP	B-MethodName
maintains	O
the	O
performance	O
as	O
the	O
base	O
model	O
.	O
The	O
TR	B-MethodName
and	O
TLM	B-MethodName
variants	O
suffer	O
from	O
performance	O
degradation	O
.	O
We	O
think	O
this	O
is	O
because	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
has	O
already	O
been	O
a	O
well	O
-	O
trained	O
multilingual	O
model	O
and	O
our	O
continued	O
pre	O
-	O
training	O
is	O
insufficient	O
to	O
improve	O
the	O
classification	O
capacity	O
.	O
However	O
,	O
we	O
demonstrate	O
DAP	B-MethodName
will	O
not	O
harm	O
classification	O
performance	O
for	O
a	O
well	O
-	O
trained	O
base	O
model	O
.	O

To	O
identify	O
directions	O
for	O
future	O
research	O
in	O
hyperrelational	O
extraction	O
,	O
we	O
analyze	O
the	O
model	O
performance	O
separately	O
for	O
each	O
general	O
qualifier	O
category	O
.	O
As	O
shown	O
in	O
Table	O
4	O
,	O
there	O
is	O
a	O
variance	O
in	O
model	O
performance	O
across	O
qualifier	O
categories	O
that	O
can	O
not	O
be	O
fully	O
explained	O
by	O
their	O
proportion	O
in	O
the	O
dataset	O
.	O
For	O
instance	O
,	O
although	O
the	O
"	O
Time	O
"	O
category	O
comprises	O
a	O
majority	O
of	O
the	O
qualifiers	O
,	O
it	O
does	O
not	O
have	O
the	O
highest	O
performance	O
.	O
This	O
suggests	O
that	O
future	O
research	O
may	O
focus	O
on	O
areas	O
such	O
as	O
temporal	O
reasoning	O
,	O
which	O
is	O
an	O
open	O
challenge	O
for	O
language	O
models	O
(	O
Vashishtha	O
et	O
al	O
.	O
,	O
2020	O
;	O
Dhingra	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
In	O
addition	O
,	O
CubeRE	B-MethodName
demonstrates	O
strong	O
performance	O
across	O
all	O
categories	O
which	O
suggests	O
that	O
it	O
can	O
serve	O
as	O
a	O
general	O
extraction	O
model	O
for	O
different	O
qualifiers	O
.	O

To	O
achieve	O
this	O
,	O
we	O
propose	O
a	O
simple	O
but	O
effective	O
method	O
,	O
named	O
dynamic	O
k	O
strategy	O
,	O
to	O
roughly	O
estimate	O
how	O
many	O
proposals	O
need	O
to	O
be	O
assigned	O
for	O
each	O
golden	O
tuple	O
.	O
Specifically	O
,	O
given	O
a	O
sentence	O
containing	O
M	O
golden	O
tuples	O
,	O
for	O
the	O
m	O
-	O
th	O
golden	O
tuple	O
,	O
instead	O
of	O
using	O
fixed	O
k	O
,	O
we	O
calculate	O
the	O
top	O
q	O
m	O
proposals	O
according	O
to	O
IoU	O
values	O
.	O
The	O
top	O
q	O
m	O
number	O
could	O
be	O
obtained	O
by	O
summing	O
up	O
the	O
corresponding	O
proposals	O
'	O
IoU	O
values	O
from	O
the	O
IoU	O
matrix	O
:	O

To	O
perform	O
the	O
analysis	O
presented	O
in	O
Section	O
4	O
,	O
we	O
cast	O
each	O
hypothesis	O
string	O
in	O
the	O
MedNLI	O
training	O
dataset	O
to	O
lowercase	O
.	O
We	O
then	O
use	O
a	O
scispaCy	O
model	O
pre	O
-	O
trained	O
on	O
the	O
en_core_sci_lg	O
corpus	O
for	O
tokenization	O
and	O
clinical	O
named	O
entity	O
recognition	O
(	O
CNER	O
)	O
(	O
Neumann	O
et	O
al	O
.	O
,	O
2019a	O
)	O
.	O
Next	O
,	O
we	O
merge	O
multi	O
-	O
token	O
entities	O
,	O
using	O
underscores	O
as	O
delimiters	O
-	O
e.g.	O
,	O
"	O
brain	O
injury	O
"	O
→	O
"	O
brain_injury	O
"	O
.	O

Augmenting	O
SANs	O
with	O
position	O
representation	O
SANs	O
ignore	O
the	O
position	O
of	O
each	O
token	O
due	O
to	O
its	O
position	O
-	O
unaware	O
"	O
bag	O
-	O
of	O
-	O
words	O
"	O
assumption	O
.	O
The	O
most	O
straightforward	O
strategy	O
is	O
adding	O
the	O
position	O
representations	O
as	O
part	O
of	O
the	O
token	O
representations	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017;Shaw	O
et	O
al	O
.	O
,	O
2018	O
lingual	O
position	O
information	O
between	O
languages	O
.	O

Typically	O
the	O
context	O
is	O
represented	O
as	O
the	O
input	O
sequence	O
with	O
x	O
t	O
replaced	O
by	O
a	O
special	O
[	O
MASK]placeholder	O
token	O
.	O
This	O
masked	O
sequence	O
is	O
encoded	O
into	O
vector	O
representations	O
by	O
a	O
transformer	O
network	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Then	O
the	O
representation	O
at	O
position	O
t	O
is	O
passed	O
into	O
a	O
softmax	O
layer	O
to	O
produce	O
a	O
distribution	O
over	O
tokens	O
p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
for	O
the	O
position	O
.	O

Information	O
extraction	O
for	O
scientific	O
publications	O
.	O
Recently	O
,	O
several	O
studies	O
addressed	O
information	O
extraction	O
and	O
knowledge	O
base	O
construction	O
in	O
the	O
scientific	O
domain	O
(	O
Augenstein	O
et	O
al	O
.	O
,	O
2017;Luan	O
et	O
al	O
.	O
,	O
2018;Jiang	O
et	O
al	O
.	O
,	O
2019;Buscaldi	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
We	O
also	O
aim	O
at	O
knowledge	O
base	O
construction	O
but	O
target	O
publications	O
about	O
materials	O
science	O
experiments	O
,	O
a	O
domain	O
understudied	O
in	O
NLP	O
to	O
date	O
.	O
Information	O
extraction	O
for	O
materials	O
science	O
.	O
The	O
work	O
closest	O
to	O
ours	O
is	O
the	O
one	O
of	O
Mysore	O
et	O
al	O
.	O
(	O
2019	O
)	O
also	O
retrieve	O
synthesis	O
procedures	O
and	O
extract	O
recipes	O
,	O
though	O
with	O
a	O
coarser	O
-	O
grained	O
label	O
set	O
,	O
focusing	O
on	O
different	O
synthesis	O
operation	O
types	O
.	O
create	O
a	O
dataset	O
for	O
named	O
entity	O
recognition	O
on	O
abstracts	O
of	O
materials	O
science	O
publications	O
.	O
In	O
contrast	O
to	O
our	O
work	O
,	O
their	O
label	O
set	O
(	O
e.g.	O
,	O
Material	O
,	O
Application	O
,	O
Property	O
)	O
is	O
targeted	O
to	O
document	O
indexing	O
rather	O
than	O
information	O
extraction	O
.	O
A	O
notable	O
difference	O
to	O
our	O
work	O
is	O
that	O
we	O
perform	O
full	O
-	O
text	O
annotation	O
while	O
the	O
aforementioned	O
approaches	O
annotate	O
a	O
pre	O
-	O
selected	O
set	O
of	O
paragraphs	O
(	O
see	O
also	O
.	O
Mysore	O
et	O
al	O
.	O
(	O
2017	O
)	O
apply	O
the	O
generative	O
model	O
of	O
Kiddon	O
et	O
al	O
.	O
(	O
2015	O
)	O
to	O
induce	O
action	O
graphs	O
for	O
synthesis	O
procedures	O
of	O
materials	O
from	O
text	O
.	O
In	O
Section	O
7.1	O
,	O
we	O
implement	O
a	O
similar	O
entity	O
extraction	O
system	O
and	O
also	O
apply	O
our	O
algorithms	O
to	O
the	O
dataset	O
of	O
Mysore	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
train	O
word2vec	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
embeddings	O
on	O
materials	O
science	O
publications	O
and	O
show	O
that	O
they	O
can	O
be	O
used	O
for	O
recommending	O
materials	O
for	O
functional	O
applications	O
.	O
Other	O
works	O
adapt	O
the	O
BERT	B-MethodName
model	O
to	O
clinical	O
and	O
biomedical	O
domains	O
(	O
Alsentzer	O
et	O
al	O
.	O
,	O
2019;Sun	O
and	O
Yang	O
,	O
2019	O
)	O
,	O
or	O
generally	O
to	O
scientific	O
text	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O

Our	O
architecture	O
adds	O
a	O
new	O
token	O
to	O
the	O
XLM	O
-	I-MethodName
R	I-MethodName
tokeniser	O
called	O
<	O
GAP	O
>	O
which	O
is	O
inserted	O
between	O
the	O
words	O
in	O
the	O
target	O
.	O
We	O
then	O
concatenate	O
the	O
source	O
and	O
the	O
target	O
with	O
a	O
[	O
SEP	O
]	O
token	O
and	O
we	O
feed	O
them	O
into	O
XLM	O
-	I-MethodName
R.	I-MethodName
A	O
simple	O
linear	O
layer	O
is	O
added	O
on	O
top	O
of	O
word	O
and	O
<	O
GAP	O
>	O
embeddings	O
to	O
predict	O
whether	O
it	O
is	O
"	O
Good	O
"	O
or	O
"	O
Bad	O
"	O
as	O
shown	O
in	O
Figure	O
1	O
.	O
The	O
training	O
configurations	O
and	O
the	O
system	O
specifications	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O
We	O
used	O
several	O
language	O
pairs	O
for	O
which	O
word	O
-	O
level	O
QE	O
annotations	O
were	O
available	O
:	O
English	O
-	O
Chinese	O
(	O
En	O
-	O
Zh	O
)	O
,	O
English	O
-	O
Czech	O
(	O
En	O
-	O
Cs	O
)	O
,	O
English	O
-	O
German	O
(	O
En	O
-	O
De	O
)	O
,	O
English	O
-	O
Russian	O
(	O
En	O
-	O
Ru	O
)	O
,	O
English	O
-	O
Latvian	O
(	O
En	O
-	O
Lv	O
)	O
and	O
German	O
-	O
English	O
(	O
De	O
-	O
En	O
)	O
.	O
The	O
texts	O
are	O
from	O
a	O
variety	O
of	O
domains	O
and	O
the	O
translations	O
were	O
produced	O
using	O
both	O
neural	O
and	O
statistical	O
machine	O
translation	O
systems	O
.	O
More	O
details	O
about	O
these	O
datasets	O
can	O
be	O
found	O
in	O
Table	O
1	O
and	O
in	O
Fonseca	O
et	O
al	O
.	O
,	O
2019	O
;	O
.	O

Inputting	O
-	O
level	O
XL	O
SANs	O
As	O
illustrated	O
in	O
Fig	O
.	O
2a	O
,	O
we	O
employ	O
a	O
non	O
-	O
linear	O
function	O
TANH(•	O
)	O
to	O
fuse	O
PE	O
abs	O
and	O
PE	O
XL	O
:	O

This	O
requires	O
handling	O
non	O
-	O
stationary	O
data	O
distribution	O
which	O
humans	O
are	O
quite	O
adept	O
at	O
,	O
partly	O
because	O
we	O
can	O
decompose	O
a	O
complex	O
task	O
in	O
a	O
modular	O
fashion	O
(	O
Berwick	O
et	O
al	O
.	O
,	O
2013	O
)	O
.	O
For	O
example	O
,	O
when	O
learning	O
to	O
classify	O
objects	O
,	O
we	O
acquire	O
modular	O
knowledge	O
exclusive	O
to	O
each	O
class	O
.	O
This	O
allows	O
us	O
to	O
robustly	O
classify	O
irrespective	O
of	O
any	O
label	O
space	O
manipulations	O
such	O
as	O
label	O
omission	O
or	O
learning	O
over	O
new	O
label	O
spaces	O
.	O
This	O
notion	O
of	O
modularity	O
at	O
the	O
level	O
of	O
each	O
class	O
label	O
is	O
what	O
we	O
call	O
label	O
modularity	O
and	O
is	O
a	O
desirable	O
quality	O
for	O
NLP	O
models	O
to	O
generalize	O
to	O
practical	O
non	O
-	O
stationary	O
classification	O
settings	O
.	O

In	O
general	O
,	O
the	O
principle	O
of	O
FIND	B-MethodName
is	O
understanding	O
the	O
features	O
and	O
then	O
disabling	O
the	O
irrelevant	O
ones	O
.	O
The	O
process	O
makes	O
visualizations	O
and	O
interpretability	O
more	O
actionable	O
.	O
Over	O
the	O
past	O
few	O
years	O
,	O
we	O
have	O
seen	O
rapid	O
growth	O
of	O
scientific	O
research	O
in	O
both	O
topics	O
(	O
visualizations	O
and	O
interpretability	O
)	O
aiming	O
to	O
understand	O
many	O
emerging	O
advanced	O
models	O
including	O
the	O
popular	O
transformer	O
-	O
based	O
models	O
(	O
Jo	O
and	O
Myaeng	O
,	O
2020;Voita	O
et	O
al	O
.	O
,	O
2019;Hoover	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
believe	O
that	O
our	O
work	O
will	O
inspire	O
other	O
researchers	O
to	O
foster	O
advances	O
in	O
both	O
topics	O
towards	O
the	O
more	O
tangible	O
goal	O
of	O
model	O
debugging	O
.	O

B2	O
.	O
Did	O
you	O
discuss	O
the	O
license	O
or	O
terms	O
for	O
use	O
and	O
/	O
or	O
distribution	O
of	O
any	O
artifacts	O
?	O

In	O
schema	O
translation	O
,	O
both	O
the	O
meaning	O
of	O
the	O
headers	O
and	O
the	O
structural	O
information	O
like	O
order	O
and	O
numbers	O
must	O
be	O
completely	O
transferred	O
to	O
the	O
target	O
language	O
.	O
Obviously	O
,	O
this	O
requirement	O
can	O
not	O
be	O
met	O
by	O
translating	O
schema	O
as	O
a	O
whole	O
with	O
the	O
traditional	O
sequence	O
-	O
to	O
-	O
sequence	O
NMT	B-MethodName
models	O
because	O
it	O
can	O
not	O
achieve	O
precisely	O
token	O
level	O
alignment	O
.	O
For	O
example	O
,	O
when	O
concatenating	O
all	O
headers	O
with	O
a	O
separator	O
"	O
|	O
"	O
,	O
the	O
separator	O
can	O
be	O
easily	O
lost	O
during	O
translation	O
.	O
To	O
meet	O
this	O
requirement	O
,	O
we	O
employ	O
a	O
header	O
-	O
to	O
-	O
header	O
translation	O
manner	O
in	O
this	O
work	O
,	O
which	O
translates	O
one	O
header	O
at	O
a	O
time	O
.	O

In	O
our	O
example	O
,	O
the	O
missing	O
article	O
"	O
the	O
"	O
is	O
considered	O
as	O
an	O
implicit	O
error	O
because	O
it	O
is	O
a	O
smaller	O
imperfection	O
in	O
grammar	O
.	O

The	O
rationale	O
generation	O
module	O
aims	O
to	O
generate	O
the	O
charge	O
rationale	O
and	O
penalty	O
rationale	O
according	O
to	O
the	O
fact	O
description	O
.	O

Table	O
1	O
shows	O
the	O
results	O
of	O
our	O
approach	O
compared	O
to	O
two	O
pretraining	O
approaches	O
that	O
rely	O
on	O
In	O
the	O
case	O
of	O
XLM	B-MethodName
,	O
the	O
effect	O
of	O
cross	O
-	O
lingual	O
lexical	O
alignment	O
is	O
more	O
evident	O
for	O
En	O
-	O
Mk	O
,	O
as	O
Mk	O
is	O
less	O
similar	O
to	O
En	O
,	O
compared	O
to	O
Sq	O
.	O
This	O
is	O
mainly	O
the	O
case	O
because	O
the	O
two	O
languages	O
use	O
a	O
different	O
alphabet	O
(	O
Latin	O
for	O
En	O
and	O
Cyrillic	O
for	O
Mk	O
)	O
.	O
This	O
is	O
also	O
true	O
for	O
RE	B-MethodName
-	I-MethodName
LM	O
when	O
translating	O
out	O
of	O
En	O
,	O
showing	O
that	O
enhancing	O
the	O
fine	O
-	O
tuning	O
step	O
of	O
MLM	B-MethodName
with	O
pretrained	O
embeddings	O
is	O
helpful	O
and	O
improves	O
the	O
final	O
UNMT	B-MethodName
performance	O
.	O

An	O
advantage	O
of	O
Electric	O
over	O
BERT	B-MethodName
is	O
that	O
it	O
can	O
efficiently	O
produce	O
pseudo	O
-	O
log	O
-	O
likelihood	O
(	O
PLL	O
)	O
scores	O
for	O
text	O
(	O
Wang	O
and	O
Cho	O
,	O
2019	O
)	O
.	O
PLLs	O
for	O
Electric	O
are	O

We	O
have	O
developed	O
an	O
energy	O
-	O
based	O
cloze	O
model	O
we	O
call	O
Electric	O
and	O
designed	O
an	O
efficient	O
training	O
algorithm	O
for	O
Electric	O
based	O
on	O
noise	O
-	O
contrastive	O
estimation	O
.	O
Although	O
Electric	O
can	O
be	O
derived	O
solely	O
from	O
the	O
cloze	O
task	O
,	O
the	O
resulting	O
pre	O
-	O
training	O
method	O
is	O
closely	O
related	O
to	O
ELECTRA	B-MethodName
's	O
GANlike	O
pre	O
-	O
training	O
algorithm	O
.	O
While	O
slightly	O
underperforming	O
ELECTRA	B-MethodName
on	O
downstream	O
tasks	O
,	O
Electric	O
is	O
useful	O
for	O
its	O
ability	O
to	O
quickly	O
produce	O
pseudo	O
-	O
log	O
-	O
likelihood	O
scores	O
for	O
text	O
.	O
Furthermore	O
,	O
it	O
offers	O
a	O
clearer	O
and	O
more	O
principled	O
view	O
of	O
the	O
ELECTRA	B-MethodName
objective	O
as	O
a	O
"	O
negative	O
sampling	O
"	O
version	O
of	O
cloze	O
pre	O
-	O
training	O
.	O

To	O
achieve	O
this	O
goal	O
,	O
an	O
unsupervised	O
Prefix	O
-	O
Tuning	O
based	O
OOD	O
detection	O
framework	O
(	O
PTO	O
)	O
is	O
proposed	O
in	O
this	O
paper	O
.	O
The	O
key	O
idea	O
of	O
PTO	O
is	O
intuitive	O
:	O
an	O
in	O
-	O
distribution	O
specific	O
prefix	O
,	O
optimized	O
with	O
the	O
training	O
data	O
via	O
maximum	O
likelihood	O
,	O
could	O
steer	O
PLMs	O
to	O
assign	O
higher	O
likelihoods	O
to	O
ID	O
samples	O
than	O
PLMs	O
without	O
the	O
prefix	O
,	O
while	O
OOD	O
samples	O
should	O
be	O
assigned	O
lower	O
likelihood	O
.	O
Thus	O
we	O
propose	O
to	O
use	O
the	O
likelihood	O
change	O
triggered	O
by	O
the	O
prefix	O
to	O
detect	O
OODsamples	O
whose	O
improvement	O
is	O
not	O
obvious	O
(	O
e.g.	O
,	O
less	O
than	O
a	O
predefined	O
threshold	O
)	O
.	O
Note	O
that	O
the	O
training	O
process	O
of	O
PTO	O
does	O
not	O
involve	O
the	O
sample	O
labels	O
,	O
expanding	O
its	O
application	O
to	O
situations	O
where	O
obtaining	O
labeled	O
data	O
is	O
cost	O
-	O
prohibitive	O
.	O

An	O
additional	O
benefit	O
of	O
being	O
able	O
to	O
link	O
to	O
multiple	O
KBs	O
is	O
the	O
ability	O
to	O
train	O
on	O
more	O
than	O
one	O
dataset	O
,	O
each	O
of	O
which	O
links	O
to	O
a	O
different	O
KB	O
with	O
different	O
schemas	O
.	O
While	O
prior	O
work	O
has	O
been	O
unable	O
to	O
do	O
so	O
due	O
to	O
its	O
reliance	O
on	O
knowledge	O
of	O
KB	O
test	O
,	O
this	O
ability	O
is	O
more	O
crucial	O
in	O
the	O
settings	O
we	O
investigate	O
,	O
as	O
it	O
allows	O
us	O
to	O
stack	O
independent	O
datasets	O
for	O
training	O
.	O
This	O
allows	O
us	O
to	O
answer	O
our	O
third	O
research	O
question	O
.	O
Specifically	O
,	O
we	O
compare	O
the	O
[	O
SEP]-separation	O
baseline	O
with	O
our	O
full	O
model	O
that	O
uses	O
attribute	O
-	O
separators	O
,	O
attributeshuffle	O
,	O
and	O
attribute	O
-	O
OOV	O
.	O
We	O
ask	O
whether	O
the	O
%	O
of	O
TAC	O
4	O
)	O
.	O
In	O
contrast	O
,	O
the	O
baseline	O
model	O
observes	O
a	O
bigger	O
increase	O
in	O
accuracy	O
from	O
49.1	O
%	O
to	O
62.6	O
%	O
.	O
While	O
the	O
difference	O
between	O
the	O
two	O
models	O
reduces	O
,	O
the	O
full	O
model	O
remains	O
more	O
accurate	O
.	O
These	O
results	O
also	O
show	O
that	O
the	O
seamless	O
stacking	O
of	O
multiple	O
datasets	O
allowed	O
by	O
our	O
models	O
is	O
effective	O
empirically	O
.	O

For	O
GLUE	B-MethodName
,	O
Amazon	O
,	O
and	O
IMDB	O
text	O
classification	O
tasks	O
,	O
only	O
the	O
[	O
CLS	O
]	O
token	O
is	O
used	O
for	O
prediction	O
.	O
When	O
we	O
finetune	O
or	O
predict	O
with	O
ContextFirst	B-MethodName
on	O
a	O
GLUE	B-MethodName
/	O
Amazon	O
/	O
IMDB	O
task	O
,	O
the	O
feedforward	O
layers	O
only	O
need	O
to	O
operate	O
on	O
the	O
[	O
CLS	O
]	O
token	O
.	O
When	O
we	O
finetune	O
or	O
predict	O
with	O
SparseQueries	B-MethodName
,	O
only	O
the	O
[	O
CLS	O
]	O
token	O
is	O
used	O
in	O
the	O
queries	O
of	O
the	O

We	O
normalize	O
the	O
length	O
value	O
to	O
obtain	O
the	O
length	O
coefficient	O
for	O
each	O
category	O
:	O

2	O
.	O
TFWSVD	B-MethodName
versus	O
FWSVD	B-MethodName
:	O
Compared	O
to	O
FWSVD	B-MethodName
,	O
TFWSVD	B-MethodName
needs	O
extra	O
time	O
for	O
fac-	O
torizing	O
the	O
weighted	O
matrices	O
through	O
optimizations	O
.	O
The	O
time	O
cost	O
of	O
factorization	O
is	O
decided	O
by	O
the	O
number	O
of	O
parameters	O
in	O
a	O
model	O
,	O
and	O
is	O
fixed	O
for	O
all	O
its	O
downstream	O
tasks	O
.	O
For	O
GLUE	O
tasks	O
trained	O
with	O
the	O
BERT	B-MethodName
model	O
,	O
TFWSVD	B-MethodName
will	O
cost	O
1.5	O
more	O
V100	O
GPU	O
hours	O
than	O
FWSVD	B-MethodName
.	O

As	O
shown	O
in	O
Figure	O
9	O
,	O
we	O
used	O
a	O
slightly	O
different	O
user	O
interface	O
in	O
Experiment	O
1	O
for	O
the	O
Amazon	O
Products	O
dataset	O
which	O
is	O
a	O
multiclass	O
classification	O
task	O
.	O
In	O
this	O
setting	O
,	O
we	O
did	O
not	O
provide	O
the	O
options	O
for	O
mostly	O
and	O
partly	O
relevant	O
;	O
otherwise	O
,	O
there	O
would	O
have	O
been	O
nine	O
options	O
per	O
question	O
which	O
are	O
too	O
many	O
for	O
the	O
participants	O
to	O
answer	O
accurately	O
.	O
With	O
the	O
user	O
interface	O
in	O
Figure	O
9	O
,	O
we	O
gave	O
a	O
score	O
to	O
the	O
feature	O
f	O
i	O
based	O
on	O
the	O
participant	O
answer	O
.	O
To	O
explain	O
,	O
we	O
re	O
-	O
scaled	O
values	O
in	O
the	O
i	O
th	O
column	O
of	O
W	O
to	O
be	O
in	O
the	O
range	O
[	O
0,1	O
]	O
using	O
min	O
-	O
max	O
normalization	O
and	O
gave	O
the	O
normalized	O
value	O
of	O
the	O
chosen	O
class	O
as	O
a	O
score	O
to	O
the	O
feature	O
f	O
i	O
.	O
If	O
the	O
participant	O
selects	O
None	O
,	O
this	O
feature	O
gets	O
a	O
zero	O
score	O
.	O
The	O
distribution	O
of	O
the	O
average	O
feature	O
scores	O
for	O
this	O
task	O
(	O
one	O
CNN	O
)	O
is	O
displayed	O
in	O
Figure	O
10	O
.	O

We	O
report	O
Spearman	O
correlation	O
for	O
STS	O
,	O
Matthews	O
correlation	O
coefficient	O
(	O
MCC	O
)	O
for	O
CoLA	B-MethodName
,	O
exact	O
match	O
for	O
SQuAD	B-MethodName
,	O
and	O
accuracy	O
for	O
the	O
other	O
tasks	O
.	O
We	O
use	O
the	O
provided	O
evaluation	O
script	O
for	O
SQuAD	B-MethodName
6	O
,	O
scipy	O
to	O
compute	O
Spearman	O
scores	O
7	O
,	O
and	O
sklearn	O
to	O
compute	O
MCC	O
8	O
.	O
We	O
use	O
the	O
standard	O
train	O
/	O
dev	O
/	O
test	O
splits	O
.	O

POET	O
-	O
Math	O
and	O
POET	B-MethodName
-	I-MethodName
Logic	I-MethodName
each	O
focus	O
on	O
one	O
specific	O
reasoning	O
skill	O
,	O
making	O
the	O
pre	O
-	O
training	O
task	O
heavily	O
dependent	O
on	O
the	O
downstream	O
task	O
.	O
Different	O
from	O
them	O
,	O
POET	B-MethodName
-	I-MethodName
SQL	I-MethodName
is	O
proposed	O
to	O
allow	O
LMs	O
to	O
master	O
different	O
reasoning	O
skills	O
simultaneously	O
.	O
In	O
our	O
implementation	O
,	O
POET	B-MethodName
-	I-MethodName
SQL	I-MethodName
is	O
pre	O
-	O
trained	O
with	O
an	O
integrated	O
SQL	O
executor	O
,	O
since	O
we	O
believe	O
that	O
SQL	O
queries	O
are	O
complex	O
enough	O
to	O
encompass	O
a	O
wide	O
variety	O
of	O
computational	O
procedures	O
(	O
Table	O
2	O
)	O
.	O

Following	O
BERT	B-MethodName
,	O
we	O
submit	O
the	O
best	O
of	O
10	O
models	O
fine	O
-	O
tuned	O
with	O
different	O
random	O
seeds	O
to	O
the	O
GLUE	O
leaderboard	O
for	O
test	O
set	O
results	O
.	O

Overall	O
,	O
our	O
results	O
demonstrate	O
that	O
Hindi	O
word	O
order	O
preferences	O
are	O
influenced	O
by	O
discourse	O
predictability	O
maximization	O
considerations	O
.	O
The	O
actual	O
mechanisms	O
of	O
discourse	O
effects	O
are	O
plausibly	O
lexical	O
and	O
syntactic	O
priming	O
.	O

A	O
For	O
every	O
submission	O
:	O
A1	O
.	O
Did	O
you	O
describe	O
the	O
limitations	O
of	O
your	O
work	O
?	O
Section	O
6	O
Limitations	O
A2	O
.	O
Did	O
you	O
discuss	O
any	O
potential	O
risks	O
of	O
your	O
work	O
?	O
Not	O
applicable	O
.	O
We	O
currently	O
do	O
not	O
identify	O
any	O
potential	O
risks	O
inherently	O
associated	O
with	O
our	O
work	O
.	O

Overall	O
Performance	O
.	O
The	O
overall	O
performances	O
of	O
two	O
NMT	B-MethodName
models	O
across	O
five	O
target	O
languages	O
show	O
similar	O
trends	O
.	O
Firstly	O
,	O
compared	O
with	O
Base	O
,	O
which	O
is	O
trained	O
only	O
on	O
plain	O
text	O
,	O
H2H	O
gains	O
significant	O
improvement	O
.	O
For	O
example	O
,	O
H2H	O
based	O
on	O
M2M-100	O
outperforms	O
Base	O
by	O
17.7	O
,	O
24.7	O
,	O
26.7	O
,	O
15.5	O
,	O
and	O
16.6	O
BLEU	B-MethodName
in	O
translating	O
schema	O
from	O
En	O
to	O
Zh	O
,	O
Es	O
,	O
Fr	O
,	O
De	O
,	O
and	O
Ja	O
,	O
respectively	O
.	O
It	O
demonstrates	O
a	O
big	O
difference	O
between	O
plain	O
text	O
and	O
tabular	O
data	O
,	O
and	O
fine	O
-	O
tuning	O
on	O
schema	O
translation	O
data	O
could	O
alleviate	O
the	O
difference	O
to	O
some	O
extent	O
.	O

An	O
important	O
drawback	O
of	O
character	O
-	O
level	O
models	O
is	O
that	O
they	O
typically	O
require	O
more	O
computations	O
than	O
sub	O
-	O
word	O
and	O
word	O
-	O
level	O
models	O
.	O
This	O
is	O
because	O
character	O
-	O
level	O
tokenization	O
produces	O
longer	O
token	O
sequences	O
compared	O
to	O
sub	O
-	O
word	O
or	O
word	O
based	O
approaches	O
,	O
and	O
the	O
computational	O
and	O
memory	O
demands	O
of	O
the	O
self	O
-	O
attention	O
mechanism	O
grow	O
quadratically	O
with	O
the	O
sequence	O
length	O
.	O
In	O
order	O
to	O
address	O
this	O
challenge	O
,	O
CANINE	B-MethodName
(	O
Clark	O
et	O
al	O
.	O
,	O
2022b	O
)	O
leverages	O
strided	O
convolution	O
to	O
downsample	O
the	O
character	O
sequence	O
,	O
while	O
Charformer	O
(	O
Tay	O
et	O
al	O
.	O
,	O
2021	O
)	O
uses	O
average	O
pooling	O
.	O
Although	O
these	O
methods	O
improve	O
the	O
computational	O
efficiency	O
of	O
character	O
-	O
level	O
models	O
,	O
they	O
require	O
a	O
predefined	O
static	O
downsampling	O
rate	O
.	O
Such	O
downsampling	O
operation	O
often	O
breaks	O
the	O
boundary	O
of	O
basic	O
linguistic	O
units	O
,	O
including	O
morphemes	O
and	O
words	O
.	O

Our	O
model	O
to	O
classify	O
cosponsorship	O
decisions	O
based	O
on	O
the	O
legislator	O
and	O
bill	O
data	O
described	O
in	O
the	O
previous	O
section	O
consists	O
of	O
two	O
main	O
elements	O
,	O
an	O
Encoder	O
and	O
a	O
Relational	O
Graph	I-MethodName
Convolutional	I-MethodName
Network	I-MethodName
(	O
RGCN	B-MethodName
)	O
.	O
The	O
Encoder	O
computes	O
high	O
dimensional	O
representations	O
of	O
legislators	O
'	O
bills	O
and	O
speeches	O
based	O
on	O
their	O
texts	O
and	O
transcripts	O
,	O
respectively	O
.	O
These	O
representations	O
are	O
used	O
by	O
an	O
RGCN	B-MethodName
and	O
a	O
downstream	O
Feed	O
-	I-MethodName
Forward	I-MethodName
Neural	I-MethodName
Network	I-MethodName
(	O
FFNN	B-MethodName
)	O
allowing	O
us	O
to	O
predict	O
how	O
(	O
i.e.	O
,	O
active	O
or	O
passive	O
)	O
a	O
cosponsor	O
supports	O
a	O
bill	O
.	O

The	O
document	O
to	O
use	O
our	O
code	O
and	O
pre	O
-	O
trained	O
model	O
is	O
in	O
the	O
supplementary	O
materials	O
.	O
C1	O
.	O
Did	O
you	O
report	O
the	O
number	O
of	O
parameters	O
in	O
the	O
models	O
used	O
,	O
the	O
total	O
computational	O
budget	O
(	O
e.g.	O
,	O
GPU	O
hours	O
)	O
,	O
and	O
computing	O
infrastructure	O
used	O
?	O
Section	O
3	O

Sentence	O
-	O
level	O
probes	O
.	O
Utilizing	O
the	O
BERTspecific	B-MethodName
sentence	O
representation	O
[	O
CLS	O
]	O
allows	O
us	O
to	O
incorporate	O
the	O
sentence	O
-	O
level	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
probe	O
into	O
our	O
kit	O
.	O

Figure	O
3	O
:	O
Results	O
of	O
secondarily	O
finetuning	O
T5	O
-	O
seq	O
with	O
dialogues	O
,	O
to	O
help	O
understand	O
whether	O
prompting	O
or	O
finetuning	O
is	O
more	O
effective	O
.	O
The	O
examples	O
used	O
for	O
finetuning	O
are	O
derived	O
from	O
the	O
set	O
of	O
dialogues	O
used	O
as	O
prompts	O
across	O
the	O
5	O
trials	O
of	O
SDT	O
-	O
seq	O
.	O
From	O
this	O
,	O
we	O
observe	O
that	O
prompting	O
with	O
a	O
single	O
dialogue	O
demonstration	O
outperforms	O
few	O
-	O
shot	O
finetuning	O
.	O

Given	O
a	O
document	O
with	O
N	O
mentions	O
,	O
each	O
of	O
which	O
has	O
K	O
entity	O
candidates	O
,	O
our	O
model	O
solves	O
ED	O
by	O
selecting	O
a	O
correct	O
referent	O
entity	O
from	O
the	O
entity	O
candidates	O
for	O
each	O
mention	O
.	O

The	O
concept	O
of	O
framing	O
dimensions	O
(	O
Boydstun	O
et	O
al	O
.	O
,	O
2014	O
)	O
is	O
close	O
to	O
argument	O
aspects	O
.	O
In	O
the	O
field	O
of	O
argument	O
mining	O
,	O
Ajjour	O
et	O
al	O
.	O
(	O
2019	O
)	O
recently	O
applied	O
frames	O
to	O
label	O
argument	O
clusters	O
.	O
Yet	O
,	O
their	O
method	O
does	O
not	O
allow	O
to	O
detect	O
frames	O
.	O
Other	O
works	O
present	O
methods	O
to	O
automatically	O
label	O
sentences	O
of	O
news	O
articles	O
and	O
online	O
discussions	O
with	O
frames	O
(	O
Hartmann	O
et	O
al	O
.	O
,	O
2019;Naderi	O
and	O
Hirst	O
,	O
2017	O
)	O
.	O
These	O
methods	O
are	O
,	O
however	O
,	O
limited	O
to	O
a	O
small	O
set	O
of	O
predefined	O
frames	O
that	O
represent	O
high	O
-	O
level	O
concepts	O
.	O
Contrarily	O
,	O
we	O
operate	O
on	O
a	O
fine	O
-	O
grained	O
span	O
-	O
level	O
to	O
detect	O
aspects	O
that	O
are	O
explicitly	O
mentioned	O
in	O
arguments	O
.	O

Using	O
Kronecker	O
decomposition	O
for	O
large	O
compression	O
factors	O
leads	O
to	O
a	O
reduction	O
in	O
the	O
model	O
expressiveness	O
.	O
This	O
is	O
due	O
to	O
the	O
nature	O
of	O
the	O
Kronecker	O
product	O
and	O
the	O
fact	O
that	O
elements	O
in	O
this	O
representation	O
are	O
tied	O
together	O
.	O
To	O
address	O
this	O
issue	O
,	O
we	O
propose	O
to	O
distill	O
knowledge	O
from	O
the	O
intermediate	O
layers	O
of	O
the	O
original	O
uncompressed	O
network	O
to	O
the	O
Kronecker	O
network	O
during	O
training	O
.	O

This	O
lets	O
us	O
talk	O
about	O
degrees	O
of	O
inequity	O
,	O
and	O
therefore	O
,	O
measure	O
progress	O
towards	O
our	O
ideals	O
.	O

We	O
use	O
ELECTRA	B-MethodName
's	O
top	O
-	O
level	O
classifiers	O
and	O
hyperparameter	O
values	O
for	O
fine	O
-	O
tuning	O
as	O
well	O
.	O
For	O
GLUE	O
tasks	O
,	O
a	O
simple	O
linear	O
classifier	O
is	O
added	O
on	O
top	O
of	O
the	O
pre	O
-	O
trained	O
transformer	O
.	O
For	O
SQuAD	B-MethodName
,	O
a	O
question	O
answering	O
module	O
similar	O
XLNet	B-MethodName
's	O
(	O
Yang	O
et	O
al	O
.	O
,	O
2019	O
)	O
is	O
added	O
on	O
top	O
of	O
the	O
transformer	O
,	O
which	O
is	O
slightly	O
more	O
sophisticated	O
than	O
BERT	B-MethodName
's	O
in	O
that	O
it	O
jointly	O
rather	O
than	O
independently	O
predicts	O
the	O
start	O
and	O
end	O
positions	O
and	O
has	O
an	O
"	O
answerability	O
"	O
classifier	O
added	O
for	O
SQuAD	B-MethodName
2.0	O
.	O
ELECTRA	B-MethodName
's	O
hyperparameters	O
are	O
similar	O
to	O
BERT	B-MethodName
's	O
,	O
with	O
the	O
main	O
difference	O
being	O
the	O
addition	O
of	O
a	O
layer	O
-	O
wise	O
learning	O
rate	O
decay	O
where	O
layers	O
of	O
the	O
network	O
closer	O
to	O
the	O
output	O
have	O
a	O
higher	O
learning	O
rate	O
.	O

Ablations	O
.	O
We	O
conduct	O
an	O
ablation	O
study	O
(	O
in	O
Table	O
5	O
)	O
of	O
the	O
HierGNN	B-MethodName
encoder	O
,	O
graph	O
-	O
selection	O
attention	O
,	O
sparse	O
MTC	B-MethodName
and	O
graph	O
fusion	O
layer	O
.	O
The	O
ablation	O
is	O
done	O
on	O
our	O
HierGNN	B-MethodName
-	I-MethodName
PGN	I-MethodName
LIR	I-MethodName
model	O
trained	O
on	O
XSum	O
.	O
The	O
ablation	O
in	O
HierGNN	B-MethodName
reasoning	O
module	O
significantly	O
degrades	O
the	O
model	O
,	O
which	O
suggests	O
the	O
positive	O
contribution	O
of	O
the	O
functionality	O
in	O
across	O
-	O
sentence	O
reasoning	O
.	O
The	O
scores	O
without	O
GSA	B-MethodName
also	O
confirm	O
the	O
guidance	O
of	O
graph	O
-	O
level	O
information	O
is	O
beneficial	O
.	O
By	O
removing	O
the	O
graph	O
fusion	O
layer	O
,	O
we	O
again	O
observe	O
the	O
performance	O
decreases	O
,	O
which	O
proves	O
the	O
benefits	O
of	O
fusing	O
the	O
neighbor	O
feature	O
from	O
multiple	O
hopping	O
distances	O
.	O

To	O
properly	O
evaluate	O
SiMT	B-MethodName
performance	O
,	O
the	O
test	O
sets	O
should	O
be	O
representative	O
of	O
the	O
characteristics	O
of	O
real	O
-	O
time	O
simultaneous	O
translation	O
,	O
in	O
both	O
content	O
and	O
translation	O
style	O
.	O
In	O
addition	O
to	O
the	O
official	O
test	O
sets	O
described	O
earlier	O
,	O
we	O
choose	O
to	O
adapt	O
the	O
WMT	B-MethodName
newstest2015	O
De→En	O
data	O
set	O
for	O
realtime	O
speech	O
translation	O
.	O
We	O
select	O
500	O
sentence	O
pairs	O
from	O
this	O
data	O
set	O
and	O
ask	O
professional	O
translators	O
to	O
produce	O
new	O
reference	O
translations	O
,	O
with	O
as	O
much	O
monotonicity	O
as	O
linguistically	O
possible	O
without	O
compromising	O
the	O
translation	O
quality	O
.	O
The	O
detail	O
of	O
this	O
annotation	O
task	O
can	O
be	O
found	O
in	O
the	O
Appendix	O
D	O
.	O

A	O
Appendix	O
PCA	O
analysis	O
Figure	O
4	O
shows	O
an	O
almost	O
linear	O
relationship	O
between	O
the	O
number	O
of	O
principal	O
components	O
and	O
the	O
explained	O
variance	O
of	O
the	O
PCA	O
(	O
see	O
Section	O
3.1	O
)	O
,	O
i.e.	O
the	O
higher	O
the	O
number	O
of	O
principal	O
components	O
,	O
the	O
larger	O
the	O
explained	O
variance	O
.	O
Therefore	O
,	O
we	O
experimented	O
with	O
various	O
numbers	O
of	O
components	O
up	O
to	O
15	O
(	O
1	O
,	O
2	O
,	O
3	O
,	O
5	O
,	O
10	O
,	O
and	O
15	O
)	O
on	O
the	O
development	O
set	O
to	O
find	O
the	O
best	O
settings	O
for	O
quality	O
prediction	O
.	O
Complete	O
results	O
Tables	O
5	O
and	O
6	O
present	O
the	O
full	O
set	O
of	O
results	O
of	O
our	O
experiments	O
on	O
document	O
and	O
sentence	O
-	O
level	O
multimodal	O
QE	O
on	O
our	O
main	O
test	O
set	O
,	O
the	O
WMT'18	O
test	O
set	O
.	O
These	O
are	O
a	O
super	O
-	O
set	O
of	O
the	O
results	O
presented	O
in	O
the	O
main	O
paper	O
but	O
include	O
all	O
combinations	O
of	O
multimodality	O
integration	O
and	O
fusion	O
strategies	O
for	O
sentence	O
-	O
level	O
prediction	O
,	O
as	O
well	O
as	O
different	O
numbers	O
of	O
principal	O
components	O
kept	O
for	O
document	O
-	O
level	O
QuEst	O
prediction	O
models	O
.	O

On	O
token	O
dropping	O
vs.	O
token	O
averaging	O
.	O
Comparing	O
"	O
token	O
drop	O
+	O
stage-2	O
"	O
with	O
"	O
token	O
avg	O
+	O
stage-2	O
,	O
"	O
we	O
see	O
that	O
average	O
pooling	O
instead	O
of	O
dropping	O
unimportant	O
tokens	O
yields	O
slightly	O
worse	O
results	O
.	O
This	O
means	O
that	O
our	O
importance	O
-	O
driven	O
token	O
selection	O
is	O
more	O
efficient	O
than	O
directly	O
averaging	O
embedding	O
across	O
every	O
nearby	O
token	O
pair	O
.	O

There	O
is	O
still	O
a	O
significant	O
gap	O
between	O
models	O
used	O
in	O
this	O
work	O
and	O
schema	O
-	O
aware	O
models	O
that	O
are	O
trained	O
on	O
the	O
same	O
KB	O
as	O
the	O
inference	O
KB	O
.	O
One	O
way	O
to	O
close	O
this	O
gap	O
is	O
by	O
using	O
automatic	O
table	O
-	O
to	O
-	O
text	O
generation	O
techniques	O
to	O
convert	O
arbitrary	O
entities	O
into	O
fluent	O
and	O
adequate	O
text	O
(	O
Kukich	O
,	O
1983;McKeown	O
,	O
1985;Reiter	O
and	O
Dale	O
,	O
1997;Wiseman	O
et	O
al	O
.	O
,	O
2017;Chisholm	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Another	O
promising	O
direction	O
is	O
to	O
move	O
beyond	O
BERT	B-MethodName
to	O
other	O
pre	O
-	O
trained	O
representations	O
that	O
are	O
better	O
known	O
to	O
encode	O
entity	O
information	O
(	O
Zhang	O
et	O
al	O
.	O
,	O
2019;Guu	O
et	O
al	O
.	O
,	O
2020;Poerner	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Table	O
5	O
shows	O
the	O
entity	O
linking	O
performance	O
and	O
KBQA	B-MethodName
performance	O
on	O
GRAILQA	B-MethodName
of	O
various	O
methods	O
.	O
Compared	O
to	O
the	O
popularity	O
-	O
based	O
baseline	O
(	O
Bert	O
Ranking	O
)	O
,	O
Our	O
entity	O
disambiguation	O
model	O
is	O
effective	O
and	O
successfully	O
improves	O
the	O
entity	O
linking	O
F1	O
by	O
7.4	O
,	O
which	O
boosts	O
the	O
final	O
KBQA	B-MethodName
F1	O
score	O
by	O
7.0	O
.	O
Our	O
entity	O
linking	O
model	O
is	O
also	O
better	O
than	O
the	O
Bootleg	O
approach	O
(	O
Orr	O
et	O
al	O
.	O
,	O
2021	O
)	O
used	O
in	O
ReTrack	B-MethodName
(	O
Chen	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Furthermore	O
,	O
our	O
method	O
without	O
the	O
entity	O
disambiguation	O
modules	O
outperforms	O
Bert	O
Ranking	O
with	O
a	O
substantially	O
large	O
margin	O
(	O
11.4	O
F1	O
score	O
)	O
.	O
Our	O
method	O
even	O
beats	O
ReTrack	B-MethodName
when	O
it	O
is	O
built	O
upon	O
a	O
much	O
better	O
entity	O
linking	O
model	O
.	O
The	O
results	O
suggest	O
the	O
strong	O
effectiveness	O
of	O
our	O
rankand	O
-	O
generate	O
framework	O
.	O

Analysis	O
We	O
conduct	O
a	O
χ	O
2	O
test	O
for	O
each	O
heuristic	O
to	O
determine	O
whether	O
we	O
are	O
able	O
to	O
reject	O
the	O
null	O
hypothesis	O
that	O
pattern	O
-	O
satisfying	O
premisehypothesis	O
pairs	O
are	O
uniformly	O
distributed	O
over	O
classes	O
.	O
The	O
results	O
support	O
our	O
hypotheses	O
regarding	O
each	O
of	O
the	O
three	O
heuristics	O
.	O
Notably	O
,	O
the	O
percentage	O
of	O
heuristic	O
-	O
satisfying	O
pairs	O
accounted	O
for	O
by	O
the	O
top	O
class	O
is	O
lowest	O
for	O
the	O
HYPERNYM	B-MethodName
hypothesis	O
,	O
which	O
we	O
attribute	O
to	O
the	O
high	O
degree	O
of	O
semantic	O
overlap	O
between	O
entailed	O
and	O
neutral	O
hypotheses	O
.	O

Firstly	O
,	O
it	O
is	O
clear	O
that	O
erasing	O
entity	O
types	O
decreases	O
the	O
performance	O
of	O
the	O
schema	O
translation	O
Table	O
7	O
:	O
Qualitative	O
analysis	O
for	O
models	O
'	O
performance	O
in	O
schema	O
translation	O
from	O
En	O
to	O
Zh	O
on	O
three	O
kinds	O
of	O
headers	O
.	O
For	O
each	O
predicting	O
result	O
,	O
we	O
add	O
extra	O
explanations	O
for	O
their	O
meanings	O
in	O
the	O
brackets	O
.	O
Results	O
with	O
underline	O
denote	O
the	O
correct	O
translation	O
for	O
the	O
header	O
.	O
models	O
.	O
Comparing	O
CAST	O
(	O
w/o	O
entity	O
type	O
)	O
with	O
CAST	B-MethodName
,	O
for	O
instance	O
,	O
We	O
can	O
see	O
a	O
0.5	O
and	O
0.5	O
decrease	O
of	O
BLEU	B-MethodName
for	O
En	O
-	O
De	I-MethodName
and	O
En	O
-	O
Fr	O
respectively	O
.	O
Secondly	O
,	O
the	O
comparison	O
between	O
CAST	B-MethodName
(	O
w/o	O
structural	O
relation	O
)	O
and	O
CAST	B-MethodName
shows	O
that	O
the	O
structure	O
relations	O
also	O
play	O
an	O
important	O
role	O
in	O
bettering	O
the	O
performance	O
of	O
context	O
modeling	O
.	O
As	O
seen	O
in	O
the	O
En	O
-	O
Fr	O
translation	O
setting	O
,	O
CAST(w	B-MethodName
/	O
o	O
structural	O
relation	O
)	O
obtains	O
a	O
1.0	O
lower	O
BLEU	B-MethodName
score	O
over	O
CAST	B-MethodName
.	O
Finally	O
,	O
when	O
erasing	O
both	O
kinds	O
of	O
edges	O
and	O
the	O
models	O
give	O
the	O
lowest	O
performance	O
.	O

The	O
results	O
for	O
CommonsenseQA	B-MethodName
and	O
QASC	B-MethodName
using	O
the	O
same	O
selection	O
of	O
sentences	O
from	O
Wikipedia	O
are	O
reported	O
in	O
table	O
3	O
.	O
Overall	O
,	O
we	O
obtain	O
similar	O
results	O
to	O
SciQ	B-MethodName
with	O
a	O
large	O
improvement	O
of	O
performances	O
when	O
generating	O
questions	O
and	O
a	O
further	O
boost	O
with	O
refined	O
distractors	O
.	O
However	O
compared	O
to	O
SciQ	B-MethodName
,	O
the	O
improvement	O
brought	O
by	O
the	O
distractor	O
refining	O
process	O
is	O
less	O
significant	O
.	O
This	O
could	O
be	O
partly	O
explained	O
by	O
the	O
fact	O
that	O
the	O
distractors	O
in	O
the	O
original	O
QASC	B-MethodName
and	O
CommonsenseQA	B-MethodName
datasets	O
are	O
overall	O
easier	O
and	O
therefore	O
it	O
is	O
less	O
advantageous	O
for	O
a	O
model	O
to	O
be	O
trained	O
on	O
harder	O
questions	O
.	O

In	O
our	O
method	O
,	O
the	O
construction	O
of	O
the	O
optimal	O
policy	O
relies	O
on	O
the	O
performance	O
of	O
the	O
translation	O
model	O
.	O
Therefore	O
,	O
the	O
training	O
of	O
the	O
translation	O
model	O
needs	O
to	O
be	O
further	O
explored	O
.	O
As	O
shown	O
in	O
Table	O
5	O
,	O
our	O
method	O
obtains	O
the	O
best	O
performance	O
.	O
Training	O
from	O
scratch	O
yields	O
the	O
worst	O
performance	O
,	O
as	O
the	O
model	O
lacks	O
the	O
ability	O
to	O
distinguish	O
between	O
good	O
and	O
poor	O
translations	O
.	O
Fine	O
-	O
tuning	O
from	O
the	O
Full	O
-	O
sentence	O
model	O
achieves	O
better	O
performance	O
,	O
but	O
it	O
does	O
not	O
have	O
the	O
ability	O
to	O
generate	O
high	O
-	O
quality	O
translation	O
with	O
partial	O
source	O
information	O
.	O
Our	O
method	O
,	O
fine	O
-	O
tuned	O
from	O
Multipath	B-MethodName
,	O
is	O
capable	O
of	O
generating	O
high	O
-	O
quality	O
translation	O
under	O
all	O
latency	O
.	O

The	O
primary	O
contribution	O
of	O
this	O
work	O
is	O
a	O
novel	O
framework	O
for	O
entity	O
linking	O
against	O
unseen	O
target	O
KBs	O
with	O
unknown	O
schemas	O
.	O
To	O
this	O
end	O
,	O
we	O
introduce	O
methods	O
to	O
generalize	O
existing	O
models	O
for	O
zero	O
-	O
shot	O
entity	O
linking	O
to	O
link	O
to	O
unseen	O
KBs	O
.	O
These	O
methods	O
rely	O
on	O
converting	O
arbitrary	O
entities	O
represented	O
using	O
a	O
set	O
of	O
attribute	O
-	O
value	O
pairs	O
into	O
a	O
string	O
representation	O
that	O
can	O
be	O
then	O
consumed	O
by	O
models	O
from	O
prior	O
work	O
.	O

A	O
Layer	O
-	O
wise	O
Relevance	O
Propagation	O

For	O
generic	O
compact	O
methods	O
(	O
MiniLM	B-MethodName
,	O
Distil	B-MethodName
-	I-MethodName
BERT	I-MethodName
,	O
and	O
TinyBERT	B-MethodName
)	O
,	O
we	O
use	O
the	O
models	O
provided	O
by	O
the	O
original	O
authors	O
as	O
the	O
initialization	O
,	O
then	O
directly	O
fine	O
-	O
tune	O
them	O
on	O
the	O
training	O
data	O
of	O
the	O
target	O
task	O
.	O
The	O
fine	O
-	O
tuning	O
is	O
optimized	O
by	O
Adam	O
with	O
a	O
learning	O
rate	O
of	O
2	O
×	O
10	O
−5	O
and	O
batch	O
size	O
of	O
32	O
on	O
one	O
GPU	O
.	O

We	O
conduct	O
experiments	O
on	O
four	O
datasets	O
of	O
three	O
text	O
generation	O
tasks	O
:	O
text	O
summarization	O
,	O
tableto	O
-	O
text	O
generation	O
,	O
and	O
dialogue	O
generation	O
.	O
For	O
text	O
summarization	O
,	O
we	O
use	O
XSum	O
(	O
Nallapati	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
CNN	O
/	I-MethodName
DM	O
(	O
Hermann	O
et	O
al	O
.	O
,	O
2015	O
)	O
for	O
evaluation	O
.	O
For	O
table	O
-	O
to	O
-	O
text	O
generation	O
,	O
we	O
use	O
WIKIPERSON	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
For	O
dialogue	O
generation	O
,	O
we	O
apply	O
dialogue	O
NLI	O
(	O
Welleck	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Details	O
of	O
all	O
datasets	O
are	O
listed	O
in	O
Table	O
10	O
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
our	O
work	O
does	O
not	O
involve	O
any	O
potential	O
risk	O
.	O

Computing	O
Infrastructure	O
and	O
Runtime	O
Specifications	O
.	O
Models	O
were	O
trained	O
on	O
Google	O
Colab	O
's	O
GPU	O
.	O
On	O
average	O
,	O
each	O
experiment	O
took	O
∼1:30	O
hours	O
to	O
train	O
.	O

In	O
the	O
near	O
future	O
,	O
it	O
is	O
worth	O
exploring	O
to	O
alleviate	O
the	O
possible	O
knowledge	O
incompleteness	O
in	O
practical	O
KG	B-MethodName
by	O
developing	O
a	O
hybrid	O
questionanswering	O
method	O
on	O
both	O
knowledge	O
graphs	O
and	O
web	O
texts	O
.	O
In	O
addition	O
,	O
this	O
paper	O
focuses	O
only	O
on	O
temporal	O
intent	O
,	O
while	O
problems	O
in	O
real	O
configurations	O
may	O
contain	O
both	O
complex	O
non	O
-	O
temporal	O
and	O
temporal	O
intents	O
.	O
Therefore	O
,	O
it	O
would	O
be	O
helpful	O
to	O
combine	O
SF	B-MethodName
-	I-MethodName
TCons	I-MethodName
with	O
general	O
KGQA	B-MethodName
systems	O
for	O
complex	O
questions	O
.	O

The	O
models	O
in	O
Section	O
3	O
were	O
designed	O
to	O
operate	O
in	O
settings	O
where	O
the	O
entities	O
in	O
the	O
target	O
KB	O
were	O
only	O
represented	O
using	O
a	O
textual	O
description	O
.	O
For	O
example	O
,	O
the	O
entity	O
Douglas	O
Adams	O
would	O
be	O
represented	O
in	O
such	O
a	O
database	O
using	O
a	O
description	O
as	O
follows	O
:	O
"	O
Douglas	O
Adams	O
was	O
an	O
English	O
author	O
,	O
screenwriter	O
,	O
essayist	O
,	O
humorist	O
,	O
satirist	O
and	O
dramatist	O
.	O
He	O
was	O
the	O
author	O
of	O
The	O
Hitchhiker	O
's	O
Guide	O
to	O
the	O
Galaxy	O
.	O
"	O

In	O
entity	O
linking	O
,	O
mentions	O
of	O
named	O
entities	O
in	O
raw	O
text	O
are	O
disambiguated	O
against	O
a	O
knowledge	O
base	O
(	O
KB	O
)	O
.	O
This	O
work	O
focuses	O
on	O
linking	O
to	O
unseen	O
KBs	O
that	O
do	O
not	O
have	O
training	O
data	O
and	O
whose	O
schema	O
is	O
unknown	O
during	O
training	O
.	O
Our	O
approach	O
relies	O
on	O
methods	O
to	O
flexibly	O
convert	O
entities	O
with	O
several	O
attribute	O
-	O
value	O
pairs	O
from	O
arbitrary	O
KBs	O
into	O
flat	O
strings	O
,	O
which	O
we	O
use	O
in	O
conjunction	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
zero	O
-	O
shot	O
linking	O
.	O
We	O
further	O
improve	O
the	O
generalization	O
of	O
our	O
model	O
using	O
two	O
regularization	O
schemes	O
based	O
on	O
shuffling	O
of	O
entity	O
attributes	O
and	O
handling	O
of	O
unseen	O
attributes	O
.	O
Experiments	O
on	O
English	O
datasets	O
where	O
models	O
are	O
trained	O
on	O
the	O
CoNLL	B-MethodName
dataset	O
,	O
and	O
tested	O
on	O
the	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
2010	O
dataset	O
show	O
that	O
our	O
models	O
are	O
12	O
%	O
(	O
absolute	O
)	O
more	O
accurate	O
than	O
baseline	O
models	O
that	O
simply	O
flatten	O
entities	O
from	O
the	O
target	O
KB	O
.	O
Unlike	O
prior	O
work	O
,	O
our	O
approach	O
also	O
allows	O
for	O
seamlessly	O
combining	O
multiple	O
training	O
datasets	O
.	O
We	O
test	O
this	O
ability	O
by	O
adding	O
both	O
a	O
completely	O
different	O
dataset	O
(	O
Wikia	O
)	O
,	O
as	O
well	O
as	O
increasing	O
amount	O
of	O
training	O
data	O
from	O
the	O
TAC	B-MethodName
-	O
KBP	I-MethodName
2010	O
training	O
set	O
.	O
Our	O
models	O
are	O
more	O
accurate	O
across	O
the	O
board	O
compared	O
to	O
baselines	O
.	O

We	O
study	O
the	O
contribution	O
of	O
each	O
negative	O
sample	O
construction	O
strategy	O
for	O
improving	O
the	O
coherence	O
of	O
the	O
outputs	O
.	O
As	O
in	O
Table	O
3	O
,	O
removing	O
each	O
strategy	O
leads	O
to	O
a	O
performance	O
degradation	O
,	O
indicating	O
the	O
effectiveness	O
of	O
all	O
types	O
of	O
negative	O
samples	O
to	O
enhance	O
the	O
contrastive	O
learning	O
.	O
Among	O
all	O
negatives	O
,	O
removing	O
REPLACE	O
shows	O
the	O
most	O
effects	O
on	O
both	O
datasets	O
.	O
We	O
hypothesize	O
that	O
replacing	O
target	O
sentences	O
breaks	O
the	O
original	O
logical	O
flow	O
and	O
thus	O
is	O
more	O
likely	O
to	O
encourage	O
the	O
model	O
to	O
focus	O
on	O
the	O
global	O
coherence	O
.	O
In	O
contrast	O
,	O
DIFFERENT	B-MethodName
shows	O
the	O
least	O
effects	O
.	O
One	O
possible	O
explanation	O
is	O
that	O
this	O
strategy	O
focuses	O
more	O
on	O
topical	O
relatedness	O
between	O
the	O
input	O
and	O
output	O
,	O
instead	O
of	O
the	O
logical	O
flow	O
within	O
the	O
output	O
as	O
the	O
negative	O
sample	O
itself	O
is	O
inherently	O
coherent	O
.	O

One	O
way	O
of	O
using	O
these	O
models	O
for	O
linking	O
against	O
arbitrary	O
KBs	O
is	O
by	O
defining	O
an	O
attribute	O
-	O
to	O
-	O
text	O
function	O
f	O
,	O
that	O
maps	O
arbitrary	O
entities	O
with	O
any	O
set	O
of	O
attributes	O
{	O
k	O
i	O
,	O
v	O
i	O
}	O
n	O
i=1	O
to	O
a	O
string	O
representation	O
e	O
that	O
can	O
be	O
consumed	O
by	O
BERT	B-MethodName
,	O
i.e.	O

We	O
extract	O
POS	O
n	O
-	O
gram	O
patterns	O
of	O
hyperbole	O
from	O
the	O
training	O
set	O
of	O
HYPO	B-MethodName
dataset	O
8	O
and	O
obtain	O
262	O
distinct	O
POS	O
n	O
-	O
grams	O
.	O
As	O
a	O
motivating	O
example	O
,	O
the	O
following	O
three	O
hyperbolic	O
spans	O
,	O
"	O
faster	O
than	O
light	O
"	O
,	O
"	O
sweeter	O
than	O
honey	O
"	O
,	O
"	O
whiter	O
than	O
snow	O
"	O
,	O
share	O
the	O
same	O
POS	O
n	O
-	O
gram	O
of	O
"	O
JJR+IN+NN	O
"	O
.	O

•	O
We	O
propose	O
a	O
novel	O
distractor	O
refining	O
method	O
able	O
to	O
select	O
harder	O
distractors	O
for	O
a	O
given	O
generated	O
question	O
and	O
show	O
its	O
superiority	O
compared	O
to	O
a	O
random	O
selection	O
.	O

-DOCSTART-	O
A	O
Matter	O
of	O
Framing	O
:	O
The	O
Impact	O
of	O
Linguistic	O
Formalism	O
on	O
Probing	O
Results	O

This	O
section	O
introduces	O
our	O
proposed	O
Post	O
-	O
Pretraining	O
Alignment	O
(	O
PPA	O
)	O
method	O
.	O
We	O
first	O
describe	O
the	O
MoCo	B-MethodName
contrastive	O
learning	O
framework	O
and	O
how	O
we	O
use	O
it	O
for	O
sentence	O
-	O
level	O
alignment	O
.	O
Next	O
,	O
we	O
describe	O
the	O
finer	O
-	O
grained	O
word	O
-	O
level	O
alignment	O
with	O
TLM	B-MethodName
.	O
Finally	O
,	O
when	O
training	O
data	O
in	O
the	O
target	O
language	O
is	O
available	O
,	O
we	O
incorporate	O
sentence	O
-	O
level	O
code	O
-	O
switching	O
as	O
a	O
form	O
of	O
both	O
alignment	O
and	O
data	O
augmentation	O
to	O
complement	O
PPA	O
.	O
Figure	O
1	O
shows	O
our	O
overall	O
model	O
structure	O
.	O

The	O
key	O
difference	O
between	O
our	O
tiny	O
-	O
attention	O
and	O
an	O
ordinary	O
attention	O
is	O
that	O
our	O
per	O
-	O
head	O
dimension	O
is	O
tiny	O
:	O
i.e.	O
,	O
z	O
(	O
ℓ	O
,	O
m	O
)	O
t	O
∈	O
R	O
D	O
and	O
D	O
is	O
very	O
small	O
.	O
Throughout	O
our	O
experiments	O
,	O
we	O
set	O
D	O
=	O
1	O
.	O

At	O
the	O
bottom	O
of	O
Table	O
1	O
,	O
we	O
present	O
the	O
results	O
of	O
ablations	O
on	O
the	O
external	O
knowledge	O
graph	O
and	O
the	O
two	O
contrastive	O
losses	O
.	O
We	O
observe	O
that	O
the	O
performance	O
drops	O
consistently	O
if	O
we	O
directly	O
use	O
class	O
names	O
to	O
initialize	O
W	O
(	O
0	O
)	O
without	O
introducing	O
external	O
KG	O
.	O
This	O
suggests	O
that	O
our	O
knowledgeable	O
label	O
word	O
initialization	O
does	O
provide	O
rich	O
and	O
essential	O
information	O
.	O
The	O
ablation	O
study	O
on	O
loss	O
functions	O
shows	O
that	O
both	O
L	O
att	O
s2w	O
and	O
L	O
att	O
w2s	O
contribute	O
to	O
fasttuning	O
,	O
though	O
the	O
former	O
has	O
a	O
more	O
significant	O
impact	O
.	O

•	O
RTE	O
:	O
Recognizing	O
Textual	O
Entailment	O
(	O
Giampiccolo	O
et	O
al	O
.	O
,	O
2007	O
)	O
.	O
Given	O
a	O
premise	O
sentence	O
and	O
a	O
hypothesis	O
sentence	O
,	O
the	O
task	O
is	O
to	O
predict	O
whether	O
the	O
premise	O
entails	O
the	O
hypothesis	O
or	O
not	O
.	O
The	O
dataset	O
contains	O
2.5k	O
train	O
examples	O
from	O
a	O
series	O
of	O
annual	O
textual	O
entailment	O
challenges	O
.	O

In	O
Figure	O
9	O
,	O
we	O
provide	O
the	O
search	O
trace	O
of	O
LAM	B-MethodName
-	I-MethodName
BADA	I-MethodName
for	O
an	O
example	O
in	O
ProofWriter	O
(	O
Depth-5	O
)	O
for	O

Table	O
7	O
lists	O
the	O
standard	O
deviations	O
of	O
each	O
methods	O
.	O
We	O
report	O
the	O
results	O
across	O
five	O
runs	O
with	O
random	O
seeds	O
.	O

where	O
T	O
is	O
a	O
set	O
of	O
all	O
sub	O
-	O
populations	O
we	O
consider	O
(	O
i.e.	O
,	O
T	O
=	O
{	O
male	O
,	O
female	O
}	O
)	O
.	O
FPR	B-MethodName
and	O
FNR	B-MethodName
stand	O
for	O
false	O
positive	O
rate	O
and	O
false	O
negative	O
rate	O
,	O
respectively	O
.	O
The	O
subscript	O
t	O
means	O
that	O
we	O
calculate	O
the	O
metrics	O
using	O
data	O
examples	O
mentioning	O
the	O
sub	O
-	O
population	O
t	O
only	O
.	O
We	O
used	O
the	O
following	O
keywords	O
to	O
identify	O
examples	O
which	O
are	O
related	O
to	O
or	O
mentioning	O
the	O
sub	O
-	O
populations	O
.	O
Male	O
gender	O
terms	O
:	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
framework	O
which	O
allows	O
humans	O
to	O
debug	O
and	O
improve	O
deep	O
text	O
classifiers	O
by	O
disabling	O
hidden	O
features	O
which	O
are	O
irrelevant	O
to	O
the	O
classification	O
task	O
.	O
We	O
name	O
this	O
framework	O
FIND	O
(	O
Feature	O
Investigation	O
aNd	O
Disabling	O
)	O
.	O
FIND	O
exploits	O
an	O
explanation	O
method	O
,	O
namely	O
layer	O
-	O
wise	O
relevance	O
propagation	O
(	O
LRP	O
)	O
(	O
Arras	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
to	O
understand	O
the	O
behavior	O
of	O
a	O
classifier	O
when	O
it	O
predicts	O
each	O
training	O
instance	O
.	O

For	O
example	O
,	O
the	O
H2H+CXT+ExtL	O
model	O
based	O
on	O
M2M100	O
obtains	O
47	O
.	O
1	O
,	O
48.6	O
,	O
53.0	O
,	O
46.6	O
,	O
and	O
40.4	O
BLEU	B-MethodName
points	O
on	O
En	O
-	O
Zh	O
,	O
En	O
-	O
Es	O
,	O
En	O
-	O
Fr	O
,	O
En	O
-	O
De	O
,	O
and	O
En	O
-	O
Ja	O
,	O
respectively	O
.	O

To	O
perform	O
this	O
top	O
-	O
k	O
search	O
,	O
we	O
use	O
efficient	O
similarity	O
search	O
libraries	O
such	O
as	O
FAISS	O
(	O
Johnson	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O

Background	O
:	O
Contrastive	O
Learning	O
Instance	O
discrimination	O
-	O
based	O
contrastive	O
learning	O
aims	O
to	O
bring	O
two	O
views	O
of	O
the	O
same	O
source	O
image	O
closer	O
to	O
each	O
other	O
in	O
the	O
representation	O
space	O
while	O
encouraging	O
views	O
of	O
different	O
source	O
images	O
to	O
be	O
dissimilar	O
through	O
a	O
contrastive	O
loss	O
.	O
Recent	O
advances	O
in	O
this	O
area	O
,	O
such	O
as	O
SimCLR	B-MethodName
(	O
Chen	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
MoCo	B-MethodName
(	O
He	O
et	O
al	O
.	O
,	O
2020	O
)	O
have	O
bridged	O
the	O
gap	O
in	O
performance	O
between	O
self	O
-	O
supervised	O
representation	O
learning	O
and	O
fully	O
-	O
supervised	O
methods	O
on	O
the	O
ImageNet	B-MethodName
(	O
Deng	O
et	O
al	O
.	O
,	O
2009	O
)	O
dataset	O
.	O
As	O
a	O
key	O
feature	O
for	O
both	O
methods	O
,	O
a	O
large	O
number	O
of	O
negative	O
examples	O
per	O
instance	O
are	O
necessary	O
for	O
the	O
models	O
to	O
learn	O
such	O
good	O
representations	O
.	O
SimCLR	B-MethodName
uses	O
in	O
-	O
batch	O
negative	O
example	O
sampling	O
,	O
thus	O
requiring	O
a	O
large	O
batch	O
size	O
,	O
whereas	O
MoCo	B-MethodName
stores	O
negative	O
examples	O
in	O
a	O
queue	O
and	O
casts	O
the	O
contrastive	O
learning	O
task	O
as	O
dictionary	O
(	O
query	O
-	O
key	O
)	O
lookup	O
.	O
In	O
what	O
follows	O
,	O
we	O
first	O
describe	O
MoCo	B-MethodName
and	O
then	O
how	O
we	O
use	O
it	O
for	O
sentence	O
-	O
level	O
alignment	O
.	O

There	O
are	O
many	O
tasks	O
in	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
that	O
require	O
extracting	O
relational	O
structures	O
from	O
texts	O
.	O
For	O
example	O
,	O
the	O
event	O
argument	O
extraction	O
task	O
aims	O
to	O
identify	O
event	O
arguments	O
and	O
their	O
corresponding	O
roles	O
for	O
a	O
given	O
event	O
trigger	O
(	O
Huang	O
et	O
al	O
.	O
,	O
2022	O
;	O
Wang	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
In	O
entity	O
relation	O
extraction	O
,	O
the	O
model	O
identifies	O
the	O
tail	O
-	O
entities	O
and	O
head	O
-	O
entities	O
that	O
forms	O
specific	O
relations	O
Yu	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
In	O
taskoriented	O
semantic	O
parsing	O
,	O
the	O
model	O
predicts	O
the	O
slots	O
and	O
their	O
semantic	O
roles	O
for	O
a	O
given	O
intent	O
in	O
an	O
*	O
The	O
authors	O
contribute	O
equally	O
.	O

•	O
aspect_pos_string	O
:	O
The	O
aspects	O
as	O
a	O
list	O
of	O
strings	O
.	O

A	O
single	O
data	O
sample	O
is	O
represented	O
by	O
an	O
argument	O
and	O
an	O
1	O
-	O
to	O
4	O
-	O
gram	O
of	O
this	O
argument	O
,	O
separated	O
by	O
the	O
BERT	B-MethodName
architecture	O
's	O
[	O
SEP	O
]	O
token	O
.	O
This	O
technique	O
expands	O
the	O
800	O
original	O
samples	O
of	O
the	O
dataset	O
to	O
around	O
80,336	O
.	O
The	O
model	O
is	O
trained	O
for	O
5	O
epochs	O
,	O
with	O
a	O
learning	O
rate	O
of	O
5	O
×	O
10	O
−5	O
,	O
and	O
a	O
batch	O
size	O
of	O
8	O
.	O
We	O
use	O
the	O
mean	O
squared	O
error	O
as	O
loss	O
and	O
take	O
the	O
recall@k	O
to	O
compare	O
the	O
models	O
.	O
The	O
in	O
-	O
and	O
cross	O
-	O
topic	O
results	O
of	O
the	O
bestperforming	O
model	O
(	O
MT	O
-	O
DNN	O
BASE	O
)	O
are	O
reported	O
in	O
Table	O
2	O
.	O
All	O
results	O
are	O
the	O
average	O
over	O
runs	O
with	O
five	O
different	O
seeds	O
(	O
and	O
over	O
all	O
four	O
splits	O
for	O
the	O
cross	O
-	O
topic	O
experiments	O
)	O
.	O

To	O
solve	O
this	O
problem	O
,	O
we	O
create	O
a	O
lattice	O
to	O
model	O
all	O
possible	O
segmenations	O
of	O
the	O
cipher	O
using	O
the	O
existing	O
key	O
.	O
Then	O
we	O
use	O
a	O
pretrained	O
language	O
model	O
to	O
choose	O
the	O
best	O
possible	O
segmentation	O
(	O
i.e.	O
the	O
segmentation	O
that	O
gives	O
the	O
most	O
probable	O
plaintext	O
according	O
to	O
the	O
language	O
model	O
)	O
.	O

In	O
this	O
section	O
we	O
outline	O
the	O
experimental	O
setups	O
(	O
§	O
3.1	O
)	O
,	O
followed	O
by	O
downstream	O
G2	O
T	I-MethodName
generation	O
results	O
in	O
full	O
(	O
§	O
3.2	O
)	O
and	O
low	O
-	O
resource	O
scenarios	O
(	O
§	O
3.3	O
)	O
.	O
We	O
also	O
present	O
a	O
set	O
of	O
generated	O
outputs	O
from	O
our	O
models	O
(	O
§	O
3.4	O
)	O
,	O
and	O
finish	O
by	O
providing	O
an	O
analysis	O
(	O
§	O
3.5	O
)	O
on	O
the	O
effect	O
of	O
pre	O
-	O
training	O
data	O
size	O
,	O
and	O
an	O
ablation	O
on	O
the	O
role	O
of	O
input	O
augmentation	O
with	O
level	O
markers	O
.	O

All	O
the	O
experiments	O
with	O
NMT	B-MethodName
models	O
in	O
this	O
paper	O
can	O
be	O
run	O
on	O
a	O
single	O
Tesla	O
V100	O
GPU	O
.	O
On	O
average	O
,	O
the	O
training	O
process	O
of	O
models	O
in	O
different	O
languages	O
can	O
be	O
finished	O
in	O
four	O
hours	O
.	O
We	O
implement	O
our	O
model	O
with	O
the	O
Transformer	B-MethodName
6	O
tools	O
in	O
Pytorch	O
7	O
,	O
and	O
the	O
data	O
will	O
be	O
released	O
with	O
the	O
paper	O
.	O

•	O
COMET	O
:	O
a	O
neural	O
quality	O
estimation	O
metric	O
by	O
Rei	O
et	O
al	O
.	O
(	O
2020a	O
)	O
which	O
was	O
shown	O
to	O
be	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
reference	O
-	O
based	O
method	O
(	O
Kocmi	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O

Online	O
education	O
platforms	O
can	O
increase	O
the	O
accessibility	O
of	O
high	O
quality	O
educational	O
resources	O
for	O
students	O
around	O
the	O
world	O
.	O
Adaptive	O
techniques	O
that	O
allow	O
for	O
more	O
individualized	O
learning	O
strategies	O
can	O
help	O
such	O
technologies	O
be	O
more	O
inclusive	O
for	O
students	O
who	O
make	O
less	O
-	O
common	O
mistakes	O
or	O
have	O
different	O
prior	O
backgrounds	O
(	O
Lee	O
and	O
Brunskill	O
,	O
2012	O
)	O
.	O
However	O
,	O
our	O
method	O
is	O
subject	O
to	O
biases	O
found	O
in	O
the	O
training	O
data	O
,	O
and	O
careful	O
consideration	O
of	O
using	O
safe	O
and	O
appropriate	O
data	O
is	O
crucial	O
in	O
an	O
education	O
context	O
.	O
Moreover	O
,	O
our	O
specific	O
use	O
of	O
pre	O
-	O
trained	O
LMs	O
relies	O
on	O
the	O
significant	O
progress	O
of	O
NLP	O
tools	O
for	O
English	O
language	O
-further	O
research	O
and	O
development	O
of	O
these	O
tools	O
for	O
other	O
languages	O
can	O
help	O
ensure	O
our	O
method	O
benefits	O
a	O
larger	O
population	O
of	O
students	O
.	O

We	O
also	O
discuss	O
the	O
effects	O
on	O
the	O
number	O
of	O
categories	O
.	O
Table	O
7	O
compares	O
different	O
models	O
under	O
10	O
-	O
way	O
1	O
-	O
shot	O
and	O
10	O
-	O
way	O
5	O
-	O
shot	O
settings	O
.	O
We	O
draw	O
similar	O
conclusions	O
from	O
this	O
table	O
as	O
in	O
Table	O
1	O
that	O
our	O
method	O
still	O
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
.	O

•	O
to	O
use	O
transfer	O
learning	O
via	O
the	O
warm	O
-	O
start	O
strategy	O
,	O
and	O

The	O
emergence	O
of	O
deep	O
pre	O
-	O
trained	O
contextualized	O
encoders	O
has	O
had	O
a	O
major	O
impact	O
on	O
the	O
field	O
of	O
natural	O
language	O
processing	O
.	O
Boosted	O
by	O
the	O
availability	O
of	O
general	O
-	O
purpose	O
frameworks	O
like	O
AllenNLP	B-MethodName
and	O
Transformers	B-MethodName
(	O
Wolf	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
pre	O
-	O
trained	O
models	O
like	O
ELMO	B-MethodName
and	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
have	O
caused	O
a	O
shift	O
towards	O
simple	O
architectures	O
where	O
a	O
strong	O
pre	O
-	O
trained	O
encoder	O
is	O
paired	O
with	O
a	O
shallow	O
downstream	O
model	O
,	O
often	O
outperforming	O
the	O
intricate	O
task	O
-	O
specific	O
architectures	O
of	O
the	O
past	O
.	O

Both	O
World	O
Values	O
Survey	O
and	O
PEW	O
survey	O
are	O
publicly	O
available	O
to	O
use	O
for	O
research	O
purposes	O
.	O
We	O
accept	O
and	O
follow	O
the	O
terms	O
and	O
conditions	O
for	O
using	O
these	O
datasets	O
,	O
which	O
can	O
be	O
found	O
in	O
https	O
:	O
/	O
/	O
www.worldvaluessurvey	O
.	O
org	O
/	O
WVSContents.jsp	O
?	O
CMSID	O
=	O
Documentation	O
,	O
and	O
https	O
:	O
/	O
/	O
www.pewresearch.org	O
/	O
about	O
/	O
terms	O
-	O
and	O
-	O
conditions	O
/	O
.	O

A	O
dog	O
ravenously	O
eats	O
a	O
pie	O
in	O
a	O
pet	O
restaurant	O
In	O
a	O
pet	O
restaurant	O
a	O
dog	O
eats	O
a	O
pie	O
ravenously	O

Post	O
-	O
pretraining	O
embedding	O
alignment	O
is	O
an	O
efficient	O
means	O
of	O
improving	O
cross	O
-	O
lingual	O
transferability	O
of	O
pretrained	O
multilingual	O
LMs	O
,	O
especially	O
when	O
pretraining	O
from	O
scratch	O
is	O
not	O
feasible	O
.	O
We	O
showed	O
that	O
our	O
self	O
-	O
supervised	O
sentence	O
-	O
level	O
and	O
word	O
-	O
level	O
alignment	O
tasks	O
can	O
greatly	O
improve	O
mBERT	B-MethodName
's	O
performance	O
on	O
downstream	O
tasks	O
of	O
NLI	O
and	O
QA	O
,	O
and	O
the	O
method	O
can	O
potentially	O
be	O
applied	O
to	O
improve	O
other	O
pretrained	O
multilingual	O
LMs	O
.	O

Effects	O
of	O
Initialization	O
.	O
Before	O
downstream	O
adaptation	O
,	O
additional	O
parameters	O
(	O
e.g.	O
,	O
extra	O
modules	O
defined	O
by	O
delta	O
tuning	O
,	O
the	O
classification	O
head	O
,	O
etc	O
.	O
)	O
may	O
be	O
introduced	O
;	O
in	O
addition	O
,	O
Wu	O
et	O
al	O
.	O
(	O
2022	O
)	O
recently	O
show	O
that	O
adding	O
noise	O
to	O
the	O
pretrained	O
weights	O
improves	O
the	O
fine	O
-	O
tuning	O
performance	O
on	O
downstream	O
tasks	O
.	O
Thus	O
,	O
both	O
finetuning	O
and	O
delta	O
tuning	O
require	O
proper	O
initialization	O
for	O
the	O
tunable	O
parameters	O
.	O
Since	O
different	O
initialization	O
could	O
lead	O
to	O
distinct	O
optimization	O
trajectories	O
,	O
we	O
explore	O
the	O
effects	O
of	O
initialization	O
on	O
PLM	O
's	O
mode	O
connectivity	O
.	O

(	O
a	O
)	O
Parameter	O
-	O
sharing	O
of	O
AR	O
decoders	O
.	O
As	O
all	O
AR	O
decoders	O
are	O
homogeneous	O
,	O
we	O
can	O
tie	O
their	O
parameters	O
to	O
reduce	O
the	O
total	O
number	O
of	O
parameters	O
.	O

Deep	O
pre	O
-	O
trained	O
contextualized	O
encoders	O
like	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
demonstrate	O
remarkable	O
performance	O
on	O
a	O
range	O
of	O
downstream	O
tasks	O
.	O
A	O
recent	O
line	O
of	O
research	O
in	O
probing	O
investigates	O
the	O
linguistic	O
knowledge	O
implicitly	O
learned	O
by	O
these	O
models	O
during	O
pretraining	O
.	O
While	O
most	O
work	O
in	O
probing	O
operates	O
on	O
the	O
task	O
level	O
,	O
linguistic	O
tasks	O
are	O
rarely	O
uniform	O
and	O
can	O
be	O
represented	O
in	O
a	O
variety	O
of	O
formalisms	O
.	O
Any	O
linguistics	O
-	O
based	O
probing	O
study	O
thereby	O
inevitably	O
commits	O
to	O
the	O
formalism	O
used	O
to	O
annotate	O
the	O
underlying	O
data	O
.	O
Can	O
the	O
choice	O
of	O
formalism	O
affect	O
probing	O
results	O
?	O
To	O
investigate	O
,	O
we	O
conduct	O
an	O
in	O
-	O
depth	O
cross	O
-	O
formalism	O
layer	O
probing	O
study	O
in	O
role	O
semantics	O
.	O
We	O
find	O
linguistically	O
meaningful	O
differences	O
in	O
the	O
encoding	O
of	O
semantic	O
role	O
-	O
and	O
proto	O
-	O
role	O
information	O
by	O
BERT	B-MethodName
depending	O
on	O
the	O
formalism	O
and	O
demonstrate	O
that	O
layer	O
probing	O
can	O
detect	O
subtle	O
differences	O
between	O
the	O
implementations	O
of	O
the	O
same	O
linguistic	O
formalism	O
.	O
Our	O
results	O
suggest	O
that	O
linguistic	O
formalism	O
is	O
an	O
important	O
dimension	O
in	O
probing	O
studies	O
and	O
should	O
be	O
investigated	O
along	O
with	O
the	O
commonly	O
used	O
cross	O
-	O
task	O
and	O
cross	O
-	O
lingual	O
experimental	O
settings	O
.	O

As	O
the	O
input	O
corpus	O
for	O
training	O
our	O
model	O
,	O
we	O
use	O
the	O
December	O
2018	O
version	O
of	O
Wikipedia	O
,	O
comprising	O
approximately	O
3.5	O
billion	O
words	O
and	O
11	O
million	O
entity	O
annotations	O
.	O
We	O
generate	O
input	O
sequences	O
by	O
splitting	O
the	O
content	O
of	O
each	O
page	O
into	O
sequences	O
comprising	O
≤	O
512	O
words	O
and	O
their	O
entity	O
annotations	O
(	O
i.e.	O
,	O
hyperlinks	O
)	O
.	O
The	O
input	O
text	O
is	O
tokenized	O
using	O
BERT	B-MethodName
's	O
tokenizer	O
with	O
its	O
vocabulary	O
consisting	O
of	O
V	O
w	O
=	O
30	O
,	O
000	O
words	O
.	O
Similar	O
to	O
Ganea	O
and	O
Hofmann	O
(	O
2017	O
)	O
,	O
we	O
create	O
an	O
entity	O
vocabulary	O
consisting	O
of	O
V	O
e	O
=	O
128	O
,	O
040	O
entities	O
,	O
which	O
are	O
contained	O
in	O
the	O
entity	O
candidates	O
in	O
the	O
datasets	O
used	O
in	O
our	O
experiments	O
.	O

The	O
high	O
precision	O
indicates	O
that	O
our	O
secondary	O
annotator	O
marks	O
essentially	O
the	O
same	O
mentions	O
as	O
our	O
primary	O
annotator	O
,	O
but	O
recall	O
suggests	O
a	O
few	O
missing	O
cases	O
.	O
The	O
difference	O
in	O
marking	O
EXPERI	B-MethodName
-	I-MethodName
MENT	I-MethodName
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
the	O
primary	O
annotator	O
sometimes	O
marks	O
several	O
verbs	O
per	O
sentence	O
as	O
experiment	O
-	O
evoking	O
elements	O
,	O
connecting	O
them	O
with	O
same	O
exp	O
or	O
exp	O
variation	O
,	O
while	O
the	O
secondary	O
annotator	O
links	O
the	O
mentions	O
of	O
relevant	O
slots	O
to	O
the	O
first	O
experiment	O
-	O
evoking	O
element	O
(	O
see	O
also	O
Supplementary	O
Material	O
Section	O
B	O
)	O
.	O
Overall	O
,	O
the	O
high	O
agreement	O
between	O
domain	O
expert	O
annotators	O
indicates	O
high	O
data	O
quality	O
.	O
Identifying	O
experiment	O
slot	O
fillers	O
.	O
We	O
compute	O
agreement	O
on	O
the	O
task	O
of	O
identifying	O
the	O
slots	O
of	O
an	O
experiment	O
frame	O
filled	O
by	O
the	O
mentions	O
in	O
a	O
sentence	O
on	O
the	O
subset	O
of	O
sentences	O
that	O
both	O
annotators	O
marked	O
as	O
experiment	O
-	O
describing	O
.	O
Slot	O
fillers	O
are	O
the	O
dependents	O
of	O
the	O
respective	O
edges	O
starting	O
at	O
the	O
experiment	O
-	O
evoking	O
element	O
.	O
Table	O
4	O
shows	O
F1	O
scores	O
for	O
the	O
most	O
frequent	O
ones	O
among	O
those	O
categories	O
.	O
See	O
Supplementary	O
Material	O
Section	O
C	O
for	O
all	O
slot	O
types	O
.	O
Overall	O
,	O
our	O
agreement	O
study	O
provides	O
support	O
for	O
the	O
high	O
quality	O
of	O
our	O
annotation	O
scheme	O
and	O
validates	O
the	O
annotated	O
dataset	O
.	O

We	O
identify	O
three	O
natural	O
levels	O
of	O
approximation	O
for	O
score	O
(	O
X	O
→	O
Y	O
Z	O
)	O
,	O
which	O
we	O
explicate	O
below	O
.	O

As	O
mentioned	O
above	O
,	O
relevant	O
entity	O
mentions	O
and	O
their	O
types	O
are	O
only	O
annotated	O
for	O
sentences	O
containing	O
experiment	O
information	O
and	O
neighboring	O
sentences	O
.	O
Therefore	O
,	O
we	O
here	O
compute	O
agreement	O
on	O
the	O
detection	O
of	O
entity	O
mention	O
and	O
type	O
assignment	O
on	O
the	O
subset	O
of	O
90	O
sentences	O
that	O
both	O
annotators	O
considered	O
as	O
containing	O
experimental	O
information	O
.	O
We	O
again	O
look	O
at	O
precision	O
and	O
recall	O
of	O
the	O
annotators	O
versus	O
each	O
other	O
,	O
see	O
Table	O
3	O
.	O

hension	O
,	O
algebra	O
,	O
and	O
deductive	O
logic	O
.	O
Meanwhile	O
,	O
pre	O
-	O
trained	O
LMs	O
can	O
effectively	O
handle	O
sequences	O
from	O
a	O
wide	O
range	O
of	O
modalities	O
(	O
Madani	O
et	O
al	O
.	O
,	O
2020;Polu	O
and	O
Sutskever	O
,	O
2020	O
)	O
.	O
In	O
this	O
work	O
,	O
we	O
focus	O
on	O
natural	O
language	O
sequences	O
,	O
where	O
recent	O
progress	O
in	O
language	O
modeling	O
has	O
shown	O
great	O
success	O
at	O
capturing	O
abstract	O
properties	O
of	O
language	O
(	O
Hewitt	O
and	O
Manning	O
,	O
2019;Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Specifically	O
,	O
we	O
show	O
how	O
pre	O
-	O
trained	O
LMs	O
can	O
be	O
easily	O
leveraged	O
to	O
adaptively	O
generate	O
questions	O
for	O
a	O
given	O
student	O
and	O
target	O
difficulty	O
in	O
a	O
reverse	O
translation	O
task	O
,	O
using	O
difficulty	O
at	O
answering	O
questions	O
as	O
a	O
proxy	O
for	O
more	O
complex	O
future	O
learning	O
objectives	O
.	O

The	O
key	O
insight	O
in	O
these	O
aggregated	O
results	O
is	O
that	O
while	O
FOP	O
-	O
based	O
methods	O
are	O
not	O
always	O
the	O
best	O
-	O
performing	O
system	O
for	O
each	O
metric	O
,	O
they	O
are	O
consistently	O
the	O
most	O
reliable	O
.	O
Specifically	O
,	O
CGMH	B-MethodName
has	O
high	O
success	O
rate	O
,	O
but	O
lowest	O
F1	O
and	O
human	O
scores	O
.	O
Prompt	O
,	O
on	O
the	O
other	O
hand	O
has	O
the	O
highest	O
human	O
evaluation	O
scores	O
but	O
the	O
worst	O
success	O
rate	O
.	O
This	O
is	O
not	O
too	O
surprising	O
.	O
It	O
is	O
,	O
after	O
all	O
,	O
an	O
unmodified	O
language	O
model	O
,	O
so	O
it	O
should	O
be	O
fluent	O
and	O
on	O
topic	O
when	O
viewed	O
by	O
a	O
human	O
.	O
However	O
,	O
given	O
its	O
extremely	O
low	O
success	O
rate	O
,	O
it	O
is	O
not	O
viable	O
for	O
long	O
-	O
form	O
controlled	O
generation	O
.	O
In	O
contrast	O
,	O
FOPbased	O
methods	O
are	O
either	O
the	O
top	O
1	O
or	O
2	O
performing	O
system	O
across	O
all	O
summary	O
statistics	O
.	O

WinoBias	O
(	O
Zhao	O
et	O
al	O
.	O
,	O
2018	O
)	O
is	O
an	O
intra	O
-	O
sentence	O
coreference	O
resolution	O
task	O
that	O
evaluates	O
a	O
system	O
's	O
ability	O
to	O
correctly	O
link	O
a	O
gendered	O
pronoun	O
to	O
an	O
occupation	O
across	O
both	O
pro	O
-	O
stereotypical	O
and	O
anti	O
-	O
stereotypical	O
contexts	O
.	O
Coreference	O
can	O
be	O
inferred	O
based	O
on	O
syntactic	O
cues	O
in	O
Type	O
1	O
sentences	O
or	O
on	O
more	O
challenging	O
semantic	O
cues	O
in	O
Type	O
2	O
sentences	O
.	O
We	O
first	O
fine	O
-	O
tune	O
the	O
model	O
on	O
the	O
OntoNotes	O
5.0	O
dataset	O
(	O
Hovy	O
et	O
al	O
.	O
,	O
2006	O
)	O
before	O
evaluating	O
on	O
the	O
WinoBias	O
benchmark	O
.	O
We	O
report	O
the	O
average	O
F1	O
-	O
scores	O
for	O
pro	O
-	O
stereotypical	O
and	O
anti	O
-	O
stereotypical	O
instances	O
,	O
and	O
the	O
true	O
positive	O
rate	O
difference	O
in	O
average	O
F1	O
-	O
scores	O
,	O
across	O
Type	O
1	O
and	O
Type	O
2	O
examples	O
.	O

1	O
.	O
Hypernym	O
Heuristic	O
:	O
a	O
premise	O
-	O
hypothesis	O
pair	O
satisfies	O
this	O
heuristic	O
if	O
specific	O
clinical	O
concept(s	O
)	O
appearing	O
in	O
the	O
premise	O
appear	O
in	O
a	O
more	O
general	O
form	O
in	O
the	O
hypothesis	O
.	O
Formally	O
:	O
{	O
(	O
p	O
,	O
h)|ϕ(p	O
)	O
ϕ(h	O
)	O
}	O
.	O
MeSH	O
tree	O
numbers	O
are	O
organized	O
hierarchically	O
,	O
and	O
increase	O
in	O
length	O
with	O
specificity	O
.	O
Thus	O
,	O
when	O
a	O
premise	O
entity	O
and	O
hypothesis	O
entity	O
are	O
leftaligned	O
,	O
the	O
hypothesis	O
entity	O
is	O
a	O
hypernym	O
for	O
the	O
premise	O
entity	O
if	O
the	O
hypothesis	O
entity	O
is	O
a	O
substring	O
of	O
the	O
premise	O
entity	O
.	O
To	O
provide	O
a	O
concrete	O
example	O
:	O
diabetes	O
mellitus	O
is	O
an	O
endocrine	O
system	O
disease	O
;	O
the	O
associated	O
MeSH	O
tree	O
numbers	O
are	O
C19.246	O
and	O
C19	O
,	O
respectively	O
.	O

In	O
this	O
study	O
,	O
you	O
will	O
negotiate	O
the	O
price	O
to	O
buy	O
or	O
sell	O
a	O
house	O
with	O
other	O
participants	O
.	O
The	O
study	O
consists	O
of	O
two	O
rounds	O
of	O
negotiation	O
.	O
The	O
person	O
you	O
negotiate	O
with	O
in	O
round	O
1	O
will	O
differ	O
from	O
the	O
person	O
you	O
negotiate	O
with	O
in	O
round	O
2	O
.	O
In	O
each	O
round	O
,	O
one	O
of	O
you	O
will	O
play	O
the	O
role	O
of	O
the	O
house	O
buyer	O
,	O
whereas	O
the	O
other	O
will	O
play	O
the	O
role	O
of	O
the	O
house	O
seller	O
.	O
In	O
both	O
rounds	O
,	O
you	O
will	O
play	O
the	O
same	O
role	O
as	O
either	O
buyer	O
or	O
seller	O
.	O

Our	O
final	O
controlled	O
argument	O
generation	O
pipeline	O
(	O
see	O
Figure	O
1	O
)	O
works	O
as	O
follows	O
:	O
(	O
1	O
)	O
We	O
gather	O
several	O
million	O
documents	O
for	O
eight	O
different	O
topics	O
from	O
two	O
large	O
data	O
sources	O
.	O
All	O
sentences	O
are	O
classified	O
into	O
pro-	O
,	O
con-	O
,	O
and	O
non	O
-	O
arguments	O
.	O
We	O
detect	O
aspects	O
of	O
all	O
arguments	O
with	O
a	O
model	O
trained	O
on	O
a	O
novel	O
dataset	O
and	O
concatenate	O
arguments	O
with	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
into	O
training	O
documents	O
.	O
(	O
2	O
)	O
We	O
use	O
the	O
collected	O
classified	O
data	O
to	O
condition	O
the	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
on	O
the	O
topics	O
,	O
stances	O
,	O
and	O
aspects	O
of	O
all	O
gathered	O
arguments	O
.	O

As	O
shown	O
in	O
the	O
figure	O
,	O
the	O
points	O
of	O
the	O
base	O
models	O
(	O
left	O
magenta	O
plots	O
)	O
scatters	O
over	O
a	O
wider	O
range	O
,	O
whereas	O
our	O
SIEF	O
training	O
(	O
right	O
cyan	O
plots	O
)	O
makes	O
them	O
more	O
concentrated	O
on	O
the	O
diagonal	O
,	O
indicating	O
that	O
the	O
prediction	O
P	O
ij	O
on	O
the	O
entire	O
document	O
is	O
mostly	O
the	O
same	O
asP	O

The	O
manner	O
of	O
transfer	O
conveniently	O
also	O
introduces	O
a	O
possibility	O
of	O
backdoor	O
injection	O
on	O
PET	O
.	O
Most	O
existing	O
works	O
focus	O
on	O
the	O
fine	O
-	O
tuning	O
of	O
pretrained	O
models	O
through	O
different	O
training	O
methods	O
to	O
enable	O
backdoor	O
injection	O
into	O
the	O
model	O
(	O
Kurita	O
et	O
al	O
.	O
,	O
2020	O
;	O
Li	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Because	O
of	O
the	O
difference	O
in	O
the	O
form	O
of	O
attack	O
targets	O
in	O
two	O
scenarios	O
,	O
the	O
effectiveness	O
of	O
these	O
consolidation	O
attack	O
methods	O
is	O
limited	O
on	O
PET	O
.	O
In	O
the	O
new	O
paradigm	O
,	O
the	O
PLMs	O
are	O
frozen	O
and	O
the	O
attack	O
object	O
transfers	O
to	O
PET	O
modules	O
.	O
The	O
change	O
from	O
full	O
-	O
parameter	O
fine	O
-	O
tuning	O
to	O
fine	O
-	O
tuning	O
a	O
small	O
number	O
of	O
parameters	O
will	O
be	O
more	O
prone	O
to	O
backdoor	O
forgetting	O
.	O

Prior	O
work	O
(	O
Raiman	O
and	O
Raiman	O
,	O
2018;Cao	O
et	O
al	O
.	O
,	O
2018;Wu	O
et	O
al	O
.	O
,	O
2020;Févry	O
et	O
al	O
.	O
,	O
2020	O
)	O
reports	O
higher	O
accuracies	O
on	O
the	O
TAC	B-MethodName
data	O
but	O
they	O
are	O
fundamentally	O
incomparable	O
with	O
our	O
numbers	O
due	O
to	O
the	O
simple	O
fact	O
that	O
we	O
are	O
solving	O
a	O
different	O
task	O
with	O
three	O
key	O
differences	O
:	O
(	O
1	O
)	O
Models	O
in	O
prior	O
work	O
are	O
trained	O
and	O
evaluated	O
using	O
mentions	O
that	O
link	O
to	O
the	O
same	O
KB	O
.	O
On	O
the	O
contrary	O
,	O
we	O
show	O
how	O
far	O
we	O
can	O
go	O
without	O
such	O
in	O
-	O
KB	O
training	O
mentions	O
.	O

MLQA	B-MethodName
is	O
an	O
evaluation	O
dataset	O
for	O
QA	O
that	O
covers	O
seven	O
languages	O
.	O
The	O
dataset	O
is	O
derived	O
from	O
a	O
three	O
step	O
process	O
.	O
We	O
focus	O
on	O
XLT	B-MethodName
in	O
this	O
work	O
.	O
For	O
zero	O
-	O
shot	O
crosslingual	O
transfer	O
,	O
we	O
train	O
on	O
the	O
English	O
SQuAD	O
v1.1	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
training	O
set	O
.	O
For	O
translate	O
-	O
train	O
,	O
we	O
train	O
on	O
translation	O
data	O
provided	O
in	O
Hu	O
et	O
al	O
.	O
(	O
2020	O
)	O
5	O

Table	O
12	O
reports	O
full	O
statistics	O
for	O
the	O
task	O
of	O
identifying	O
experiment	O
-	O
describing	O
sentences	O
,	O
including	O
precision	O
and	O
recall	O
in	O
the	O
dev	O
setting	O
.	O

Furthermore	O
,	O
we	O
find	O
that	O
the	O
confidence	O
-	O
order	O
model	O
works	O
especially	O
well	O
for	O
mentions	O
that	O
require	O
a	O
highly	O
detailed	O
context	O
to	O
resolve	O
.	O
For	O
example	O
,	O
a	O
mention	O
of	O
"	O
Matthew	O
Burke	O
"	O
can	O
refer	O
to	O
two	O
different	O
former	O
Australian	O
rugby	O
players	O
.	O
Although	O
the	O
local	O
and	O
natural	O
-	O
order	O
models	O
incorrectly	O
resolve	O
this	O
mention	O
to	O
the	O
player	O
who	O
has	O
the	O
larger	O
number	O
of	O
occurrences	O
in	O
our	O
Wikipediabased	O
corpus	O
,	O
the	O
confidence	O
-	O
order	O
model	O
successfully	O
resolves	O
this	O
by	O
disambiguating	O
its	O
contextual	O
mentions	O
,	O
including	O
his	O
teammates	O
,	O
in	O
advance	O
.	O
We	O
provide	O
detailed	O
inference	O
sequence	O
of	O
the	O
corresponding	O
document	O
in	O
Appendix	O
D.	O

To	O
annotate	O
a	O
single	O
error	O
in	O
S	O
i	O
,	O
annotators	O
select	O
the	O
error	O
span	O
t	O
j	O
∈	O
S	O
i	O
and	O
the	O
coherence	O
error	O
type	O
e	O
j	O
(	O
error	O
taxonomy	O
outlined	O
in	O
Section	O
3.2	O
)	O
to	O
construct	O
the	O
error	O
triple	O
a	O
j	O
=	O
(	O
S	O
i	O
,	O
t	O
j	O
,	O
e	O
j	O
)	O
.	O
This	O
process	O
is	O
repeated	O
until	O
all	O
errors	O
in	O
segment	O
S	O
i	O
have	O
been	O
added	O
,	O
after	O
which	O
they	O
proceed	O
to	O
the	O
next	O
segment	O
S	O
i+1	O
for	O
annotation	O
.	O
At	O
the	O
end	O
of	O
the	O
annotation	O
,	O
workers	O
produce	O
the	O
full	O
set	O
of	O
annotations	O
A	O
=	O
{	O
a	O
j	O
∀j	O
}	O
across	O
all	O
the	O
text	O
segments	O
.	O
The	O
outcome	O
of	O
this	O
is	O
shown	O
in	O
Figure	O
2	O
.	O

-DOCSTART-	O
Unsupervised	O
multiple	O
-	O
choice	O
question	O
generation	O
for	O
out	O
-	O
of	O
-	O
domain	O
Q&A	O
fine	O
-	O
tuning	O

We	O
conduct	O
our	O
experiments	O
on	O
the	O
SciQ	B-MethodName
dataset	O
(	O
Welbl	O
et	O
al	O
.	O
,	O
2017	O
choice	O
questions	O
(	O
4	O
choices	O
)	O
featuring	O
subjects	O
centered	O
around	O
physics	O
,	O
biology	O
and	O
chemistry	O
.	O
An	O
example	O
of	O
question	O
can	O
be	O
found	O
in	O
Figure	O
1	O
.	O
We	O
focus	O
on	O
the	O
SciQ	B-MethodName
dataset	O
because	O
it	O
has	O
not	O
yet	O
been	O
used	O
for	O
training	O
UnifiedQA	B-MethodName
and	O
it	O
requires	O
precise	O
scientific	O
knowledge	O
.	O
Furthermore	O
,	O
our	O
experiments	O
reveal	O
that	O
the	O
direct	O
application	O
of	O
UnifiedQA	B-MethodName
on	O
the	O
SciQ	B-MethodName
benchmark	O
leads	O
to	O
a	O
much	O
lower	O
performance	O
than	O
when	O
fine	O
-	O
tuning	O
it	O
on	O
the	O
SciQ	B-MethodName
training	O
set	O
(	O
see	O
Section	O
4	O
)	O
.	O
Our	O
objective	O
in	O
this	O
work	O
is	O
to	O
solve	O
this	O
gap	O
between	O
UnifiedQA	B-MethodName
and	O
UnifiedQA	B-MethodName
fine	O
-	O
tuned	O
on	O
supervised	O
data	O
with	O
the	O
unsupervised	O
question	O
generation	O
approach	O
described	O
in	O
Section	O
2	O
.	O
We	O
additionally	O
test	O
our	O
method	O
on	O
two	O
commonly	O
used	O
multiple	O
choice	O
question	O
answering	O
datasets	O
:	O
Common	B-MethodName
-	I-MethodName
senseQA	I-MethodName
(	O
Talmor	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
QASC	B-MethodName
.	O
These	O
datasets	O
contain	O
questions	O
with	O
similar	O
domains	O
to	O
SciQ	B-MethodName
even	O
though	O
the	O
questions	O
are	O
slightly	O
less	O
specific	O
.	O
Furthermore	O
,	O
neither	O
of	O
them	O
has	O
been	O
used	O
during	O
the	O
initial	O
training	O
of	O
UnifiedQA	B-MethodName
.	O

In	O
Algorithm	O
1	O
,	O
we	O
detail	O
the	O
procedure	O
for	O
obtaining	O
label	O
assignments	O
for	O
our	O
synthetic	O
tasks	O
.	O
Given	O
that	O
our	O
rules	O
are	O
in	O
an	O
"	O
IF	O
...	O
THEN	O
..	O
"	O
format	O
,	O
we	O
split	O
each	O
rule	O
into	O
an	O
antecedent	O
and	O
a	O
consequent	O
based	O
on	O
the	O
position	O
of	O
THEN	O
.	O
Note	O
that	O
our	O
voting	O
-	O
based	O
approach	O
to	O
choose	O
the	O
final	O
label	O
for	O
an	O
example	O
helps	O
to	O
tackle	O
(	O
1	O
)	O
negation	O
on	O
a	O
label	O
for	O
multiclass	O
tasks	O
and	O
(	O
2	O
)	O
choose	O
the	O
most	O
suited	O
label	O
in	O
case	O
antecedents	O
from	O
multiple	O
rules	O
are	O
satisfied	O
by	O
an	O
example	O
.	O

(	O
1	O
)	O
identifying	O
sentences	O
describing	O
relevant	O
experiments	O
,	O
(	O
2	O
)	O
identifying	O
mentions	O
of	O
materials	O
,	O
values	O
,	O
and	O
devices	O
,	O
and	O
(	O
3	O
)	O
recognizing	O
mentions	O
of	O
slots	O
and	O
their	O
values	O
related	O
to	O
these	O
experiments	O
.	O
We	O
propose	O
and	O
compare	O
several	O
machine	O
learning	O
methods	O
for	O
the	O
different	O
sub	O
-	O
tasks	O
,	O
including	O
bidirectional	O
long	O
-	O
short	O
term	O
memory	O
(	O
BiLSTM	O
)	O
networks	O
and	O
BERT	O
-	O
based	O
models	O
.	O
In	O
our	O
results	O
,	O
BERT	O
-	O
based	O
models	O
show	O
superior	O
performance	O
.	O
However	O
,	O
with	O
increasing	O
complexity	O
of	O
the	O
task	O
,	O
it	O
is	O
beneficial	O
to	O
combine	O
the	O
two	O
approaches	O
.	O

To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
two	O
novel	O
and	O
effective	O
types	O
of	O
soft	O
noise	O
to	O
enable	O
safer	O
exploration	O
,	O
namely	O
High	O
-	O
temperature	O
Generation	O
and	O
Soft	O
Pseudo	O
Text	O
,	O
in	O
what	O
follows	O
.	O

Morphological	O
Difference	O
.	O
The	O
morphology	O
of	O
table	O
headers	O
differs	O
from	O
that	O
of	O
plain	O
text	O
in	O
the	O
following	O
four	O
aspects	O
.	O
First	O
,	O
headers	O
are	O
always	O
phrases	O
and	O
they	O
usually	O
contain	O
a	O
lot	O
of	O
domainspecific	O
abbreviations	O
(	O
e.g.	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
,	O
"	O
No	O
.	O
"	O
is	O
the	O
abbreviation	O
of	O
"	O
Number	O
"	O
and	O
the	O
"	O
Loc	O
.	O
"	O
is	O
short	O
for	O
"	O
Location	O
"	O
)	O
and	O
special	O
symbols	O
(	O
e.g.	O
,	O
"	O
$	O
"	O
means	O
"	O
dollar	O
"	O
in	O
Figure	O
1	O
)	O
.	O
Second	O
,	O
verb	O
-	O
object	O
phrases	O
are	O
frequently	O
used	O
as	O
headers	O
which	O
indicate	O
a	O
subject	O
-	O
object	O
relationship	O
between	O
two	O
columns	O
.	O
For	O
example	O
,	O
"	O
Hosted	O
by	O
"	O
in	O
Figure	O
1	O
indicates	O
a	O
host	O
relationship	O
between	O
the	O
second	O
and	O
the	O
third	O
columns	O
.	O
Third	O
,	O
special	O
tokenizations	O
like	O
CamelCase	B-MethodName
and	O
underscore	O
are	O
idiomatic	O
usages	O
in	O
headers	O
.	O
At	O
last	O
,	O
capitalized	O
words	O
are	O
particularly	O
preferred	O
in	O
order	O
to	O
capture	O
more	O
readers	O
'	O
attention	O
for	O
headers	O
.	O
These	O
special	O
word	O
-	O
forms	O
are	O
commonly	O
used	O
in	O
headers	O
but	O
rarely	O
seen	O
in	O
plain	O
text	O
.	O
Therefore	O
,	O
the	O
NMT	B-MethodName
models	O
trained	O
with	O
a	O
massive	O
amount	O
of	O
plain	O
text	O
can	O
not	O
be	O
directly	O
applied	O
to	O
schema	O
translation	O
.	O

In	O
order	O
to	O
alleviate	O
the	O
noisy	O
label	O
problem	O
in	O
the	O
DS	O
data	O
,	O
we	O
construct	O
a	O
pre	O
-	O
denoising	O
DocRE	B-MethodName
model	O
to	O
generate	O
pseudo	O
labels	O
.	O
As	O
shown	O
in	O
Figure	O
2	O
(	O
a	O
)	O
,	O
we	O
adopt	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
to	O
capture	O
the	O
contextual	O
representation	O
{	O
z	O
i	O
}	O
n	O
i=1	O
,	O
where	O
n	O
is	O
the	O
number	O
of	O
tokens	O
in	O
a	O
document	O
.	O
We	O
also	O
adopt	O
a	O
dropout	O
layer	O
to	O
enhance	O
the	O
generalization	O
ability	O
of	O
our	O
DocRE	B-MethodName
model	O
.	O

We	O
first	O
experiment	O
with	O
text	O
-	O
only	O
models	O
,	O
including	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
POLITICS	B-MethodName
(	O
Liu	O
et	O
al	O
.	O
,	O
2022a	O
)	O
,	O
a	O
RoBERTa	O
model	O
further	O
pretrained	O
with	O
a	O
political	O
ideology	O
objective	O
and	O
thus	O
specialized	O
for	O
ideology	O
prediction	O
and	O
stance	O
detection	O
.	O

Then	O
we	O
feed	O
them	O
to	O
the	O
relational	O
aware	O
layers	O
and	O
get	O
the	O
final	O
contextualized	O
sequence	O
of	O
embedding	O
X	O

Fast	O
Pseudo	O
-	O
Log	O
-	O
Likelihood	O
Scoring	O

a.	O
Despite	O
surface	O
-	O
level	O
differences	O
,	O
the	O
sentences	O
express	O
the	O
same	O
meaning	O
,	O
suggesting	O
an	O
underlying	O
semantic	O
representation	O
in	O
which	O
these	O
sentences	O
are	O
equivalent	O
.	O
One	O
such	O
representation	O
is	O
offered	O
by	O
role	O
semantics	O
-a	O
shallow	O
predicatesemantic	O
formalism	O
closely	O
related	O
to	O
syntax	O
.	O
In	O
terms	O
of	O
role	O
semantics	O
,	O
Mary	O
,	O
book	O
and	O
John	O
are	O
semantic	O
arguments	O
of	O
the	O
predicate	O
give	O
,	O
and	O
are	O
assigned	O
roles	O
from	O
a	O
pre	O
-	O
defined	O
inventory	O
,	O
for	O
example	O
,	O
Agent	O
,	O
Recipient	O
and	O
Theme	O
.	O

•	O
Olive	O
Garden	O
is	O
the	O
place	O
that	O
makes	O
the	O
best	O
pastas	O
.	O
I	O
try	O
to	O
visit	O
the	O
place	O
as	O
much	O
I	O
can	O
with	O
my	O
friends	O
•	O
I	O
love	O
Olive	O
Garden	O
especially	O
the	O
original	O
one	O
in	O
Orlando	O
they	O
opened	O
in	O
1982	O
.	O

The	O
attributes	O
k	O
i	O
collectively	O
form	O
the	O
schema	O
of	O
KB	O
.	O
The	O
disambiguation	O
of	O
each	O
m	O
∈	O
M	O
is	O
aided	O
by	O
the	O
context	O
c	O
in	O
which	O
m	O
appears	O
.	O

We	O
evaluate	O
fine	O
-	O
tuning	O
the	O
Electric	O
model	O
on	O
the	O
GLUE	O
natural	O
language	O
understanding	O
benchmark	O
and	O
the	O
SQuAD	O
2.0	O
question	O
answering	O
dataset	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
We	O
report	O
exact	O
-	O
match	O
for	O
SQuAD	B-MethodName
,	O
average	O
score	O
3	O
over	O
the	O
GLUE	O
tasks	O
4	O
,	O
and	O
accuracy	O
on	O
the	O
multi	O
-	O
genre	O
natural	O
language	O
inference	O
GLUE	O
task	O
.	O
Reported	O
scores	O
are	O
medians	O
over	O
10	O
fine	O
-	O
tuning	O
runs	O
with	O
different	O
random	O
seeds	O
.	O
We	O
use	O
the	O
same	O
finetuning	O
setup	O
and	O
hyperparameters	O
as	O
ELECTRA	B-MethodName
.	O

The	O
argument	O
aspect	O
detection	O
dataset	O
contains	O
a	O
total	O
of	O
5,032	O
samples	O
in	O
JSONL	O
-	O
format	O
,	O
i.e.	O
each	O
dataset	O
sample	O
has	O
a	O
separate	O
line	O
and	O
can	O
be	O
parsed	O
as	O
JSON	O
.	O
A	O
sample	O
contains	O
the	O
keys	O
:	O

The	O
experimental	O
results	O
show	O
that	O
MRD	O
greatly	O
improves	O
downstream	O
task	O
performance	O
and	O
pretraining	O
efficiency	O
(	O
and	O
more	O
discussion	O
on	O
MRD	O
in	O
Appendix	O
A	O
)	O
.	O

Finally	O
,	O
equipped	O
with	O
the	O
relation	O
-	O
aware	O
module	O
,	O
CAST	B-MethodName
can	O
make	O
the	O
best	O
use	O
of	O
the	O
context	O
and	O
obtain	O
significant	O
improvement	O
over	O
H2H	O
across	O
all	O
settings	O
.	O
For	O
models	O
based	O
on	O
M2M-100	O
,	O
CAST	B-MethodName
outperforms	O
H2H	O
by	O
2.6	O
,	O
1.4	O
,	O
0.3	O
,	O
1.8	O
,	O
and	O
1.9	O
BLEU	B-MethodName
in	O
En	O
-	O
Zh	O
,	O
En	O
-	O
Es	O
,	O
En	O
-	O
Fr	O
,	O
En	O
-	O
De	O
,	O
and	O
En	O
-	O
Ja	O
,	O
respectively	O
.	O
When	O
it	O
comes	O
to	O
models	O
based	O
on	O
MBart-50M2	O
M	O
,	O
CAST	O
obtains	O
1.6	O
,	O
2.7	O
,	O
1.9	O
,	O
0.9	O
,	O
0.2	O
improvements	O
of	O
BLEU	B-MethodName
points	O
over	O
H2H	O
in	O
translating	O
schema	O
from	O
En	O
to	O
5	O
target	O
languages	O
.	O
It	O
is	O
also	O
noticeable	O
that	O
CAST	B-MethodName
can	O
help	O
denoise	O
the	O
concatenated	O
context	O
for	O
H2H+CXT	O
.	O
For	O
instance	O
,	O
CAST	O
based	O
on	O
M2M-100	B-MethodName
achieves	O
1.5	O
and	O
1.2	O
improvements	O
of	O
BLEU	B-MethodName
points	O
over	O
H2H+CXT	O
for	O
schema	O
translation	O
from	O
En	O
to	O
Es	O
and	O
Fr	O
respectively	O
.	O
This	O
improvement	O
shows	O
CAST	B-MethodName
can	O
better	O
model	O
the	O
target	O
header	O
and	O
its	O
context	O
.	O
We	O
also	O
run	O
a	O
Wilcoxon	O
signed	O
-	O
rank	O
tests	O
between	O
CAST	B-MethodName
and	O
H2H+CXT	O
and	O
the	O
results	O
show	O
the	O
improvement	O
are	O
significant	O
with	O
p	O
<	O
0.05	O
in	O
3	O
out	O
of	O
5	O
languages	O
.	O
For	O
the	O
rest	O
of	O
the	O
languages	O
CAST	B-MethodName
achieves	O
comparable	O
results	O
.	O

Compared	O
to	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
which	O
use	O
250k	O
parallel	O
sentences	O
per	O
language	O
from	O
the	O
same	O
sources	O
as	O
we	O
do	O
for	O
post	O
-	O
pretraining	O
alignment	O
,	O
our	O
250k	O
model	O
does	O
better	O
for	O
all	O
languages	O
considered	O
and	O
we	O
do	O
not	O
rely	O
on	O
the	O
word	O
-	O
to	O
-	O
word	O
pre	O
-	O
alignment	O
step	O
using	O
FastAlign	B-MethodName
,	O
which	O
is	O
prone	O
to	O
error	O
propagation	O
to	O
the	O
rest	O
of	O
the	O
pipeline	O
.	O

In	O
traditional	O
entity	O
linking	O
,	O
the	O
training	O
mentions	O
M	O
train	O
and	O
test	O
mentions	O
M	O
test	O
both	O
link	O
to	O
the	O
same	O
KB	O
.	O
Even	O
in	O
the	O
zero	O
-	O
shot	O
settings	O
of	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
while	O
the	O
training	O
and	O
target	O
domains	O
and	O
KBs	O
are	O
mutually	O
exclusive	O
,	O
the	O
schema	O
of	O
the	O
KB	O
is	O
constant	O
and	O
known	O
.	O
On	O
the	O
contrary	O
,	O
our	O
goal	O
is	O
to	O
link	O
test	O
mentions	O
M	O
test	O
to	O
a	O
knowledge	O
base	O
KB	O
test	O
which	O
is	O
not	O
known	O
during	O
training	O
.	O
The	O
objective	O
is	O
to	O
train	O
models	O
on	O
mentions	O
M	O
train	O
that	O
link	O
to	O
KB	O
train	O
and	O
directly	O
use	O
these	O
models	O
to	O
link	O
M	O
test	O
to	O
KB	O
test	O
.	O

Overall	O
Summ	O
.	O
Trans	O
.	O
vite	O
more	O
errors	O
(	O
13	O
∼	O
47	O
%	O
)	O
.	O
This	O
verifies	O
our	O
assumption	O
that	O
the	O
pipeline	O
annotation	O
protocol	O
,	O
which	O
ignores	O
valuable	O
input	O
context	O
,	O
can	O
lead	O
to	O
poor	O
data	O
quality	O
.	O

We	O
plot	O
the	O
loss	O
on	O
FewRel	B-MethodName
training	O
set	O
and	O
the	O
5	O
-	O
way	O
1	O
-	O
shot	O
accuracy	O
on	O
FewRel	B-MethodName
validation	O
set	O
as	O
functions	O
of	O
the	O
number	O
of	O
iterations	O
.	O
As	O
we	O
can	O
see	O
from	O
Figure	O
8	O

Under	O
this	O
taxonomy	O
,	O
a	O
common	O
error	O
(	O
33	O
%	O
)	O
is	O
predicting	O
a	O
more	O
specific	O
entity	O
than	O
that	O
indicated	O
by	O
the	O
mention	O
(	O
the	O
city	O
of	O
Hartford	O
,	O
Connecticut	O
,	O
rather	O
than	O
the	O
state	O
)	O
.	O
The	O
reverse	O
is	O
also	O
observed	O
(	O
i.e.	O
the	O
model	O
predicts	O
a	O
more	O
general	O
entity	O
)	O
,	O
but	O
far	O
less	O
frequently	O
(	O
6	O
%	O
)	O
.	O
Another	O
major	O
error	O
category	O
(	O
33	O
%	O
)	O
is	O
when	O
the	O
model	O
fails	O
to	O
pick	O
up	O
the	O
correct	O
signals	O
from	O
the	O
context	O
and	O
assigns	O
a	O
similarly	O
named	O
entity	O
of	O
a	O
similar	O
type	O
(	O
e.g.	O
the	O
river	O
Mobile	O
,	O
instead	O
of	O
the	O
city	O
Mobile	O
,	O
both	O
of	O
which	O
are	O
locations	O
)	O
.	O
21	O
%	O
of	O
the	O
errors	O
are	O
cases	O
where	O
the	O
model	O
predicts	O
an	O
entity	O
that	O
is	O
related	O
to	O
the	O
gold	O
entity	O
,	O
but	O
is	O
neither	O
more	O
specific	O
,	O
nor	O
more	O
generic	O
,	O
but	O
rather	O
of	O
a	O
different	O
type	O
(	O
Santos	O
Football	O
Club	O
instead	O
of	O
the	O
city	O
of	O
Santos	O
)	O
.	O

For	O
each	O
position	O
t	O
=	O
1	O
to	O
n	O
:	O
add	O
to	O
the	O
loss	O
−	O
log	O

Data	O
Limitations	O
Regarding	O
the	O
HyperRED	O
dataset	O
,	O
the	O
distant	O
supervision	O
method	O
of	O
data	O
collection	O
may	O
not	O
align	O
all	O
valid	O
facts	O
present	O
in	O
the	O
text	O
articles	O
.	O
This	O
is	O
due	O
to	O
the	O
possible	O
incompleteness	O
of	O
the	O
knowledge	O
graph	O
which	O
is	O
an	O
open	O
research	O
challenge	O
(	O
Nickel	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
On	O
the	O
other	O
hand	O
,	O
it	O
is	O
not	O
feasible	O
to	O
manually	O
annotate	O
all	O
possible	O
facts	O
due	O
to	O
constraints	O
in	O
annotation	O
time	O
and	O
cost	O
.	O
Furthermore	O
,	O
there	O
are	O
a	O
large	O
number	O
of	O
relation	O
and	O
qualifier	O
labels	O
to	O
consider	O
,	O
resulting	O
in	O
a	O
challenging	O
task	O
for	O
human	O
annotators	O
.	O
A	O
promising	O
and	O
practical	O
method	O
to	O
address	O
the	O
challenges	O
in	O
distant	O
supervision	O
is	O
to	O
adopt	O
a	O
human	O
-	O
in	O
-	O
theloop	O
annotation	O
scheme	O
for	O
RE	O
(	O
Tan	O
et	O
al	O
.	O
,	O
2022b	O
)	O
.	O

The	O
reference	O
data	O
was	O
crawled	O
from	O
two	O
debate	O
portals	O
8	O
and	O
consists	O
of	O
pro	O
-	O
and	O
con	O
-	O
paragraphs	O
discussing	O
the	O
eight	O
topics	O
of	O
the	O
UKP	B-MethodName
-	O
Corpus	I-MethodName
.	O
As	O
the	O
paragraphs	O
may	O
include	O
non	O
-	O
arguments	O
,	O
we	O
filter	O
these	O
out	O
by	O
classifying	O
all	O
sentences	O
with	O
the	O
ArgumenText	B-MethodName
API	O
into	O
arguments	O
and	O
nonarguments	O
.	O
This	O
leaves	O
us	O
with	O
349	O
pro	O
-	O
and	O
355	O
con	O
-	O
arguments	O
over	O
all	O
topics	O
(	O
see	O
App	O
.	O
D	O
for	O
the	O
topic	O
-	O
wise	O
distribution	O
)	O
.	O
Next	O
,	O
we	O
detect	O
all	O
aspects	O
in	O
these	O
arguments	O
.	O
Arguments	O
with	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
are	O
then	O
grouped	O
and	O
used	O
as	O
reference	O
for	O
arguments	O
from	O
the	O
(	O
a	O
)	O
generated	O
arguments	O
and	O
(	O
b	O
)	O
retrieval	O
approach	O
arguments	O
if	O
these	O
hold	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
.	O
The	O
results	O
reveal	O
that	O
both	O
the	O
average	O
METEOR	B-MethodName
and	O
ROUGE	O
-	I-MethodName
L	I-MethodName
scores	O
are	O
only	O
marginally	O
lower	O
than	O
the	O
retrieval	O
scores	O
(	O
METEOR	O
is	O
0.5/1.1	O
points	O
lower	O
for	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
/Arg	O
-	O
CTRL	O
CC	O
,	O
see	O
Table	O
5	O
)	O
.	O
It	O
not	O
only	O
shows	O
the	O
strength	O
of	O
the	O
architecture	O
,	O
but	O
also	O
the	O
success	O
in	O
generating	O
sound	O
aspect	O
-	O
specific	O
arguments	O
with	O
our	O
approach	O
.	O
Overlap	O
with	O
Training	O
Data	O
We	O
find	O
arguments	O
generated	O
by	O
the	O
models	O
to	O
be	O
genuine	O
,	O
i.e.	O
demonstrating	O
substantial	O
differences	O
to	O
the	O
training	O
data	O
.	O
For	O
each	O
of	O
the	O
7,991	O
generated	O
arguments	O
,	O
we	O
find	O
the	O
most	O
similar	O
argument	O
in	O
the	O
training	O
data	O
based	O
on	O
the	O
cosine	O
similarity	O
of	O
their	O
BERT	B-MethodName
embeddings	O
We	O
compare	O
all	O
models	O
by	O
verifying	O
whether	O
or	O
not	O
the	O
aspect	O
used	O
for	O
generation	O
(	O
including	O
synonyms	O
and	O
their	O
stems	O
and	O
lemmas	O
)	O
can	O
be	O
found	O
in	O
the	O
generated	O
arguments	O
.	O
For	O
the	O
original	O
models	O
conditioned	O
on	O
aspects	O
,	O
this	O
is	O
true	O
in	O
79	O
%	O
of	O
Generated	O
sentence	O
:	O
We	O
do	O
n't	O
need	O
more	O
gun	O
control	O
laws	O
when	O
we	O
already	O
have	O
enough	O
restrictions	O
on	O
who	O
can	O
buy	O
guns	O
in	O
this	O
country	O
.	O

Step	O
15k	O
Effects	O
of	O
Data	O
Domain	O
.	O
PLMs	O
are	O
shown	O
to	O
generalize	O
well	O
on	O
out	O
-	O
of	O
-	O
distribution	O
data	O
(	O
Hendrycks	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
implying	O
the	O
connection	O
of	O
minima	O
trained	O
with	O
different	O
data	O
distributions	O
.	O
To	O
gain	O
a	O
deeper	O
understanding	O
,	O
we	O
choose	O
two	O
natural	O
language	O
inference	O
datasets	O
(	O
MNLI	B-MethodName
and	O
ANLI	B-MethodName
(	O
Nie	O
et	O
al	O
.	O
,	O
2020	O
)	O
)	O
,	O
and	O
two	O
sentiment	O
analysis	O
datasets	O
(	O
Rotten	O
Tomatoes	O
(	O
Pang	O
and	O
Lee	O
,	O
2005	O
)	O
and	O
Yelp	B-MethodName
Polarity	I-MethodName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2015	O
)	O
)	O
sourced	O
from	O
different	O
domains	O
.	O
Then	O
we	O
fine	O
-	O
tune	O
two	O
copies	O
of	O
T5	B-MethodName
BASE	I-MethodName
on	O
two	O
datasets	O
of	O
the	O
same	O
task	O
,	O
and	O
evaluate	O
the	O
linear	O
mode	O
connectivity	O
between	O
two	O
minima	O
.	O
Note	O
previous	O
works	O
typically	O
study	O
mode	O
connectivity	O
on	O
the	O
same	O
dataset	O
;	O
while	O
in	O
our	O
setting	O
,	O
we	O
extend	O
the	O
analysis	O
by	O
evaluating	O
the	O
interpolations	O
on	O
two	O
datasets	O
.	O

FrameNet	B-MethodName
takes	O
a	O
meaning	O
-	O
driven	O
stance	O
on	O
the	O
role	O
encoding	O
by	O
modeling	O
it	O
in	O
terms	O
of	O
frame	O
semantics	O
:	O
predicates	O
are	O
grouped	O
into	O
frames	O
(	O
e.g.	O
Commerce	O
buy	O
)	O
,	O
which	O
specify	O
role	O
-	O
like	O
slots	O
to	O
be	O
filled	O
.	O
FrameNet	B-MethodName
offers	O
fine	O
-	O
grained	O
frame	O
distinctions	O
,	O
and	O
roles	O
in	O
FrameNet	B-MethodName
are	O
frame	O
-	O
specific	O
,	O
e.g.	O
Buyer	O
,	O
Seller	O
and	O
Money	O
.	O
The	O
resource	O
accompanies	O
each	O
frame	O
with	O
a	O
description	O
of	O
the	O
situation	O
and	O
its	O
core	O
and	O
peripheral	O
participants	O
.	O

C1	O
.	O
Did	O
you	O
report	O
the	O
number	O
of	O
parameters	O
in	O
the	O
models	O
used	O
,	O
the	O
total	O
computational	O
budget	O
(	O
e.g.	O
,	O
GPU	O
hours	O
)	O
,	O
and	O
computing	O
infrastructure	O
used	O
?	O
No	O
response	O
.	O

The	O
authors	O
would	O
like	O
to	O
thank	O
colleagues	O
from	O
Amazon	O
AI	O
for	O
many	O
helpful	O
discussions	O
that	O
shaped	O
this	O
work	O
,	O
and	O
for	O
reading	O
and	O
providing	O
feedback	O
on	O
earlier	O
drafts	O
of	O
the	O
paper	O
.	O
They	O
also	O
thank	O
all	O
the	O
anonymous	O
reviewers	O
for	O
their	O
helpful	O
feedback	O
.	O

We	O
advocate	O
the	O
adoption	O
of	O
a	O
mechanism	O
design	O
perspective	O
,	O
so	O
as	O
to	O
develop	O
modified	O
annotation	O
tasks	O
that	O
reduce	O
the	O
cognitive	O
load	O
placed	O
on	O
expert	O
annotators	O
while	O
incentivizing	O
the	O
production	O
of	O
domain	O
-	O
specific	O
NLI	O
datasets	O
with	O
high	O
downstream	O
utility	O
(	O
Ho	O
et	O
al	O
.	O
,	O
2015;Liu	O
and	O
Chen	O
,	O
2017	O
)	O
.	O
An	O
additional	O
option	O
is	O
to	O
narrow	O
the	O
generative	O
scope	O
by	O
defining	O
a	O
set	O
of	O
inferences	O
deemed	O
to	O
be	O
useful	O
for	O
a	O
specific	O
task	O
.	O
Annotators	O
can	O
then	O
map	O
(	O
premise	O
,	O
relation	O
)	O
tuples	O
to	O
relation	O
-	O
satisfying	O
,	O
potentially	O
fuzzy	O
subsets	O
of	O
this	O
pool	O
of	O
useful	O
inferences	O
,	O
or	O
return	O
partial	O
functions	O
when	O
more	O
information	O
is	O
needed	O
.	O

Training	O
Settings	O
.	O
We	O
measure	O
performance	O
of	O
various	O
models	O
in	O
both	O
finetuned	O
and	O
zero	O
-	O
shot	O
settings	O
.	O
First	O
,	O
we	O
directly	O
finetune	O
the	O
base	O
pretrained	O
model	O
on	O
the	O
model	O
on	O
MEETINGQA	O
.	O
Next	O
,	O
to	O
supplement	O
training	O
data	O
we	O
explore	O
intermediatetraining	O
(	O
Phang	O
et	O
al	O
.	O
,	O
2018	O
;	O
Pruksachatkun	O
et	O
al	O
.	O
,	O
2020	O
)	O
with	O
SQuAD	O
v2.0	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2018	O
)	O
6	O
or	O
a	O
combination	O
including	O
silver	O
data	O
from	O
Section	O
3.3	O
prior	O
to	O
finetuning	O
on	O
MEETINGQA	O
,	O
increasing	O
the	O
training	O
data	O
by	O
5x	O
and	O
10x	O
respectively	O
.	O
Additional	O
details	O
on	O
checkpoints	O
,	O
hyperparameters	O
,	O
and	O
training	O
are	O
present	O
in	O
Appendix	O
B	O
.	O

For	O
the	O
kNN	O
approach	O
,	O
we	O
compare	O
the	O
performance	O
by	O
using	O
only	O
the	O
query	O
-	O
document	O
similarity	O
for	O
obtaining	O
the	O
relevance	O
score	O
(	O
i.e.	O
dropping	O
the	O
second	O
term	O
in	O
Equation	O
1	O
)	O
.	O
On	O
average	O
this	O
results	O
in	O
a	O
drop	O
of	O
5.6	O
percentage	O
points	O
,	O
proving	O
the	O
effectiveness	O
of	O
injecting	O
feedback	O
documents	O
in	O
the	O
kNN	O
re	O
-	O
ranking	O
approach	O
.	O

•	O
The	O
binary	O
classifier	O
is	O
trained	O
to	O
distinguish	O
positive	O
vs	O
negative	O
data	O
points	O
,	O
with	O
k	O
negatives	O
sampled	O
for	O
every	O
n	O
positive	O
data	O
points	O
.	O

First	O
,	O
we	O
compare	O
the	O
effects	O
of	O
recency	O
of	O
the	O
event	O
described	O
(	O
TIMESINCEEVENT	O
:	O
a	O
continuous	O
variable	O
representing	O
the	O
log	O
time	O
since	O
the	O
event	O
)	O
.	O
9	O
Then	O
,	O
we	O
contrast	O
recalled	O
stories	O
to	O
their	O
retold	O
counterparts	O
in	O
pairwise	O
comparisons	O
.	O
Finally	O
,	O
we	O
measure	O
the	O
effect	O
of	O
how	O
frequently	O
the	O
experienced	O
event	O
is	O
thought	O
or	O
talked	O
about	O
(	O
FREQUENCYOFRECALL	O
:	O
a	O
continuous	O
variable	O
ranging	O
from	O
very	O
rarely	O
to	O
very	O
frequently	O
)	O
.	O
10	O
As	O
in	O
§	O
4	O
,	O
we	O
Holm	O
-	O
correct	O
for	O
multiple	O
comparisons	O
.	O

C.1	O
Linearity	O
with	O
Varying	O
Context	O
Size	O
Shown	O
in	O
Figure	O
5	O
,	O
we	O
compare	O
the	O
negative	O
loglikelihood	O
of	O
sentences	O
when	O
conditioned	O
on	O
varying	O
history	O
sizes	O
(	O
using	O
the	O
story	O
summary	O
as	O
context	O
E	O
)	O
.	O
As	O
expected	O
,	O
conditioning	O
on	O
longer	O
histories	O
increases	O
the	O
predictability	O
of	O
a	O
sentence	O
.	O
However	O
,	O
this	O
effect	O
is	O
significantly	O
larger	O
for	O
imagined	O
stories	O
,	O
which	O
suggests	O
that	O
imagined	O
stories	O
flow	O
more	O
linearly	O
than	O
recalled	O
stories	O
.	O

Can	O
these	O
differences	O
affect	O
the	O
probing	O
results	O
?	O
This	O
question	O
is	O
intriguing	O
for	O
several	O
reasons	O
.	O
Lin	O
-	O
guistic	O
formalisms	O
are	O
well	O
-	O
documented	O
,	O
and	O
if	O
the	O
choice	O
of	O
formalism	O
indeed	O
has	O
an	O
effect	O
on	O
probing	O
,	O
cross	O
-	O
formalism	O
comparison	O
will	O
yield	O
new	O
insights	O
into	O
the	O
linguistic	O
knowledge	O
obtained	O
by	O
contextualized	O
encoders	O
during	O
pre	O
-	O
training	O
.	O
If	O
,	O
alternatively	O
,	O
the	O
probing	O
results	O
remain	O
stable	O
despite	O
substantial	O
differences	O
between	O
formalisms	O
,	O
this	O
prompts	O
a	O
further	O
scrutiny	O
of	O
what	O
the	O
pretrained	O
encoders	O
in	O
fact	O
encode	O
.	O
Finally	O
,	O
on	O
the	O
reverse	O
side	O
,	O
cross	O
-	O
formalism	O
probing	O
might	O
be	O
used	O
as	O
a	O
tool	O
to	O
empirically	O
compare	O
the	O
formalisms	O
and	O
their	O
language	O
-	O
specific	O
implementations	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
we	O
are	O
the	O
first	O
to	O
explicitly	O
address	O
the	O
influence	O
of	O
formalism	O
on	O
probing	O
.	O

We	O
follow	O
the	O
method	O
used	O
by	O
the	O
original	O
paper	O
on	O
MetaQA	B-MethodName
to	O
build	O
the	O
relation	O
graph	O
of	O
KQA	B-MethodName
Pro	O
.	O
As	O
mentioned	O
in	O
Section	O
5.2	O
,	O
we	O
use	O
half	O
of	O
its	O
KB	O
triples	O
as	O
the	O
label	O
form	O
.	O
We	O
constructe	O
the	O
text	O
form	O
by	O
extracting	O
sentences	O
from	O
Wikipedia	O
.	O
Following	O
the	O
original	O
paper	O
,	O
we	O
use	O
exact	O
match	O
of	O
surface	O
forms	O
for	O
entity	O
recognition	O
Algorithm	O
2	O
Generation	O
of	O
HQDT	O
Input	O
:	O
a	O
complex	O
question	O
q	O
0	O
,	O
a	O
question	O
decomposer	O
M	O
θ	O
,	O
a	O
question	O
generator	O
M	O
ϕ	O
.	O
Output	O
:	O
a	O
list	O
T	O
representing	O
the	O
HQDT	O
,	O
where	O
element	O
(	O
q	O
i	O
,	O
p	O
i	O
g	O
,	O
f	O
ai	O
)	O
in	O
T	O
denote	O
a	O
sub	O
-	O
question	O
q	O
i	O
,	O
certainty	O
score	O
of	O
q	O
i	O
and	O
the	O
father	O
of	O
q	O
i	O
,	O
respectively	O
.	O

As	O
there	O
are	O
no	O
existing	O
models	O
for	O
hyper	O
-	O
relational	O
extraction	O
,	O
we	O
introduce	O
two	O
strong	O
baselines	O
that	O
leverage	O
pretrained	O
language	O
models	O
.	O
The	O
pipeline	O
baseline	O
is	O
based	O
on	O
a	O
competitive	O
table	O
-	O
filling	O
model	O
for	O
joint	O
entity	O
and	O
relation	O
extraction	O
,	O
while	O
the	O
generative	O
baseline	O
is	O
extended	O
from	O
a	O
state	O
-	O
ofthe	O
-	O
art	O
approach	O
for	O
end	O
-	O
to	O
-	O
end	O
relation	O
extraction	O
.	O

Our	O
statistical	O
model	O
(	O
see	O
Table	O
4	O
)	O
reveals	O
similar	O
conclusions	O
:	O
we	O
see	O
the	O
main	O
factor	O
of	O
P	O
(	O
β	O
=	O
0.0148	O
,	O
p	O
<	O
1e-15	O
)	O
is	O
significant	O
and	O
its	O
interaction	O
with	O
G	O
(	O
β	O
=	O
-0.0032	O
,	O
p	O
<	O
0.053	O
)	O
are	O
marginally	O
significant	O
.	O
This	O
indicates	O
that	O
P	O
is	O
generally	O
positive	O
correlated	O
with	O
performance	O
gain	O
and	O
there	O
is	O
a	O
weak	O
tendency	O
that	O
the	O
coefficients	O
of	O
P	O
reduces	O
as	O
G	O
increases	O
.	O
In	O
other	O
words	O
,	O
paraphrasing	O
improves	O
the	O
downstream	O
performance	O
but	O
becomes	O
less	O
effective	O
when	O
adding	O
more	O
gold	O
data	O
(	O
a	O
similar	O
trend	O
is	O
also	O
seen	O
in	O
Figure	O
1	O
)	O
.	O

•	O
Entity	O
/	O
Pronoun	O
/	O
Date	O
/	O
Number	O
Swap	O
(	O
ES	O
/	O
PS	O
/	O
DS	O
/	O
NS	O
)	O
:	O
An	O
NER	O
system	O
is	O
first	O
applied	O
to	O
both	O
source	O
and	O
target	O
text	O
.	O
The	O
entities	O
from	O
the	O
target	O
text	O
are	O
randomly	O
swapped	O
with	O
entities	O
from	O
the	O
source	O
text	O
if	O
they	O
share	O
the	O
same	O
entity	O
type	O
.	O

The	O
authors	O
would	O
like	O
to	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
insightful	O
comments	O
.	O
This	O
work	O
was	O
supported	O
by	O
the	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
62076133	O
and	O
62006117	O
)	O
,	O
and	O
the	O
Natural	O
Science	O
Foundation	O
of	O
Jiangsu	O
Province	O
for	O
Young	O
Scholars	O
(	O
BK20200463	O
)	O
and	O
Distinguished	O
Young	O
Scholars	O
(	O
BK20200018	O
)	O
.	O

iii	O
We	O
inspect	O
few	O
-	O
shot	O
and	O
zero	O
-	O
shot	O
word	O
-	O
level	O
quality	O
estimation	O
with	O
the	O
bilingual	O
and	O
multilingual	O
models	O
.	O
We	O
report	O
how	O
the	O
sourcetarget	O
direction	O
,	O
domain	O
and	O
MT	O
type	O
affect	O
the	O
predictions	O
for	O
a	O
new	O
language	O
pair	O
.	O

Given	O
the	O
dialogue	O
context	O
C	O
and	O
the	O
retrieved	O
knowledge	O
K	O
,	O
we	O
first	O
encode	O
them	O
into	O
distributed	O
representations	O
with	O
contextualized	O
encoders	O
.	O
Specifically	O
,	O
we	O
add	O
special	O
tokens	O
to	O
differentiate	O
the	O
roles	O
of	O
user	O
and	O
system	O
as	O
well	O
as	O
different	O
types	O
of	O
knowledge	O
as	O
:	O
Pretrained	O
language	O
models	O
(	O
PLMs	O
)	O
,	O
e.g.	O
,	O
GPT2	B-MethodName
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
have	O
shown	O
superior	O
capability	O
of	O
generating	O
high	O
-	O
quality	O
responses	O
in	O
many	O
dialogue	O
systems	O
,	O
especially	O
those	O
PLMs	O
pretrained	O
on	O
dialogue	O
corpus	O
,	O
e.g.	O
,	O
BlenderBot	O
(	O
Roller	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
To	O
leverage	O
the	O
advantages	O
of	O
these	O
generative	O
PLMs	O
,	O
we	O
reformulate	O
the	O
mixedinitiative	O
emotional	O
support	O
conversation	O
problem	O
as	O
a	O
Seq2Seq	O
problem	O
,	O
which	O
linearizes	O
the	O
input	O
and	O
output	O
as	O
a	O
sequence	O
of	O
tokens	O
as	O
follows	O
:	O

Baseline	O
.	O
We	O
choose	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
NMT	B-MethodName
models	O
,	O
including	O
M2M-100	O
and	O
MBart-50M2	B-MethodName
M	O
(	O
Tang	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
as	O
our	O
baselines	O
.	O
Specifically	O
,	O
both	O
of	O
the	O
baseline	O
models	O
employ	O
the	O
Transformer	B-MethodName
sequence	O
-	O
to	O
-	O
sequence	O
architecture	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
to	O
capture	O
features	O
from	O
source	O
language	O
input	O
and	O
generate	O
the	O
translation	O
.	O
The	O
M2M-100	O
is	O
directly	O
trained	O
on	O
large	O
-	O
scaled	O
translation	O
data	O
while	O
MBart-50M2	O
M	O
is	O
firstly	O
pre	O
-	O
trained	O
with	O
a	O
"	O
Multilingual	O
Denoising	O
Pretraining	O
"	O
objective	O
and	O
then	O
fine	O
-	O
tuned	O
in	O
machine	O
-	O
translation	O
task	O
.	O
We	O
evaluate	O
the	O
baseline	O
models	O
with	O
the	O
following	O
settings	O
:	O

•	O
Waseem	O
:	O
The	O
authors	O
of	O
(	O
Waseem	O
and	O
Hovy	O
,	O
2016	O
)	O
kindly	O
provided	O
the	O
dataset	O
to	O
us	O
by	O
email	O
.	O
We	O
considered	O
"	O
racism	O
"	O
and	O
"	O
sexism	O
"	O
examples	O
as	O
"	O
Abusive	O
"	O
and	O
"	O
neither	O
"	O
examples	O
as	O
"	O
Non	O
-	O
abusive	O
"	O
.	O

We	O
present	O
a	O
novel	O
message	O
-	O
passing	O
mechanism	O
over	O
the	O
learned	O
hierarchical	O
graph	O
.	O
This	O
mechanism	O
realizes	O
the	O
inter	O
-	O
sentence	O
reasoning	O
where	O
connectors	O
can	O
aggregate	O
information	O
from	O
their	O
related	O
information	O
nodes	O
while	O
propagating	O
the	O
information	O
to	O
others	O
.	O
For	O
the	O
i	O
-	O
th	O
sentence	O
node	O
,	O
the	O
edge	O
marginal	O
controls	O
the	O
aggregation	O
from	O
its	O
K	O
information	O
nodes	O
;	O
and	O
the	O
root	O
probability	O
controls	O
the	O
neighbouring	O
information	O
is	O
combined	O
as	O
i	O
-	O
th	O
node	O
's	O
update	O
u	O
(	O
l	O
)	O
in	O
the	O
l	O
-	O
th	O
reasoning	O
layer	O
,	O

To	O
identify	O
the	O
shortcomings	O
of	O
our	O
best	O
model	O
,	O
we	O
categorize	O
100	O
random	O
mentions	O
that	O
are	O
incorrectly	O
linked	O
by	O
this	O
model	O
into	O
six	O
categories	O
(	O
demonstrated	O
with	O
examples	O
in	O
Table	O
6	O
)	O
,	O
inspired	O
by	O
the	O
taxonomy	O
of	O
.	O

To	O
understand	O
how	O
the	O
model	O
M	O
works	O
,	O
we	O
analyze	O
the	O
patterns	O
or	O
characteristics	O
of	O
the	O
input	O
that	O
activate	O
each	O
feature	O
f	O
i	O
.	O
Specifically	O
,	O
using	O
LRP	O
1	O
,	O
for	O
each	O
f	O
i	O
of	O
an	O
example	O
x	O
j	O
in	O
the	O
training	O
dataset	O
,	O
we	O
calculate	O
a	O
relevance	O
vector	O
r	O
ij	O
∈	O
R	O
L	O
showing	O
the	O
relevance	O
scores	O
(	O
the	O
contributions	O
)	O
of	O
each	O
word	O
in	O
x	O
j	O
for	O
the	O
value	O
of	O
f	O
i	O
.	O
After	O
doing	O
this	O
for	O
all	O
d	O
features	O
of	O
all	O
training	O
examples	O
,	O
we	O
can	O
produce	O
word	O
clouds	O
to	O
help	O
the	O
users	O
better	O
understand	O
the	O
model	O
M	O
.	O
Word	O
clouds	O
-For	O
each	O
feature	O
f	O
i	O
,	O
we	O
create	O
(	O
one	O
or	O
more	O
)	O
word	O
clouds	O
to	O
visualize	O
the	O
patterns	O
in	O
the	O
input	O
texts	O
which	O
highly	O
activate	O
f	O
i	O
.	O
This	O
can	O
be	O
done	O
by	O
analyzing	O
r	O
ij	O
for	O
all	O
x	O
j	O
in	O
the	O
training	O
data	O
and	O
displaying	O
,	O
in	O
the	O
word	O
clouds	O
,	O
words	O
or	O
n	O
-	O
grams	O
which	O
get	O
high	O
relevance	O
scores	O
.	O
Note	O
that	O
different	O
model	O
architectures	O
may	O
have	O
different	O
ways	O
to	O
generate	O
the	O
word	O
clouds	O
so	O
as	O
to	O
effectively	O
reveal	O
the	O
behavior	O
of	O
the	O
features	O
.	O

Step	O
2	O
:	O
Annotation	O
scheme	O
Instead	O
of	O
free	O
spanlevel	O
annotations	O
,	O
we	O
present	O
annotators	O
with	O
a	O
ranked	O
list	O
of	O
aspect	O
recommendations	O
.	O
To	O
generate	O
meaningful	O
recommendations	O
,	O
we	O
train	O
a	O
ranking	O
model	O
using	O
the	O
preliminary	O
annotations	O
(	O
Step	O
1	O
)	O
.	O

Token	O
embedding	O
is	O
the	O
embedding	O
of	O
the	O
corresponding	O
token	O
.	O
The	O
matrices	O
of	O
the	O
word	O
and	O
entity	O
token	O
embeddings	O
are	O
represented	O
as	O
A	O
∈	O
R	O
Vw×H	O
and	O
B	O
∈	O
R	O
Ve×H	O
,	O
respectively	O
,	O
where	O
H	O
is	O
the	O
size	O
of	O
the	O
hidden	O
states	O
of	O
BERT	B-MethodName
,	O
and	O
V	O
w	O
and	O
V	O
e	O
are	O
the	O
number	O
of	O
items	O
in	O
the	O
word	O
vocabulary	O
and	O
that	O
of	O
the	O
entity	O
vocabulary	O
,	O
respectively	O
.	O

In	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
,	O
text	O
generation	O
is	O
an	O
important	O
research	O
topic	O
that	O
aims	O
to	O
automatically	O
produce	O
understandable	O
text	O
in	O
human	O
language	O
from	O
input	O
data	O
(	O
Li	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
In	O
recent	O
decades	O
,	O
various	O
approaches	O
have	O
been	O
widely	O
applied	O
to	O
a	O
variety	O
of	O
text	O
generation	O
tasks	O
Gehring	O
et	O
al	O
.	O
,	O
2017	O
;	O
Li	O
et	O
al	O
.	O
,	O
2021a	O
)	O
,	O
especially	O
the	O
emergence	O
of	O
pretrained	O
language	O
models	O
(	O
PLMs	O
)	O
(	O
Li	O
et	O
al	O
.	O
,	O
2021c	O
)	O
.	O
By	O
involving	O
large	O
-	O
scale	O
parameters	O
pretrained	O
on	O
massive	O
general	O
corpora	O
,	O
PLMs	O
such	O
as	O
GPT-3	B-MethodName
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O
have	O
achieved	O
substantial	O
progress	O
in	O
text	O
generation	O
.	O
Through	O
the	O
fine	O
-	O
tuning	O
paradigm	O
,	O
PLMs	O
can	O
adapt	O
to	O
various	O
text	O
generation	O
tasks	O
by	O
directly	O
adjusting	O
the	O
model	O
parameters	O
with	O
labelled	O
datasets	O
.	O

But	O
also	O
some	O
customers	O
believe	O
that	O
website	O
refunds	O
money	O
the	O
service	O
is	O
not	O
100	O
%	O
perfect	O
.	O

The	O
grammar	O
is	O
basically	O
accurate	O
,	O
but	O
there	O
are	O
some	O
problems	O
,	O
such	O
as	O
inaccurate	O
words	O
,	O
improper	O
collocation	O
,	O
and	O
insufficient	O
fluency	O
,	O
which	O
can	O
be	O
fixed	O
at	O
a	O
small	O
cost	O
.	O

LMs	O
towards	O
desired	O
attributes	O
.	O
Examples	O
include	O
using	O
reinforcement	O
learning	O
to	O
control	O
quality	O
metrics	O
(	O
Ranzato	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
adjusting	O
sampling	O
weights	O
to	O
control	O
for	O
poetry	O
style	O
(	O
Ghazvininejad	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
and	O
learning	O
to	O
condition	O
on	O
valence	O
or	O
domain	O
-	O
specific	O
codes	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019;Peng	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O

Fully	O
detached	O
are	O
the	O
easiest	O
to	O
detect	O
.	O
As	O
expected	O
,	O
fully	O
detached	O
hallucinations	O
are	O
the	O
easiest	O
to	O
detect	O
:	O
all	O
methods	O
detect	O
them	O
entirely	O
when	O
taking	O
20	O
%	O
of	O
the	O
hallucination	O
dataset	O
(	O
Figure	O
4	O
)	O
,	O
and	O
they	O
are	O
the	O
most	O
frequent	O
among	O
the	O
examples	O
flagged	O
by	O
the	O
best	O
performing	O
methods	O
(	O
Figure	O
3	O
)	O
.	O
This	O
agrees	O
with	O
Guerreiro	O
et	O
al	O
.	O
(	O
2022	O
)	O
that	O
oscillatory	O
and	O
strongly	O
detached	O
hallucinations	O
are	O
more	O
difficult	O
to	O
detect	O
,	O
and	O
shows	O
that	O
improvements	O
with	O
our	O
methods	O
mostly	O
come	O
from	O
these	O
types	O
.	O

A	O
play	O
on	O
the	O
term	O
"	O
paperless	O
"	O
-	O
"	O
going	O
paperless	O
"	O
is	O
a	O
goal	O
for	O
many	O
companies	O
because	O
it	O
would	O
save	O
money	O
and	O
be	O
more	O
efficient	O
.	O
But	O
here	O
,	O
the	O
company	O
is	O
so	O
far	O
from	O
that	O
goal	O
that	O
they	O
have	O
a	O
tiger	O
on	O
top	O
of	O
their	O
filing	O
cabinet	O
.	O
So	O
instead	O
of	O
"	O
going	O
paperless	O
,	O
"	O
this	O
company	O
is	O
going	O
"	O
tiger	O
-	O
full	O
.	O
"	O

Topic	O
:	O
Nuclear	O
Energy	O
Argument	O
:	O
Running	O
nuclear	O
reactors	O
is	O
costly	O
as	O
it	O
involves	O
long	O
-	O
time	O
disposal	O
of	O
radioactive	O
waste	O
.	O

To	O
understand	O
BiLSTM	O
features	O
,	O
we	O
created	O
two	O
word	O
clouds	O
for	O
each	O
feature	O
.	O
The	O
first	O
word	O
cloud	O
contains	O
top	O
three	O
words	O
which	O
gain	O
the	O
highest	O
positive	O
relevance	O
scores	O
from	O
each	O
training	O
example	O
,	O
while	O
the	O
second	O
word	O
cloud	O
does	O
the	O
same	O
but	O
for	O
the	O
top	O
three	O
words	O
which	O
gain	O
the	O
lowest	O
negative	O
relevance	O
scores	O
(	O
see	O
Figure	O
11	O
)	O
.	O

For	O
English⇒German	O
,	O
the	O
training	O
set	O
consists	O
of	O
4.5	O
million	O
sentence	O
pairs	O
and	O
newstest2013	O
&	O
2014	O
are	O
used	O
as	O
the	O
dev	O
.	O
and	O
test	O
sets	O
,	O
respectively	O
.	O
BPE	B-MethodName
with	O
32	O
K	O
merge	O
operations	O
is	O
used	O
to	O
handle	O
low	O
-	O
frequency	O
words	O
.	O
For	O
Japanese⇒English	O
,	O
we	O
follow	O
Morishita	O
et	O
al	O
.	O
(	O
2017	O
)	O
to	O
use	O
the	O
first	O
two	O
sections	O
as	O
training	O
data	O
,	O
which	O
consists	O
of	O
2.0	O
million	O
sentence	O
pairs	O
.	O
The	O
dev	O
.	O
and	O
test	O
sets	O
contain	O
1790	O
and	O
1812	O
sentences	O
.	O
For	O
Chinese⇔English	O
,	O
we	O
follow	O
Hassan	O
et	O
al	O
.	O
(	O
2018	O
)	O
sentence	O
pairs	O
.	O
We	O
develop	O
on	O
devtest2017	O
and	O
test	O
on	O
newstest2017	O
.	O
We	O
use	O
SacreBLEU	B-MethodName
(	O
Post	O
,	O
2018	O
)	O
as	O
the	O
evaluation	O
metric	O
with	O
statistical	O
significance	O
test	O
(	O
Collins	O
et	O
al	O
.	O
,	O
2005	O
)	O
.	O
We	O
evaluate	O
the	O
proposed	O
XL	O
PE	I-MethodName
strategies	O
on	O
Transformer	B-MethodName
.	O
The	O
baseline	O
systems	O
include	O
Relative	B-MethodName
PE	I-MethodName
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
directional	O
SAN	O
(	O
DiSAN	O
,	O
Shen	O
et	O
al	O
.	O
2018	O
)	O
.	O
We	O
implement	O
them	O
on	O
top	O
of	O
OpenNMT	O
(	O
Klein	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
In	O
addition	O
,	O
we	O
report	O
the	O
results	O
of	O
previous	O
studies	O
(	O
Hao	O
et	O
al	O
.	O
,	O
2019;Chen	O
et	O
al	O
.	O
,	O
2019b	O
,	O
a;Du	O
and	O
Way	O
,	O
2017;Hassan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

(	O
4	O
)	O
Transfer	O
learning	O
incurs	O
further	O
improvement	O
,	O
with	O
scores	O
equal	O
or	O
better	O
to	O
the	O
ones	O
achieved	O
with	O
semi	O
-	O
supervised	O
NMT	B-MethodName
.	O
Here	O
,	O
each	O
metric	O
favors	O
a	O
different	O
setting	O
.	O
ChrF	O
indicates	O
a	O
significant	O
improvement	O
with	O
fine	O
tuning	O
,	O
TER	B-MethodName
prefers	O
warm	O
start	O
,	O
whereas	O
BLEU	B-MethodName
indicates	O
only	O
a	O
very	O
small	O
difference	O
between	O
the	O
two	O
.	O

With	O
the	O
developments	O
of	O
Neural	O
Machine	I-MethodName
Translation	I-MethodName
(	O
NMT	B-MethodName
)	O
systems	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014;Bahdanau	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
tremendous	O
success	O
has	O
been	O
achieved	O
by	O
existing	O
studies	O
on	O
machine	O
translation	O
tasks	O
.	O
For	O
instance	O
,	O
Vaswani	O
et	O
al	O
.	O
(	O
2017	O
)	O
greatly	O
improved	O
bilingual	O
machine	O
translation	O
systems	O
with	O
the	O
Transformer	B-MethodName
architectures	O
,	O
(	O
Edunov	O
et	O
al	O
.	O
,	O
2018	O
)	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
WMT	B-MethodName
'	O
14	O
English	O
-	O
German	O
tasks	O
with	O
back	O
-	O
translations	O
augmentation	O
,	O
Weng	O
et	O
al	O
.	O
(	O
2020	O
)	O
and	O
Yang	O
et	O
al	O
.	O
(	O
2020	O
)	O
explored	O
ways	O
to	O
boost	O
the	O
performance	O
of	O
NMT	B-MethodName
systems	O
with	O
pre	O
-	O
trained	O
language	O
models	O
.	O
Recent	O
works	O
saw	O
the	O
potential	O
to	O
improve	O
NMT	B-MethodName
models	O
in	O
many	O
-	O
to	O
-	O
many	O
settings	O
and	O
proposed	O
models	O
that	O
can	O
perform	O
machine	O
translation	O
on	O
various	O
language	O
pairs	O
.	O
While	O
the	O
above	O
-	O
mentioned	O
studies	O
focus	O
on	O
sentence	O
-	O
level	O
translation	O
in	O
plain	O
text	O
,	O
they	O
are	O
not	O
suitable	O
for	O
schema	O
translation	O
.	O

Layer	O
-	O
wise	O
Relevance	O
Propagation	O
(	O
LRP	O
)	O
is	O
a	O
technique	O
for	O
explaining	O
predictions	O
of	O
neural	O
networks	O
in	O
terms	O
of	O
importance	O
scores	O
of	O
input	O
features	O
(	O
Bach	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
Originally	O
,	O
it	O
was	O
devised	O
to	O
explain	O
predictions	O
of	O
image	O
classifiers	O
by	O
creating	O
a	O
heatmap	O
on	O
the	O
input	O
image	O
highlighting	O
pixels	O
that	O
are	O
important	O
for	O
the	O
classification	O
.	O
Then	O
Arras	O
et	O
al	O
.	O
(	O
2016	O
)	O
and	O
Arras	O
et	O
al	O
.	O
(	O
2017	O
)	O
extended	O
LRP	O
to	O
work	O
on	O
CNNs	O
and	O
RNNs	O
for	O
text	O
classification	O
,	O
respectively	O
.	O

The	O
combined	O
effect	O
size	O
of	O
each	O
of	O
the	O
models	O
is	O
examined	O
on	O
WEAT	O
stimulus	O
6	O
,	O
which	O
contains	O
target	O
words	O
of	O
career	O
/	O
family	O
and	O
attribute	O
words	O
of	O
male	O
/	O
female	O
names	O
.	O
This	O
was	O
the	O
only	O
one	O
that	O
detected	O
bias	O
on	O
a	O
pre	O
-	O
trained	O
RoBERTa	O
(	O
CES	O
close	O
to	O
0.5	O
and	O
p	O
<	O
0.05	O
)	O
.	O
The	O
points	O
that	O
we	O
kept	O
in	O
our	O
analysis	O
are	O
those	O
where	O
p	O
<	O
0.05	O
,	O
which	O
make	O
up	O
90	O
%	O
of	O
the	O
points	O
in	O
occupation	O
prediction	O
and	O
95	O
%	O
of	O
the	O
points	O
in	O
coreference	O
resolution	O
.	O

LGTM	B-MethodName
consistently	O
outperforms	O
other	O
baselines	O
in	O
most	O
of	O
the	O
tasks	O
except	O
competitive	O
results	O
on	O
SST-2	O
.	O
This	O
indicates	O
the	O
robustness	O
of	O
our	O
method	O
which	O
suggests	O
its	O
wide	O
usage	O
in	O
various	O
knowledge	O
distillation	O
settings	O
.	O

As	O
mentioned	O
previously	O
,	O
existing	O
meta	O
-	O
learning	O
methods	O
often	O
require	O
a	O
sufficiently	O
large	O
dataset	O
to	O
build	O
diverse	O
episodes	O
for	O
meta	O
-	O
training	O
.	O
Otherwise	O
,	O
the	O
performance	O
will	O
drop	O
seriously	O
.	O

where	O
I	O
m	O
denotes	O
the	O
imaginary	O
part	O
of	O
a	O
quaternion	O
representation	O
.	O

Concretely	O
,	O
MoCo	B-MethodName
employs	O
a	O
dual	O
-	O
encoder	O
architecture	O
.	O
Given	O
two	O
views	O
v	O
1	O
and	O
v	O
2	O
of	O
the	O
same	O
image	O
,	O
v	O
1	O
is	O
encoded	O
by	O
the	O
query	O
encoder	O
f	O
q	O
and	O
v	O
2	O
by	O
the	O
momentum	O
encoder	O
f	O
k	O
.	O
v	O
1	O
and	O
v	O
2	O
form	O
a	O
positive	O
pair	O
.	O
Negative	O
examples	O
are	O
views	O
of	O
different	O
source	O
images	O
,	O
and	O
are	O
stored	O
in	O
a	O
queue	O
∈	O
K	O
,	O
which	O
is	O
randomly	O
initialized	O
.	O
K	O
is	O
usually	O
a	O
large	O
number	O
(	O
e.g.	O
,	O
K	O
=	O
65	O
,	O
536	O
for	O
ImageNet	B-MethodName
)	O
.	O
Negative	O
pairs	O
are	O
formed	O
by	O
comparing	O
v	O
1	O
with	O
each	O
item	O
in	O
the	O
queue	O
.	O
Similarity	O
between	O
pairs	O
is	O
measured	O
by	O
dot	O
product	O
.	O
MoCo	B-MethodName
uses	O
the	O
InfoNCE	B-MethodName
loss	O
(	O
van	O
den	O
Oord	O
et	O
al	O
.	O
,	O
2019	O
)	O
to	O
bring	O
positive	O
pairs	O
closer	O
to	O
each	O
other	O
and	O
push	O
negative	O
pairs	O
apart	O
.	O
After	O
a	O
batch	O
of	O
view	O
pairs	O
are	O
processed	O
,	O
those	O
encoded	O
by	O
the	O
momentum	O
encoder	O
are	O
added	O
to	O
the	O
queue	O
as	O
negative	O
examples	O
for	O
future	O
queries	O
.	O
During	O
training	O
,	O
the	O
query	O
encoder	O
is	O
updated	O
by	O
the	O
optimizer	O
while	O
the	O
momentum	O
encoder	O
is	O
updated	O
by	O
the	O
exponential	O
moving	O
average	O
of	O
the	O
query	O
encoder	O
's	O
parameters	O
to	O
maintain	O
queue	O
consistency	O
:	O

Positive	O
F1	O
Accuracy	O
Macro	O
F1	O
Original	O
0.767	O
±	O
0.02	O
0.800	O
±	O
0.00	O
0.785	O
±	O
0.01	O
0.789	O
±	O
0.01	O
Disabling	O
(	O
MTurk	O
)	O
0.786	O
±	O
0.00	O
0.804	O
±	O
0.00	O
0.795	O
±	O
0.00	O
0.796	O
±	O
0.00	O

Compared	O
to	O
XLM	O
,	O
our	O
250k	O
,	O
600k	O
and	O
2	O
M	O
settings	O
represent	O
3.1	O
%	O
,	O
7	O
%	O
and	O
17.8	O
%	O
of	O
the	O
parallel	O
data	O
used	O
by	O
XLM	O
,	O
respectively	O
(	O
see	O
Table	O
1	O
)	O
.	O
The	O
XLM	O
model	O
also	O
has	O
45	O
%	O
more	O
parameters	O
than	O
ours	O
as	O
Table	O
3	O
shows	O
.	O
Furthermore	O
,	O
XLM	O
trained	O
with	O
MLM	O
only	O
is	O
already	O
significantly	O
better	O
than	O
mBERT	O
even	O
though	O
the	O
source	O
of	O
its	O
training	O
data	O
is	O
the	O
same	O
as	O
mBERT	O
from	O
Wikipedia	O
.	O
One	O
reason	O
could	O
be	O
that	O
XLM	O
contains	O
45	O
%	O
more	O
model	O
parameters	O
than	O
mBERT	O
as	O
model	O
depth	O
and	O
capacity	O
are	O
shown	O
to	O
be	O
key	O
to	O
cross	O
-	O
lingual	O
success	O
(	O
K	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Additionally	O
,	O
Wu	O
and	O
Dredze	O
(	O
2019	O
)	O
hypothesize	O
that	O
limiting	O
pretraining	O
to	O
the	O
languages	O
used	O
by	O
downstream	O
tasks	O
may	O
be	O
beneficial	O
since	O
XLM	O
models	O
are	O
pretrained	O
on	O
the	O
15	O
XNLI	O
languages	O
only	O
.	O
Our	O
2	O
M	O
model	O
bridges	O
the	O
gap	O
between	O
mBERT	O
and	O
XLM	O
from	O
7.5	O
%	O
to	O
2.8	O
%	O
for	O
zero	O
-	O
shot	O
transfer	O
.	O
Note	O
that	O
,	O
for	O
bg	O
,	O
our	O
total	O
processed	O
pool	O
of	O
en	O
-	O
bg	O
data	O
consists	O
of	O
456k	O
parallel	O
sentences	O
,	O
so	O
there	O
is	O
no	O
difference	O
in	O
en	O
-	O
bg	O
data	O
between	O
our	O
600k	O
and	O
2	O
M	O
settings	O
.	O
For	O
translatetrain	O
,	O
our	O
model	O
achieves	O
comparable	O
performance	O
to	O
XLM	O
with	O
the	O
further	O
help	O
of	O
code	O
-	O
switching	O
during	O
finetuning	O
.	O

We	O
train	O
two	O
Electric	O
models	O
the	O
same	O
size	O
as	O
BERT	B-MethodName
-	I-MethodName
Base	I-MethodName
(	O
110	O
M	O
parameters	O
):	O
one	O
on	O
Wikipedia	O
and	O
BooksCorpus	B-MethodName
(	O
Zhu	O
et	O
al	O
.	O
,	O
2015	O
)	O
for	O
comparison	O
with	O
BERT	B-MethodName
and	O
one	O
on	O
OpenWebTextCorpus	B-MethodName
(	O
Gokaslan	O
and	O
Cohen	O
,	O
2019	O
)	O
for	O
comparison	O
2	O
with	O
GPT-2	B-MethodName
.	O
The	O
noise	O
distribution	O
transformers	O
T	O
LTR	O
and	O
T	O
RTL	I-MethodName
are	O
1/4	O
the	O
hidden	O
size	O
of	O
Electric	O
.	O
We	O
do	O
no	O
hyperparameter	O
tuning	O
,	O
using	O
the	O
same	O
hyperparameter	O
values	O
as	O
ELECTRA	B-MethodName
.	O
Further	O
details	O
on	O
training	O
are	O
in	O
the	O
appendix	O
.	O

To	O
analyze	O
which	O
speaker	O
features	O
influence	O
codeswitch	O
predictions	O
,	O
we	O
ablate	O
a	O
phrase	O
,	O
corresponding	O
to	O
one	O
of	O
six	O
speaker	O
features	O
(	O
age	O
,	O
gender	O
,	O
country	O
of	O
origin	O
,	O
language	O
and	O
code	O
-	O
switching	O
preferences	O
,	O
and	O
speaker	O
order	O
)	O
.	O
Table	O
7	O
indicates	O
that	O
linguistic	O
preferences	O
are	O
most	O
influential	O
.	O

Most	O
importantly	O
,	O
Shapley	O
values	O
are	O
not	O
based	O
on	O
model	O
accuracy	O
or	O
performance	O
,	O
but	O
solely	O
on	O
the	O
model	O
's	O
input	O
and	O
its	O
prediction	O
,	O
e.g.	O
,	O
the	O
probability	O
for	O
an	O
image	O
and	O
a	O
caption	O
to	O
match	O
.	O
This	O
is	O
an	O
important	O
property	O
for	O
our	O
MM	O
score	O
,	O
since	O
its	O
objective	O
is	O
to	O
quantify	O
how	O
much	O
inputs	O
of	O
either	O
modality	O
matter	O
for	O
prediction	O
-even	O
if	O
the	O
cooperation	O
between	O
(	O
multimodal	O
)	O
inputs	O
is	O
not	O
sufficient	O
to	O
reach	O
success	O
,	O
i.e.	O
,	O
yielding	O
the	O
correct	O
outcome	O
.	O

Takeaways	O
.	O
We	O
conclude	O
this	O
section	O
with	O
three	O
concrete	O
recommendations	O
for	O
future	O
work	O
.	O

Finally	O
,	O
our	O
representations	O
achieve	O
state	O
-	O
of	O
-	O
theart	O
performance	O
for	O
voting	O
prediction	O
.	O
This	O
is	O
remarkable	O
,	O
as	O
our	O
result	O
comes	O
from	O
a	O
zero	O
-	O
shot	O
prediction	O
,	O
i.e.	O
,	O
our	O
representation	O
has	O
not	O
been	O
trained	O
on	O
any	O
voting	O
data	O
.	O
This	O
further	O
emphasizes	O
the	O
value	O
of	O
our	O
legislator	O
representation	O
as	O
a	O
general	O
proxy	O
for	O
legislators	O
'	O
ideology	O
.	O

BERT	B-MethodName
LARGE	I-MethodName
predicts	O
classes	O
B	O
and	O
I	O
with	O
an	O
F	O
1	O
of	O
.65	O
and	O
.53	O
,	O
hence	O
aspects	O
with	O
more	O
than	O
one	O
token	O
are	O
less	O
well	O
identified	O
.	O
A	O
difference	O
is	O
to	O
be	O
expected	O
,	O
as	O
the	O
class	O
balance	O
of	O
B	O
's	O
to	O
I	O
's	O
is	O
2,768	O
to	O
2,103	O
.	O
While	O
the	O
ranker	O
performs	O
worse	O
based	O
on	O
the	O
shown	O
metrics	O
,	O
it	O
has	O
a	O
slightly	O
higher	O
recall	O
for	O
class	O
I.	O
We	O
assume	O
this	O
is	O
due	O
to	O
the	O
fact	O
that	O
it	O
generally	O
ranks	O
aspects	O
with	O
more	O
than	O
one	O
token	O
on	O
top	O
,	O
i.e.	O
there	O
will	O
often	O
be	O
at	O
least	O
one	O
or	O
more	O
I	O
's	O
in	O
the	O
prediction	O
.	O
In	O
contrast	O
to	O
that	O
,	O
BERT	B-MethodName
LARGE	I-MethodName
focuses	O
more	O
on	O
shorter	O
aspects	O
,	O
which	O
is	O
also	O
in	O
accordance	O
with	O
the	O
average	O
aspect	O
length	O
of	O
1.8	O
tokens	O
per	O
aspect	O
in	O
the	O
dataset	O
.	O
In	O
total	O
,	O
BERT	B-MethodName
LARGE	I-MethodName
outperforms	O
the	O
ranker	O
by	O
almost	O
6	O
percentage	O
points	O
in	O
F	O
1	O
macro	O
.	O

In	O
broad	O
terms	O
,	O
a	O
sequence	O
labeling	O
model	O
consists	O
of	O
an	O
encoder	O
E	O
and	O
a	O
classifier	O
C.	O
The	O
encoder	O
consumes	O
a	O
sequence	O
of	O
input	O
tokens	O
t	O
i	O
and	O
outputs	O
a	O
sequence	O
of	O
contextualized	O
representations	O
h	O
i	O
(	O
Eq	O
.	O
1	O
)	O
.	O
These	O
representations	O
are	O
then	O
fed	O
to	O
the	O
classifier	O
which	O
produces	O
a	O
probability	O
distribution	O
over	O
all	O
of	O
the	O
possible	O
types	O
.	O
A	O
candidate	O
label	O
is	O
selected	O
by	O
choosing	O
the	O
type	O
with	O
the	O
largest	O
probability	O
.	O
The	O
model	O
loss	O
L	O
C	O
is	O
then	O
computed	O
via	O
negative	O
log	O
-	O
likelihood	O
with	O
the	O
classifier	O
-	O
selected	O
labels	O
and	O
the	O
expected	O
gold	O
labels	O
(	O
Eq	O
.	O
2	O
)	O
.	O

Our	O
question	O
generation	O
model	O
demonstrates	O
the	O
ability	O
to	O
generate	O
novel	O
questions	O
that	O
do	O
not	O
exist	O
in	O
the	O
entire	O
Duolingo	O
question	O
dataset	O
,	O
especially	O
when	O
a	O
sampling	O
penalty	O
is	O
applied	O
to	O
encourage	O
more	O
diverse	O
outputs	O
.	O
However	O
,	O
this	O
comes	O
at	O
a	O
cost	O
to	O
fluency	O
.	O
Below	O
we	O
include	O
a	O
set	O
of	O
outputs	O
generated	O
by	O
our	O
model	O
for	O
1	O
Spanish	O
student	O
and	O
1	O
French	O
student	O
from	O
the	O
Duolingo	O
dataset	O
,	O
with	O
a	O
target	O
difficulty	O
of	O
d	O
=	O
0.1	O
,	O
and	O
both	O
with	O
and	O
without	O
a	O
repetition	O
penalty	O
.	O
We	O
observe	O
that	O
while	O
applying	O
a	O
penalty	O
results	O
in	O
a	O
far	O
more	O
novel	O
questions	O
generated	O
,	O
several	O
of	O
these	O
are	O
also	O
non	O
-	O
fluent	O
,	O
using	O
a	O
combination	O
of	O
manual	O
judgement	O
and	O
the	O
Python	O
language	O
-	O
check	O
package	O
(	O
https://pypi.org/project/language-check/	O
)	O
.	O

Although	O
the	O
context	O
information	O
of	O
tables	O
is	O
important	O
,	O
how	O
to	O
effectively	O
use	O
it	O
for	O
schema	O
translation	O
is	O
challenging	O
.	O
On	O
the	O
one	O
hand	O
,	O
the	O
NMT	B-MethodName
model	O
needs	O
to	O
make	O
use	O
of	O
the	O
context	O
information	O
to	O
make	O
word	O
-	O
sense	O
disambiguation	O
for	O
polysemy	O
headers	O
and	O
abbreviation	O
headers	O
.	O
For	O
another	O
,	O
the	O
context	O
information	O
should	O
not	O
bring	O
additional	O
noise	O
when	O
translating	O
the	O
target	O
header	O
.	O

Given	O
any	O
autoregressive	O
language	O
model	O
(	O
e.g.	O
GPT-2	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
we	O
can	O
fine	O
-	O
tune	O
a	O
LM	O
-	I-MethodName
KT	I-MethodName
model	O
(	O
p	O
θ	O
KT	O
)	O
to	O
predict	O
whether	O
an	O
individual	O
student	O
will	O
correctly	O
answer	O
the	O
next	O
question	O
.	O
If	O
this	O
model	O
has	O
well	O
-	O
calibrated	O
uncertainty	O
,	O
we	O
can	O
use	O
its	O
predicted	O
probability	O
of	O
a	O
correct	O
answer	O
as	O
a	O
proxy	O
for	O
the	O
difficulty	O
of	O
a	O
question	O
to	O
a	O
student	O
.	O
We	O
then	O
train	O
a	O
question	O
generation	O
model	O
(	O
p	O
θ	O
QG	O
)	O
to	O
generate	O
a	O
new	O
question	O
conditioned	O
on	O
a	O
student	O
and	O
desired	O
target	O
difficulty	O
.	O

Human	O
Evaluation	O
.	O
Since	O
the	O
machine	O
evaluation	O
metrics	O
can	O
not	O
absolutely	O
make	O
sure	O
whether	O
the	O
predicted	O
result	O
is	O
correct	O
or	O
not	O
,	O
we	O
conduct	O
a	O
human	O
evaluation	O
on	O
the	O
test	O
set	O
for	O
a	O
more	O
precise	O
evaluation	O
.	O
Specifically	O
,	O
we	O
invite	O
two	O
experts	O
to	O
evaluate	O
each	O
language	O
pair	O
.	O
For	O
each	O
case	O
,	O
they	O
compare	O
the	O
machine	O
translation	O
and	O
the	O
human	O
annotation	O
.	O
The	O
label	O
is	O
set	O
as	O
1	O
if	O
they	O
think	O
the	O
translation	O
is	O
equivalent	O
to	O
the	O
annotation	O
,	O
otherwise	O
0	O
.	O
We	O
report	O
the	O
human	O
evaluation	O
results	O
for	O
the	O
Base	O
,	O
H2H	O
,	O
H2H+CXT	O
,	O
and	O
CAST	O
based	O
on	O
M2M-100	O
on	O
the	O
En	B-MethodName
-	I-MethodName
Zh	I-MethodName
setting	O
in	O
Table	O
5	O
.	O
According	O
to	O
human	O
evaluation	O
,	O
H2H	O
achieves	O
14.84	O
%	O
improvement	O
over	O
Base	O
,	O
and	O
the	O
performance	O
is	O
further	O
boosted	O
by	O
3.11	O
%	O
when	O
the	O
context	O
is	O
added	O
.	O
Finally	O
,	O
enhanced	O
by	O
the	O
relationaware	O
structure	O
,	O
CAST	B-MethodName
obtains	O
2.3	O
%	O
improvement	O
over	O
H2H+CXT	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O

We	O
divide	O
errors	O
into	O
two	O
categories	O
:	O
a	O
)	O
Coherence	O
errors	O
:	O
these	O
measure	O
whether	O
the	O
summary	O
is	O
well	O
-	O
structured	O
and	O
events	O
in	O
the	O
summary	O
make	O
narrative	O
sense	O
,	O
and	O
b	O
)	O
Language	O
errors	O
:	O
these	O
measure	O
other	O
aspects	O
of	O
the	O
quality	O
of	O
generated	O
text	O
,	O
such	O
as	O
grammar	O
.	O
While	O
these	O
do	O
not	O
come	O
under	O
the	O
ambit	O
of	O
coherence	O
errors	O
,	O
we	O
found	O
it	O
useful	O
to	O
provide	O
these	O
additional	O
error	O
types	O
for	O
crowd	O
workers	O
to	O
anchor	O
other	O
"	O
badness	O
"	O
in	O
text	O
to	O
.	O

We	O
introduce	O
MetaICL	O
:	O
Meta	O
-	O
training	O
for	O
In	O
-	O
Context	O
Learning	O
.	O
Table	O
1	O
provides	O
an	O
overview	O
of	O
the	O
approach	O
.	O
The	O
key	O
idea	O
is	O
to	O
use	O
a	O
multi	O
-	O
task	O
learning	O
scheme	O
over	O
a	O
large	O
collection	O
of	O
metatraining	O
tasks	O
,	O
in	O
order	O
for	O
the	O
model	O
to	O
learn	O
how	O
to	O
condition	O
on	O
a	O
small	O
set	O
of	O
training	O
examples	O
,	O
recover	O
the	O
semantics	O
of	O
a	O
task	O
,	O
and	O
predict	O
the	O
output	O
based	O
on	O
it	O
.	O
Following	O
previous	O
literature	O
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
)	O

-DOCSTART-	O
Linking	O
Entities	O
to	O
Unseen	O
Knowledge	O
Bases	O
with	O
Arbitrary	O
Schemas	O

Effectiveness	O
of	O
the	O
proxy	O
KL	O
-	O
divergence	O
loss	O
.	O
We	O
use	O
the	O
proposed	O
proxy	O
KL	O
-	O
divergence	O
loss	O
to	O
compute	O
the	O
head	O
importance	O
to	O
identify	O
the	O
general	O
language	O
knowledge	O
in	O
the	O
LM	O
without	O
using	O
the	O
LM	O
's	O
original	O
pre	O
-	O
training	O
data	O
(	O
Sec	O
.	O
3.1	O
)	O
.	O

This	O
work	O
is	O
inspired	O
by	O
the	O
seminal	O
work	O
of	O
on	O
CoT	O
prompting	O
.	O
They	O
demonstrate	O
that	O
prefixing	O
an	O
input	O
with	O
2	O
-	O
8	O
exemplars	O
of	O
CoT	O
reasoning	O
encourages	O
LMs	O
to	O
do	O
the	O
same	O
,	O
reaching	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
datasets	O
such	O
as	O
GSM8	B-MethodName
K	I-MethodName
(	O
Cobbe	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
show	O
that	O
task	O
accuracy	O
can	O
be	O
further	O
improved	O
by	O
using	O
self	O
-	O
consistency	O
in	O
CoT	O
prompting	O
.	O
Selfconsistency	O
samples	O
CoT	O
reasoning	O
paths	O
from	O
a	O
model	O
's	O
decoder	O
and	O
returns	O
the	O
most	O
consistent	O
path	O
by	O
taking	O
the	O
majority	O
vote	O
.	O
Subsequently	O
,	O
Chung	O
et	O
al	O
.	O
(	O
2022	O
)	O
explore	O
finetuning	O
a	O
FLANbased	B-MethodName
(	O
Wei	O
et	O
al	O
.	O
,	O
2021	O
)	O
version	O
of	O
PaLM	B-MethodName
on	O
manually	O
generated	O
CoT	O
data	O
.	O

We	O
construct	O
HIPPOCORPUS	O
,	O
containing	O
6,854	O
stories	O
(	O
Table	O
1	O
)	O
,	O
to	O
enable	O
the	O
study	O
of	O
imagined	O
and	O
recalled	O
stories	O
,	O
as	O
most	O
prior	O
corpora	O
are	O
either	O
limited	O
in	O
size	O
or	O
topic	O
(	O
e.g.	O
,	O
Greenberg	O
et	O
al	O
.	O
,	O
1996;Ott	O
et	O
al	O
.	O
,	O
2011	O
)	O
.	O
See	O
Appendix	O
A	O
for	O
additional	O
details	O
(	O
e.g.	O
,	O
worker	O
demographics	O
;	O
§	O
A.2	O
)	O
.	O

To	O
find	O
out	O
why	O
a	O
low	O
PPL	O
can	O
not	O
lead	O
to	O
a	O
better	O
GEC	O
performance	O
,	O
we	O
carry	O
out	O
a	O
detailed	O
analysis	O
on	O
the	O
ensemble	O
results	O
and	O
get	O
some	O
insights	O
on	O
GEC	O
:	O
1	O
)	O
In	O
the	O
test	O
data	O
,	O
human	O
references	O
are	O
insufficient	O
,	O
while	O
PLM	O
-	O
based	O
ensemble	O
strategies	O
produce	O
valuable	O
candidates	O
,	O
after	O
being	O
human	O
checked	O
,	O
which	O
may	O
be	O
considered	O
as	O
necessary	O
complement	O
to	O
human	O
references	O
.	O

(	O
with	O
1	O
being	O
very	O
easy	O
and	O
5	O
being	O
very	O
difficult	O
)	O

We	O
evaluated	O
our	O
proposed	O
tiny	O
-	O
attention	O
adapter	O
on	O
a	O
range	O
of	O
natural	O
language	O
understanding	O
tasks	O
including	O
GLUE	B-MethodName
and	O
FewGLUE	O
.	O
Our	O
method	O
is	O
implemented	O
in	O
PyTorch	B-MethodName
(	O
Paszke	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
heavily	O
relies	O
on	O
HuggingFace	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Our	O
code	O
is	O
submitted	O
for	O
review	O
and	O
it	O
will	O
be	O
publicly	O
released	O
after	O
the	O
paper	O
is	O
published	O
.	O

Experiment	O
detection	O
.	O
The	O
task	O
of	O
experiment	O
detection	O
can	O
be	O
modeled	O
as	O
a	O
binary	O
sentence	O
classification	O
problem	O
.	O
It	O
can	O
also	O
be	O
conceived	O
as	O
a	O
retrieval	O
task	O
,	O
selecting	O
sentences	O
as	O
candidates	O
for	O
experiment	O
frame	O
extraction	O
.	O
We	O
implement	O
a	O
bidirectional	O
long	O
short	O
-	O
term	O
memory	O
(	O
BiLSTM	B-MethodName
)	O
model	O
with	O
attention	O
for	O
the	O
task	O
of	O
experiment	O
sentence	O
detection	O
.	O
Each	O
input	O
token	O
is	O
represented	O
by	O
a	O
concatenation	O
of	O
several	O
pretrained	O
word	O
embeddings	O
,	O
each	O
of	O
which	O
is	O
fine	O
-	O
tuned	O
during	O
training	O
.	O
We	O
use	O
the	O
Google	O
News	O
word2vec	O
embeddings	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
domain	O
-	O
specific	O
word2vec	O
embeddings	O
(	O
mat2vec	O
,	O
,	O
see	O
also	O
Section	O
2	O
)	O
,	O
subword	O
embeddings	O
based	O
on	O
byte	O
-	O
pair	O
encoding	O
(	O
bpe	O
,	O
Heinzerling	O
and	O
Strube	O
,	O
2018	O
)	O
,	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
SciBERT	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2019	O
)	O
embeddings	O
.	O
For	O
BERT	B-MethodName
and	O
SciBERT	B-MethodName
,	O
we	O
take	O
the	O
embeddings	O
of	O
the	O
first	O
word	O
piece	O
as	O
token	O
representation	O
.	O
The	O
embeddings	O
are	O
fed	O
into	O
a	O
BiLSTM	B-MethodName
model	O
followed	O
by	O
an	O
attention	O
layer	O
that	O
computes	O
a	O
vector	O
for	O
the	O
whole	O
sentence	O
.	O
Finally	O
,	O
a	O
softmax	O
layer	O
decides	O
whether	O
the	O
sentence	O
contains	O
an	O
experiment	O
.	O

Open	O
-	O
sourcing	O
such	O
language	O
models	O
also	O
encourages	O
the	O
work	O
on	O
counter	O
-	O
measures	O
to	O
detect	O
malicious	O
use	O
:	O
While	O
many	O
works	O
have	O
been	O
published	O
on	O
the	O
topic	O
of	O
automatic	O
fake	O
news	O
detection	O
in	O
texts	O
(	O
Kaliyar	O
et	O
al	O
.	O
,	O
2020;Reis	O
et	O
al	O
.	O
,	O
2019;Hanselowski	O
et	O
al	O
.	O
,	O
2018;Pérez	O
-	O
Rosas	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
the	O
recent	O
emergence	O
of	O
large	O
-	O
scale	O
language	O
models	O
has	O
also	O
encouraged	O
research	O
to	O
focus	O
on	O
detecting	O
the	O
creator	O
of	O
these	O
texts	O
(	O
Varshney	O
et	O
al	O
.	O
,	O
2020;Zellers	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
former	O
approaches	O
are	O
aimed	O
at	O
detecting	O
fake	O
news	O
in	O
general	O
,	O
i.e.	O
independent	O
of	O
who	O
(	O
or	O
what	O
)	O
composed	O
a	O
text	O
,	O
whereas	O
the	O
latter	O
approaches	O
are	O
designed	O
to	O
recognize	O
if	O
a	O
text	O
was	O
written	O
by	O
a	O
human	O
or	O
generated	O
by	O
a	O
language	O
model	O
.	O
We	O
encourage	O
the	O
work	O
on	O
both	O
types	O
of	O
methods	O
.	O
Ideally	O
,	O
social	O
networks	O
and	O
news	O
platforms	O
would	O
indicate	O
if	O
a	O
statement	O
was	O
automatically	O
generated	O
in	O
addition	O
to	O
its	O
factual	O
correctness	O
.	O

In	O
contrast	O
,	O
if	O
we	O
understand	O
which	O
patterns	O
or	O
qualities	O
of	O
the	O
input	O
are	O
captured	O
in	O
each	O
feature	O
,	O
we	O
can	O
comprehend	O
the	O
overall	O
reasoning	O
mechanism	O
of	O
the	O
model	O
as	O
the	O
dense	O
layer	O
in	O
the	O
classification	O
part	O
then	O
becomes	O
interpretable	O
.	O
In	O
this	O
paper	O
,	O
we	O
make	O
this	O
possible	O
using	O
LRP	O
.	O
By	O
understanding	O
the	O
model	O
,	O
humans	O
can	O
check	O
whether	O
the	O
input	O
patterns	O
detected	O
by	O
each	O
feature	O
are	O
relevant	O
for	O
classification	O
.	O
Also	O
,	O
the	O
features	O
should	O
be	O
used	O
by	O
the	O
subsequent	O
dense	O
layer	O
to	O
support	O
the	O
right	O
classes	O
.	O
If	O
these	O
are	O
not	O
the	O
case	O
,	O
debugging	O
can	O
be	O
done	O
by	O
disabling	O
the	O
features	O
which	O
may	O
be	O
harmful	O
if	O
they	O
exist	O
in	O
the	O
model	O
.	O
Figure	O
1	O
shows	O
the	O
overview	O
of	O
our	O
debugging	O
framework	O
,	O
FIND	O
.	O

for	O
cognitive	O
skills	O
such	O
as	O
knowing	O
what	O
is	O
not	O
true	O
or	O
what	O
not	O
to	O
think	O
(	O
MacDonald	O
,	O
1965	O
;	O
Minsky	O
,	O
1997	O
;	O
Barker	O
and	O
Jago	O
,	O
2012	O
)	O
.	O
Therefore	O
,	O
we	O
ask	O
this	O
question	O
:	O
Do	O
LLMs	O
(	O
such	O
as	O
GPT-3	O
models	O
)	O
acquire	O
such	O
implicit	O
negative	O
knowledge	O
through	O
extensive	O
language	O
modeling	O
pre	O
-	O
training	O
?	O

D2	O
.	O
Did	O
you	O
report	O
information	O
about	O
how	O
you	O
recruited	O
(	O
e.g.	O
,	O
crowdsourcing	O
platform	O
,	O
students	O
)	O

We	O
also	O
present	O
the	O
results	O
on	O
the	O
SGD	B-MethodName
dataset	O
in	O
Table	O
2	O
,	O
where	O
Prompter	O
shows	O
improvements	O
on	O
average	O
.	O
We	O
share	O
results	O
over	O
6	O
representative	O
domains	O
along	O
with	O
results	O
for	O
official	O
unseen	O
domain	O
performance	O
.	O
Once	O
more	O
,	O
Prompter	O
demonstrates	O
superior	O
performance	O
on	O
average	O
in	O
unfamiliar	O
domains	O
.	O
Compared	O
to	O
the	O
results	O
reported	O
in	O
the	O
original	O
paper	O
by	O
Wang	O
et	O
al	O
.	O
(	O
2022	O
)	O
for	O
four	O
domains	O
(	O
Columns	O
1	O
through	O
4	O
of	O
Table	O
Table	O
2	O

where	O
Y	O
t	O
′	O
is	O
a	O
vector	O
in	O
which	O
each	O
element	O
Y	O
j	O
t	O
′	O

Unexpectedness	O
Hyperbolic	O
spans	O
are	O
less	O
coherent	O
with	O
the	O
literal	O
contexts	O
and	O
thus	O
their	O
vector	O
representations	O
are	O
distant	O
from	O
the	O
context	O
vectors	O
.	O
Troiano	O
et	O
al	O
.	O
(	O
2018	O
)	O
have	O
verified	O
this	O
intuition	O
with	O
the	O
unexpectedness	O
metric	O
.	O
They	O
define	O
the	O
unexpectedness	O
score	O
U	O
s	O
of	O
a	O
sentence	O
s	O
with	O
the	O
token	O
sequence	O
{	O
x	O
0	O
,	O
x	O
1	O
,	O
...	O
,	O
x	O
N	O
}	O
as	O
the	O
average	O
cosine	O
distance	O
among	O
all	O
of	O
its	O
word	O
pairs	O
.	O

For	O
homogeneous	O
moral	O
norm	O
inference	O
,	O
we	O
compute	O
Pearson	O
correlation	O
between	O
1	O
)	O
the	O
empirical	O
homogeneous	O
moral	O
ratings	O
,	O
obtained	O
by	O
aggregating	O
the	O
human	O
moral	O
ratings	O
toward	O
a	O
topic	O
from	O
all	O
countries	O
,	O
and	O
2	O
)	O
language	O
model	O
inferred	O
moral	O
scores	O
,	O
estimated	O
from	O
our	O
homogeneous	O
probing	O
method	O
(	O
i.e.	O
,	O
without	O
specifying	O
country	O
in	O
prompts	O
)	O
.	O

Then	O
it	O
aggregates	O
all	O
the	O
information	O
using	O
word	O
clouds	O
to	O
create	O
a	O
global	O
visual	O
picture	O
of	O
the	O
model	O
.	O
This	O
enables	O
humans	O
to	O
comprehend	O
the	O
features	O
automatically	O
learned	O
by	O
the	O
deep	O
classifier	O
and	O
then	O
decide	O
to	O
disable	O
some	O
features	O
that	O
could	O
undermine	O
the	O
prediction	O
accuracy	O
during	O
testing	O
.	O
The	O
main	O
differences	O
between	O
our	O
work	O
and	O
existing	O
work	O
are	O
:	O
(	O
i	O
)	O
first	O
,	O
FIND	O
leverages	O
human	O
feedback	O
on	O
the	O
model	O
components	O
,	O
not	O
the	O
individual	O
predictions	O
,	O
to	O
perform	O
debugging	O
;	O
(	O
ii	O
)	O
second	O
,	O
FIND	O
targets	O
deep	O
text	O
classifiers	O
which	O
are	O
more	O
convoluted	O
than	O
traditional	O
classifiers	O
used	O
in	O
existing	O
work	O
(	O
such	O
as	O
Naive	O
Bayes	O
classifiers	O
and	O
Support	O
Vector	O
Machines	O
)	O
.	O

The	O
second	O
regularization	O
scheme	O
discourages	O
the	O
model	O
from	O
memorizing	O
the	O
order	O
in	O
which	O
particular	O
attributes	O
occur	O
.	O
Under	O
attribute	O
-	O
shuffle	O
,	O
every	O
time	O
an	O
entity	O
is	O
encountered	O
during	O
training	O
,	O
its	O
attribute	O
/	O
values	O
are	O
randomly	O
shuffled	O
before	O
it	O
is	O
converted	O
to	O
a	O
string	O
representation	O
using	O
the	O
techniques	O
from	O
Section	O
4.1	O
.	O

Our	O
method	O
generalizes	O
to	O
any	O
education	O
activity	O
that	O
can	O
be	O
represented	O
with	O
text	O
sequences	O
.	O
Due	O
to	O
the	O
availability	O
of	O
real	O
student	O
learning	O
data	O
,	O
we	O
focus	O
on	O
a	O
reverse	O
language	O
translation	O
task	O
,	O
where	O
a	O
student	O
translates	O
phrases	O
from	O
their	O
native	O
language	O
(	O
e.g.	O
English	O
,	O
"	O
she	O
eats	O
"	O
)	O
to	O
the	O
second	O
language	O
they	O
are	O
learning	O
(	O
e.g.	O
Spanish	O
,	O
"	O
ella	O
come	O
"	O
)	O
.	O

The	O
contents	O
of	O
thousands	O
of	O
historical	O
documents	O
are	O
still	O
unknown	O
to	O
the	O
contemporary	O
age	O
,	O
even	O
though	O
they	O
are	O
encrypted	O
using	O
classical	O
methods	O
.	O
Example	O
documents	O
include	O
books	O
from	O
secret	O
societies	O
,	O
diplomatic	O
correspondences	O
,	O
and	O
pharmacological	O
books	O
.	O
Previous	O
work	O
has	O
been	O
done	O
on	O
collecting	O
historical	O
ciphers	O
from	O
libraries	O
and	O
archives	O
and	O
making	O
them	O
available	O
for	O
researchers	O
(	O
Megyesi	O
et	O
al	O
.	O
,	O
2019	O
(	O
Megyesi	O
et	O
al	O
.	O
,	O
,	O
2020	O
.	O
However	O
,	O
decipherment	O
of	O
classical	O
ciphers	O
is	O
an	O
essential	O
step	O
to	O
reveal	O
the	O
contents	O
of	O
those	O
historical	O
documents	O
.	O

To	O
further	O
restrict	O
malicious	O
use	O
,	O
we	O
release	O
the	O
training	O
data	O
for	O
the	O
Arg	O
-	I-MethodName
CTRLs	I-MethodName
with	O
an	O
additional	O
clause	O
that	O
forbids	O
use	O
for	O
any	O
other	O
than	O
research	O
purposes	O
.	O
Also	O
,	O
all	O
the	O
training	O
datasets	O
for	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRLs	I-MethodName
will	O
be	O
accessible	O
only	O
via	O
access	O
control	O
(	O
e	O
-	O
mail	O
,	O
name	O
,	O
and	O
purpose	O
of	O
use	O
)	O
.	O
Lastly	O
,	O
this	O
work	O
has	O
been	O
reviewed	O
by	O
the	O
ethics	O
committee	O
of	O
the	O
Technical	O
University	O
of	O
Darmstadt	O
that	O
issued	O
a	O
positive	O
vote	O
.	O
page	O
833	O
-	O
838	O
,	O
USA	O
.	O
American	O
Association	O
for	O
Artificial	O
Intelligence	O
.	O

In	O
this	O
paper	O
,	O
we	O
used	O
two	O
metrics	O
to	O
quantify	O
biases	O
in	O
the	O
models	O
-False	O
positive	O
equality	O
difference	O
(	O
FPED	O
)	O
and	O
False	O
negative	O
equality	O
difference	O
(	O
FNED	O
)	O
-with	O
the	O
following	O
definitions	O
(	O
Dixon	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

Our	O
results	O
show	O
that	O
MP	O
obtains	O
comparable	O
linear	O
guarding	O
in	O
one	O
projection	O
where	O
INLP	B-MethodName
requires	O
multiple	O
iterations	O
.	O
They	O
also	O
confirm	O
that	O
the	O
rest	O
of	O
the	O
space	O
remains	O
more	O
stable	O
through	O
fewer	O
changes	O
in	O
nearest	O
neighbors	O
of	O
randomly	O
chosen	O
words	O
and	O
similarity	O
scores	O
that	O
are	O
closer	O
to	O
the	O
original	O
scores	O
compared	O
to	O
INLP	B-MethodName
.	O
Two	O
results	O
led	O
to	O
further	O
questions	O
:	O
similarity	O
scores	O
improved	O
after	O
applying	O
INLP	B-MethodName
and	O
INLP	B-MethodName
resulted	O
in	O
better	O
WEAT	O
scores	O
than	O
MP	O
.	O
We	O
conducted	O
additional	O
experiments	O
to	O
test	O
whether	O
the	O
extra	O
debiasing	O
iterations	O
performed	O
in	O
INLP	B-MethodName
end	O
up	O
removing	O
more	O
subtle	O
representations	O
of	O
gender	O
bias	O
that	O
are	O
missed	O
by	O
the	O
single	O
MP	O
iteration	O
.	O

•	O
We	O
propose	O
a	O
Neural	O
Vocabulary	O
Selection	O
(	O
NVS	O
)	O
model	O
based	O
on	O
the	O
contextualized	O
deep	O
encoder	O
representation	O
(	O
§	O
3	O
)	O
.	O

As	O
described	O
in	O
section	O
5	O
,	O
we	O
train	O
two	O
sentence	O
fusion	O
baselines	O
using	O
a	O
pre	O
-	O
trained	O
auto	O
-	O
encoder	O
BART	I-MethodName
base	O
model	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
on	O
PYRFUS	O
and	O
PYRFUS++	O
respectively	O
.	O
We	O
used	O
the	O
training	O
script	O
9	O
made	O
available	O
by	O
the	O
transformers	O
library	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
with	O
the	O
following	O
parameters	O
:	O
4	O
training	O
epochs	O
and	O
a	O
learning	O
rate	O
of	O
3e-5	O
.	O
A	O
"	O
steps	O
"	O
evaluation	O
parameter	O
was	O
used	O
with	O
5000	O
evaluation	O
steps	O
and	O
an	O
evaluation	O
beam	O
of	O
6	O
.	O
Max	O
source	O
input	O
was	O
limited	O
to	O
265	O
while	O
max	O
target	O
length	O
was	O
set	O
to	O
30	O
.	O
Minimum	O
target	O
length	O
were	O

We	O
proposed	O
FIND	B-MethodName
,	O
a	O
framework	O
which	O
enables	O
humans	O
to	O
debug	O
deep	O
text	O
classifiers	O
by	O
disabling	O
irrelevant	O
or	O
harmful	O
features	O
.	O
Using	O
the	O
proposed	O
framework	O
on	O
CNN	B-MethodName
text	O
classifiers	O
,	O
we	O
found	O
that	O
(	O
i	O
)	O
word	O
clouds	O
generated	O
by	O
running	O
LRP	B-MethodName
on	O
the	O
training	O
data	O
accurately	O
revealed	O
the	O
behaviors	O
of	O
CNN	B-MethodName
features	O
,	O
(	O
ii	O
)	O
some	O
of	O
the	O
learned	O
features	O
might	O
be	O
more	O
useful	O
to	O
the	O
task	O
than	O
the	O
others	O
and	O
(	O
iii	O
)	O
disabling	O
the	O
irrelevant	O
or	O
harmful	O
features	O
could	O
improve	O
the	O
model	O
predictive	O
performance	O
and	O
reduce	O
unintended	O
biases	O
in	O
the	O
model	O
.	O

A.1	O
Hypothesis	O
-	O
only	O
Baseline	O
Analysis	O

In	O
Table	O
2	O
,	O
we	O
show	O
the	O
related	O
words	O
for	O
SST-2	B-MethodName
.	O

C2	O
.	O
Did	O
you	O
discuss	O
the	O
experimental	O
setup	O
,	O
including	O
hyperparameter	O
search	O
and	O
best	O
-	O
found	O
hyperparameter	O
values	O
?	O
We	O
introduce	O
the	O
experiment	O
settings	O
in	O
section	O
5.1	O
.	O

The	O
rest	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
Section	O
2	O
explains	O
related	O
work	O
about	O
analyzing	O
,	O
explaining	O
,	O
and	O
human	O
-	O
debugging	O
text	O
classifiers	O
.	O
Section	O
3	O
proposes	O
FIND	O
,	O
our	O
debugging	O
framework	O
.	O
Section	O
4	O
explains	O
the	O
experimental	O
setup	O
followed	O
by	O
the	O
three	O
human	O
experiments	O
in	O
Section	O
5	O
to	O
7	O
.	O
Finally	O
,	O
Section	O
8	O
discusses	O
generalization	O
of	O
the	O
framework	O
and	O
concludes	O
the	O
paper	O
.	O
Code	O
and	O
datasets	O
of	O
this	O
paper	O
are	O
available	O
at	O
https://github.com/plkumjorn/FIND	O
.	O

•	O
A	O
negative	O
data	O
point	O
is	O
the	O
same	O
except	O
x	O
t	O
,	O
the	O
token	O
at	O
position	O
t	O
,	O
is	O
replaced	O
with	O
a	O
noise	O
tokenx	O
t	O
sampled	O
from	O
q.	O

To	O
mitigate	O
the	O
hallucination	O
problem	O
that	O
caused	O
by	O
the	O
polarized	O
optimization	O
objectives	O
in	O
knowledge	O
grounded	O
dialogue	O
generation	O
,	O
we	O
take	O
inspiration	O
from	O
human	O
communicating	O
,	O
and	O
propose	O
the	O
Augmentative	O
and	O
Contrastive	O
Knowledge	O
Dialogue	O
Expansion	O
Framework	O
(	O
ACK	O
-	O
DEF	O
)	O
.	O
Our	O
ACK	B-MethodName
-	I-MethodName
DEF	I-MethodName
aims	O
to	O
soften	O
the	O
polarized	O
training	O
optimization	O
objectives	O
of	O
current	O
knowledgegrounded	O
dialogue	O
generation	O
methods	O
,	O
and	O
guide	O
the	O
dialogue	O
system	O
reply	O
patterns	O
for	O
the	O
knowledge	O
with	O
different	O
level	O
of	O
errors	O
.	O
To	O
achieve	O
this	O
end	O
,	O
we	O
design	O
two	O
effective	O
expansion	O
method	O
,	O
which	O
will	O
be	O
detailed	O
in	O
below	O
.	O

In	O
order	O
to	O
obtain	O
better	O
representations	O
of	O
textual	O
curricula	O
,	O
we	O
propose	O
to	O
use	O
pre	O
-	O
trained	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
embeddings	O
that	O
have	O
been	O
finetuned	O
in	O
a	O
computing	O
discipline	O
classification	O
task	O
,	O
using	O
an	O
approach	O
that	O
combines	O
a	O
novel	O
coursebased	O
attention	O
mechanism	O
and	O
metric	O
learning	O
.	O

We	O
use	O
three	O
different	O
LMs	O
as	O
our	O
baseline	O
models	O
,	O
each	O
with	O
different	O
architectures	O
:	O
RoBERTa	B-MethodName
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
GPT-2	B-MethodName
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
T5	B-MethodName
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
These	O
architectures	O
compose	O
transformer	O
layers	O
in	O
various	O
typical	O
fashions	O
:	O

While	O
we	O
could	O
not	O
find	O
previously	O
published	O
work	O
on	O
this	O
problem	O
,	O
we	O
can	O
see	O
that	O
our	O
best	O
method	O
(	O
Unigram	B-MethodName
LM	O
2	O
)	O
achieves	O
an	O
average	O
SegER	O
of	O
27	O
%	O
on	O
the	O
three	O
real	O
homophonic	O
ciphers	O
,	O
with	O
the	O
best	O
score	O
of	O
15	O
%	O
on	O
the	O
longest	O
,	O
2,239	O
-	O
digit	O
F283	O
cipher	O
.	O

The	O
following	O
are	O
the	O
25	O
news	O
sources	O
in	O
AllSides	O
:	O
BBC	O
News	O
,	O
Breitbart	O
News	O
,	O
CBN	O
,	O
Christian	O
Science	O
Monitor	O
,	O
CNN	O
,	O
Fox	O
News	O
,	O
HuffPost	O
,	O
National	O
Review	O
,	O
New	O
York	O
Times	O
,	O
Newsmax	O
,	O
NPR	O
,	O
Politico	O
,	O
Reason	O
,	O
Reuters	O
,	O
Salon	O
,	O
The	O
Guardian	O
,	O
The	O
Hill	O
,	O
TheBlaze.com	O
,	O
Townhall	O
,	O
USA	O
TODAY	O
,	O
Vox	O
,	O
Wall	O
Street	O
Journal	O
,	O
Washington	O
Examiner	O
,	O
Washington	O
Post	O
,	O
Washington	O
Times	O
.	O

A	O
document	O
is	O
split	O
if	O
it	O
is	O
longer	O
than	O
512	O
words	O
,	O
which	O
is	O
the	O
maximum	O
word	O
length	O
of	O
the	O
BERT	B-MethodName
model	O
.	O

The	O
second	O
unmodified	O
BERT	B-MethodName
model	O
(	O
i.e.	O
not	O
containing	O
the	O
indicator	O
embeddings	O
as	O
in	O
the	O
mention	O
encoder	O
)	O
independently	O
encodes	O
each	O
e	O
∈	O
KB	O
into	O
vectors	O
.	O
The	O
candidates	O
E	O
for	O
a	O
mention	O
are	O
the	O
K	O
entities	O
whose	O
representations	O
are	O
most	O
similar	O
to	O
v	O
m	O
.	O
Both	O
BERT	B-MethodName
models	O
are	O
fine	O
-	O
tuned	O
jointly	O
using	O
a	O
cross	O
-	O
entropy	O
loss	O
to	O
maximize	O
the	O
similarity	O
between	O
a	O
mention	O
and	O
its	O
corresponding	O
correct	O
entity	O
,	O
when	O
compared	O
to	O
other	O
random	O
entities	O
.	O

Prompt	O
-	O
Finetuning	O
.	O
We	O
finetune	O
each	O
of	O
our	O
pretrained	O
METRO	B-MethodName
-	I-MethodName
T5	I-MethodName
models	O
on	O
three	O
multi	O
-	O
task	O
mixtures	O
:	O
T0	O
/	O
T0+	O
/	O
T0++	O
Train	O
,	O
using	O
the	O
same	O
prompt	O
templates	O
and	O
shuffling	O
strategy	O
as	O
Sanh	O
et	O
al	O
.	O
(	O
2022	O
)	O
does	O
.	O
Each	O
model	O
is	O
finetuned	O
for	O
125k	O
steps	O
,	O
using	O
the	O
same	O
hyperparameters	O
as	O
pretraining	O
,	O
except	O
the	O
peak	O
learning	O
rate	O
is	O
reduced	O
to	O
0.1x	O
.	O
We	O
do	O
not	O
perform	O
any	O
checkpoint	O
selection	O
and	O
simply	O
use	O
the	O
last	O
checkpoint	O
at	O
125k	O
steps	O
for	O
evaluation	O
.	O

"	O
female	O
"	O
,	O
"	O
females	O
"	O
,	O
"	O
girl	O
"	O
,	O
"	O
girls	O
"	O
,	O
"	O
woman	O
"	O
,	O
"	O
women	O
"	O
,	O
"	O
lady	O
"	O
,	O
"	O
ladies	O
"	O
,	O
"	O
she	O
"	O
,	O
"	O
her	O
"	O
,	O
"	O
herself	O
"	O
,	O
"	O
sister	O
"	O
,	O
"	O
daughter	O
"	O
,	O
"	O
wife	O
"	O
,	O
"	O
girlfriend	O
"	O
,	O
"	O
mother	O
"	O
,	O
"	O
aunt	O
"	O
,	O
"	O
mom	O
"	O
.	O
All	O
the	O
bios	O
are	O
from	O
Common	O
Crawl	O
August	O
2018	O
Index	O
.	O

c	O
that	O
are	O
aligned	O
with	O
words	O
in	O
the	O
corresponding	O
English	O
sentence	O
,	O
x	O
(	O
i	O
)	O
en	O
.	O
3	O
Denote	O
by	O
2	O
We	O
investigate	O
the	O
similarity	O
of	O
translation	O
pairs	O
via	O
their	O
multilingual	O
representations	O
in	O
Appendix	O
C	O
,	O
finding	O
that	O
translation	O
pairs	O
do	O
form	O
similar	O
inputs	O
for	O
a	O
multilingual	O
model	O
.	O
3	O
We	O
use	O
English	O
as	O
the	O
reference	O
language	O
since	O
our	O
cross-	O

To	O
obtain	O
the	O
final	O
score	O
s	O
i	O
for	O
each	O
O	O
i	O
,	O
we	O
concatenate	O
the	O
dual	O
matching	O
features	O
f	O
QO	O
i	O
and	O
f	O
QC	O
i	O
and	O
feed	O
them	O
into	O
a	O
two	O
-	O
layer	O
multi	O
-	O
layer	O
perceptron	O
(	O
MLP	O
)	O
:	O

Formally	O
,	O
the	O
ACE	O
using	O
the	O
do	O
-	O
notation	O
can	O
be	O
calculated	O
by	O
conditioning	O
on	O
Z.	O
Specifically	O
,	O
we	O
integrate	O
over	O
the	O
distribution	O
of	O
P	O
(	O
Z	O
)	O
,	O
and	O
calculate	O
the	O
difference	O
in	O
the	O
conditional	O
probability	O
distribution	O
P	O
(	O
S	O
=	O
s|M	O
=	O
1	O
,	O
Z	O
=	O
z	O
)	O
−	O
P	O
(	O
S	O
=	O
s|M	O
=	O
0	O
,	O
Z	O
=	O
z	O
)	O
of	O
S	O
given	O
the	O
data	O
-	O
model	O
di-	O
rection	O
match	O
value	O
M	O
conditioned	O
on	O
the	O
other	O
key	O
variables	O
Z	O
for	O
each	O
of	O
its	O
possible	O
value	O
z	O
,	O
as	O
shown	O
in	O
Eq	O
.	O
(	O
2	O
)	O
:	O

D3	O
.	O
Did	O
you	O
discuss	O
whether	O
and	O
how	O
consent	O
was	O
obtained	O
from	O
people	O
whose	O
data	O
you	O
're	O
using	O
/	O
curating	O
?	O
For	O
example	O
,	O
if	O
you	O
collected	O
data	O
via	O
crowdsourcing	O
,	O
did	O
your	O
instructions	O
to	O
crowdworkers	O
explain	O
how	O
the	O
data	O
would	O
be	O
used	O
?	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O

•	O
For	O
the	O
embedding	O
-	O
based	O
metrics	O
,	O
we	O
use	O
(	O
i	O
)	O
Vector	B-MethodName
Extrema	I-MethodName
(	O
VE	O
)	O
(	O
Forgues	O
and	O
Pineau	O
,	O
2014	O
)	O
,	O
(	O
ii	O
)	O
Greedy	O
Matching	O
(	O
GM	O
)	O
(	O
Rus	O
and	O
Lintean	O
,	O
2012	O
)	O
,	O
(	O
iii	O
)	O
Embedding	O
Averaging	O
(	O
EA	O
)	O
(	O
Landauer	O
and	O
Dumais	O
,	O
1997	O
)	O
,	O
(	O
iv	O
)	O
LabSE	B-MethodName
(	O
Feng	O
et	O
al	O
.	O
,	O
2020	O
)	O
&	O
(	O
v	O
)	O
LASER	B-MethodName
(	O
Artetxe	O
and	O
Schwenk	O
,	O
2019	O
)	O
embeddings	O
and	O
(	O
vi	O
)	O
BERTScore	B-MethodName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

The	O
experimental	O
results	O
of	O
all	O
models	O
are	O
summarized	O
in	O
Table	O
3	O
.	O
First	O
of	O
all	O
,	O
it	O
should	O
be	O
noted	O
that	O
there	O
are	O
only	O
a	O
few	O
studies	O
on	O
readability	O
assessment	O
,	O
and	O
there	O
is	O
no	O
unified	O
standard	O
for	O
data	O
division	O
and	O
experimental	O
parameter	O
configuration	O
.	O
This	O
has	O
led	O
to	O
large	O
differences	O
in	O
the	O
results	O
of	O
different	O
research	O
works	O
.	O

In	O
this	O
section	O
,	O
we	O
describe	O
our	O
schema	O
translation	O
approach	O
in	O
detail	O
.	O
We	O
first	O
introduce	O
the	O
requirement	O
and	O
our	O
definition	O
for	O
the	O
schema	O
translation	O
task	O
and	O
then	O
introduce	O
the	O
model	O
architecture	O
.	O

Combining	O
preprocessed	O
data	O
We	O
collect	O
different	O
types	O
of	O
source	O
text	O
applied	O
with	O
different	O
preprocessing	O
methods	O
of	O
Section	O
4.2	O
.	O
For	O
PHOENIX	O
,	O
we	O
combine	O
the	O
original	O
,	O
the	O
normalized	O
,	O
the	O
lemmatized	O
,	O
and	O
the	O
lemmatized+normalized	O
text	O
with	O
the	O
copied	O
target	O
glosses	O
.	O
For	O
DGS	B-MethodName
,	O
we	O
mix	O
the	O
original	O
and	O
lemmatized	O
text	O
with	O
the	O
corresponding	O
target	O
glosses	O
into	O
a	O
new	O
training	O
dataset	O
.	O

A	O
much	O
bigger	O
problem	O
for	O
applying	O
knowledge	O
of	O
prototypical	O
functions	O
is	O
that	O
physical	O
objects	O
are	O
often	O
mentioned	O
when	O
they	O
are	O
not	O
used	O
at	O
all	O
!	O
For	O
example	O
,	O
the	O
sentences	O
below	O
mention	O
a	O
knife	O
,	O
but	O
the	O
knife	O
is	O
not	O
being	O
used	O
:	O

HuffPost	O
Reuters	I-MethodName
Amazon	O
Average	O
1	O
shot	O
5	O
shot	O
1	O
shot	O
5	O
shot	O
1	O
shot	O
5	O
shot	O
1	O
shot	O
5	O
shot	O
1	O
shot	O
5	O
shot	O
Table	O
7	O
:	O
Results	O
of	O
10	O
-	O
way	O
1	O
-	O
shot	O
and	O
10	O
-	O
way	O
5	O
-	O
shot	O
text	O
classification	O
accuracies	O
(	O
%	O
)	O
on	O
four	O
benchmark	O
test	O
sets	O
.	O
The	O
test	O
set	O
of	O
Amazon	O
product	O
data	O
only	O
contains	O
nine	O
categories	O
.	O
Thus	O
we	O
test	O
the	O
9	O
-	O
way	O
1	O
-	O
shot	O
and	O
9	O
-	O
way	O
5	O
-	O
shot	O
performance	O
instead	O
.	O

The	O
deep	O
learning	O
based	O
models	O
that	O
have	O
been	O
developed	O
to	O
solve	O
text	O
-	O
based	O
(	O
logical	O
)	O
reasoning	O
tasks	O
can	O
be	O
categorized	O
as	O
follows	O
(	O
see	O
Huang	O
and	O
Chang	O
2022	O
for	O
a	O
recent	O
survey	O
of	O
the	O
literature	O
)	O
.	O

For	O
reproducibility	O
,	O
we	O
define	O
a	O
fixed	O
cross	O
-	O
topic	O
split	O
with	O
the	O
data	O
of	O
two	O
topics	O
as	O
test	O
set	O
(	O
gun	O
control	O
,	O
school	O
uniforms	O
)	O
,	O
the	O
data	O
of	O
one	O
topic	O
as	O
development	O
set	O
(	O
death	O
penalty	O
)	O
,	O
and	O
the	O
data	O
of	O
the	O
remaining	O
five	O
topics	O
as	O
train	O
set	O
.	O
We	O
also	O
create	O
a	O
fixed	O
in	O
-	O
topic	O
split	O
by	O
randomly	O
taking	O
3,532	O
samples	O
of	O
all	O
topics	O
for	O
training	O
,	O
500	O
for	O
development	O
,	O
and	O
1,000	O
for	O
testing	O
.	O
nuclear	O
AND	O
(	O
energy	O
OR	O
fission	O
OR	O
power	O
OR	O
plant	O
)	O
In	O
addition	O
,	O
we	O
must	O
continue	O
developing	O
safer	O
technologies	O
like	O
small	O
modular	O
reactors	O
which	O
will	O
help	O
us	O
meet	O
our	O
nation	O
's	O
need	O
for	O
reliable	O
,	O
emission	O
-	O
free	O
sources	O
of	O
low	O
-	O
emission	O
energy	O
while	O
also	O
creating	O
jobs	O
and	O
providing	O
solutions	O
to	O
some	O
of	O
the	O
world	O
s	O
most	O
pressing	O
problems	O
:	O
climate	O
change	O
,	O
food	O
security	O
and	O
sustainable	O
development	O
.	O
(	O
0.96	O
)	O
nuclear	O
energy	O
CON	O
leak	O
.	O
"	O
We	O
are	O
concerned	O
about	O
the	O
possibility	O
of	O
further	O
releases	O
of	O
radioactivity	O
due	O
to	O
possible	O
melting	O
or	O
cracking	O
of	O
fuel	O
rods	O
at	O
the	O
No	O
.	O
(	O
0.47	O
)	O
death	O
penalty	O
CON	O
inhuman	O
.	O
Amnesty	O
International	O
opposes	O
the	O
death	O
penalty	O
in	O
all	O
cases	O
as	O
the	O
ultimate	O
form	O
of	O
cruel	O
,	O
inhuman	O
or	O
degrading	O
punishment	O
and	O
a	O
violation	O
of	O
fundamental	O
rights	O
-the	O
right	O
to	O
life	O
and	O
the	O
prohibition	O
of	O
torture	O
.	O

We	O
report	O
our	O
model	O
and	O
training	O
hyperparameters	O
in	O
table	O
8	O
.	O
We	O
did	O
not	O
perform	O
explicit	O
hyperparameter	O
tuning	O
,	O
besides	O
some	O
manual	O
testing	O
early	O
in	O
development	O
on	O
a	O
subset	O
of	O
the	O
MRP	O
shared	O
task	O
data	O
.	O
Those	O
data	O
are	O
annotated	O
with	O
SLR	O
frameworks	O
other	O
than	O
the	O
ones	O
we	O
compare	O
here	O
,	O
and	O
we	O
ended	O
up	O
excluding	O
them	O
from	O
our	O
experiments	O
for	O
lack	O
of	O
overlap	O
with	O
most	O
of	O
the	O
other	O
frameworks	O
'	O
annotations	O
.	O

In	O
this	O
process	O
,	O
we	O
found	O
that	O
Google	O
translator	O
is	O
not	O
good	O
enough	O
in	O
schema	O
translation	O
since	O
industry	O
jargon	O
and	O
abbreviations	O
are	O
commonly	O
used	O
in	O
column	O
headers	O
.	O
Table	O
1	O
shows	O
some	O
example	O
headers	O
and	O
their	O
paraphrases	O
under	O
different	O
domains	O
in	O
our	O
dataset	O
.	O
However	O
,	O
domain	O
information	O
is	O
implicit	O
,	O
and	O
the	O
meaning	O
of	O
the	O
header	O
needs	O
to	O
be	O
inferred	O
carefully	O
from	O
the	O
entire	O
table	O
context	O
.	O
To	O
get	O
more	O
precise	O
translations	O
,	O
we	O
provide	O
three	O
kinds	O
of	O
additional	O
information	O
as	O
a	O
schema	O
context	O
:	O
(	O
1	O
)	O
a	O
whole	O
table	O
with	O
structural	O
information	O
,	O
including	O
its	O
table	O
name	O
,	O
column	O
headers	O
and	O
cell	O
values	O
;	O
(	O
2	O
)	O
an	O
original	O
web	O
-	O
page	O
URL	O
for	O
the	O
table	O
from	O
the	O
Wikipedia	O
website	O
;	O
(	O
3	O
)	O
some	O
natural	O
language	O
question	O
/	O
answer	O
pairs	O
about	O
the	O
table	O
2	O
.	O
Our	O
translators	O
are	O
asked	O
to	O
first	O
understand	O
the	O
context	O
of	O
the	O
given	O
schema	O
before	O
validating	O
the	O
translations	O
.	O
We	O
find	O
that	O
the	O
modification	O
rate	O
is	O
40	O
%	O
,	O
which	O
indicates	O
that	O
the	O
provided	O
context	O
is	O
very	O
useful	O
.	O
Finally	O
,	O
we	O
further	O
verify	O
the	O
annotated	O
data	O
by	O
asking	O
a	O
different	O
translator	O
to	O
check	O
if	O
the	O
headers	O
are	O
correctly	O
translated	O
.	O

To	O
solve	O
the	O
program	O
,	O
we	O
follow	O
the	O
convex	O
relaxation	O
approach	O
developed	O
in	O
(	O
Srikant	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Specifically	O
,	O
the	O
boolean	O
variables	O
(	O
for	O
tweet	O
and	O
word	O
selection	O
)	O
are	O
relaxed	O
into	O
the	O
continuous	O
space	O
so	O
that	O
they	O
can	O
be	O
optimized	O
by	O
gradientbased	O
methods	O
over	O
a	O
convex	O
hull	O
.	O
Two	O
main	O
implementations	O
of	O
the	O
optimization	O
-	O
based	O
attack	O
generation	O
method	O
are	O
proposed	O
:	O
joint	O
optimization	O
(	O
JO	O
)	O
solver	O
and	O
alternating	O
greedy	O
optimization	O
(	O
AGO	O
)	O
solver	O
.	O
JO	O
calls	O
projected	O
gradient	O
descent	O
method	O
to	O
optimize	O
the	O
tweet	O
and	O
word	O
selection	O
variables	O
and	O
word	O
replacement	O
variables	O
simultaneously	O
.	O
AGO	O
uses	O
an	O
alternative	O
optimization	O
procedure	O
to	O
sequentially	O
update	O
the	O
discrete	O
selection	O
variables	O
and	O
the	O
replacement	O
selection	O
variables	O
.	O
More	O
details	O
on	O
the	O
optimization	O
program	O
and	O
the	O
solvers	O
can	O
be	O
found	O
in	O
Appendix	O
A	O
.	O

We	O
evaluate	O
the	O
re	O
-	O
ranking	O
model	O
(	O
Section	O
3	O
)	O
in	O
several	O
settings	O
to	O
answer	O
the	O
following	O
questions	O
:	O
For	O
all	O
experiments	O
,	O
we	O
report	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
accuracy	O
across	O
five	O
runs	O
with	O
different	O
random	O
seeds	O
.	O

The	O
generation	O
mode	O
is	O
independent	O
of	O
the	O
generation	O
model	O
,	O
so	O
the	O
generation	O
models	O
and	O
the	O
generation	O
modes	O
can	O
be	O
combined	O
arbitrarily	O
.	O
We	O
employ	O
two	O
generation	O
modes	O
here	O
.	O

The	O
task	O
of	O
finding	O
experiment	O
-	O
specific	O
information	O
can	O
be	O
modeled	O
as	O
a	O
retrieval	O
task	O
(	O
i.e.	O
,	O
finding	O
relevant	O
information	O
in	O
documents	O
)	O
and	O
at	O
the	O
same	O
time	O
as	O
a	O
semantic	O
-	O
role	O
-	O
labeling	O
task	O
(	O
i.e.	O
,	O
identifying	O
the	O
slot	O
fillers	O
)	O
.	O
We	O
identify	O
three	O
sub	O
-	O
tasks	O
:	O

•	O
TASK	O
TYPE	O
defines	O
the	O
nature	O
of	O
the	O
mapping	O
from	O
instance	O
inputs	O
to	O
outputs	O
(	O
e.g.	O
,	O
question	O
answering	O
,	O
classification	O
,	O
etc	O
.	O
)	O
.	O

After	O
planning	O
the	O
target	O
T	O
and	O
the	O
keyword	O
sequence	O
W	O
,	O
we	O
train	O
CONPER	B-MethodName
to	O
generate	O
the	O
whole	O
story	O
conditioned	O
on	O
the	O
input	O
and	O
plans	O
with	O
the	O
standard	O
language	O
model	O
loss	O
L	O
ST	O
.	O
Since	O
we	O
extract	O
one	O
sentence	O
from	O
a	O
story	O
as	O
the	O
target	O
,	O
we	O
do	O
not	O
train	O
CONPER	B-MethodName
to	O
regenerate	O
the	O
sentence	O
in	O
the	O
story	O
generation	O
stage	O
.	O
And	O
we	O
insert	O
a	O
special	O
token	O
Target	O
in	O
the	O
story	O
to	O
specify	O
the	O
position	O
of	O
the	O
target	O
during	O
training	O
.	O
In	O
the	O
inference	O
time	O
,	O
CONPER	B-MethodName
first	O
plans	O
the	O
target	O
and	O
plot	O
,	O
then	O
generates	O
the	O
whole	O
story	O
,	O
and	O
finally	O
places	O
the	O
target	O
into	O
the	O
position	O
of	O
Target	O
.	O

We	O
use	O
the	O
standard	O
training	O
,	O
development	O
and	O
test	O
datasets	O
from	O
the	O
WMT'18	O
Task	O
4	O
track	O
.	O
For	O
feature	O
-	O
based	O
systems	O
,	O
we	O
follow	O
the	O
built	O
-	O
in	O
crossvalidation	O
in	O
QuEst++	O
,	O
and	O
train	O
a	O
single	O
model	O
with	O
the	O
hyperparameters	O
found	O
by	O
cross	O
-	O
validation	O
.	O
For	O
neural	O
-	O
based	O
models	O
,	O
we	O
use	O
early	O
-	O
stopping	O
with	O
a	O
patience	O
of	O
10	O
to	O
avoid	O
over	O
-	O
fitting	O
,	O
and	O
all	O
reported	O
figures	O
are	O
averaged	O
over	O
5	O
runs	O
corresponding	O
to	O
different	O
seeds	O
.	O

Neural	O
Retriever	O
Augmented	O
Language	O
Modeling	O
(	O
NRALM	O
)	O
:	O
Augmenting	O
language	O
models	O
with	O
neural	O
retrieval	O
has	O
been	O
shown	O
to	O
be	O
very	O
effective	O
,	O
such	O
as	O
by	O
retrieving	O
nearest	O
neighbor	O
words	O
for	O
LM	O
tasks	O
(	O
Khandelwal	O
et	O
al	O
.	O
,	O
2020	O
;	O
or	O
Machine	O
Translation	O
(	O
Khandelwal	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Dinan	O
et	O
al	O
.	O
(	O
2019	O
)	O
proposed	O
a	O
decomposed	O
transformer	O
for	O
conversation	O
tasks	O
,	O
which	O
enabled	O
pre	O
-	O
computation	O
of	O
the	O
external	O
knowledge	O
embeddings	O
.	O
ORQA	B-MethodName
proposed	O
the	O
ICT	O
task	O
to	O
pre	O
-	O
train	O
a	O
decomposed	O
retriever	O
,	O
and	O
DPR	B-MethodName
enhanced	O
this	O
approach	O
with	O
in	O
-	O
batch	O
negatives	O
and	O
hard	O
negatives	O
to	O
eliminate	O
the	O
pre	O
-	O
training	O
.	O
Synthetic	O
Data	I-MethodName
Augmentation	I-MethodName
is	O
also	O
commonly	O
used	O
,	O
such	O
as	O
in	O
DPR	B-MethodName
-	I-MethodName
PAQ	I-MethodName
(	O
Oguz	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
PAIR	B-MethodName
,	O
Hu	O
et	O
al	O
.	O
(	O
2021	O
)	O
.	O
Per	O
-	O
token	O
embeddings	O
or	O
multiple	O
embeddings	O
were	O
used	O
in	O
ColBERT	B-MethodName
,	O
ME	B-MethodName
-	I-MethodName
BERT	I-MethodName
(	O
Luan	O
et	O
al	O
.	O
,	O
2021	O
,	O
Lee	O
et	O
al	O
.	O
(	O
2021	O
)	O
.	O

,	O
and	O
v	O
I	O
i	O
is	O
obtained	O
from	O
Eq	O
.	O
(	O
4	O
)	O
.	O
Next	O
,	O
the	O
complete	O
class	O
-	O
level	O
embeddings	O
are	O
obtained	O
as	O
:	O

Template	O
:	O
Wrong	O
Answer	O
with	O
input	O
:	O
<	O
input	O
>	O
.	O
Expected	O
output	O
is	O
<	O
output_1	O
>	O
,	O
but	O
generated	O
output	O
is	O
<	O
output_2	O
>	O
.	O
Rewrite	O
the	O
code	O
.	O
Example	O
:	O
Wrong	O
Answer	O
with	O
input	O
:	O
2	O
5	O
3	O
.	O
Expected	O
output	O
is	O
1	O
,	O
but	O
generated	O
output	O
is	O
0	O
.	O
Rewrite	O
the	O
code	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
unsupervised	O
process	O
to	O
generate	O
questions	O
,	O
answers	O
and	O
associated	O
distractors	O
in	O
order	O
to	O
fine	O
-	O
tune	O
and	O
improve	O
the	O
performance	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
UnifiedQA	B-MethodName
on	O
unseen	O
domains	O
.	O
This	O
method	O
,	O
being	O
unsupervised	O
,	O
needs	O
no	O
additional	O
annotated	O
domain	O
specific	O
data	O
requiring	O
only	O
a	O
set	O
of	O
unannotated	O
sentences	O
of	O
the	O
domain	O
of	O
interest	O
from	O
which	O
the	O
questions	O
are	O
created	O
.	O
Contrarily	O
to	O
most	O
of	O
the	O
aforementioned	O
works	O
,	O
our	O
aim	O
is	O
not	O
to	O
train	O
a	O
new	O
completely	O
unsupervised	O
model	O
but	O
rather	O
to	O
incorporate	O
new	O
information	O
into	O
an	O
existing	O
stateof	O
-	O
the	O
-	O
art	O
model	O
and	O
thus	O
to	O
take	O
advantage	O
of	O
the	O
question	O
-	O
answering	O
knowledge	O
already	O
learned	O
.	O

We	O
begin	O
by	O
outlining	O
our	O
experimental	O
setup	O
,	O
and	O
describe	O
the	O
benchmarks	O
,	O
model	O
,	O
baselines	O
,	O
and	O
other	O
relevant	O
experimental	O
settings	O
.	O

We	O
evaluate	O
the	O
quality	O
(	O
intrinsic	O
evaluation	O
)	O
of	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
and	O
its	O
performance	O
on	O
an	O
exemplary	O
task	O
(	O
extrinsic	O
evaluation	O
)	O
.	O
As	O
a	O
basis	O
,	O
we	O
use	O
the	O
7,991	O
arguments	O
generated	O
in	O
Section	O
5	O
.	O

After	O
an	O
alignment	O
model	O
is	O
trained	O
with	O
PPA	O
,	O
we	O
extract	O
the	O
query	O
encoder	O
from	O
MoCo	B-MethodName
and	O
finetune	O
it	O
on	O
downstream	O
tasks	O
for	O
evaluation	O
.	O
We	O
follow	O
the	O
standard	O
way	O
of	O
finetuning	O
BERT	O
-	O
like	O
models	O
for	O
sequence	O
classification	O
and	O
QA	O
tasks	O
:	O

Position	O
Encoding	O
To	O
tackle	O
the	O
position	O
unaware	O
problem	O
,	O
absolute	O
position	O
information	O
is	O
injected	O
into	O
the	O
SANs	O
:	O

Table	O
10	O
shows	O
the	O
sources	O
and	O
number	O
of	O
arguments	O
for	O
all	O
topics	O
of	O
the	O
reference	O
dataset	O
.	O
The	O
dataset	O
is	O
used	O
to	O
compare	O
the	O
argument	O
generation	O
models	O
to	O
a	O
retrieval	O
approach	O
.	O

Audio	O
preprocessing	O
.	O
We	O
use	O
Kaldi	O
(	O
Povey	O
et	O
al	O
.	O
,	O
2011	O
)	O
to	O
create	O
Mel	O
-	O
filter	O
bank	O
features	O
(	O
FBANK	O
)	O
from	O
the	O
raw	O
audio	O
signals	O
.	O
Specifically	O
,	O
we	O
use	O
the	O
Hanning	O
window	O
,	O
128	O
triangular	O
Melfrequency	O
bins	O
,	O
and	O
10	O
millisecond	O
frameshift	O
.	O
We	O
always	O
use	O
the	O
first	O
audio	O
channel	O
when	O
an	O
audio	O
clip	O
has	O
more	O
than	O
one	O
channel	O
.	O
We	O
apply	O
two	O
normalizations	O
:	O
(	O
1	O
)	O
before	O
applying	O
Kaldi	O
,	O
we	O
subtract	O
the	O
mean	O
from	O
the	O
raw	O
audio	O
signals	O
;	O
and	O
(	O
2	O
)	O
we	O
compute	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
FBANK	O
on	O
the	O
unbalanced	O
AS	O
training	O
set	O
,	O
and	O
then	O
normalize	O
the	O
FBANK	O
of	O
each	O
audio	O
clip	O
.	O
For	O
data	O
augmentation	O
,	O
inspired	O
by	O
,	O
we	O
use	O
frequency	O
masking	O
and	O
time	O
masking	O
:	O
we	O
randomly	O
mask	O
out	O
one	O
-	O
fifth	O
FBANK	B-MethodName
along	O
the	O
time	O
dimension	O
and	O
one	O
-	O
forth	O
FBANK	O
along	O
the	O
frequency	O
dimension	O
during	O
training	O
.	O

In	O
real	O
-	O
life	O
applications	O
factual	O
knowledge	O
is	O
apt	O
to	O
evolve	O
over	O
time	O
(	O
Nonaka	O
et	O
al	O
.	O
,	O
2000	O
;	O
Roddick	O
and	O
Spiliopoulou	O
,	O
2002	O
;	O
Hoffart	O
et	O
al	O
.	O
,	O
2011	O
;	O
Gottschalk	O
and	O
Demidova	O
,	O
2018	O
)	O
;	O
for	O
instance	O
,	O
The	O
host	O
city	O
of	O
the	O
Winter	O
Olympic	O
Games	O
in	O
2018	O
was	O
South	O
Korea	O
,	O
while	O
in	O
2022	O
it	O
was	O
Beijing	O
.	O
In	O
this	O
connection	O
,	O
there	O
is	O
a	O
current	O
trend	O
to	O
investigate	O
knowledge	O
graphs	O
(	O
KGs	O
)	O
involving	O
time	O
,	O
and	O
these	O
KGs	O
are	O
coined	O
as	O
temporal	O
knowledge	O
graphs	O
(	O
TKGs	O
)	O
.	O
In	O
a	O
TKG	O
,	O
fact	O
triplets	O
are	O
equipped	O
with	O
temporal	O
information	O
(	O
e.g.	O
,	O
timestamps	O
)	O
,	O
and	O
a	O
temporal	O
fact	O
can	O
be	O
stated	O
in	O
the	O
form	O
like	O
"	O
(	O
Beijing	O
,	O
held	O
,	O
Winter	O
Olympic	O
Games	O
,	O
2022	O
)	O
"	O
.	O

A	O
binary	O
classifier	O
identical	O
to	O
Fin	B-MethodName
-	I-MethodName
GRU	I-MethodName
,	O
but	O
utilizes	O
LSTM	O
(	O
Hochreiter	O
and	O
Schmidhuber	O
,	O
1997	O
)	O
to	O
encode	O
temporal	O
dependence	O
.	O
The	O
model	O
is	O
trained	O
in	O
the	O
same	O
manner	O
as	O
FinGRU	B-MethodName
.	O

Limitations	O
have	O
been	O
described	O
as	O
separate	O
section	O
after	O
the	O
Conclusions	O
,	O
as	O
required	O
by	O
the	O
ACL	O
instructions	O
.	O

Relation	O
-	O
Aware	O
Self	O
-	O
Attention	O
.	O
First	O
,	O
we	O
introduce	O
self	O
-	O
attention	O
and	O
then	O
its	O
extension	O
,	O
relationaware	O
self	O
-	O
attention	O
.	O
Consider	O
a	O
sequence	O
of	O
inputs	O

We	O
provide	O
an	O
example	O
answer	O
generated	O
by	O
finetuning	O
and	O
our	O
inducer	O
-	O
tuning	O
with	O
LoRA	B-MethodName
on	O
CoQA	B-MethodName
in	O
Table	O
6	O
.	O

We	O
have	O
tried	O
two	O
kinds	O
of	O
MRD	O
to	O
dynamically	O
adjust	O
the	O
masking	O
ratio	O
,	O
namely	O
linear	O
decay	O
and	O
cosine	O
decay	O
as	O
follows	O
:	O

To	O
perform	O
the	O
statistical	O
analysis	O
presented	O
in	O
Section	O
5	O
,	O
we	O
take	O
the	O
premise	O
-	O
hypothesis	O
pairs	O
from	O
the	O
MedNLI	O
training	O
,	O
dev	O
,	O
and	O
test	O
splits	O
,	O
and	O
combine	O
them	O
to	O
produce	O
a	O
single	O
corpus	O
.	O
We	O
use	O
a	O
scispaCy	O
model	O
pre	O
-	O
trained	O
on	O
the	O
en_core_sci_lg	O
corpus	O
for	O
tokenization	O
and	O
entity	O
linking	O
(	O
Neumann	O
et	O
al	O
.	O
,	O
2019b	O
)	O
,	O
and	O
link	O
against	O
the	O
Medical	O
Subject	O
Headings	O
(	O
MeSH	O
)	O
knowledge	O
base	O
.	O
We	O
take	O
the	O
top	O
-	O
ranked	O
knowledge	O
base	O
entry	O
for	O
each	O
linked	O
entity	O
.	O
Linking	O
against	O
MeSH	O
provides	O
a	O
unique	O
concept	O
i	O
d	O
,	O
canonical	O
name	O
,	O
alias(es	O
)	O
,	O
a	O
definition	O
,	O
and	O
one	O
or	O
more	O
MeSH	O
tree	O
numbers	O
for	O
each	O
recovered	O
entity	O
.	O
Tree	O
numbers	O
convey	O
semantic	O
type	O
information	O
by	O
embedding	O
each	O
concept	O
into	O
the	O
broader	O
MeSH	O
hierarchy	O
3	O
.	O
We	O
operationalize	O
each	O
of	O
our	O
heuristics	O
with	O
a	O
set	O
of	O
MeSH	O
-	O
informed	O
semantic	O
properties	O
,	O
which	O
are	O
defined	O
as	O
follows	O
:	O

We	O
conducted	O
three	O
human	O
experiments	O
(	O
one	O
feasibility	O
study	O
and	O
two	O
debugging	O
experiments	O
)	O
to	O
demonstrate	O
the	O
usefulness	O
of	O
FIND	O
.	O
For	O
all	O
the	O
experiments	O
,	O
we	O
used	O
as	O
classifiers	O
convolutional	O
neural	O
networks	O
(	O
CNNs	O
)	O
(	O
Kim	O
,	O
2014	O
)	O
,	O
which	O
are	O
a	O
popular	O
,	O
well	O
-	O
performing	O
architecture	O
for	O
many	O
text	O
classification	O
tasks	O
including	O
the	O
tasks	O
we	O
experimented	O
with	O
(	O
Gambäck	O
and	O
Sikdar	O
,	O
2017;Johnson	O
and	O
Zhang	O
,	O
2015;Zhang	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
overall	O
results	O
show	O
that	O
FIND	B-MethodName
with	O
human	O
-	O
in	O
-	O
the	O
-	O
loop	O
can	O
improve	O
the	O
text	O
classifiers	O
and	O
mitigate	O
the	O
said	O
problems	O
in	O
the	O
datasets	O
.	O
After	O
the	O
experiments	O
,	O
we	O
discuss	O
the	O
generalization	O
of	O
the	O
proposed	O
framework	O
to	O
other	O
tasks	O
and	O
models	O
.	O
Overall	O
,	O
the	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
:	O

The	O
scores	O
presented	O
are	O
significantly	O
different	O
(	O
p	O
<	O
0.05	O
)	O
from	O
the	O
respective	O
baseline	O
.	O
CHRF1	O
refers	O
to	O
character	O
n	O
-	O
gram	O
F1	O
score	O
(	O
Popović	O
,	O
2015	O
)	O
.	O
The	O
models	O
in	O
italics	O
are	O
ours	O
.	O

1	O
.	O
If	O
the	O
target	O
word	O
is	O
the	O
surname	O
of	O
a	O
person	O
,	O
the	O
example	O
should	O
be	O
tagged	O
surname	O
.	O
15	O
2	O
.	O
If	O
the	O
entity	O
(	O
as	O
a	O
whole	O
)	O
refers	O
to	O
one	O
of	O
the	O
word	O
-	O
meanings	O
,	O
it	O
should	O
be	O
labeled	O
as	O
such	O
.	O
For	O
example	O
,	O
Quitobaquito	O
Springs	O
label	O
should	O
refer	O
to	O
a	O
natural	O
source	O
of	O
water	O
.	O

Stability	O
w.r.t	O
.	O
the	O
number	O
of	O
runs	O
K.	O
Figure	O
1	O
shows	O
the	O
results	O
on	O
stability	O
.	O
In	O
light	O
of	O
limited	O
computation	O
resources	O
,	O
we	O
only	O
experiment	O
with	O
some	O
representative	O
strategies	O
.	O
Both	O
CV	O
and	O
MDL	O
represent	O
strategies	O
whose	O
number	O
of	O
runs	O
are	O
coupled	O
with	O
the	O
size	O
of	O
data	O
split	O
,	O
while	O
Multi	O
-	I-MethodName
Splits	I-MethodName
represents	O
strategies	O
that	O
have	O
a	O
fixed	O
ratio	O
and	O
independent	O
K.	O
We	O
observe	O
:	O
(	O
1	O
)	O
Multi	O
-	O
Splits	O
(	O
blue	O
lines	O
)	O
is	O
the	O
most	O
stable	O
in	O
correlation	O
and	O
performance	O
,	O
while	O
other	O
strategies	O
CV	O
and	O
MDL	O
are	O
more	O
sensitive	O
to	O
the	O
choice	O
of	O
K	O
.	O

where	O
L	O
impt	O
is	O
a	O
task	O
-	O
specific	O
/	O
domain	O
-	O
specific	O
loss	O
function	O
.	O
The	O
gradient	O
can	O
be	O
used	O
as	O
the	O
importance	O
score	O
because	O
changing	O
g	O
lh	O
is	O
liable	O
to	O
have	O
a	O
large	O
effect	O
on	O
the	O
model	O
if	O
I	O
lh	O
has	O
a	O
high	O
value	O
.	O
Although	O
Eq	O
.	O
6	O
offers	O
a	O
way	O
to	O
compute	O
the	O
importance	O
of	O
attention	O
heads	O
w.r.t	O
.	O
a	O
given	O
loss	O
L	O
impt	O
,	O
we	O
are	O
unable	O
to	O
directly	O
apply	O
it	O
:	O
If	O
we	O
use	O
the	O
domain	O
data	O
at	O
hand	O
and	O
the	O
MLM	O
loss	O
as	O
L	O
impt	O
,	O
∇	O
g	O
lh	O
only	O
indicates	O
the	O
importance	O
score	O
for	O
domain	O
-	O
specific	O
knowledge	O
.	O
However	O
,	O
our	O
goal	O
is	O
to	O
estimate	O
the	O
attention	O
heads	O
importance	O
for	O
the	O
general	O
knowledge	O
in	O
LM	O
which	O
requires	O
the	O
data	O
used	O
in	O
training	O
the	O
LM	O
to	O
compute	O
the	O
L	O
impt	O
.	O

We	O
also	O
fine	O
-	O
tune	O
the	O
original	O
BERT	B-MethodName
and	O
SciB	B-MethodName
-	I-MethodName
ERT	I-MethodName
sequence	O
tagging	O
models	O
on	O
this	O
task	O
.	O
Since	O
we	O
use	O
BIO	B-MethodName
labels	O
,	O
we	O
extend	O
it	O
with	O
a	O
CRF	O
output	O
layer	O
to	O
enable	O
it	O
to	O
correctly	O
label	O
multi	O
-	O
token	O
mentions	O
and	O
to	O
enable	O
it	O
to	O
learn	O
transition	O
scores	O
between	O
labels	O
.	O
As	O
a	O
non	O
-	O
neural	O
baseline	O
,	O
we	O
train	O
5	O
https://github.com/huggingface/	O
transformers	O
6	O
We	O
use	O
sklearn	O
,	O
https://scikit-learn.org	O
.	O

For	O
tasks	O
like	O
table	O
-	O
to	O
-	O
text	O
that	O
word	O
overlapping	O
is	O
enough	O
to	O
infer	O
the	O
precise	O
causality	O
,	O
we	O
randomly	O
sample	O
several	O
spans	O
from	O
y	O
as	O
Y	O
and	O
find	O
the	O
corresponding	O
X	O
by	O
word	O
overlapping	O
.	O
While	O
,	O
for	O
highly	O
abstractive	O
generation	O
like	O
text	O
summarization	O
,	O
we	O
use	O
the	O
global	O
information	O
y	O
as	O
Y	O
and	O
infer	O
X	O
by	O
gradient	O
ranking	O
,	O
which	O
measures	O
the	O
salience	O
of	O
a	O
token	O
by	O
gradient	O
norm	O
(	O
Simonyan	O
et	O
al	O
.	O
,	O
2014	O
;	O
Li	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
After	O
the	O
X	O
is	O
inferred	O
,	O
we	O
search	O
around	O
the	O
neighbors	O
of	O
word	O
embedding	O
space	O
for	O
meaning	O
preserving	O
swapping	O
,	O
utilizing	O
the	O
semantic	O
textual	O
similarity	O
of	O
word	O
embeddings	O
(	O
Li	O
et	O
al	O
.	O
,	O
2020a	O
)	O
.	O
To	O
make	O
the	O
adversarial	O
samples	O
more	O
challenging	O
,	O
we	O
search	O
at	O
the	O
direction	O
of	O
gradient	O
ascent	O
to	O
replace	O
x	O
t	O
∈	O
X	O
withx	O
t	O
:	O

•	O
SQuAD	O
2.0	O
:	O
Stanford	O
Question	O
Answering	O
Dataset	O
version	O
2.0	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
This	O
task	O
adds	O
addition	O
questions	O
to	O
SQuAD	O
whose	O
answer	O
does	O
not	O
exist	O
in	O
the	O
context	O
;	O
models	O
have	O
to	O
recognize	O
when	O
these	O
questions	O
occur	O
and	O
not	O
return	O
an	O
answer	O
for	O
them	O
.	O

Dataset	O
Analysis	O
.	O
To	O
have	O
a	O
more	O
quantitative	O
analysis	O
of	O
our	O
dataset	O
,	O
we	O
count	O
the	O
ratio	O
of	O
headers	O
containing	O
four	O
lexical	O
features	O
,	O
including	O
abbreviation	O
,	O
symbol	O
characters	O
,	O
verb	O
-	O
object	O
phrase	O
and	O
capitalized	O
character	O
.	O
As	O
we	O
can	O
see	O
in	O
table	O
2	O
,	O
these	O
lexical	O
features	O
commonly	O
occur	O
in	O
headers	O
,	O
making	O
them	O
quite	O
different	O
from	O
plain	O
text	O
.	O

We	O
evaluate	O
LM	B-MethodName
-	I-MethodName
KT	I-MethodName
two	O
ways	O
:	O
first	O
,	O
its	O
ability	O
to	O
predict	O
if	O
an	O
individual	O
student	O
will	O
answer	O
a	O
novel	O
question	O
correctly	O
on	O
a	O
held	O
-	O
out	O
test	O
set	O
of	O
real	O
Duolingo	O
student	O
responses	O
.	O
Second	O
,	O
how	O
wellcalibrated	O
these	O
predictions	O
are	O
,	O
which	O
is	O
crucial	O
to	O
our	O
later	O
use	O
of	O
LM	O
-	I-MethodName
KT	I-MethodName
for	O
question	O
generation	O
.	O
Table	O
1	O
compares	O
AUC	B-MethodName
-	I-MethodName
ROC	I-MethodName
on	O
a	O
held	O
-	O
out	O
test	O
set	O
for	O
our	O
LM	O
-	O
KT	I-MethodName
model	O
with	O
standard	O
DKT	B-MethodName
,	O
which	O
uses	O
question	O
IDs	O
instead	O
of	O
text	O
,	O
and	O
a	O
baseline	O
that	O
ignores	O
the	O
student	O
state	O
,	O
only	O
using	O
the	O
question	O
text	O
representation	O
.	O
This	O
question	O
only	O
baseline	O
would	O
perform	O
well	O
if	O
the	O
Duolingo	O
dataset	O
largely	O
consisted	O
of	O
universally	O
"	O
easy	O
"	O
and	O
"	O
difficult	O
"	O
questions	O
,	O
independent	O
of	O
individual	O
student	O
.	O
Our	O
results	O
show	O
that	O
incorporating	O
the	O
student	O
state	O
is	O
crucial	O
for	O
accurately	O
predicting	O
Duolingo	O
user	O
responses	O
,	O
and	O
including	O
question	O
text	O
also	O
leads	O
to	O
a	O
significant	O
improvement	O
.	O
LM	O
-	I-MethodName
KT	I-MethodName
outperforms	O
Standard	O
DKT	I-MethodName
especially	O
on	O
novel	O
questions	O
-	O
a	O
necessary	O
generalization	O
ability	O
for	O
generation	O
.	O

Fine	O
-	O
tuning	O
UnifiedQA	B-MethodName
on	O
synthetic	O
questions	O
with	O
random	O
distractors	O
improves	O
the	O
results	O
as	O
compared	O
to	O
the	O
baseline	O
and	O
,	O
as	O
expected	O
,	O
the	O
closer	O
the	O
unlabeled	O
sentences	O
are	O
to	O
the	O
topics	O
of	O
the	O
questions	O
,	O
the	O
better	O
is	O
the	O
accuracy	O
.	O
Hence	O
,	O
generating	O
questions	O
from	O
only	O
the	O
train	O
set	O
of	O
SciQ	B-MethodName
gives	O
performances	O
that	O
are	O
comparable	O
but	O
slightly	O
lower	O
to	O
the	O
ones	O
obtained	O
from	O
the	O
combined	O
train	O
,	O
dev	O
and	O
test	O
set	O
of	O
SciQ.	B-MethodName
Finally	O
,	O
questions	O
selected	O
from	O
Wikipedia	O
also	O
improve	O
the	O
results	O
,	O
despite	O
being	O
loosely	O
related	O
to	O
the	O
target	O
test	O
corpus	O
.	O
Our	O
distractor	O
selection	O
method	O
further	O
boosts	O
the	O
accuracy	O
results	O
in	O
all	O
setups	O
.	O
This	O
suggests	O
that	O
a	O
careful	O
selection	O
of	O
distractors	O
is	O
important	O
,	O
and	O
that	O
the	O
hard	O
selection	O
criterion	O
used	O
here	O
seems	O
adequate	O
in	O
our	O
context	O
.	O

PLLs	O
can	O
be	O
used	O
to	O
re	O
-	O
rank	O
the	O
outputs	O
of	O
an	O
NMT	B-MethodName
or	O
ASR	B-MethodName
system	O
.	O
While	O
historically	O
log	O
-	O
likelihoods	O
from	O
language	O
models	O
have	O
been	O
used	O
for	O
such	O
reranking	O
,	O
recent	O
work	O
has	O
demonstrated	O
that	O
PLLs	O
from	O
masked	O
language	O
models	O
perform	O
better	O
(	O
Shin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
However	O
,	O
computing	O
PLLs	O
from	O
a	O
masked	O
language	O
model	O
requires	O
n	O
passes	O
of	O
the	O
transformer	O
:	O
once	O
with	O
each	O
token	O
masked	O
out	O
.	O
Salazar	O
et	O
al	O
.	O
(	O
2020	O
)	O
suggest	O
distilling	O
BERT	B-MethodName
into	O
a	O
model	O
that	O
uses	O
no	O
masking	O
to	O
avoid	O
this	O
cost	O
,	O
but	O
this	O
model	O
considerably	O
under	O
-	O
performed	O
regular	O
LMs	O
in	O
their	O
experiments	O
.	O

Multimodality	O
is	O
achieved	O
with	O
two	O
changes	O
in	O
our	O
monomodal	O
models	O
:	O
multimodality	O
integration	O
(	O
where	O
to	O
integrate	O
the	O
visual	O
features	O
in	O
the	O
architecture	O
)	O
,	O
and	O
fusion	O
strategy	O
(	O
how	O
to	O
fuse	O
the	O
visual	O
and	O
textual	O
features	O
)	O
.	O
We	O
propose	O
the	O
following	O
places	O
to	O
integrate	O
the	O
visual	O
feature	O
vector	O
into	O
the	O
BiRNN	O
architecture	O
:	O

Energy	O
-	O
based	O
models	O
have	O
been	O
widely	O
explored	O
in	O
machine	O
learning	O
(	O
Dayan	O
et	O
al	O
.	O
,	O
1995	O
et	O
al	O
.	O
,	O
2007	O
)	O
.	O
While	O
many	O
training	O
methods	O
involve	O
sampling	O
from	O
the	O
EBM	O
using	O
gradientbased	O
MCMC	B-MethodName
(	O
Du	O
and	O
Mordatch	O
,	O
2019	O
)	O
or	O
Gibbs	O
sampling	O
(	O
Hinton	O
,	O
2002	O
)	O
,	O
we	O
considered	O
these	O
approaches	O
too	O
slow	O
for	O
pre	O
-	O
training	O
because	O
they	O
require	O
multiple	O
passes	O
through	O
the	O
model	O
per	O
sample	O
.	O
We	O
instead	O
use	O
noise	O
-	O
contrastive	O
estimation	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010	O
)	O
,	O
which	O
has	O
widely	O
been	O
used	O
in	O
NLP	O
for	O
learning	O
word	O
vectors	O
(	O
Mnih	O
and	O
Kavukcuoglu	O
,	O
2013	O
)	O
and	O
text	O
generation	O
models	O
(	O
Jean	O
et	O
al	O
.	O
,	O
2014;Józefowicz	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
While	O
EBMs	O
have	O
previously	O
been	O
applied	O
to	O
leftto	O
-	O
right	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2015	O
)	O
or	O
globally	O
normalized	O
(	O
Rosenfeld	O
et	O
al	O
.	O
,	O
2001;Deng	O
et	O
al	O
.	O
,	O
2020	O
)	O
text	O
generation	O
,	O
they	O
have	O
not	O
previously	O
been	O
applied	O
to	O
cloze	O
models	O
or	O
for	O
pre	O
-	O
training	O
NLP	O
models	O
.	O
Several	O
papers	O
have	O
pointed	O
out	O
the	O
connection	O
between	O
EBMs	O
and	O
GANs	O
(	O
Zhao	O
et	O
al	O
.	O
,	O
2016;Finn	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
which	O
is	O
similar	O
to	O
the	O
Electric	O
/	O
ELECTRA	O
connection	O
.	O

Although	O
self	O
-	O
attention	O
networks	O
(	O
SANs	O
)	O
(	O
Lin	O
et	O
al	O
.	O
,	O
2017	O
)	O
have	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
several	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
tasks	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017;Devlin	O
et	O
al	O
.	O
,	O
2019;Radford	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
they	O
possess	O
the	O
innate	O
disadvantage	O
of	O
sequential	O
modeling	O
due	O
to	O
the	O
lack	O
of	O
positional	O
information	O
.	O
Therefore	O
,	O
absolute	O
position	O
encoding	O
(	O
APE	O
)	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
relative	O
position	O
encoding	O
(	O
RPE	O
)	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
were	O
introduced	O
to	O
better	O
capture	O
the	O
sequential	O
dependencies	O
.	O
However	O
,	O
either	O
absolute	O
or	O
relative	O
PE	O
is	O
language	O
-	O
independent	O
and	O
its	O
embedding	O
remains	O
fixed	O
.	O
This	O
inhibits	O
the	O
capacity	O
of	O
SANs	O
when	O
modelling	O
multiple	O
languages	O
,	O
which	O
have	O
diverse	O
word	O
orders	O
and	O
structures	O
(	O
Gell	O
-	O
Mann	O
and	O
Ruhlen	O
,	O
2011	O
)	O
.	O
Recent	O
work	O
have	O
shown	O
that	O
modeling	O
cross	O
-	O
lingual	O
information	O
(	O
e.g.	O
,	O
alignment	O
or	O
reordering	O
)	O
at	O
encoder	O
or	O
attention	O
level	O
improves	O
translation	O
performance	O
for	O
different	O
language	O
pairs	O
(	O
Cohn	O
et	O
al	O
.	O
,	O
2016;Du	O
and	O
Way	O
,	O
2017;Zhao	O
et	O
al	O
.	O
,	O
2018;Kawara	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Inspired	O
by	O
their	O
work	O
,	O
we	O
propose	O
to	O
augment	O
SANs	O
with	O
cross	O
-	O
lingual	O
representations	O
,	O
by	O
encoding	O
reordering	O
indices	O
at	O
embedding	O
level	O
.	O
Taking	O
English⇒Chinese	O
translation	O
task	O
for	O
example	O
,	O
we	O
first	O
reorder	O
the	O
English	O
sentence	O
by	O
deriving	O
a	O
latent	O
bracketing	O
transduction	O
grammar	O
(	O
BTG	O
)	O
tree	O
(	O
Wu	O
,	O
1997	O
)	O
(	O
Fig	O
.	O
1a	O
)	O
.	O
Similar	O
to	O
absolute	O
position	O
,	O
the	O
reordering	O
information	O
can	O
be	O
represented	O
as	O
cross	O
-	O
lingual	O
position	O
(	O
Fig	O
.	O
1b	O
)	O
.	O
In	O
addition	O
,	O
we	O
propose	O
two	O
strategies	O
to	O
incorporate	O
cross	O
-	O
lingual	O
position	O
encoding	O
into	O
SANs	O
.	O
We	O
conducted	O
experiments	O
on	O
three	O
commonlycited	O
datasets	O
of	O
machine	O
translation	O
.	O
Results	O
show	O
that	O
exploiting	O
cross	O
-	O
lingual	O
PE	O
consistently	O
improves	O
translation	O
quality	O
.	O
Further	O
analysis	O
reveals	O
that	O
our	O
method	O
improves	O
the	O
alignment	O
quality	O
(	O
§	O
Sec	O
.	O
4.3	O
)	O
and	O
context	O
-	O
free	O
Transformer	O
(	O
Tang	O
et	O
al	O
.	O
,	O
2019	O
)	O
(	O
§	O
Sec	O
.	O
4.4	O
)	O
.	O
Furthermore	O
,	O
contrastive	O
evaluation	O
demonstrates	O
that	O
NMT	O
models	O
benefits	O
from	O
the	O
cross	O
-	O
lingual	O
information	O
rather	O
than	O
denoising	O
ability	O
(	O
§	O
Sec	O
.	O
4.5	O
)	O
.	O

Consider	O
a	O
neuron	O
k	O
whose	O
value	O
is	O
computed	O
using	O
n	O
neurons	O
in	O
the	O
previous	O
layer	O
,	O

We	O
confirm	O
the	O
presence	O
of	O
annotation	O
artifacts	O
in	O
MedNLI	B-MethodName
and	O
proceed	O
to	O
identify	O
their	O
lexical	O
and	O
semantic	O
characteristics	O
.	O
We	O
then	O
conduct	O
adversarial	O
filtering	O
to	O
partition	O
MedNLI	B-MethodName
into	O
easy	O
and	O
difficult	O
subsets	O
(	O
Sakaguchi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
find	O
that	O
performance	O
of	O
off	O
-	O
the	O
-	O
shelf	O
fastText	O
-	O
based	O
hypothesis	O
-	O
only	O
and	O
hypothesis	O
-	O
plus	O
-	O
premise	O
classifiers	O
is	O
lower	O
on	O
the	O
difficult	O
subset	O
than	O
on	O
the	O
full	O
and	O
easy	O
subsets	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
We	O
provide	O
partition	O
information	O
for	O
downstream	O
use	O
,	O
and	O
conclude	O
by	O
advocating	O
alternative	O
dataset	O
construction	O
strategies	O
for	O
knowledge	O
-	O
intensive	O
domains	O
.	O
1	O

We	O
follow	O
the	O
definition	O
of	O
an	O
unrestricted	O
compression	O
ratio	O
(	O
Grusky	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
dividing	O
the	O
(	O
token	O
)	O
length	O
of	O
an	O
article	O
by	O
the	O
associated	O
summary	O
(	O
token	O
)	O
length	O
.	O
This	O
carries	O
the	O
same	O
semantic	O
value	O
as	O
inverse	O
definitions	O
of	O
compression	O
ratio	O
,	O
such	O
as	O
used	O
by	O
Bommasani	O
and	O
Cardie	O
(	O
2020	O
)	O
.	O
When	O
looking	O
at	O
the	O
token	O
-	O
level	O
compression	O
ratio	O
displayed	O
in	O
Figure	O
3	O
,	O
a	O
comparatively	O
high	O
mean	O
is	O
observed	O
,	O
despite	O
extremely	O
long	O
summary	O
documents	O
.	O
Comparing	O
compression	O
ratios	O
reported	O
by	O
(	O
Zhong	O
et	O
al	O
.	O
,	O
2019	O
)	O
for	O
news	O
-	O
based	O
datasets	O
indicates	O
that	O
EUR	B-MethodName
-	I-MethodName
Lex	I-MethodName
-	I-MethodName
Sum	I-MethodName
has	O
a	O
mean	O
compression	O
ratios	O
similar	O
to	O
the	O
CNN	O
/	O
DailyMail	O
(	O
Hermann	O
et	O
al	O
.	O
,	O
2015	O
)	O
and	O
NYT	O
(	O
Sandhaus	O
,	O
2008	O
)	O
corpora	O
.	O

Judgment	O
includes	O
the	O
referred	O
law	O
articles	O
,	O
the	O
charge	O
and	O
the	O
term	O
of	O
penalty	O
,	O
which	O
is	O
determined	O
by	O
the	O
judge	O
according	O
to	O
the	O
fact	O
and	O
rationales	O
.	O
Here	O
,	O
we	O
denote	O
the	O
referred	O
law	O
article	O
as	O
a	O
,	O
the	O
charge	O
as	O
c	O
,	O
and	O
the	O
term	O
of	O
penalty	O
as	O
p.	O
The	O
law	O
article	O
and	O
the	O
charge	O
are	O
in	O
the	O
form	O
of	O
labels	O
,	O
and	O
the	O
term	O
of	O
penalty	O
is	O
represented	O
in	O
months	O
(	O
numerical	O
values	O
)	O
.	O

The	O
number	O
of	O
scored	O
candidate	O
distractors	O
is	O
an	O
hyper	O
-	O
parameter	O
.	O
A	O
small	O
number	O
of	O
candidates	O
may	O
result	O
in	O
a	O
situation	O
where	O
none	O
of	O
the	O
candidates	O
are	O
credible	O
enough	O
,	O
while	O
a	O
large	O
number	O
requires	O
more	O
computation	O
time	O
,	O
since	O
the	O
score	O
of	O
each	O
candidate	O
for	O
every	O
question	O
needs	O
to	O
be	O
computed	O
,	O
and	O
has	O
a	O
higher	O
risk	O
of	O
proposing	O
multiple	O
valid	O
answers	O
.	O
In	O
our	O
experiments	O
,	O
we	O
use	O
a	O
number	O
of	O
64	O
candidates	O
in	O
order	O
to	O
limit	O
computation	O
time	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
2	O
.	O
Electric	O
scores	O
better	O
than	O
GPT-2	B-MethodName
when	O
trained	O
on	O
comparable	O
data	O
.	O
While	O
scoring	O
worse	O
than	O
BERT	B-MethodName
,	O
Electric	O
is	O
much	O
faster	O
to	O
run	O
.	O
It	O
also	O
slightly	O
outperforms	O
ELECTRA	B-MethodName
-	I-MethodName
TT	I-MethodName
,	O
which	O
is	O
consistent	O
with	O
the	O
finding	O
from	O
Labeau	O
and	O
Allauzen	O
(	O
2018	O
)	O
that	O
NCE	B-MethodName
outperforms	O
negative	O
sampling	O
for	O
training	O
language	O
models	O
.	O
Furthermore	O
,	O
Electric	O
is	O
simpler	O
and	O
faster	O
than	O
ELETRA	B-MethodName
-	I-MethodName
TT	I-MethodName
in	O
that	O
it	O
does	O
not	O
require	O
running	O
the	O
generator	O
to	O
produce	O
PLL	B-MethodName
scores	O
.	O
TwoTower	B-MethodName
scores	O
lower	O
than	O
Electric	O
,	O
presumably	O
because	O
it	O
is	O
not	O
a	O
"	O
deeply	O
"	O
bidirectional	O
model	O
and	O
instead	O
just	O
concatenates	O
forward	O
and	O
backward	O
hidden	O
states	O
.	O

For	O
each	O
output	O
token	O
,	O
the	O
LM	O
prediction	O
is	O
obtained	O
by	O
feeding	O
the	O
prefix	O
upto	O
that	O
token	O
to	O
the	O
LM	O
model	O
.	O
These	O
predictions	O
are	O
pre	O
-	O
computed	O
for	O
training	O
and	O
validation	O
sets	O
.	O
This	O
ensures	O
parallelization	O
and	O
avoids	O
the	O
overhead	O
to	O
run	O
the	O
LM	O
simultaneously	O
during	O
the	O
training	O
process	O
.	O
During	O
inference	O
,	O
the	O
LM	O
model	O
is	O
called	O
every	O
time	O
a	O
new	O
output	O
token	O
is	O
written	O
.	O

There	O
exists	O
a	O
rich	O
body	O
of	O
work	O
on	O
precisely	O
modeling	O
student	O
"	O
ability	O
"	O
and	O
learning	O
.	O
For	O
example	O
,	O
Item	B-MethodName
Response	I-MethodName
Theory	I-MethodName
(	O
IRT	O
)	O
seeks	O
to	O
model	O
individual	O
student	O
ability	O
based	O
on	O
their	O
responses	O
to	O
different	O
questions	O
,	O
creating	O
a	O
strong	O
factorization	O
between	O
students	O
and	O
test	O
items	O
(	O
Lord	O
,	O
1980;Hambelton	O
and	O
Jodoin	O
,	O
2003	O
)	O
.	O
Meanwhile	O
,	O
Computer	O
Adaptive	O
Testing	O
(	O
CAT	O
)	O
techniques	O
are	O
used	O
to	O
determine	O
a	O
fixed	O
student	O
ability	O
as	O
quickly	O
as	O
possible	O
by	O
selecting	O
test	O
items	O
based	O
on	O
information	O
utility	O
(	O
Weiss	O
and	O
Kingsbury	O
,	O
1984;Thissen	O
and	O
Mislevy	O
,	O
2000;Settles	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
However	O
,	O
these	O
methods	O
,	O
which	O
have	O
been	O
used	O
to	O
develop	O
efficient	O
standardized	O
tests	O
,	O
do	O
not	O
necessarily	O
optimize	O
a	O
student	O
's	O
learning	O
experience	O
(	O
Mu	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
We	O
instead	O
focus	O
on	O
tracking	O
each	O
student	O
's	O
evolving	O
knowledge	O
,	O
choosing	O
questions	O
to	O
target	O
difficulty	O
.	O

(	O
2	O
)	O
Hypothesis	O
Faithfulness	O
.	O
Does	O
H	O
faithfully	O
follow	O
T	O
p	O
?	O
To	O
check	O
this	O
,	O
we	O
extract	O
the	O
highest	O
conclusion	O
int	O
h	O
in	O
T	O
p	O
(	O
e.g.	O
,	O
int	O
2	O
in	O
Figure	O
2	O
)	O
and	O
verify	O
if	O
int	O
h	O
can	O
support	O
H.	O
Following	O
Dalvi	O
et	O
al	O
.	O
(	O
2021	O
)	O
,	O
we	O
use	O
BLEURT	B-MethodName
(	O
Sellam	O
et	O
al	O
.	O
,	O
2020	O
)	O
as	O
the	O
scorer	O
V	O
h	O
to	O
estimate	O
the	O
sentence	O
similarity	O
between	O
int	O
h	O
and	O
H.	O
In	O
addition	O
,	O
we	O
check	O
whether	O
H	O
is	O
entailed	O
by	O
int	O
h	O
with	O
the	O
step	O
verifier	O
V	O
s	O
.	O

Parallel	O
Data	O
All	O
parallel	O
data	O
we	O
use	O
involve	O
English	O
as	O
the	O
source	O
language	O
.	O
Specifically	O
,	O
we	O
collect	O
en	O
-	O
fr	O
,	O
en	O
-	O
es	O
,	O
en	O
-	O
de	O
parallel	O
pairs	O
from	O
Europarl	O
,	O
en	O
-	O
ar	O
,	O
en	O
-	O
zh	O
from	O
MultiUN	B-MethodName
(	O
Ziemski	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
en	O
-	O
hi	O
from	O
IITB	O
(	O
Kunchukuttan	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
and	O
en	O
-	O
bg	O
from	O
both	O
Europarl	O
and	O
EUbookshop	O
.	O
All	O
datasets	O
were	O
downloaded	O
from	O
the	O
OPUS	B-MethodName
3	O
website	O
(	O
Tiedemann	O
,	O
2012	O
)	O
.	O
In	O
our	O
experiments	O
,	O
we	O
vary	O
the	O
number	O
of	O
parallel	O
sentence	O
pairs	O
for	O
PPA	O
.	O
For	O
each	O
language	O
,	O
we	O
take	O
the	O
first	O
250k	O
,	O
600k	O
,	O
and	O
2	O
M	O
English	O
-	O
translation	O
parallel	O
sentence	O
pairs	O
except	O
for	O
those	O
too	O
short	O
(	O
where	O
either	O
sentence	O
has	O
less	O
than	O
10	O
WordPiece	O
tokens	O
)	O
,	O
or	O
too	O
long	O
(	O
where	O
both	O
sentences	O
concatenated	O
together	O
have	O
more	O
than	O
128	O
WordPiece	O
tokens	O
)	O
.	O
Table	O
1	O
shows	O
the	O
actual	O
number	O
of	O
parallel	O
pairs	O
in	O
each	O
of	O
our	O
250k	O
,	O
600k	O
,	O
and	O
2	O
M	O
settings	O
.	O

In	O
addition	O
to	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
transfer	O
,	O
we	O
also	O
showed	O
that	O
code	O
-	O
switching	O
with	O
English	O
during	O
finetuning	O
provides	O
additional	O
alignment	O
signals	O
,	O
when	O
training	O
data	O
is	O
available	O
for	O
the	O
target	O
language	O
.	O

For	O
both	O
French	O
and	O
Spanish	O
question	O
generation	O
models	O
,	O
we	O
select	O
15	O
students	O
unseen	O
during	O
training	O
and	O
generate	O
30	O
questions	O
across	O
9	O
difficulties	O
from	O
0.1	O
to	O
0.9	O
,	O
using	O
nucleus	O
sampling	O
(	O
Holtzman	O
et	O
al	O
.	O
,	O
2020	O
)	O
(	O
p	O
=	O
0.99	O
)	O
with	O
a	O
maximum	O
output	O
length	O
of	O
20	O
tokens	O
.	O
We	O
also	O
vary	O
a	O
repetition	O
penalty	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
that	O
penalizes	O
for	O
previous	O
tokens	O
(	O
including	O
those	O
in	O
the	O
student	O
state	O
)	O
.	O
Lastly	O
,	O
we	O
resize	O
all	O
prompts	O
(	O
student	O
state	O
and	O
target	O
difficulty	O
)	O
to	O
fit	O
into	O
the	O
GPT-2	O
Model	O
by	O
taking	O
the	O
most	O
recent	O
1024	O
tokens	O
,	O
as	O
in	O
training	O
.	O
This	O
is	O
a	O
limitation	O
of	O
our	O
work	O
,	O
as	O
the	O
full	O
student	O
history	O
is	O
not	O
able	O
to	O
be	O
considered	O
for	O
students	O
who	O
have	O
answered	O
a	O
large	O
set	O
of	O
questions	O
.	O

We	O
found	O
that	O
answer	O
generation	O
more	O
easily	O
over	O
-	O
fits	O
compared	O
to	O
the	O
retrieval	O
during	O
finetuning	O
.	O
To	O
prevent	O
this	O
over	O
-	O
fitting	O
,	O
the	O
model	O
is	O
once	O
reinitialized	O
from	O
the	O
pre	O
-	O
trained	O
YONO	B-MethodName
model	O
at	O
the	O
6	O
th	O
iteration	O
after	O
the	O
model	O
achieves	O
acceptable	O
recall	O
on	O
the	O
downstream	O
task	O
.	O

Head	O
-	O
level	O
XL	O
SANs	I-MethodName
Instead	O
of	O
projecting	O
XL	O
PE	I-MethodName
to	O
all	O
attention	O
heads	O
,	O
we	O
feed	O
partial	O
of	O
them	O
,	O
such	O
that	O
some	O
heads	O
contain	O
XL	O
PE	O
and	O
others	O
contain	O
APE	O
,	O
namely	O
HeadXL	B-MethodName
.	O
As	O
shown	O
in	O
Fig	O
.	O
2b	O
,	O
we	O
fist	O
add	O
APE	O
and	O
XL	O
PE	O
for	O
X	O
,	O
respectively	O
:	O

Nonetheless	O
,	O
there	O
are	O
side	O
-	O
effects	O
of	O
suboptimal	O
datasets	O
that	O
can	O
not	O
be	O
predicted	O
and	O
are	O
only	O
found	O
after	O
training	O
thanks	O
to	O
post	O
-	O
hoc	O
error	O
analysis	O
.	O
To	O
rectify	O
such	O
problems	O
,	O
there	O
have	O
been	O
attempts	O
to	O
enable	O
humans	O
to	O
fix	O
the	O
trained	O
models	O
(	O
i.e.	O
,	O
to	O
perform	O
model	O
debugging	O
)	O
(	O
Stumpf	O
et	O
al	O
.	O
,	O
2009;Teso	O
and	O
Kersting	O
,	O
2019	O
)	O
.	O
Since	O
the	O
models	O
are	O
usually	O
too	O
complex	O
to	O
understand	O
,	O
manually	O
modifying	O
the	O
model	O
parameters	O
is	O
not	O
possible	O
.	O
Existing	O
techniques	O
,	O
therefore	O
,	O
allow	O
humans	O
to	O
provide	O
feedback	O
on	O
individual	O
predictions	O
instead	O
.	O
Then	O
,	O
additional	O
training	O
examples	O
are	O
created	O
based	O
on	O
the	O
feedback	O
to	O
retrain	O
the	O
models	O
.	O
However	O
,	O
such	O
local	O
improvements	O
for	O
individual	O
predictions	O
could	O
add	O
up	O
to	O
inferior	O
overall	O
performance	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Furthermore	O
,	O
these	O
existing	O
techniques	O
allow	O
us	O
to	O
rectify	O
only	O
errors	O
related	O
to	O
examples	O
at	O
hand	O
but	O
provide	O
no	O
way	O
to	O
fix	O
problems	O
kept	O
hidden	O
in	O
the	O
model	O
parameters	O
.	O

where	O
p	O
tnc	O
is	O
the	O
element	O
from	O
the	O
output	O
feature	O
tensor	O
P	O
,	O
and	O
l	O
tmc	O
is	O
the	O
element	O
from	O
ground	O
truth	O
matrix	O
L.	O
Then	O
,	O
DetIE	B-MethodName
utilizes	O
the	O
Hungarian	O
algorithm	O
(	O
Kuhn	O
,	O
1955	O
)	O
that	O
matches	O
one	O
proposal	O
for	O
each	O
ground	O
truth	O
with	O
the	O
global	O
minimum	O
IoU	O
.	O

Here	O
the	O
r	O
ij	O
terms	O
encode	O
the	O
known	O
relationships	O
between	O
the	O
two	O
tokens	O
x	O
i	O
and	O
x	O
j	O
in	O
the	O
input	O
sequence	O
.	O
In	O
this	O
way	O
,	O
this	O
self	O
-	O
attention	O
is	O
biased	O
toward	O
some	O
pre	O
-	O
defined	O
relationships	O
using	O
the	O
relation	O
vector	O
r	O
ij	O
in	O
each	O
layer	O
when	O
learning	O
the	O
contextualized	O
embedding	O
.	O
Specifically	O
,	O
they	O
use	O
it	O
to	O
represent	O
the	O
relative	O
position	O
information	O
between	O
sequence	O
elements	O
.	O
More	O
details	O
could	O
be	O
found	O
in	O
their	O
work	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Figure	O
2	O
:	O
An	O
overview	O
of	O
CAST	B-MethodName
with	O
an	O
illustrative	O
example	O
of	O
English	O
-	O
to	O
-	O
Chinese	O
schema	O
translation	O
.	O
Firstly	O
,	O
the	O
target	O
header	O
"	O
Chinese	O
"	O
and	O
its	O
context	O
are	O
modeled	O
as	O
a	O
directed	O
graph	O
.	O
Then	O
a	O
stack	O
of	O
relation	O
-	O
aware	O
transformers	O
encodes	O
the	O
input	O
sequence	O
X	O
to	O
X	O
0	O
with	O
a	O
relational	O
matrix	O
R	O
induced	O
from	O
the	O
graph	O
.	O

where	O
[	O
C	O
]	O
is	O
the	O
placeholder	O
separator	O
for	O
the	O
following	O
relation	O
.	O
For	O
example	O
in	O
Figure	O
2	O
,	O
the	O
target	O
RE	O
task	O
contains	O
three	O
novel	O
relations	O
:	O
em	O
-	O
ployee_of	O
,	O
ceo_of	O
,	O
and	O
others	O
,	O
of	O
which	O
the	O
relation	O
descriptions	O
are	O
then	O
concatenated	O
altogether	O
to	O
form	O
the	O
multi	O
-	O
choice	O
prompt	O
"	O
[	O
C	O
]	O
employee	O
of	O
[	O
C	O
]	O
ceo	O
of	O
[	O
C	O
]	O
others	O
"	O
.	O
After	O
obtaining	O
the	O
multichoice	O
prompt	O
,	O
we	O
then	O
feed	O
it	O
accompanied	O
with	O
the	O
input	O
sentence	O
into	O
the	O
instance	O
encoder	O
,	O
and	O
the	O
representations	O
at	O
separator	O
[	O
C	O
]	O
is	O
regarded	O
as	O
the	O
representation	O
of	O
its	O
following	O
relation	O
.	O

6	O
Exp	O
2	O
:	O
Training	O
Data	O
with	O
Biases	O

Furthermore	O
,	O
we	O
also	O
conducted	O
Experiment	O
1	O
for	O
BiLSTMs	O
.	O
Each	O
direction	O
of	O
the	O
recurrent	O
layer	O
had	O
15	O
hidden	O
units	O
and	O
the	O
feature	O
vector	O
was	O
obtained	O
by	O
taking	O
element	O
-	O
wise	O
max	O
of	O
all	O
the	O
hidden	O
states	O
(	O
i.e.	O
,	O
d	O
=	O
15	O
×	O
2	O
=	O
30	O
)	O
.	O
We	O
adapted	O
the	O
code	O
of	O
(	O
Arras	O
et	O
al	O
.	O
,	O
2017	O
)	O
to	O
run	O
LRP	B-MethodName
on	O
BiLSTMs	O
.	O
Regarding	O
human	O
feedback	O
collection	O
,	O
we	O
collected	O
feedback	O
from	O
Amazon	O
Mechanical	O
Turk	I-MethodName
workers	O
by	O
splitting	O
the	O
pair	O
of	O
word	O
clouds	O
into	O
two	O
and	O
asking	O
the	O
question	O
about	O
the	O
relevant	O
class	O
independently	O
of	O
each	O
other	O
.	O
The	O
answer	O
of	O
the	O
positive	O
relevance	O
word	O
cloud	O
should	O
be	O
consistent	O
with	O
the	O
weight	O
matrix	O
W	O
,	O
while	O
the	O
answer	O
of	O
the	O
negative	O
relevance	O
word	O
cloud	O
should	O
be	O
the	O
opposite	O
of	O
the	O
weight	O
matrix	O
W.	O
The	O
score	O
of	O
a	O
BiLSTM	B-MethodName
feature	O
is	O
the	O
sum	O
of	O
its	O
scores	O
from	O
the	O
positive	O
word	O
cloud	O
and	O
the	O
negative	O
word	O
cloud	O
.	O

Data	O
Usage	O
and	O
License	O
ConvSumX	O
is	O
based	O
on	O
two	O
public	O
English	O
conversation	O
summarization	O
datasets	O
,	O
namely	O
DIALOGSUM	B-MethodName
and	O
QMSum	B-MethodName
.	O
Both	O
datasets	O
are	O
freely	O
available	O
online	O
under	O
the	O
MIT	O
license	O
,	O
which	O
has	O
no	O
constraint	O
to	O
academic	O
use	O
,	O
modification	O
,	O
and	O
further	O
distribution	O
.	O
We	O
will	O
follow	O
the	O
MIT	O
license	O
to	O
make	O
our	O
data	O
(	O
annotated	O
target	O
summaries	O
/	O
queries	O
and	O
corrected	O
English	O
summaries	O
/	O
queries	O
)	O
freely	O
available	O
online	O
.	O

Setting	O
JGA	B-MethodName
Unfreeze	O
all	O
up	O
to	O
2nd	O
layer	O
37.9	O
Unfreeze	O
all	O
up	O
to	O
3rd	O
layer	O
37.7	O
Unfreeze	O
all	O
up	O
to	O
4th	O
layer	O
38.8	O
Unfreeze	O
all	O
up	O
to	O
5th	O
layer	O
34.5	O
Unfreeze	O
all	O
up	O
to	O
6th	O
layer	O
39.1	O
Unfreeze	O
the	O
first	O
and	O
last	O
layers	O
(	O
ours	O
)	O
39.7	O
Unfreeze	O
the	O
first	O
two	O
and	O
last	O
two	O
layers	O
30.2	O
all	O
layers	O
except	O
the	O
first	O
layer	O
of	O
the	O
encoder	O
and	O
decoder	O
after	O
the	O
initial	O
1,000	O
steps	O
.	O
Our	O
findings	O
revealed	O
that	O
the	O
optimal	O
approach	O
is	O
to	O
freeze	O
all	O
layers	O
except	O
the	O
first	O
and	O
last	O
layers	O
of	O
both	O
the	O
encoder	O
and	O
decoder	O
after	O
1,000	O
steps	O
.	O

The	O
absolute	O
value	O
of	O
s	O
(	O
ij	O
)	O
measures	O
the	O
strength	O
of	O
the	O
influence	O
of	O
z	O
(	O
i	O
)	O
on	O
z	O
(	O
j	O
)	O
.	O
The	O
sign	O
of	O
s	O
(	O
ij	O
)	O
show	O
the	O
direction	O
of	O
influence	O
.	O
A	O
negative	O
s	O
(	O
ij	O
)	O
means	O
that	O
removing	O
z	O
(	O
i	O
)	O
decreases	O
the	O
loss	O
at	O
z	O
(	O
j	O
)	O
,	O
i.e.	O
z	O
(	O
i	O
)	O
is	O
harmful	O
to	O
z	O
(	O
j	O
)	O
.	O
s	O
(	O
ij	O
)	O
has	O
high	O
variance	O
because	O
it	O
depends	O
on	O
a	O
single	O
(	O
arbitrary	O
)	O
data	O
point	O
z	O
(	O
j	O
)	O
.	O
To	O
better	O
estimate	O
the	O
influence	O
of	O
z	O
(	O
i	O
)	O
on	O
the	O
entire	O
data	O
distribution	O
,	O
researchers	O
average	O
the	O
influence	O
scores	O
of	O
z	O
(	O
i	O
)	O
over	O
a	O
reference	O
set	O
Z	O
′	O

In	O
particular	O
,	O
we	O
modify	O
the	O
original	O
sentences	O
by	O
replacing	O
terms	O
describing	O
one	O
of	O
the	O
protected	O
groups	O
(	O
dominant	O
or	O
minoritized	O
)	O
with	O
identity	O
words	O
for	O
the	O
other	O
group	O
,	O
e.g.	O
,	O
he	O
→	O
she	O
,	O
Michael	O
→	O
Elizabeth	O
,	O
etc	O
.	O
Denote	O
the	O
original	O
sentence	O
as	O
c	O
1	O
,	O
and	O
the	O
modified	O
sentence	O
as	O
c	O
2	O
.	O
Also	O
,	O
we	O
replace	O
the	O
identity	O
words	O
with	O
some	O
neutral	O
terms	O
that	O
do	O
not	O
imply	O
identity	O
of	O
any	O
protected	O
groups	O
(	O
e.g.	O
,	O
he	O
→	O
person	O
)	O
to	O
create	O
an	O
unbiased	O
reference	O
r.	O
With	O
such	O
constructed	O
paired	O
samples	O
at	O
hand	O
,	O
we	O
can	O
mitigate	O
the	O
bias	O
against	O
the	O
protected	O
group	O
by	O
encouraging	O
the	O
model	O
to	O
assign	O
the	O
same	O
score	O
to	O
(	O
c	O
1	O
,	O
r	O
)	O
and	O
(	O
c	O
2	O
,	O
r	O
)	O
.	O
Formally	O
,	O
the	O
instance	O
-	O
wise	O
loss	O
can	O
be	O
described	O
as	O
follows	O
,	O

We	O
collect	O
annotations	O
from	O
two	O
types	O
of	O
annotators	O
:	O
experts	O
and	O
crowdworkers	O
.	O

Electric	O
also	O
models	O
p	O
data	O
(	O
x	O
t	O
|x	O
\t	O
)	O
,	O
but	O
does	O
not	O
use	O
masking	O
or	O
a	O
softmax	O
layer	O
.	O
Electric	O
first	O
maps	O
the	O
unmasked	O
input	O
x	O
=	O
[	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
]	O
into	O
contextualized	O
vector	O
representations	O
h(x	O
)	O
=	O
[	O
h	O
1	O
,	O
...	O
,	O
h	O
n	O
]	O
using	O
a	O
transformer	O
network	O
.	O
The	O
model	O
assigns	O
a	O
given	O
position	O
t	O
an	O
energy	O
score	O
E(x	O
)	O
t	O
=	O
w	O
T	O
h(x	O
)	O
t	O
using	O
a	O
learned	O
weight	O
vector	O
w.	O
The	O
energy	O
function	O
defines	O
a	O
distribution	O
over	O
the	O
possible	O
tokens	O
at	O
position	O
t	O
as	O

We	O
have	O
demonstrated	O
that	O
the	O
choice	O
of	O
linguistic	O
formalism	O
can	O
have	O
substantial	O
,	O
linguistically	O
meaningful	O
effects	O
on	O
role	O
-	O
semantic	O
probing	O
results	O
.	O
We	O
have	O
shown	O
how	O
probing	O
classifiers	O
can	O
be	O
used	O
to	O
detect	O
discrepancies	O
between	O
formalism	O
implementations	O
,	O
and	O
presented	O
evidence	O
of	O
semantic	O
proto	O
-	O
role	O
encoding	O
in	O
the	O
pre	O
-	O
trained	O
mBERT	O
model	O
.	O
Our	O
refined	O
implementation	O
of	O
the	O
edge	O
probing	O
framework	O
coupled	O
with	O
the	O
anchor	O
task	O
methodology	O
enabled	O
new	O
insights	O
into	O
the	O
processing	O
of	O
predicate	O
-	O
semantic	O
information	O
within	O
mBERT	O
.	O
Our	O
findings	O
suggest	O
that	O
linguistic	O
formalism	O
is	O
an	O
important	O
factor	O
to	O
be	O
accounted	O
for	O
in	O
probing	O
studies	O
.	O
This	O
prompts	O
several	O
recommendations	O
for	O
the	O
follow	O
-	O
up	O
probing	O
studies	O
.	O
First	O
,	O
the	O
formalism	O
and	O
implementation	O
used	O
to	O
prepare	O
the	O
linguistic	O
material	O
underlying	O
a	O
probing	O
study	O
should	O
be	O
always	O
explicitly	O
specified	O
.	O
Second	O
,	O
if	O
possible	O
,	O
results	O
on	O
multiple	O
formalisations	O
of	O
the	O
same	O
task	O
should	O
be	O
reported	O
and	O
validated	O
for	O
several	O
languages	O
.	O
Finally	O
,	O
assembling	O
corpora	O
with	O
parallel	O
cross	O
-	O
formalism	O
annotations	O
would	O
facilitate	O
further	O
research	O
on	O
the	O
effect	O
of	O
formalism	O
in	O
probing	O
.	O

In	O
some	O
cases	O
,	O
we	O
observe	O
that	O
the	O
edit	O
-	O
pass@1	O
outperforms	O
the	O
pass@5	O
.	O
It	O
demonstrates	O
that	O
editing	O
the	O
candidate	O
code	O
is	O
very	O
sample	O
efficient	O
.	O
With	O
the	O
editor	O
model	O
,	O
the	O
number	O
of	O
required	O
programs	O
sampled	O
from	O
the	O
LLM	O
can	O
be	O
reduced	O
.	O

•	O
Hyper	O
-	O
parameters	O
:	O
Besides	O
what	O
explained	O
in	O
the	O
paper	O
,	O
we	O
did	O
not	O
specifically	O
run	O
hyperparameter	O
exploration	O
.	O
However	O
,	O
on	O
our	O
early	O
experiments	O
both	O
models	O
we	O
tried	O
several	O
learning	O
rate	O
variations	O
around	O
the	O
reported	O
10	O
−4	O
and	O
manually	O
picked	O
the	O
best	O
for	O
our	O
main	O
experimental	O
setup	O
.	O

Figure	O
1	O
presents	O
the	O
high	O
-	O
level	O
architecture	O
of	O
the	O
document	O
-	O
level	O
BiRNN	B-MethodName
model	O
,	O
with	O
the	O
various	O
multimodality	O
integration	O
and	O
fusion	O
approaches	O
.	O

There	O
are	O
no	O
significant	O
differences	O
between	O
the	O
performance	O
of	O
H2H+CXT	B-MethodName
and	O
H2H+CXT+ExtL	B-MethodName
which	O
has	O
two	O
extra	O
Transformers	O
layers	O
since	O
the	O
pre	O
-	O
trained	O
NMT	B-MethodName
models	O
have	O
already	O
had	O
12	O
Transformers	O
layers	O
.	O

Figure	O
1	O
:	O
Intra	O
-	O
sentence	O
similarity	O
by	O
layer	O
L	O
of	O
the	O
multilingual	O
BERT	B-MethodName
-	O
base	O
.	O
Functional	O
tokens	O
are	O
similar	O
in	O
L	O
=	O
0	O
,	O
syntactic	O
groups	O
emerge	O
at	O
higher	O
levels	O
.	O

In	O
Stage	O
2	O
,	O
we	O
use	O
the	O
teacher	O
model	O
to	O
rescore	O
each	O
of	O
the	O
b	O
1	O
partial	O
hypotheses	O
conditioned	O
on	O
the	O
full	O
source	O
sentence	O
and	O
only	O
keep	O
the	O
top	O
b	O
2	O
(	O
b	O
2	O
<	O
b	O
1	O
)	O
partial	O
hypotheses	O
for	O
the	O
next	O
step	O
in	O
the	O
two	O
-	O
stage	O
beam	O
search	O
process	O
.	O
With	O
this	O
strategy	O
,	O
future	O
information	O
in	O
the	O
source	O
sentence	O
is	O
utilized	O
to	O
improve	O
the	O
quality	O
of	O
top	O
partial	O
hypotheses	O
,	O
while	O
also	O
preserving	O
the	O
local	O
word	O
order	O
dictated	O
by	O
the	O
prefix	O
source	O
.	O

Our	O
experimental	O
setup	O
follows	O
Le	O
and	O
Titov	O
(	O
2018	O
)	O
.	O
In	O
particular	O
,	O
we	O
test	O
the	O
proposed	O
ED	O
models	O
using	O
six	O
standard	O
datasets	O
:	O
AIDA	B-MethodName
-	I-MethodName
CoNLL	I-MethodName
(	O
CoNLL	B-MethodName
)	O
(	O
Hoffart	O
et	O
al	O
.	O
,	O
2011	O
)	O
,	O
MSNBC	B-MethodName
,	O
AQUAINT	B-MethodName
,	O
ACE2004	B-MethodName
,	O
WNED	B-MethodName
-	I-MethodName
CWEB	I-MethodName
(	O
CWEB	B-MethodName
)	O
,	O
and	O
WNED	B-MethodName
-	I-MethodName
WIKI	I-MethodName
(	O
WIKI	O
)	O
(	O
Guo	O
and	O
Barbosa	O
,	O
2018	O
)	O
.	O
We	O
consider	O
only	O
the	O
mentions	O
that	O
refer	O
to	O
valid	O
entities	O
in	O
Wikipedia	O
.	O
For	O
all	O
datasets	O
,	O
we	O
use	O
the	O
KB+YAGO	B-MethodName
entity	O
candidates	O
and	O
their	O
associatedp(e|m	O
)	O
(	O
Ganea	O
and	O
Hofmann	O
,	O
2017	O
)	O
,	O
and	O
use	O
the	O
top	O
30	O
candidates	O
based	O
onp(e|m	O
)	O
.	O

This	O
section	O
evaluates	O
the	O
performance	O
of	O
our	O
proposed	O
PBML	O
.	O
We	O
conduct	O
extensive	O
experiments	O
on	O
four	O
widely	O
-	O
used	O
text	O
classification	O
datasets	O
under	O
few	O
-	O
shot	O
settings	O
and	O
make	O
a	O
full	O
-	O
scale	O
comparison	O
with	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
.	O
We	O
report	O
our	O
implementation	O
details	O
in	O
Appendix	O
E	O
.	O

For	O
the	O
data	O
preprocessing	O
,	O
at	O
source	O
side	O
,	O
we	O
perform	O
lemmatization	O
on	O
both	O
corpora	O
and	O
alphabet	O
normalization	O
specifically	O
on	O
the	O
PHOENIX	O
(	O
the	O
letters	O
ü	O
,	O
ö	O
,	O
ä	O
,	O
and	O
ß	O
in	O
the	O
glosses	O
are	O
prenormalized	O
by	O
dataset	O
creators	O
)	O
.	O
We	O
then	O
apply	O
Byte	O
Pair	I-MethodName
Encoding	I-MethodName
(	O
BPE	O
;	O
Sennrich	O
et	O
al	O
.	O
,	O
2016b	O
)	O
to	O
decompose	O
the	O
words	O
and	O
build	O
vocabulary	O
.	O
In	O
the	O
end	O
,	O
we	O
set	O
the	O
lemmatized+normalized	O
sentences	O
with	O
lowercased	O
glosses	O
of	O
PHOENIX	O
and	O
lemmatized	O
sentences	O
with	O
generalized	O
glosses	O
of	O
the	O
DGS	O
corpus	O
to	O
train	O
the	O
models	O
.	O
We	O
present	O
the	O
relevant	O
statistics	O
in	O
Appendixes	O
A	O
and	O
B	O
.	O

The	O
versatility	O
of	O
pre	O
-	O
trained	O
representations	O
implies	O
that	O
they	O
encode	O
some	O
aspects	O
of	O
general	O

In	O
doing	O
so	O
we	O
iv	O
)	O
re	O
-	O
evaluate	O
prior	O
findings	O
on	O
visual	O
vs.	O
textual	O
unimodal	O
collapse	O
and	O
v	O
)	O
showcase	O
MM	B-MethodName
-	I-MethodName
SHAP	I-MethodName
's	O
abilities	O
for	O
interpreting	O
predictions	O
for	O
individual	O
samples	O
,	O
for	O
error	O
analysis	O
.	O

MedNLI	O
is	O
Not	O
Immune	O
from	O
Artifacts	O

•	O
We	O
propose	O
using	O
word	O
clouds	O
as	O
visual	O
explanations	O
of	O
the	O
features	O
learned	O
.	O

Update	O
original	O
θs	O
:	O
θs	O
←	O
θs	O
−	O
ηs∇	O
θs	O
Ls	O
(	O
θs	O
,	O
θt	O
,	O
z	O
r	O
)	O
10	O
:	O

Perceived	O
Learning	O
Effect	O
.	O
Table	O
17	O
shows	O
similar	O
trends	O
to	O
the	O
previous	O
results	O
that	O
basic	O
-	O
level	O
learners	O
perceived	O
more	O
learning	O
effects	O
on	O
both	O
vocabulary	O
and	O
grammar	O
.	O
They	O
tend	O
to	O
show	O
more	O
willingness	O
to	O
re	O
-	O
participate	O
in	O
data	O
annotation	O
.	O

In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
the	O
task	O
of	O
OoD	O
detection	O
with	O
only	O
in	O
-	O
distribution	O
texts	O
available	O
during	O
learning	O
for	O
its	O
capability	O
of	O
dealing	O
with	O
diverse	O
scenarios	O
such	O
as	O
non	O
-	O
classification	O
applications	O
while	O
requiring	O
the	O
least	O
data	O
collection	O
effort	O
.	O

Context	O
-	O
aware	O
schema	O
encoding	O
has	O
received	O
considerable	O
attention	O
in	O
both	O
recent	O
semantic	O
parsing	O
literature	O
(	O
Hwang	O
et	O
al	O
.	O
,	O
2019;Gong	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Table	O
-	O
to	O
-	O
Text	O
literature	O
(	O
Gong	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
In	O
general	O
,	O
there	O
are	O
two	O
sorts	O
of	O
techniques	O
:	O
1	O
)	O
.	O
add	O
additional	O
entity	O
type	O
embedding	O
and	O
special	O
separator	O
token	O
from	O
the	O
input	O
sequence	O
to	O
distinguish	O
the	O
table	O
structure	O
(	O
i.e.	O
,	O
Type	O
-	O
SQL	O
and	O
IRNET	O
)	O
;	O
2	O
)	O
.	O
encode	O
the	O
schema	O
as	O
a	O
directed	O
graph	O
.	O
For	O
example	O
,	O
Bogin	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
a	O
Graph	B-MethodName
Neural	I-MethodName
Network	I-MethodName
(	O
Scarselli	O
et	O
al	O
.	O
,	O
2008	O
)	O
,	O
and	O
;	O
Shaw	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
a	O
transformer	O
self	O
-	O
attention	O
mechanism	O
to	O
encode	O
the	O
schema	O
over	O
predefined	O
schema	O
relationships	O
.	O
Unlike	O
these	O
works	O
,	O
we	O
explore	O
the	O
suitability	O
of	O
schema	O
encoding	O
techniques	O
for	O
the	O
newly	O
proposed	O
schema	O
translation	O
task	O
.	O

Blagojevich	O
is	O
currently	O
serving	O
a	O
14	O
-	O
year	O
sentence	O
at	O
the	O
Federal	O
Correctional	O
Institution	O
Englewood	O
near	O
Denver	O
.	O

Why	O
does	O
PER	B-MethodName
benefit	O
more	O
than	O
other	O
entity	O
types	O
?	O
To	O
answer	O
this	O
,	O
we	O
count	O
the	O
fraction	O
of	O
mentions	O
of	O
each	O
entity	O
type	O
that	O
have	O
at	O
least	O
one	O
column	O
represented	O
using	O
attribute	O
separators	O
.	O
This	O
counting	O
reveals	O
that	O
approximately	O
56	O
-	O
58	O
%	O
of	O
mentions	O
of	O
type	O
ORG	B-MethodName
,	O
GPE	B-MethodName
,	O
and	O
UKN	B-MethodName
have	O
at	O
least	O
one	O
such	O
column	O
.	O
On	O
the	O
other	O
hand	O
,	O
this	O
number	O
is	O
71	O
%	O
for	O
PER	B-MethodName
mentions	O
.	O
This	O
suggests	O
that	O
the	O
difference	O
is	O
directly	O
attributable	O
to	O
more	O
PER	B-MethodName
entities	O
having	O
a	O
column	O
that	O
has	O
been	O
modeled	O
using	O
attribute	O
separators	O
,	O
further	O
highlighting	O
the	O
benefits	O
of	O
this	O
modeling	O
decision	O
.	O

Our	O
framing	O
of	O
the	O
quality	O
ranking	O
task	O
could	O
be	O
interpreted	O
as	O
seemingly	O
prescriptive	O
(	O
i.e.	O
,	O
that	O
joke	O
A	O
is	O
"	O
objectively	O
"	O
better	O
than	O
joke	O
B	O
)	O
,	O
but	O
New	O
Yorker	O
editorial	O
selections	O
should	O
not	O
be	O
taken	O
as	O
ground	O
truth	O
for	O
funniness	O
;	O
disagreement	O
about	O
what	O
is	O
funny	O
is	O
expected	O
and	O
valid	O
.	O
Our	O
tasks	O
operationalize	O
the	O
prediction	O
of	O
only	O
average	O
preferences	O
(	O
rather	O
than	O
individual	O
ones	O
)	O
,	O
and	O
these	O
preferences	O
may	O
include	O
a	O
partiality	O
or	O
bias	O
towards	O
items	O
that	O
conform	O
to	O
the	O
characteristics	O
of	O
prior	O
contest	O
winners	O
or	O
published	O
New	O
Yorker	O
cartoons	O
.	O

FLONET	B-MethodName
is	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approach	O
for	O
learning	O
flowchart	O
grounded	O
task	O
oriented	O
dialogs	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
It	O
follows	O
the	O
RAG	B-MethodName
sequence	O
model	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
The	O
RAG	B-MethodName
sequence	O
model	O
has	O
two	O
main	O
components	O
:	O
(	O
1	O
)	O
a	O
retriever	O
p	O
con	O
η	O
(	O
z|h	O
i	O
)	O
which	O
computes	O
a	O
distribution	O
over	O
retrievable	O
documents	O
z	O
(	O
i.e.	O
,	O
flowchart	O
nodes	O
and	O
FAQs	O
)	O
based	O
on	O
the	O
dialog	O
history	O
h	O
i	O
and	O
(	O
2	O
)	O
a	O
generator	O
p	O
θ	O
(	O
y	O
t	O
|h	O
i	O
,	O
z	O
,	O
y	O
1	O
:	O
t−1	O
)	O
which	O
generates	O
the	O
agent	O
response	O
token	O
-	O
by	O
-	O
token	O
.	O
The	O
overall	O
RAG	B-MethodName
model	O
is	O
given	O
by	O
,	O

•	O
We	O
provide	O
a	O
new	O
corpus	O
of	O
45	O
materialsscience	O
publications	O
in	O
the	O
research	O
area	O
of	O
SOFCs	B-MethodName
,	O
manually	O
annotated	O
by	O
domain	O
experts	O
for	O
information	O
on	O
experimental	O
settings	O
and	O
results	O
(	O
Section	O
4	O
)	O
.	O
Our	O
corpus	O
is	O
publicly	O
available	O
.	O
1	O
Our	O
inter	O
-	O
annotator	O
agreement	O
study	O
provides	O
evidence	O
for	O
high	O
annotation	O
quality	O
(	O
Section	O
5	O
)	O
.	O

•	O
We	O
propose	O
the	O
task	O
of	O
schema	O
translation	O
,	O
and	O
discuss	O
its	O
differences	O
with	O
a	O
plain	O
text	O
translation	O
.	O
To	O
facilitate	O
the	O
research	O
study	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
schema	O
translation	O
dataset	O
.	O

Table	O
2	O
shows	O
the	O
evaluation	O
results	O
.	O
The	O
distilled	O
datasets	O
with	O
the	O
hard	O
labels	O
,	O
i.e.	O
,	O
only	O
optimizing	O
the	O
input	O
embeddings	O
and	O
not	O
applying	O
the	O
attention	O
labels	O
,	O
still	O
achieved	O
87.4	O
,	O
81.6	O
,	O
and	O
68.6	O
for	O
AGNews	B-MethodName
,	O
SST-2	B-MethodName
,	O
and	O
QNLI	B-MethodName
,	O
respectively	O
,	O
which	O
is	O
92.4	O
,	O
88.0	O
,	O
and	O
74.7	O
%	O
performance	O
of	O
the	O
full	O
dataset	O
.	O
Furthermore	O
,	O
using	O
the	O
soft	O
labels	O
further	O
improved	O
these	O
performances	O
,	O
especially	O
by	O
almost	O
8	O
points	O
for	O
QNLI	B-MethodName
.	O
However	O
,	O
for	O
MRPC	B-MethodName
,	O
the	O
distilled	O
dataset	O
achieved	O
only	O
the	O
same	O
performance	O
as	O
the	O
majority	O
class	O
baseline	O
regardless	O
of	O
the	O
use	O
of	O
the	O
soft	O
labels	O
.	O

Debugging	O
text	O
classifiers	O
using	O
human	O
feedback	O
-Early	O
work	O
in	O
this	O
area	O
comes	O
from	O
the	O
human	O
-	O
computer	O
interaction	O
community	O
.	O
Stumpf	O
et	O
al	O
.	O
(	O
2009	O
)	O
studied	O
the	O
types	O
of	O
feedback	O
humans	O
usually	O
give	O
in	O
response	O
to	O
machine	O
-	O
generated	O
predictions	O
and	O
explanations	O
.	O
Also	O
,	O
some	O
of	O
the	O
feedback	O
collected	O
(	O
i.e.	O
,	O
important	O
words	O
of	O
each	O
category	O
)	O
was	O
used	O
to	O
improve	O
the	O
classifier	O
via	O
a	O
user	O
co	O
-	O
training	O
approach	O
.	O
Kulesza	O
et	O
al	O
.	O
(	O
2015	O
)	O
presented	O
an	O
explanatory	O
debugging	O
approach	O
in	O
which	O
the	O
system	O
explains	O
to	O
users	O
how	O
it	O
made	O
each	O
prediction	O
,	O
and	O
the	O
users	O
then	O
rectify	O
the	O
model	O
by	O
adding	O
/	O
removing	O
words	O
from	O
the	O
explanation	O
and	O
adjusting	O
important	O
weights	O
.	O
Even	O
without	O
explanations	O
shown	O
,	O
an	O
active	O
learning	O
framework	O
proposed	O
by	O
Settles	O
(	O
2011	O
)	O
asks	O
humans	O
to	O
iteratively	O
label	O
some	O
chosen	O
features	O
(	O
i.e.	O
,	O
words	O
)	O
and	O
adjusts	O
the	O
model	O
parameters	O
that	O
correspond	O
to	O
the	O
features	O
.	O
However	O
,	O
these	O
early	O
works	O
target	O
simpler	O
machine	O
learning	O
classifiers	O
(	O
e.g.	O
,	O
Naive	O
Bayes	O
classifiers	O
with	O
bag	O
-	O
of	O
-	O
words	O
)	O
and	O
it	O
is	O
not	O
clear	O
how	O
to	O
apply	O
the	O
proposed	O
approaches	O
to	O
deep	O
text	O
classifiers	O
.	O

MQM	O
Score	O
=	O
1	O
−	O
n	O
min	O
+	O
5n	O
maj	O
+	O
10n	O
cri	O
n	O

Queries	O
are	O
present	O
in	O
23.05	O
%	O
and	O
25.31	O
%	O
of	O
valid	O
seen	O
and	O
unseen	O
splits	O
,	O
respectively	O
.	O
This	O
is	O
a	O
key	O
challenge	O
as	O
it	O
demonstrates	O
a	O
clear	O
use	O
case	O
for	O
dialogue	O
and	O
limitation	O
of	O
current	O
models	O
.	O

•	O
We	O
propose	O
a	O
header	O
-	O
to	O
-	O
header	O
context	O
-	O
aware	O
schema	O
translation	O
model	O
,	O
called	O
CAST	B-MethodName
,	O
for	O
the	O
new	O
schema	O
translation	O
task	O
.	O
Specifically	O
,	O
we	O
use	O
the	O
transformer	O
self	O
-	O
attention	O
mechanism	O
to	O
encode	O
the	O
schema	O
over	O
predefined	O
entity	O
types	O
and	O
structural	O
relationships	O
,	O
making	O
it	O
aware	O
of	O
the	O
schema	O
context	O
.	O

MedNLI	B-MethodName
is	O
domain	O
-	O
specific	O
evaluation	O
dataset	O
inspired	O
by	O
general	O
-	O
purpose	O
NLI	O
datasets	O
,	O
including	O
SNLI	B-MethodName
and	O
MultiNLI	B-MethodName
(	O
Romanov	O
and	O
Shivade	O
,	O
2018;Bowman	O
et	O
al	O
.	O
,	O
2015;Williams	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Much	O
like	O
its	O
predecessors	O
,	O
MedNLI	B-MethodName
consists	O
of	O
premisehypothesis	O
pairs	O
,	O
in	O
which	O
the	O
premises	O
are	O
drawn	O
1021	O
from	O
the	O
Past	O
Medical	O
History	O
sections	O
of	O
a	O
randomly	O
selected	O
subset	O
of	O
de	O
-	O
identified	O
clinical	O
notes	O
contained	O
in	O
MIMIC	B-MethodName
-	O
III	O
(	O
Johnson	O
et	O
al	O
.	O
,	O
2016;Goldberger	O
et	O
al	O
.	O
,	O
2000	O
(	O
June	O
13	O
)	O
.	O
MIMIC	B-MethodName
-	I-MethodName
III	O
was	O
created	O
from	O
the	O
records	O
of	O
adult	O
and	O
neonatal	O
intensive	O
care	O
unit	O
(	O
ICU	O
)	O
patients	O
.	O
As	O
such	O
,	O
complex	O
and	O
clinically	O
severe	O
cases	O
are	O
disproportionately	O
represented	O
,	O
relative	O
to	O
their	O
frequency	O
of	O
occurrence	O
in	O
the	O
general	O
population	O
.	O

Instead	O
,	O
the	O
goal	O
of	O
these	O
models	O
is	O
to	O
produce	O
a	O
small	O
but	O
high	O
-	O
recall	O
candidate	O
list	O
E.	O
Ergo	O
,	O
the	O
success	O
of	O
this	O
stage	O
is	O
measured	O
using	O
a	O
metric	O
such	O
as	O
recall@K	O
i.e.	O
whether	O
the	O
candidate	O
list	O
contains	O
the	O
correct	O
entity	O
.	O

We	O
have	O
presented	O
a	O
new	O
dataset	O
for	O
information	O
extraction	O
in	O
the	O
materials	O
science	O
domain	O
consisting	O
of	O
45	O
open	O
-	O
access	O
scientific	O
articles	O
related	O
to	O
solid	O
oxide	O
fuel	O
cells	O
.	O
Our	O
detailed	O
corpus	O
and	O
interannotator	O
agreement	O
studies	O
highlight	O
the	O
complexity	O
of	O
the	O
task	O
and	O
verify	O
the	O
high	O
annotation	O
quality	O
.	O
Based	O
on	O
the	O
annotated	O
structures	O
,	O
we	O
suggest	O
three	O
information	O
extraction	O
tasks	O
:	O
the	O
detection	O
of	O
experiment	O
-	O
describing	O
sentences	O
,	O
entity	O
mention	O
recognition	O
and	O
typing	O
,	O
and	O
experiment	O
slot	O
filling	O
.	O
We	O
have	O
presented	O
various	O
strong	O
baselines	O
for	O
them	O
,	O
generally	O
finding	O
that	O
BERT	O
-	O
based	O
models	O
outperform	O
other	O
model	O
variants	O
.	O
While	O
some	O
categories	O
remain	O
challenging	O
,	O
overall	O
,	O
our	O
models	O
show	O
solid	O
performance	O
and	O
thus	O
prove	O
that	O
this	O
type	O
of	O
data	O
modeling	O
is	O
feasible	O
and	O
can	O
lead	O
to	O
systems	O
that	O
are	O
applicable	O
in	O
production	O
settings	O
.	O
Along	O
with	O
this	O
paper	O
,	O
we	O
make	O
the	O
annotation	O
guidelines	O
and	O
the	O
annotated	O
data	O
freely	O
available	O
.	O

CL	B-MethodName
Algorithm	I-MethodName
CL	I-MethodName
is	O
a	O
cooperative	O
learning	O
algorithm	O
proposed	O
by	O
Shekhar	O
et	O
al	O
.	O
(	O
2019	O
)	O
to	O
model	O
the	O
question	O
-	O
player	O
.	O
The	O
algorithm	O
is	O
based	O
primarily	O
on	O
a	O
self	O
-	O
play	O
learning	O
phase	O
(	O
Das	O
et	O
al	O
.	O
,	O
2017	O
)	O
which	O
learns	O
from	O
machine	O
-	O
machine	O
dialogue	O
.	O
This	O
is	O
used	O
in	O
addition	O
to	O
(	O
after	O
)	O
a	O
more	O
traditional	O
supervised	O
learning	O
phase	O
(	O
i.e.	O
,	O
on	O
human	O
-	O
human	O
dialogue	O
)	O
.	O
See	O
Appendix	O
A.6	O
for	O
details	O
.	O

The	O
reordered	O
source	O
sentences	O
are	O
generated	O
by	O
BTG	O
-	O
based	O
preordering	O
model	O
(	O
Neubig	O
et	O
al	O
.	O
,	O
2012	O
)	O
trained	O
with	O
above	O
sub	O
-	O
word	O
level	O
1	O
parallel	O
corpus	O
.	O
At	O
training	O
phase	O
,	O
we	O
first	O
obtain	O
word	O
alignments	O
from	O
parallel	O
data	O
using	O
GIZA++	B-MethodName
or	O
FastAlign	B-MethodName
,	O
and	O
then	O
the	O
training	O
process	O
is	O
to	O
find	O
the	O
optimal	O
BTG	B-MethodName
tree	O
for	O
source	O
sentence	O
consistent	O
with	O
the	O
order	O
of	O
the	O
target	O
sentence	O
based	O
on	O
the	O
word	O
alignments	O
and	O
parallel	O
data	O
.	O
At	O
decoding	O
phase	O
,	O
we	O
only	O
provide	O
source	O
sentences	O
as	O
input	O
and	O
the	O
model	O
can	O
output	O
reordering	O
indices	O
,	O
which	O
will	O
be	O
fed	O
into	O
NMT	B-MethodName
model	O
.	O
Thus	O
,	O
bilingual	O
alignment	O
information	O
is	O
only	O
used	O
to	O
preprocess	O
training	O
data	O
,	O
but	O
not	O
necessary	O
at	O
decoding	O
time	O
.	O

We	O
design	O
a	O
commonsense	O
extraction	O
tool	O
that	O
aligns	O
sentences	O
in	O
stories	O
with	O
commonsense	O
tuples	O
,	O
using	O
a	O
heuristic	O
matching	O
algorithm	O
.	O
Given	O
a	O
story	O
,	O
we	O
match	O
possible	O
ATOMIC	B-MethodName
events	O
to	O
sentences	O
by	O
selecting	O
events	O
that	O
share	O
noun	O
chunks	O
and	O
verb	O
phrases	O
with	O
sentences	O
.	O
For	O
every	O
sentence	O
s	O
i	O
that	O
matches	O
an	O
event	O
E	O
in	O
ATOMIC	B-MethodName
,	O
we	O
check	O
surrounding	O
sentences	O
for	O
mentions	O
of	O
commonsense	O
inferences	O
(	O
using	O
the	O
same	O
noun	O
and	O
verb	O
phrase	O
matching	O
strategy	O
)	O
;	O
specifically	O
,	O
we	O
check	O
the	O
n	O
c	O
preceding	O
sentences	O
for	O
matches	O
of	O
causes	O
of	O
E	O
,	O
and	O
the	O
n	O
e	O
following	O
sentences	O
for	O
event	O
E	O
's	O
effects	O
.	O

In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
new	O
information	O
extraction	O
use	O
case	O
from	O
the	O
materials	O
science	O
domain	O
and	O
propose	O
a	O
series	O
of	O
new	O
challenging	O
information	O
extraction	O
tasks	O
.	O
We	O
target	O
publications	O
about	O
solid	O
oxide	O
fuel	O
cells	O
(	O
SOFCs	O
)	O
in	O
which	O
the	O
interdependence	O
between	O
chosen	O
materials	O
,	O
measurement	O
conditions	O
and	O
performance	O
is	O
complex	O
(	O
see	O
Figure	O
1	O
)	O
.	O
For	O
making	O
progress	O
within	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
,	O
the	O
genre	O
-	O
domain	O
combination	O
presents	O
interesting	O
challenges	O
and	O
characteristics	O
,	O
e.g.	O
,	O
domain	O
-	O
specific	O
tokens	O
such	O
as	O
material	O
names	O
and	O
chemical	O
formulas	O
.	O

Following	O
the	O
common	O
finetuning	O
practice	O
,	O
we	O
do	O
not	O
use	O
any	O
additional	O
training	O
strategies	O
.	O
We	O
train	O
all	O
tasks	O
5	O
times	O
respectively	O
and	O
report	O
the	O
average	O
scores	O
.	O
For	O
GLUE	O
,	O
We	O
use	O
8	O
widely	O
used	O
tasks	O
in	O
GLUE	O
.	O
5	O

Outlook	O
.	O
In	O
Section	O
7.1	O
,	O
we	O
have	O
shown	O
that	O
our	O
findings	O
generalize	O
well	O
by	O
applying	O
model	O
architectures	O
developed	O
on	O
our	O
corpus	O
to	O
another	O
dataset	O
.	O
A	O
natural	O
next	O
step	O
is	O
to	O
combine	O
the	O
datasets	O
in	O
a	O
multi	O
-	O
task	O
setting	O
to	O
investigate	O
to	O
what	O
extent	O
models	O
can	O
profit	O
from	O
combining	O
the	O
information	O
annotated	O
in	O
the	O
respective	O
datasets	O
.	O
Further	O
research	O
will	O
investigate	O
the	O
joint	O
modeling	O
of	O
entity	O
extraction	O
,	O
typing	O
and	O
experiment	O
frame	O
recognition	O
.	O
In	O
addition	O
,	O
there	O
are	O
also	O
further	O
natural	O
language	O
processing	O
tasks	O
that	O
can	O
be	O
researched	O
using	O
our	O
dataset	O
.	O
They	O
include	O
the	O
detection	O
of	O
events	O
and	O
sub	O
-	O
events	O
when	O
regarding	O
the	O
experiment	O
-	O
descriptions	O
as	O
events	O
,	O
and	O
a	O
more	O
linguistically	O
motivated	O
evaluation	O
of	O
the	O
framesemantic	O
approach	O
to	O
experiment	O
descriptions	O
in	O
text	O
,	O
e.g.	O
,	O
moving	O
away	O
from	O
the	O
one	O
-	O
experimentper	O
-	O
sentence	O
and	O
one	O
-	O
sentence	O
-	O
per	O
-	O
experiment	O
assumptions	O
and	O
modeling	O
the	O
graph	O
-	O
based	O
structures	O
as	O
annotated	O
.	O

We	O
list	O
the	O
performance	O
of	O
two	O
other	O
large	O
pretrained	O
BERT	O
-	O
based	O
models	O
on	O
the	O
PAN	B-MethodName
XL	I-MethodName
dataset	O
splits	O
in	O
Tab	O
.	O
6	O
.	O
The	O
large	O
gap	O
between	O
other	O
models	O
and	O
siamBERT	B-MethodName
(	O
sB	O
)	O
could	O
be	O
due	O
to	O
how	O
the	O
model	O
functions	O
,	O
without	O
learning	O
over	O
both	O
documents	O
simultaneously	O
.	O
BERT	B-MethodName
processes	O
a	O
pair	O
of	O
sequences	O
,	O
so	O
the	O
word	O
-	O
piece	O
representations	O
interact	O
at	O
every	O
level	O
before	O
making	O
a	O
prediction	O
based	O
on	O
the	O
sequence	O
pair	O
embedding	O
h	O
[	O
CLS	O
]	O
.	O
In	O
contrast	O
,	O
siamBERT	B-MethodName
processes	O
each	O
sequence	O
separately	O
,	O
making	O
the	O
word	O
-	O
pieces	O
'	O
interact	O
'	O
at	O
the	O
end	O
through	O
the	O
sequence	O
embeddings	O
h	O

Difficulty	O
Control	O
To	O
explore	O
whether	O
our	O
question	O
generation	O
model	O
indeed	O
depends	O
on	O
target	O
difficulty	O
and	O
the	O
individual	O
student	O
,	O
we	O
first	O
measure	O
the	O
model	O
's	O
perplexity	O
on	O
a	O
held	O
-	O
out	O
test	O
set	O
of	O
Duolingo	O
questions	O
,	O
compared	O
to	O
permutation	O
baselines	O
.	O
Table	O
2	O
(	O
top	O
)	O
shows	O
that	O
perplexity	O
is	O
lower	O
for	O
true	O
student	O
/	O
target	O
difficulty	O
inputs	O
than	O
when	O
either	O
or	O
both	O
of	O
these	O
are	O
permuted	O
.	O
The	O
target	O
difficulty	O
values	O
in	O
this	O
analysis	O
were	O
defined	O
by	O
the	O
LM	O
-	O
DKT	O
model	O
.	O
We	O
can	O
remove	O
this	O
dependence	O
by	O
using	O
the	O
actual	O
student	O
responses	O
from	O
Duolingo	O
:	O
we	O
set	O
the	O
target	O
difficulty	O
to	O
1	O
if	O
the	O
student	O
was	O
correct	O
and	O
0	O
otherwise	O
.	O
Table	O
2	O
(	O
bottom	O
)	O
shows	O
our	O
model	O
prefers	O
questions	O
paired	O
with	O
these	O
"	O
true	O
correctness	O
"	O
targets	O
than	O
paired	O
with	O
random	O
ones	O
.	O

To	O
evaluate	O
how	O
well	O
INLP	B-MethodName
,	O
MP	O
,	O
and	O
TMP	B-MethodName
do	O
in	O
terms	O
of	O
linear	O
guarding	O
,	O
we	O
consider	O
the	O
number	O
of	O
misclassifications	O
with	O
respect	O
to	O
a	O
*	O
by	O
the	O
best	O
possible	O
linear	O
classifier	O
after	O
a	O
single	O
projection	O
;	O
the	O
higher	O
the	O
number	O
of	O
misclassifications	O
,	O
the	O
better	O
the	O
method	O
performs	O
.	O
If	O
a	O
single	O
projection	O
is	O
sufficient	O
to	O
achieve	O
linear	O
guarding	O
,	O
then	O
arguably	O
the	O
semantic	O
encoding	O
of	O
other	O
attributes	O
in	O
our	O
word	O
embeddings	O
are	O
preserved	O
as	O
well	O
as	O
possible	O
.	O

We	O
use	O
the	O
publicly	O
provided	O
train	O
/	O
dev	O
/	O
test	O
splits	O
from	O
the	O
Shared	O
Task	O
,	O
which	O
are	O
temporally	O
ordered	O
in	O
sequence	O
.	O
We	O
therefore	O
construct	O
student	O
states	O
by	O
tracking	O
user	O
IDs	O
throughout	O
the	O
datasets	O
and	O
appending	O
each	O
new	O
question	O
and	O
response	O
to	O
the	O
current	O
student	O
state	O
.	O
When	O
evaluating	O
our	O
LM	O
-	I-MethodName
KT	I-MethodName
model	O
,	O
we	O
use	O
the	O
true	O
responses	O
of	O
preceding	O
questions	O
in	O
the	O
test	O
set	O
to	O
form	O
the	O
student	O
state	O
for	O
a	O
given	O
question	O
.	O
Overall	O
,	O
we	O
find	O
that	O
the	O
dataset	O
is	O
severely	O
imbalanced	O
(	O
as	O
in	O
the	O
original	O
task	O
)	O
-about	O
30	O
%	O
of	O
questions	O
are	O
answered	O
incorrectly	O
across	O
students	O
studying	O
both	O
French	O
and	O
Spanish	O
.	O

Unlike	O
previous	O
work	O
,	O
our	O
models	O
also	O
allow	O
seamless	O
mixing	O
of	O
multiple	O
training	O
datasets	O
which	O
link	O
to	O
different	O
KBs	O
with	O
different	O
schemas	O
.	O
We	O
investigate	O
the	O
impact	O
of	O
training	O
on	O
multiple	O
datasets	O
in	O
two	O
sets	O
of	O
experiments	O
involving	O
additional	O
training	O
data	O
that	O
links	O
to	O
(	O
a	O
)	O
a	O
third	O
KB	O
that	O
is	O
different	O
from	O
our	O
original	O
training	O
and	O
testing	O
KBs	O
,	O
and	O
(	O
b	O
)	O
the	O
same	O
KB	O
as	O
the	O
test	O
data	O
.	O
These	O
experiments	O
reveal	O
that	O
our	O
models	O
perform	O
favorably	O
under	O
all	O
conditions	O
compared	O
to	O
baselines	O
.	O

Additional	O
test	O
set	O
Tables	O
7	O
and	O
8	O
present	O
the	O
full	O
set	O
of	O
results	O
of	O
our	O
experiments	O
on	O
the	O
WMT'19	O
Task	O
2	O
test	O
set	O
on	O
document	O
and	O
sentencelevel	O
multimodal	O
QE	O
,	O
respectively	O
.	O
This	O
was	O
the	O
follow	O
-	O
up	O
edition	O
of	O
the	O
WMT'18	O
Task	O
4	O
,	O
where	O
the	O
same	O
training	O
set	O
is	O
used	O
,	O
but	O
a	O
new	O
test	O
set	O
is	O
released	O
.	O

This	O
is	O
the	O
detailed	O
datasheet	O
,	O
including	O
ethical	O
considerations	O
,	O
of	O
the	O
unlabelled	O
pretraining	O
dataset	O
proposed	O
in	O
Section	O
4.1	O
.	O

We	O
tie	O
the	O
embedding	O
and	O
output	O
(	O
projection	O
)	O
layers	O
of	O
both	O
LM	O
and	O
NMT	B-MethodName
models	O
(	O
Press	O
and	O
Wolf	O
,	O
2017	O
)	O
.	O
We	O
use	O
a	O
dropout	O
rate	O
of	O
0.1	O
and	O
GELU	O
activations	O
(	O
Hendrycks	O
and	O
Gimpel	O
,	O
2017	O
)	O
.	O
We	O
use	O
the	O
default	O
parameters	O
of	O
Lample	O
and	O
Conneau	O
(	O
2019	O
)	O
in	O
order	O
to	O
train	O
our	O
models	O
.	O

Novelty	O
and	O
Fluency	O
By	O
leveraging	O
a	O
pretrained	O
language	O
model	O
's	O
ability	O
to	O
manipulate	O
structure	O
,	O
we	O
can	O
generate	O
novel	O
questions	O
not	O
present	O
in	O
the	O
entire	O
Duolingo	O
question	O
set	O
(	O
See	O
Table	O
3	O
)	O
.	O
Across	O
4,050	O
questions	O
generated	O
for	O
Spanish	O
learners	O
,	O
we	O
found	O
that	O
with	O
a	O
repetition	O
penalty	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
around	O
43	O
%	O
of	O
all	O
questions	O
,	O
and	O
66	O
%	O
of	O
high	O
difficulty	O
(	O
d	O
=	O
0.1	O
)	O
required	O
to	O
rank	O
all	O
questions	O
in	O
the	O
pool	O
,	O
varying	O
its	O
size	O
(	O
Figure	O
4	O
)	O
.	O
On	O
one	O
NVIDIA	O
Titan	O
XP	O
GPU	O
,	O
we	O
find	O
that	O
,	O
averaged	O
across	O
all	O
target	O
difficulties	O
,	O
our	O
question	O
generation	O
model	O
takes	O
half	O
the	O
time	O
to	O
achieve	O
the	O
same	O
quality	O
as	O
pool	O
selection	O
.	O
The	O
gap	O
increases	O
when	O
trying	O
to	O
sample	O
harder	O
questions	O
(	O
d	O
<	O
0.5	O
)	O
-even	O
a	O
pool	O
size	O
of	O
1000	O
does	O
not	O
have	O
sufficient	O
difficult	O
questions	O
,	O
likely	O
due	O
to	O
a	O
skew	O
in	O
the	O
Duolingo	O
question	O
set	O
.	O
Additional	O
controls	O
,	O
such	O
as	O
for	O
style	O
or	O
topic	O
,	O
can	O
easily	O
be	O
combined	O
with	O
our	O
generation	O
method	O
,	O
but	O
would	O
make	O
pool	O
selection	O
exponentially	O
more	O
complex	O
.	O
Pool	O
Sampling	O
(	O
all	O
targets	O
)	O
Pool	O
Sampling	O
(	O
difficult	O
targets	O
only	O
)	O
Generation	O
(	O
all	O
targets	O
)	O
Generation	O
(	O
difficult	O
targets	O
only	O
)	O

Since	O
our	O
science	O
is	O
based	O
around	O
the	O
belief	O
that	O
femoids	O
can	O
not	O
be	O
forever	O
alone	O
,	O
we	O
have	O
the	O
logical	O
conclusion	O
.	O
The	O
results	O
of	O
this	O
argument	O
could	O
be	O
considered	O
as	O
a	O
valid	O
conclusion	O
.	O

In	O
this	O
study	O
,	O
we	O
propose	O
a	O
global	O
ED	O
model	O
based	O
on	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Our	O
model	O
treats	O
words	O
and	O
entities	O
in	O
the	O
document	O
as	O
input	O
tokens	O
,	O
and	O
is	O
trained	O
by	O
predicting	O
randomly	O
masked	O
entities	O
in	O
a	O
large	O
entity	O
-	O
annotated	O
corpus	O
obtained	O
from	O
Wikipedia	O
.	O
This	O
training	O
enables	O
the	O
model	O
to	O
learn	O
how	O
to	O
disambiguate	O
masked	O
entities	O
based	O
on	O
words	O
and	O
non	O
-	O
masked	O
entities	O
.	O
At	O
the	O
inference	O
time	O
,	O
our	O
model	O
disambiguates	O
*	O
Work	O
done	O
at	O
RIKEN	O
.	O

To	O
conduct	O
the	O
analysis	O
presented	O
in	O
Section	O
3	O
,	O
we	O
take	O
the	O
MedNLI	O
training	O
dataset	O
as	O
input	O
,	O
and	O
exclude	O
the	O
premise	O
text	O
for	O
each	O
training	O
example	O
.	O
We	O
cast	O
the	O
text	O
of	O
each	O
training	O
hypothesis	O
to	O
lowercase	O
,	O
but	O
do	O
not	O
perform	O
any	O
additional	O
preprocessing	O
.	O
We	O
use	O
an	O
off	O
-	O
the	O
-	O
shelf	O
fastText	O
classifier	O
,	O
with	O
all	O
model	O
hyperparameters	O
set	O
to	O
their	O
default	O
values	O
with	O
the	O
exception	O
of	O
wordNgrams	O
,	O
which	O
we	O
set	O
equal	O
to	O
2	O
to	O
allow	O
the	O
model	O
to	O
use	O
bigrams	O
in	O
addition	O
to	O
unigrams	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
We	O
evaluate	O
the	O
trained	O
classifier	O
on	O
the	O
hypotheses	O
contained	O
in	O
the	O
MedNLI	O
dev	O
and	O
test	O
datasets	O
,	O
and	O
report	O
results	O
for	O
each	O
split	O
.	O

Fenwick	O
's	O
wife	O
becomes	O
frightened	O
when	O
a	O
tramp	O
threatens	O
to	O
kill	O
her	O
and	O
her	O
child	O
.	O
"	O
These	O
refer	O
to	O
text	O
spans	O
that	O
contradict	O
previous	O
content	O
(	O
either	O
in	O
the	O
context	O
or	O
the	O
next	O
segment	O
box	O
itself	O
.	O
)	O

We	O
apply	O
AFLite	B-MethodName
to	O
two	O
different	O
versions	O
of	O
MedNLI	O
:	O
(	O
1	O
)	O
X	O
h	O
,	O
m	O
:	O
hypothesis	O
-	O
only	O
,	O
multi	O
-	O
token	O
entities	O
merged	O
,	O
and	O
(	O
2	O
)	O
X	O
ph	O
,	O
m	O
:	O
premise	O
and	O
hypothesis	O
concatenated	O
,	O
multi	O
-	O
token	O
entities	O
merged	O
.	O
AFLIte	B-MethodName
maps	O
each	O
version	O
to	O
an	O
easy	O
and	O
difficult	O
partition	O
,	O
which	O
can	O
in	O
turn	O
be	O
split	O
into	O
training	O
,	O
dev	O
,	O
and	O
test	O
subsets	O
.	O
We	O
report	O
results	O
for	O
the	O
fastText	O
classifier	O
trained	O
on	O
the	O
original	O
,	O
hypothesis	O
-	O
only	O
(	O
hypothesis	O
+	O
premise	O
)	O
MedNLI	O
training	O
set	O
,	O
and	O
evaluated	O
on	O
the	O
full	O
,	O
easy	O
and	O
difficult	O
dev	O
and	O
test	O
subsets	O
of	O
X	O
h	O
,	O
m	O
(	O
X	O
ph	O
,	O
m	O
)	O
,	O
and	O
observe	O
that	O
performance	O
decreases	O
on	O
the	O
difficult	O
partition	O
:	O

While	O
there	O
is	O
a	O
great	O
effort	O
to	O
enlarge	O
Transformer	O
-	O
based	O
LMs	O
such	O
as	O
PALM	B-MethodName
(	O
Chowdhery	O
et	O
al	O
.	O
,	O
2022	O
)	O
and	O
Minerva	B-MethodName
(	O
Lewkowycz	O
et	O
al	O
.	O
,	O
2022	O
)	O
,	O
to	O
improve	O
the	O
performance	O
in	O
symbolic	O
and	O
logical	O
reasoning	O
,	O
our	O
result	O
reveals	O
that	O
it	O
might	O
be	O
necessary	O
to	O
demonstrate	O
the	O
action	O
sequence	O
with	O
reasonable	O
abstraction	O
to	O
the	O
Transformer	B-MethodName
to	O
leverage	O
its	O
full	O
strength	O
.	O

x∈n	O
-	O
best(f	O
,	O
s	O
)	O
f	O
(	O
x|s	O
)	O
+	O
λPLL(x	O
)	O

Then	O
,	O
we	O
tag	O
each	O
example	O
with	O
its	O
rank	O
indexq	O
i	O
referring	O
toq	O
i	O
:	O

In	O
this	O
section	O
,	O
we	O
first	O
introduce	O
the	O
theoretical	O
background	O
before	O
we	O
lay	O
out	O
the	O
four	O
tasks	O
and	O
discuss	O
dataset	O
generation	O
.	O
The	O
dataset	O
is	O
available	O
at	O
https	O
:	O
/	O
/	O
github.com	O
/	O
sysulic	O
/	O
trac	O
.	O

Our	O
alignment	O
-	O
oriented	O
method	O
is	O
,	O
to	O
a	O
large	O
degree	O
,	O
upper	O
-	O
bounded	O
by	O
the	O
English	O
performance	O
,	O
since	O
all	O
our	O
parallel	O
data	O
involve	O
English	O
and	O
all	O
the	O
other	O
languages	O
are	O
implicitly	O
aligning	O
with	O
English	O
through	O
our	O
PPA	O
objectives	O
.	O
Our	O
2	O
M	O
model	O
is	O
able	O
to	O
improve	O
the	O
English	O
performance	O
to	O
82.4	O
from	O
the	O
mBERT	O
baseline	O
,	O
but	O
it	O
is	O
still	O
lower	O
than	O
XLM	O
(	O
MLM	O
)	O
,	O
and	O
much	O
lower	O
than	O
XLM	O
(	O
MLM+TLM	O
)	O
.	O
We	O
hypothesize	O
that	O
more	O
highquality	O
monolingual	O
data	O
and	O
model	O
capacity	O
are	O
needed	O
to	O
further	O
improve	O
our	O
English	O
performance	O
,	O
thereby	O
helping	O
other	O
languages	O
better	O
align	O
with	O
it	O
.	O

where	O
x	O
i	O
2	O
R	O
dx	O
.	O
Self	O
-	O
attention	O
introduced	O
by	O
Vaswani	O
et	O
al	O
.	O
(	O
2017	O
)	O
transforms	O
each	O
x	O
i	O
into	O
z	O
i	O
2	O
R	O
dx	O
as	O
follows	O
:	O

We	O
also	O
design	O
multiple	O
-	O
choice	O
question	O
prompts	O
to	O
leverage	O
the	O
question	O
-	O
answering	O
capabilities	O
of	O
GPT3	B-MethodName
(	O
denoted	O
as	O
GPT3	B-MethodName
-	O
QA	O
)	O
.	O
Similar	O
to	O
the	O
wording	O
used	O
in	O
our	O
ground	O
-	O
truth	O
survey	O
datasets	O
,	O
questions	O
are	O
followed	O
by	O
three	O
options	O
each	O
describing	O
a	O
degree	O
of	O
moral	O
acceptability	O
.	O
We	O
repeat	O
this	O
question	O
-	O
answering	O
process	O
5	O
times	O
for	O
each	O
topic	O
-	O
country	O
pair	O
and	O
take	O
the	O
average	O
of	O
the	O
model	O
responses	O
.	O
Table	O
2	O
in	O
the	O
Appendix	O
shows	O
our	O
prompts	O
for	O
all	O
models	O
.	O

Results	O
on	O
English	O
datasets	O
:	O
Table	O
6	O
compares	O
the	O
performance	O
of	O
Perplection	O
to	O
random	O
baselines	O
on	O
three	O
English	O
datasets	O
.	O
Perplection	O
consistently	O
tops	O
the	O
comparison	O
in	O
almost	O
all	O
cases	O
except	O
for	O
SST-2	B-MethodName
with	O
RoBERTa	O
.	O
This	O
observation	O
supports	O
the	O
supposition	O
that	O
Perplection	O
is	O
agnostic	O
to	O
the	O
pre	O
-	O
trained	O
model	O
used	O
,	O
and	O
shows	O
that	O
it	O
is	O
promising	O
to	O
extrapolate	O
results	O
to	O
other	O
languages	O
.	O

The	O
results	O
of	O
the	O
extra	O
BiLSTM	B-MethodName
experiments	O
are	O
shown	O
in	O
Table	O
4	O
and	O
5	O
.	O
Table	O
4	O
shows	O
unexpected	O
results	O
after	O
disabling	O
features	O
.	O
For	O
instance	O
,	O
disabling	O
rank	O
B	O
features	O
caused	O
a	O
larger	O
performance	O
drop	O
than	O
removing	O
rank	O
A	O
features	O
.	O
This	O
suggests	O
that	O
how	O
we	O
created	O
word	O
clouds	O
for	O
each	O
BiLSTM	B-MethodName
feature	O
(	O
i.e.	O
,	O
displaying	O
top	O
three	O
words	O
with	O
the	O
highest	O
positive	O
and	O
lowest	O
negative	O
rel-	O
evance	O
)	O
might	O
not	O
be	O
an	O
accurate	O
way	O
to	O
explain	O
the	O
feature	O
.	O
Nevertheless	O
,	O
another	O
observation	O
from	O
Table	O
4	O
is	O
that	O
even	O
when	O
we	O
disabled	O
two	O
-	O
third	O
of	O
the	O
BiLSTM	O
features	O
,	O
the	O
maximum	O
macro	O
F1	O
drop	O
was	O
less	O
than	O
5	O
%	O
.	O
This	O
suggests	O
that	O
there	O
is	O
a	O
lot	O
of	O
redundant	O
information	O
in	O
the	O
features	O
of	O
the	O
BiLSTMs	O
.	O

If	O
all	O
entities	O
in	O
the	O
KB	O
are	O
represented	O
using	O
such	O
string	O
representations	O
,	O
then	O
the	O
models	O
described	O
in	O
Section	O
3	O
can	O
directly	O
be	O
used	O
for	O
arbitrary	O
schemas	O
.	O
This	O
leads	O
to	O
the	O
question	O
:	O
how	O
can	O
we	O
generate	O
string	O
representations	O
for	O
entities	O
from	O
arbitrary	O
KBs	O
such	O
that	O
they	O
can	O
be	O
used	O
for	O
BERT	O
-	O
based	O
models	O
?	O
Alternatively	O
,	O
what	O
form	O
can	O
f	O
take	O
?	O

Model	O
The	O
goal	O
of	O
a	O
statistical	O
language	O
model	O
is	O
to	O
learn	O
the	O
conditional	O
probability	O
of	O
the	O
next	O
word	O
given	O
all	O
(	O
or	O
a	O
subset	O
of	O
)	O
the	O
previous	O
ones	O
(	O
Bengio	O
et	O
al	O
.	O
,	O
2003	O
)	O
.	O
That	O
is	O
,	O
for	O
a	O
sequence	O
of	O
tokens	O
x	O
=	O
(	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
)	O
,	O
the	O
model	O
learns	O
p(x	O
i	O
|x	O
<	O
i	O
)	O
where	O
x	O
i	O
is	O
the	O
i	O
-	O
th	O
word	O
of	O
sequence	O
x.	O
For	O
this	O
work	O
,	O
we	O
use	O
the	O
1.63	O
billion	O
-	O
parameter	O
Conditional	O
Transformer	O
Language	O
Model	O
(	O
CTRL	O
)	O
by	O
Keskar	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
is	O
built	O
on	O
a	O
transformerbased	O
sequence	O
to	O
sequence	O
architecture	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
The	O
CTRL	O
has	O
shown	O
to	O
produce	O
high	O
quality	O
text	O
,	O
is	O
general	O
enough	O
to	O
be	O
adapted	O
for	O
conditioning	O
on	O
the	O
control	O
codes	O
we	O
aim	O
to	O
use	O
,	O
and	O
we	O
do	O
not	O
need	O
to	O
pre	O
-	O
train	O
the	O
weights	O
from	O
scratch	O
.	O
Formally	O
,	O
the	O
CTRL	O
adds	O
an	O
extra	O
condition	O
to	O
each	O
sequence	O
by	O
prepending	O
a	O
control	O
code	O
c	O
,	O
hence	O
learning	O
p(x	O
i	O
|x	O
<	O
i	O
,	O
c	O
)	O
.	O
The	O
control	O
code	O
is	O
represented	O
by	O
a	O
single	O
token	O
and	O
can	O
then	O
be	O
used	O
to	O
direct	O
the	O
model	O
output	O
at	O
inference	O
.	O
We	O
extend	O
the	O
model	O
from	O
its	O
previous	O
limit	O
of	O
a	O
singletoken	O
control	O
code	O
to	O
accept	O
multiple	O
tokens	O
.	O
For	O
The	O
respective	O
control	O
code	O
is	O
prepended	O
to	O
each	O
sequence	O
of	O
256	O
subwords	O
of	O
a	O
document	O
.	O

To	O
alleviate	O
the	O
above	O
issue	O
,	O
we	O
propose	O
adaptive	O
modeling	O
of	O
the	O
virtual	O
key	O
vectors	O
.	O
For	O
a	O
query	O
Q	O
i	O
,	O
we	O
suggest	O
taking	O
a	O
vector	O
close	O
to	O
Q	O
i	O
itself	O
as	O
the	O
corresponding	O
virtual	O
key	O
vector	O
(	O
the	O
length	O
of	O
the	O
new	O
prefix	O
is	O
thus	O
1	O
)	O
,	O
in	O
the	O
hope	O
of	O
leading	O
to	O
better	O
inference	O
.	O

In	O
Study	O
1	O
,	O
before	O
scoring	O
answers	O
to	O
a	O
question	O
prompt	O
,	O
the	O
participants	O
were	O
required	O
to	O
answer	O
the	O
following	O
three	O
questions	O
to	O
indicate	O
their	O
interest	O
,	O
familiarity	O
,	O
and	O
perceived	O
difficulty	O
of	O
the	O
question	O
prompt	O
on	O
a	O
rating	O
scale	O
of	O
[	O
1,5	O
]	O
:	O

All	O
models	O
are	O
implemented	O
in	O
PyTorch	B-MethodName
and	O
experiments	O
are	O
run	O
on	O
1	O
NVIDIA	O
Tesla	O
T4	O
GPU	O
.	O
Model	O
hyperparameters	O
are	O
reported	O
in	O
appendix	O
A.5	O
.	O

searching	O
,	O
understanding	O
,	O
and	O
analysis	O
(	O
Zhang	O
and	O
Balog	O
,	O
2018;Deng	O
et	O
al	O
.	O
,	O
2019;Sherborne	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Note	O
that	O
in	O
this	O
work	O
,	O
we	O
focus	O
on	O
translating	O
the	O
headers	O
instead	O
of	O
the	O
entire	O
table	O
content	O
,	O
since	O
for	O
each	O
entity	O
in	O
table	O
content	O
,	O
it	O
is	O
hard	O
to	O
decide	O
if	O
it	O
needs	O
to	O
be	O
translated	O
or	O
not	O
.	O
Over	O
translation	O
could	O
even	O
have	O
negative	O
effects	O
in	O
reality	O
.	O
Despite	O
its	O
importance	O
,	O
most	O
research	O
efforts	O
are	O
dedicated	O
to	O
plain	O
text	O
machine	O
translation	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014;Bahdanau	O
et	O
al	O
.	O
,	O
2015;Vaswani	O
et	O
al	O
.	O
,	O
2017;Yang	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
and	O
schema	O
translation	O
is	O
not	O
well	O
studied	O
in	O
the	O
community	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
.	O
According	O
to	O
our	O
preliminary	O
study	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
(	O
NMT	O
)	O
systems	O
can	O
not	O
work	O
well	O
on	O
schema	O
translation	O
because	O
of	O
two	O
intrinsic	O
differences	O
between	O
plain	O
text	O
and	O
tabular	O
data	O
:	O
morphological	O
difference	O
and	O
context	O
difference	O
.	O

Additionally	O
,	O
our	O
models	O
perform	O
worse	O
than	O
Yang	O
et	O
al	O
.	O
(	O
2018	O
)	O
on	O
the	O
CWEB	B-MethodName
dataset	O
.	O
This	O
is	O
because	O
this	O
dataset	O
is	O
significantly	O
longer	O
on	O
average	O
than	O
other	O
datasets	O
,	O
i.e.	O
,	O
approximately	O
1,700	O
words	O
per	O
document	O
on	O
average	O
,	O
which	O
is	O
more	O
than	O
three	O
times	O
longer	O
than	O
the	O
512	O
-	O
word	O
limit	O
that	O
can	O
be	O
handled	O
by	O
BERT	O
-	O
based	O
models	O
including	O
ours	O
.	O
Yang	O
et	O
al	O
.	O
(	O
2018	O
)	O
achieved	O
excellent	O
performance	O
on	O
this	O
dataset	O
because	O
their	O
model	O
uses	O
various	O
hand	O
-	O
engineered	O
features	O
capturing	O
document	O
-	O
level	O
contextual	O
information	O
.	O

Previous	O
prompting	O
methods	O
which	O
take	O
singlerelation	O
inputs	O
clearly	O
fail	O
to	O
apply	O
in	O
this	O
iterative	O
setting	O
due	O
to	O
the	O
complexity	O
of	O
the	O
input	O
context	O
q	O
,	O
c	O
1	O
,	O
...	O
,	O
c	O
j−1	O
.	O
Task	O
-	O
level	O
prompting	O
methods	O
such	O
as	O
Prompt	O
-	O
Tuning	O
(	O
Lester	O
et	O
al	O
.	O
,	O
2021	O
)	O
and	O
Prefix	O
-	O
Tuning	O
(	O
Li	O
and	O
Liang	O
,	O
2021	O
)	O
are	O
applicable	O
here	O
,	O
where	O
T	O
is	O
treated	O
as	O
a	O
static	O
parameter	O
.	O
However	O
,	O
as	O
described	O
earlier	O
,	O
this	O
modeling	O
is	O
not	O
ideal	O
for	O
T	O
to	O
fully	O
capture	O
variabilities	O
across	O
different	O
inference	O
steps	O
.	O
In	O
this	O
work	O
,	O
we	O
model	O
T	O
as	O
the	O
output	O
of	O
our	O
Prompter	O
,	O
a	O
learnable	O
function	O
mapping	O
f	O
W	O
which	O
dynamically	O
synthesizes	O
T	O
w.r.t	O
.	O
the	O
current	O
step	O
input	O
context	O
:	O

The	O
goal	O
of	O
GEC	O
.	O
This	O
is	O
a	O
significant	O
issue	O
.	O
Is	O
it	O
enough	O
to	O
just	O
get	O
a	O
sentence	O
rid	O
of	O
errors	O
?	O
Taking	O
coding	O
into	O
example	O
,	O
can	O
we	O
say	O
a	O
piece	O
of	O
code	O
"	O
good	O
"	O
when	O
all	O
the	O
"	O
errors	O
"	O
are	O
clear	O
but	O
pages	O
of	O
"	O
warnings	O
"	O
are	O
flashing	O
?	O
In	O
"	O
Good	O
"	O
samples	O
,	O
we	O
compare	O
the	O
human	O
references	O
and	O
automatically	O
generated	O
sentences	O
,	O
and	O
find	O
many	O
of	O
references	O
are	O
only	O
correct	O
but	O
not	O
so	O
idiomatic	O
.	O
On	O
the	O
other	O
hand	O
,	O
many	O
output	O
sentences	O
of	O
PLM	O
-	O
based	O
ensemble	O
strategies	O
are	O
more	O
natural	O
and	O
like	O
native	O
speakers	O
.	O
If	O
a	O
GEC	O
system	O
is	O
aimed	O
at	O
helping	O
overseas	O
students	O
with	O
their	O
language	O
learning	O
,	O
for	O
example	O
,	O
then	O
idiomaticity	O
should	O
be	O
taken	O
into	O
consideration	O
.	O

•	O
Wikitoxic	O
:	O
The	O
dataset	O
can	O
be	O
downloaded	O
here	O
10	O
.	O
We	O
used	O
only	O
examples	O
which	O
were	O
given	O
the	O
same	O
label	O
by	O
all	O
the	O
annotators	O
.	O

its	O
posterior	O
p	O
(	O
Ψ|D	O
)	O
is	O
in	O
the	O
same	O
parametric	O
family	O
as	O
the	O
prior	O
p	O
(	O
Ψ|Ω	O
)	O
.	O
Therefore	O
,	O
given	O
a	O
test	O
utterance	O
x	O
*	O
,	O
the	O
predictive	O
posterior	O
p	O
(	O
y	O
*	O
|D	O
)	O
has	O

Ref1	O
:	O
He	O
looked	O
like	O
a	O
rapper	O
in	O
drugs	O
.	O

Experiments	O
on	O
our	O
dataset	O
demonstrate	O
that	O
CAST	B-MethodName
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
.	O
Our	O
contributions	O
are	O
summarized	O
as	O
follows	O
.	O

.	O
GR	O
is	O
the	O
task	O
to	O
recognize	O
the	O
goal	O
from	O
the	O
partial	O
observation	O
of	O
actions	O
.	O
We	O
use	O
a	O
simplified	O
version	O
,	O
where	O
systems	O
observe	O
a	O
partial	O
action	O
sequence	O
and	O
need	O
to	O
figure	O
out	O
if	O
the	O
given	O
goal	O
is	O
the	O
true	O
objective	O
:	O
Given	O
an	O
initial	O
state	O
s	O
,	O
a	O
potential	O
goal	O
g	O
,	O
and	O
a	O
sequence	O
⃗	O
a	O
of	O
N	O
actions	O
as	O
the	O
observation	O
,	O
decide	O
if	O
g	O
is	O
the	O
true	O
objective	O
.	O
That	O
is	O
,	O
decide	O
if	O
⃗	O
a	O
is	O
a	O
prefix	O
of	O
any	O
optimal	O
plans	O
to	O
achieve	O
g.	O
The	O
context	O
is	O
s	O
and	O
⃗	O
a	O
,	O
and	O
the	O
query	O
is	O
g.	O

High	O
School	O
Examinations	O
(	O
EXAMS	O
)	O
Figure	O
2	O
shows	O
the	O
average	O
number	O
of	O
options	O
per	O
question	O
for	O
each	O
subset	O
in	O
the	O
datasets	O
.	O
Both	O
the	O
Dev	O
and	O
Test	O
subset	O
have	O
four	O
options	O
,	O
but	O
Train	O
contains	O
questions	O
with	O
three	O
answers	O
coming	O
from	O
online	O
history	O
exams	O
collected	O
from	O
Hardalov	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
These	O
examples	O
also	O
affect	O
the	O
subject	O
distribution	O
for	O
the	O
training	O
set	O
.	O

In	O
general	O
,	O
the	O
bidirectional	O
encoder	O
shows	O
poor	O
performance	O
for	O
simultaneous	O
MT	O
.	O
This	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
there	O
exists	O
a	O
mismatch	O
between	O
the	O
training	O
condition	O
(	O
whole	O
source	O
available	O
)	O
and	O
the	O
inference	O
condition	O
(	O
only	O
a	O
prefix	O
of	O
the	O
source	O
is	O
available	O
for	O
k	O
<	O
32	O
)	O
.	O
These	O
results	O
are	O
consistent	O
with	O
(	O
Elbayad	O
et	O
al	O
.	O
,	O
2020a	O
)	O
.	O
Keep	O
in	O
mind	O
that	O
this	O
bidirectional	O
model	O
is	O
different	O
from	O
the	O
offline	O
one	O
because	O
it	O
has	O
been	O
subject	O
to	O
the	O
constraints	O
of	O
Eq	O
.	O
7	O
during	O
training	O
.	O
As	O
a	O
result	O
of	O
the	O
BLEU	B-MethodName
scores	O
reported	O
in	O
Figure	O
2	O
,	O
the	O
streaming	O
MT	O
system	O
with	O
h	O
=	O
60	O
and	O
PBE	B-MethodName
was	O
used	O
in	O
the	O
rest	O
of	O
the	O
German	O
-	O
English	O
experiments	O
.	O

We	O
observe	O
that	O
when	O
training	O
on	O
original	O
DS	B-MethodName
data	O
,	O
the	O
performance	O
of	O
baselines	O
on	O
the	O
RE	B-MethodName
-	I-MethodName
DocRED	I-MethodName
dataset	O
is	O
obviously	O
lower	O
than	O
the	O
Do	B-MethodName
-	I-MethodName
cRED	I-MethodName
dataset	O
.	O
This	O
is	O
because	O
there	O
are	O
more	O
positive	O
instances	O
in	O
the	O
RE	B-MethodName
-	I-MethodName
DocRED	I-MethodName
dataset	O
than	O
in	O
the	O
DocRED	B-MethodName
dataset	O
,	O
which	O
makes	O
the	O
noise	O
problem	O
more	O
obvious	O
.	O
Thus	O
,	O
the	O
performance	O
improvement	O
of	O
models	O
trained	O
on	O
our	O
denoised	O
data	O
will	O
also	O
be	O
more	O
obvious	O
.	O
The	O
performance	O
improvements	O
of	O
baselines	O
that	O
are	O
fine	O
-	O
tuned	O
on	O
humanannotated	O
data	O
can	O
be	O
seen	O
in	O
Appendix	O
A.2	O
.	O

We	O
conducted	O
an	O
error	O
analysis	O
analyzing	O
the	O
model	O
performance	O
w.r.t	O
the	O
different	O
topics	O
of	O
the	O
bills	O
.	O
Our	O
models	O
provides	O
significantly	O
robust	O
performances	O
across	O
most	O
topics	O
in	O
fig	O
.	O
10	O
.	O
Furthermore	O
,	O
we	O
analyze	O
the	O
model	O
performance	O
on	O
each	O
legislator	O
of	O
the	O
U.S.	O
Congress	O
.	O
We	O
obtain	O
an	O
average	O
F1	O
-	O
Score	O
per	O
legislator	O
of	O
0.889	O
with	O
a	O
stand	O
deviation	O
of	O
0.05	O
.	O
Unsurprisingly	O
,	O
our	O
model	O
performance	O
drops	O
for	O
legislators	O
with	O
less	O
than	O
8	O
speeches	O
achieving	O
an	O
average	O
F1	O
-	O
score	O
of	O
0.758	O
with	O
a	O
standard	O
deviation	O
of	O
0.09	O

Furthermore	O
,	O
to	O
address	O
the	O
challenges	O
in	O
schema	O
translation	O
,	O
we	O
propose	O
a	O
Context	O
Aware	O
Schema	O
Translation	O
(	O
CAST	O
)	O
model	O
,	O
which	O
is	O
a	O
header	O
-	O
to	O
-	O
header	O
neural	O
machine	O
translation	O
model	O
augmented	O
with	O
table	O
context	O
.	O
Specifically	O
,	O
we	O
model	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
to	O
represent	O
their	O
entity	O
types	O
and	O
structural	O
relations	O
.	O
Then	O
CAST	B-MethodName
encodes	O
the	O
graph	O
with	O
a	O
relational	O
-	O
aware	O
transformer	O
and	O
uses	O
another	O
transformer	O
to	O
decode	O
the	O
header	O
in	O
the	O
target	O
language	O
.	O
The	O
advantages	O
of	O
our	O
approach	O
come	O
from	O
two	O
folds	O
:	O
(	O
1	O
)	O
The	O
structure	O
relationships	O
make	O
the	O
transformer	O
encoder	O
capture	O
the	O
structural	O
information	O
and	O
learn	O
a	O
contextualized	O
representation	O
for	O
the	O
target	O
header	O
;	O
(	O
2	O
)	O
The	O
entity	O
types	O
differentiate	O
the	O
target	O
header	O
from	O
its	O
context	O
and	O
thus	O
help	O
denoise	O
the	O
target	O
header	O
translation	O
.	O

In	O
the	O
clinical	O
domain	O
,	O
the	O
ability	O
to	O
conduct	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
on	O
unstructured	O
,	O
domainspecific	O
texts	O
such	O
as	O
patient	O
notes	O
,	O
pathology	O
reports	O
,	O
and	O
scientific	O
papers	O
,	O
plays	O
a	O
critical	O
role	O
in	O
the	O
development	O
of	O
predictive	O
models	O
and	O
clinical	O
decision	O
support	O
(	O
CDS	O
)	O
systems	O
.	O

Semantic	O
roles	O
and	O
their	O
properties	O
have	O
received	O
extensive	O
attention	O
in	O
linguistics	O
(	O
Fillmore	O
,	O
1968;Levin	O
and	O
Rappaport	O
Hovav	O
,	O
2005;Dowty	O
,	O
1991	O
)	O
and	O
are	O
considered	O
a	O
universal	O
feature	O
of	O
human	O
language	O
.	O
The	O
size	O
and	O
organization	O
of	O
the	O
role	O
and	O
predicate	O
inventory	O
are	O
subject	O
to	O
debate	O
,	O
giving	O
rise	O
to	O
a	O
variety	O
of	O
role	O
-	O
semantic	O
formalisms	O
.	O

He	O
becomes	O
infatuated	O
with	O
Madame	O
de	O
Pastourelles	O
,	O
a	O
beautiful	O
and	O
intelligent	O
artist	O
.	O

To	O
determine	O
whether	O
MedNLI	O
contains	O
annotation	O
artifacts	O
that	O
may	O
artificially	O
inflate	O
the	O
performance	O
of	O
models	O
trained	O
on	O
this	O
dataset	O
,	O
we	O
train	O
a	O
simple	O
,	O
premise	O
-	O
unaware	O
,	O
fastText	O
classifier	O
to	O
predict	O
the	O
label	O
of	O
each	O
premise	O
-	O
hypothesis	O
pair	O
,	O
and	O
compare	O
the	O
performance	O
of	O
this	O
classifier	O
to	O
a	O
majority	O
-	O
class	O
baseline	O
,	O
in	O
which	O
all	O
training	O
examples	O
are	O
mapped	O
to	O
the	O
most	O
commonly	O
occurring	O
class	O
label	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2016;Poliak	O
et	O
al	O
.	O
,	O
2018;Gururangan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Note	O
that	O
since	O
annotators	O
were	O
asked	O
to	O
create	O
an	O
entailed	O
,	O
contradictory	O
,	O
and	O
neutral	O
hypothesis	O
for	O
each	O
premise	O
,	O
MedNLI	B-MethodName
is	O
class	O
-	O
balanced	O
.	O
Thus	O
,	O
in	O
this	O
setting	O
,	O
a	O
majority	O
class	O
baseline	O
is	O
equivalent	O
to	O
choosing	O
a	O
label	O
uniformly	O
at	O
random	O
for	O
each	O
training	O
example	O
.	O

Given	O
a	O
question	O
Q	O
and	O
options	O
O	O
,	O
following	O
previous	O
works	O
Weir	O
and	O
Durme	O
,	O
2022	O
)	O
,	O
we	O
first	O
convert	O
them	O
into	O
declarative	O
hypotheses	O
{	O
H	O
1	O
,	O
.	O
.	O
.	O
,	O
H	O
|O|	O
}	O
.	O
2	O
We	O
then	O
try	O
to	O
generate	O
an	O
entailment	O
tree	O
for	O
each	O
hypothesis	O
in	O
a	O
forward	O
chaining	O
manner	O
and	O
select	O
the	O
most	O
plausible	O
option	O
based	O
on	O
the	O
validity	O
and	O
faithfulness	O
of	O
trees	O
.	O

Both	O
during	O
training	O
and	O
inference	O
,	O
we	O
only	O
retain	O
the	O
100	O
most	O
frequent	O
attributes	O
in	O
the	O
respective	O
KBs	O
.	O
The	O
attribute	O
-	O
separators	O
(	O
Section	O
4.1	O
)	O
are	O
created	O
corresponding	O
to	O
the	O
100	O
most	O
frequent	O
attributes	O
in	O
the	O
training	O
KB	O
.	O
Candidates	O
and	O
mentions	O
(	O
with	O
context	O
)	O
are	O
represented	O
using	O
strings	O
of	O
128	O
sub	O
-	O
word	O
tokens	O
each	O
,	O
across	O
all	O
models	O
.	O

Similarly	O
,	O
the	O
label	O
-	O
to	O
-	O
text	O
direction	O
is	O
trained	O
on	O
{	O
y	O
,	O
x	O
}	O
pairs	O
from	O
D	O
S	O
by	O
minimizing	O
the	O
standard	O
maximum	O
likelihood	O
loss	O
:	O

We	O
show	O
detailed	O
results	O
on	O
GLUE	B-MethodName
and	O
SQuAD	B-MethodName
in	O
Table	O
4	O
and	O
detailed	O
results	O
on	O
LibriSpeech	B-MethodName
reranking	O
in	O
Table	O
5	O
.	O
Following	O
BERT	B-MethodName
,	O
we	O
do	O
not	O
show	O
results	O
on	O
the	O
WNLI	B-MethodName
GLUE	O
task	O
,	O
as	O
it	O
is	O
difficult	O
to	O
beat	O
even	O
the	O
majority	O
classifier	O
using	O
a	O
standard	O
fine	O
-	O
tuning	O
-	O
as	O
-	O
classifier	O
approach	O
.	O
We	O
show	O
dev	O
rather	O
than	O
test	O
results	O
on	O
GLUE	B-MethodName
in	O
the	O
main	O
paper	O
because	O
they	O
are	O
more	O
reliable	O
;	O
the	O
performance	O
of	O
fine	O
-	O
tuned	O
models	O
varies	O
substantially	O
based	O
on	O
the	O
random	O
seed	O
(	O
Phang	O
et	O
al	O
.	O
,	O
2018;Clark	O
et	O
al	O
.	O
,	O
2019;Dodge	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
but	O
GLUE	B-MethodName
only	O
supports	O
submitting	O
a	O
single	O
model	O
rather	O
than	O
getting	O
a	O
median	O
score	O
of	O
multiple	O
models	O
.	O
While	O
6	O
https://worksheets	O
.	O
codalab.org/rest/bundles/	O
0x6b567e1cf2e041ec80d7098f031c5c9e/	O
contents	O
/	O
blob/	O
7	O
https://docs.scipy.org/doc/	O
scipy	O
/	O
reference	O
/	O
generated	O
/	O
scipy.stats	O
.	O
spearmanr.html	O

To	O
supplement	O
our	O
analyses	O
,	O
we	O
compute	O
several	O
coarse	O
-	O
grained	O
lexical	O
counts	O
for	O
each	O
story	O
in	O
HIPPOCORPUS	O
.	O
Such	O
approaches	O
have	O
been	O
used	O
in	O
prior	O
efforts	O
to	O
investigate	O
author	O
mental	O
states	O
,	O
temporal	O
orientation	O
,	O
or	O
counterfactual	O
thinking	O
in	O
language	O
(	O
Tausczik	O
and	O
Pennebaker	O
,	O
2010;Schwartz	O
et	O
al	O
.	O
,	O
2015;Son	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O

For	O
the	O
final	O
crowdsourcing	O
study	O
,	O
we	O
use	O
Amazon	O
Mechanical	O
Turk	O
.	O
Workers	O
had	O
to	O
take	O
a	O
qualification	O
test	O
,	O
have	O
an	O
acceptance	O
rate	O
of	O
at	O
least	O
95	O
%	O
,	O
and	O
location	O
within	O
the	O
US	O
.	O
We	O
paid	O
$	O
7.6	O
per	O
hour	O
(	O
minimum	O
wage	O
is	O
$	O
7.25	O
per	O
hour	O
)	O
.	O
Each	O
data	O
sample	O
is	O
annotated	O
by	O
eight	O
crowdworkers	O
.	O
In	O
case	O
the	O
ranker	O
cut	O
off	O
the	O
real	O
aspect(s	O
)	O
from	O
the	O
list	O
of	O
candidates	O
,	O
crowdworkers	O
could	O
select	O
any	O
sequence	O
up	O
to	O
four	O
tokens	O
from	O
a	O
second	O
list	O
.	O

Our	O
sentence	O
-	O
level	O
alignment	O
falls	O
under	O
the	O
general	O
problem	O
of	O
bringing	O
two	O
views	O
of	O
inputs	O
from	O
the	O
same	O
source	O
closer	O
in	O
the	O
representation	O
space	O
while	O
keeping	O
those	O
from	O
different	O
sources	O
dissimilar	O
through	O
a	O
contrastive	O
loss	O
.	O
From	O
a	O
crosslingual	O
alignment	O
perspective	O
,	O
we	O
treat	O
an	O
English	O
sequence	O
S	O
en	O
i	O
and	O
its	O
translation	O
S	O
tr	O
i	O
in	O
another	O
language	O
tr	O
∈	O
L	O
as	O
two	O
manifestations	O
of	O
the	O
same	O
semantics	O
.	O
At	O
the	O
same	O
time	O
,	O
sentences	O
that	O
are	O
not	O
translations	O
of	O
each	O
other	O
should	O
be	O
further	O
apart	O
in	O
the	O
representation	O
space	O
.	O
Given	O
parallel	O
corpora	O
consisting	O
of	O
{	O
(	O
S	O
en	O
1	O
,	O
S	O
tr	O
1	O
)	O
,	O
.	O
.	O
.	O
,	O
(	O
S	O
en	O
N	O
,	O
S	O
tr	O
N	O
)	O
}	O
,	O
we	O
align	O
sentence	O
representations	O
in	O
all	O
the	O
different	O
languages	O
together	O
using	O
MoCo	O
.	O

Factoid	O
QA	O
by	O
Retrieval	O
This	O
model	O
is	O
a	O
baseline	O
(	O
Lukovnikov	O
et	O
al	O
.	O
,	O
2017	O
)	O
that	O
individually	O
retrieves	O
the	O
entities	O
and	O
relations	O
based	O
on	O
their	O
embedding	O
-	O
level	O
similarities	O
to	O
input	O
queries	O
.	O
Then	O
,	O
it	O
merges	O
the	O
retrieved	O
entities	O
and	O
relations	O
with	O
the	O
KG	O
-	O
specific	O
schema	O
to	O
construct	O
the	O
triplets	O
.	O

Model	O
Noise	O
Dist	O
.	O
Binary	O
Classifier	O
Electric	O
Two	O
-	O
Tower	O
Cloze	O
Model	O
σ	O
E(x)t	O
+	O
log	O
k•q(x|x	O
\t	O
)	O
n	O
ELECTRA	O
Masked	O
LM	O
σ(E(x)t	O
)	O

Step	O
3	O
:	O
Annotation	O
study	O
We	O
use	O
Amazon	O
Mechanical	I-MethodName
Turk	I-MethodName
to	O
annotate	O
each	O
sample	O
by	O
eight	O
different	O
workers	O
located	O
in	O
the	O
US	O
,	O
paying	O
$	O
7.6	O
per	O
hour	O
(	O
minimum	O
wage	O
is	O
$	O
7.25	O
per	O
hour	O
)	O
.	O
Based	O
on	O
a	O
subset	O
of	O
232	O
samples	O
,	O
we	O
compute	O
an	O
α	O
u	O
of	O
.67	O
between	O
crowdworkers	O
and	O
experts	O
(	O
three	O
doctoral	O
researchers	O
)	O
.	O
Compared	O
to	O
the	O
initial	O
study	O
,	O
the	O
new	O
approach	O
increases	O
the	O
inter	O
-	O
annotator	O
agreement	O
between	O
experts	O
by	O
approx	O
.	O
11	O
points	O
(	O
see	O
App	O
.	O
A	O
for	O
further	O
details	O
on	O
the	O
annotation	O
study	O
)	O
.	O
Based	O
on	O
this	O
promising	O
result	O
,	O
we	O
create	O
a	O
dataset	O
of	O
5,032	O
high	O
-	O
quality	O
samples	O
that	O
are	O
labelled	O
with	O
aspects	O
,	O
as	O
well	O
as	O
with	O
their	O
original	O
stance	O
labels	O
from	O
the	O
UKP	B-MethodName
-	I-MethodName
Corpus	I-MethodName
.	O
We	O
show	O
the	O
most	O
frequent	O
(	O
lemmatized	O
)	O
aspects	O
that	O
appear	O
in	O
some	O
topics	O
in	O
Table	O
1	O
.	O

To	O
analyse	O
how	O
the	O
MM	O
contributions	O
are	O
affected	O
by	O
fine	O
-	O
tuning	O
,	O
we	O
compare	O
4	O
ALBEF	B-MethodName
5	I-MethodName
models	O
fine	O
-	O
tuned	O
on	O
(	O
1	O
)	O
image	O
retrieval	O
on	O
MSCOCO	B-MethodName
,	O
(	O
2	O
)	O
image	O
retrieval	O
on	O
Flickr30k	B-MethodName
(	O
Plummer	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
(	O
3	O
)	O
visual	O
grounding	O
on	O
RefCOCO+	B-MethodName
(	O
Yu	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
(	O
4	O
)	O
VQA	B-MethodName
(	O
Goyal	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O

The	O
2018	O
Duolingo	O
Shared	O
Task	O
on	O
Second	O
Language	O
Acquisition	O
Modeling	O
(	O
Settles	O
et	O
al	O
.	O
,	O
2018	O
)	O
dataset	O
contains	O
questions	O
and	O
responses	O
for	O
Duolingo	O
users	O
over	O
the	O
first	O
30	O
days	O
of	O
learning	O
a	O
second	O
language	O
.	O
The	O
dataset	O
contains	O
three	O
different	O
question	O
types	O
:	O
reverse	O
translate	O
(	O
free	O
response	O
translation	O
of	O
a	O
given	O
prompt	O
in	O
the	O
language	O
they	O
are	O
learning	O
)	O
,	O
reverse	O
tap	O
(	O
a	O
selection	O
-	O
based	O
equivalent	O
of	O
reverse	O
translate	O
)	O
,	O
and	O
listen	O
,	O
where	O
students	O
listen	O
to	O
a	O
vocal	O
utterance	O
.	O
We	O
focus	O
on	O
the	O
reverse	O
translate	O
question	O
type	O
for	O
English	O
-	O
speaking	O
students	O
learning	O
French	O
and	O
Spanish	O
.	O
The	O
dataset	O
size	O
for	O
French	O
learners	O
(	O
1.2k	O
users	O
)	O
is	O
roughly	O
half	O
the	O
size	O
of	O
that	O
for	O
Spanish	O
learners	O
(	O
2.6k	O
users	O
)	O
.	O

Table	O
9	O
shows	O
the	O
performance	O
of	O
our	O
models	O
when	O
trained	O
and	O
evaluated	O
on	O
the	O
synthesis	O
procedures	O
dataset	O
.	O
Detailed	O
scores	O
by	O
entity	O
type	O
can	O
be	O
found	O
in	O
the	O
Supplementary	O
Material	O
.	O
We	O
chose	O
to	O
use	O
the	O
data	O
split	O
suggested	O
by	O
the	O
authors	O
for	O
the	O
NER	O
task	O
,	O
using	O
200	O
documents	O
for	O
training	O
,	O
and	O
15	O
documents	O
for	O
each	O
dev	O
and	O
test	O
set	O
.	O
Among	O
the	O
non	O
-	O
BERT	O
-	O
based	O
systems	O
,	O
the	O
BiLSTM	O
variant	O
using	O
both	O
mat2vec	O
and	O
word2vec	O
performs	O
best	O
,	O
indicating	O
that	O
the	O
two	O
pre	O
-	O
trained	O
embeddings	O
contain	O
complementary	O
information	O
with	O
regard	O
to	O
this	O
task	O
.	O
The	O
best	O
performance	O
is	O
reached	O
by	O
the	O
BiL	B-MethodName
-	I-MethodName
STM	I-MethodName
model	O
including	O
word2vec	O
,	O
mat2vec	O
,	O
bpe	O
and	O
SciBERT	B-MethodName
embeddings	O
,	O
with	O
92.2	O
micro	O
-	O
average	O
F1	O
providing	O
a	O
strong	O
baseline	O
for	O
future	O
work	O
.	O

where	O
e	O
i	O
is	O
the	O
logit	O
of	O
paragraph	O
i	O
in	O
the	O
evidence	O
selection	O
step	O
,	O
n	O
is	O
the	O
number	O
of	O
paragraphs	O
and	O

The	O
above	O
two	O
steps	O
of	O
recognizing	O
relevant	O
sentences	O
and	O
marking	O
coarse	O
-	O
grained	O
entity	O
types	O
are	O
in	O
general	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
experiment	O
types	O
within	O
the	O
materials	O
science	O
domain	O
.	O
We	O
now	O
define	O
a	O
set	O
of	O
slot	O
types	O
particular	O
to	O
experiments	O
on	O
SOFCs	O
.	O
During	O
annotation	O
,	O
we	O
mark	O
these	O
slot	O
types	O
as	O
links	O
between	O
the	O
experimentevoking	O
phrase	O
and	O
the	O
respective	O
slot	O
filler	O
(	O
entity	O
mention	O
)	O
,	O
see	O
Figure	O
1	O
.	O
As	O
a	O
result	O
,	O
experiment	O
frames	O
are	O
represented	O
by	O
graphs	O
rooted	O
in	O
the	O
node	O
corresponding	O
to	O
the	O
frame	O
-	O
evoking	O
element	O
.	O

While	O
recent	O
results	O
indicate	O
that	O
BERT	B-MethodName
successfully	O
represents	O
lexical	O
-	O
semantic	O
and	O
grammatical	O
information	O
,	O
the	O
evidence	O
of	O
its	O
high	O
-	O
level	O
semantic	O
capabilities	O
is	O
inconclusive	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
show	O
that	O
the	O
English	O
PropBank	B-MethodName
semantics	O
can	O
be	O
extracted	O
from	O
the	O
encoder	O
and	O
follows	O
syntax	O
in	O
the	O
layer	O
structure	O
.	O
However	O
,	O
out	O
of	O
all	O
formalisms	O
PropBank	B-MethodName
is	O
most	O
closely	O
tied	O
to	O
syntax	O
,	O
and	O
the	O
results	O
on	O
proto	O
-	O
role	O
and	O
relation	O
probing	O
do	O
not	O
follow	O
the	O
same	O
pattern	O
.	O
Kovaleva	O
et	O
al	O
.	O
(	O
2019	O
)	O
identify	O
two	O
attention	O
heads	O
in	O
BERT	B-MethodName
responsible	O
for	O
FrameNet	B-MethodName
relations	O
.	O
However	O
,	O
they	O
find	O
that	O
disabling	O
them	O
in	O
a	O
fine	O
-	O
tuning	O
evaluation	O
on	O
the	O
GLUE	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2018	O
)	O
benchmark	O
does	O
not	O
result	O
in	O
decreased	O
performance	O
.	O

The	O
dataset	O
contains	O
67k	O
train	O
examples	O
from	O
movie	O
reviews	O
.	O

Dataset	O
shift	O
is	O
a	O
problem	O
where	O
the	O
joint	O
distribution	O
of	O
inputs	O
and	O
outputs	O
differs	O
between	O
training	O
and	O
test	O
stage	O
(	O
Quionero	O
-	O
Candela	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
Many	O
classifiers	O
perform	O
poorly	O
under	O
dataset	O
shift	O
because	O
some	O
of	O
the	O
learned	O
features	O
are	O
inapplicable	O
(	O
or	O
sometimes	O
even	O
harmful	O
)	O
to	O
classify	O
test	O
documents	O
.	O
We	O
hypothesize	O
that	O
FIND	B-MethodName
is	O
useful	O
for	O
investigating	O
the	O
learned	O
features	O
and	O
disabling	O
the	O
overfitting	O
ones	O
to	O
increase	O
the	O
generalizability	O
of	O
the	O
model	O
.	O

B4	O
.	O
Did	O
you	O
discuss	O
the	O
steps	O
taken	O
to	O
check	O
whether	O
the	O
data	O
that	O
was	O
collected	O
/	O
used	O
contains	O
any	O
information	O
that	O
names	O
or	O
uniquely	O
identifies	O
individual	O
people	O
or	O
offensive	O
content	O
,	O
and	O
the	O
steps	O
taken	O
to	O
protect	O
/	O
anonymize	O
it	O
?	O
No	O
response	O
.	O

•	O
aspect_pos	O
:	O
List	O
of	O
string	O
tuples	O
"	O
(	O
begin	O
,	O
length	O
)	O
"	O
,	O
marking	O
the	O
character	O
position	O
and	O
length	O
of	O
each	O
aspect	O
within	O
the	O
argument	O
.	O

Instead	O
of	O
a	O
fixed	O
role	O
label	O
,	O
each	O
argument	O
is	O
assessed	O
via	O
a	O
11	O
-	O
dimensional	O
cardinal	O
feature	O
set	O
including	O
Proto	O
-	O
Agent	O
and	O
Proto	O
-	O
Patient	O
properties	O
like	O
volitional	O
,	O
sentient	O
,	O
destroyed	O
,	O
etc	O
.	O
The	O
feature	O
-	O
based	O
approach	O
eliminates	O
some	O
of	O
the	O
theoretical	O
issues	O
associated	O
with	O
categorical	O
role	O
inventories	O
and	O
allows	O
for	O
more	O
flexible	O
modeling	O
of	O
role	O
semantics	O
.	O

We	O
used	O
human	O
responses	O
on	O
MTurk	B-MethodName
to	O
assign	O
ranks	O
to	O
features	O
.	O
As	O
each	O
classifier	O
had	O
30	O
original	O
features	O
(	O
d	O
=	O
30	O
)	O
,	O
we	O
divided	O
them	O
into	O
three	O
ranks	O
(	O
A	O
,	O
B	O
,	O
and	O
C	O
)	O
each	O
of	O
which	O
with	O
10	O
features	O
.	O
We	O
expected	O
that	O
features	O
in	O
rank	O
A	O
are	O
most	O
relevant	O
and	O
useful	O
for	O
the	O
prediction	O
task	O
,	O
and	O
features	O
in	O
rank	O
C	O
least	O
relevant	O
,	O
potentially	O
undermining	O
the	O
performance	O
of	O
the	O
model	O
.	O
To	O
make	O
the	O
annotation	O
more	O
accessible	O
to	O
lay	O
users	O
,	O
we	O
designed	O
the	O
questions	O
to	O
ask	O
whether	O
a	O
given	O
word	O
cloud	O
is	O
(	O
mostly	O
or	O
partially	O
)	O
relevant	O
to	O
one	O
of	O
the	O
classes	O
or	O
not	O
,	O
as	O
shown	O
in	O
Figure	O
3	O
.	O
If	O
the	O
answer	O
matches	O
how	O
the	O
model	O
really	O
uses	O
this	O
feature	O
(	O
as	O
indicated	O
by	O
W	O
)	O
,	O
the	O
feature	O
gets	O
a	O
positive	O
score	O
from	O
this	O
human	O
response	O
.	O
For	O
example	O
,	O
if	O
the	O
CNN	O
feature	O
of	O
the	O
word	O
cloud	O
in	O
Figure	O
3	O
is	O
used	O
by	O
the	O
model	O
for	O
the	O
negative	O
sentiment	O
class	O
,	O
the	O
scores	O
of	O
the	O
five	O
options	O
in	O
the	O
figure	O
are	O
-2	O
,	O
-1	O
,	O
0	O
,	O
1	O
,	O
2	O
,	O
respectively	O
.	O
We	O
collected	O
ten	O
responses	O
for	O
each	O
question	O
and	O
used	O
the	O
average	O
score	O
to	O
sort	O
the	O
features	O
descendingly	O
.	O
After	O
sorting	O
,	O
the	O
1	O
st	O
-10	O
th	O
features	O
,	O
11	O
th	O
-20	O
th	O
features	O
,	O
and	O
21	O
st	O
-30	O
th	O
features	O
are	O
considered	O
as	O
rank	O
A	O
,	O
B	O
,	O
and	O
C	O
,	O
respectively	O
.	O
3	O
To	O
show	O
the	O
effects	O
of	O
feature	O
disabling	O
,	O
we	O
compared	O
the	O
original	O
model	O
M	O
with	O
the	O
modified	O
model	O
M	O
with	O
features	O
in	O
rank	O
X	O
disabled	O
where	O
X	O
∈	O
{	O
A	O
,	O
B	O
,	O
C	O
,	O
A	O
and	O
B	O
,	O
A	O
and	O
C	O
,	O
B	O
and	O
C	O
}	O
.	O

TriviaQA	B-MethodName
FEVER	I-MethodName
WoW	O
R	O
-	O
Prec	O
R	O
@	O
5	O
R	O
-	O
Prec	O
R	O
@	O
5	O
R	O
-	O
Prec	O
R	O
@	O
5	O
R	O
-	O
Prec	O
R	O
@	O
5	O
R	O
-	O
Prec	O
R	O
@	O
However	O
,	O
there	O
is	O
a	O
sharp	O
decline	O
in	O
the	O
performance	O
of	O
TriviaQA	B-MethodName
,	O
in	O
retrieval	O
metrics	O
.	O
This	O
is	O
true	O
despite	O
the	O
fact	O
that	O
retrieving	O
these	O
passages	O
greatly	O
improves	O
answer	O
accuracy	O
and	O
F1	O
.	O
This	O
suggests	O
some	O
incompleteness	O
in	O
the	O
provenance	O
ground	O
truth	O
for	O
TriviaQA	B-MethodName
.	O

We	O
explore	O
feature	O
-	O
based	O
and	O
neural	O
-	O
based	O
models	O
from	O
two	O
open	O
-	O
source	O
frameworks	O
:	O
QuEst++	O
:	O
QuEst++	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2015	O
)	O
is	O
a	O
feature	O
-	O
based	O
QE	O
framework	O
composed	O
of	O
two	O
modules	O
:	O
a	O
feature	O
extractor	O
module	O
,	O
to	O
extract	O
the	O
relevant	O
QE	O
features	O
from	O
both	O
the	O
source	O
sentences	O
and	O
their	O
translations	O
,	O
and	O
a	O
machine	O
learning	O
module	O
.	O
We	O
only	O
use	O
this	O
framework	O
for	O
our	O
experiments	O
on	O
document	O
-	O
level	O
QE	O
,	O
since	O
it	O
does	O
not	O
perform	O
well	O
enough	O
for	O
sentence	O
-	O
level	O
prediction	O
.	O
We	O
use	O
the	O
same	O
model	O
(	O
Support	O
Vector	O
Regression	O
)	O
,	O
hyperparameters	O
and	O
feature	O
settings	O
as	O
the	O
baseline	O
model	O
for	O
the	O
document	O
-	O
level	O
QE	O
task	O
at	O
WMT'18	B-MethodName
.	O

It	O
is	O
known	O
that	O
neural	O
networks	O
suffer	O
from	O
the	O
miscalibration	O
problem	O
between	O
accuracy	O
and	O
confidence	O
(	O
Guo	O
et	O
al	O
.	O
,	O
2017;Wang	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Overconfidence	O
can	O
lead	O
to	O
predicting	O
high	O
confidence	O
for	O
poor	O
translations	O
,	O
while	O
under	O
-	O
confidence	O
leads	O
to	O
low	O
confidence	O
for	O
good	O
translations	O
.	O
Here	O
,	O
we	O
evaluate	O
whether	O
CANMT	B-MethodName
alleviates	O
the	O
over-	O
and	O
under	O
-	O
confidence	O
problem	O
on	O
Zh→En	O
multidomain	O
tests	O
.	O
For	O
each	O
method	O
,	O
we	O
split	O
sentences	O
into	O
five	O
bins	O
according	O
to	O
the	O
predicted	O
scores	O
(	O
ranging	O
from	O
low	O
quality	O
to	O
high	O
)	O
and	O
compute	O
the	O
average	O
human	O
scores	O
.	O
We	O
plot	O
these	O
values	O
of	O
CANMT	B-MethodName
and	O
confidence	O
-	O
based	O
QE	O
methods	O
(	O
TP	O
and	O
D	O
-	O
TP	I-MethodName
)	O
in	O
Figure	O
3	O
.	O

Table	O
1	O
:	O
Example	O
of	O
incorrectly	O
machine	O
-	O
translated	O
text	O
:	O
the	O
word	O
shorts	O
is	O
used	O
to	O
indicate	O
short	O
trousers	O
,	O
but	O
gets	O
translated	O
in	O
French	O
as	O
court	O
,	O
the	O
adjective	O
short	O
.	O
Here	O
multimodality	O
could	O
help	O
to	O
detect	O
the	O
error	O
(	O
extracted	O
from	O
the	O
Amazon	O
Reviews	O
Dataset	O
of	O
McAuley	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
creasingly	O
accompanied	O
with	O
visual	O
elements	O
such	O
as	O
images	O
or	O
videos	O
,	O
especially	O
in	O
social	O
media	O
but	O
also	O
in	O
domains	O
such	O
as	O
e	O
-	O
commerce	O
.	O
Multimodality	O
has	O
not	O
yet	O
been	O
applied	O
to	O
QE	O
.	O
Table	O
1	O
shows	O
an	O
example	O
from	O
our	O
e	O
-	O
commerce	O
dataset	O
in	O
which	O
multimodality	O
could	O
help	O
to	O
improve	O
QE	O
.	O
Here	O
,	O
the	O
English	O
noun	O
shorts	O
is	O
translated	O
by	O
the	O
adjective	O
court	O
(	O
for	O
the	O
adjective	O
short	O
)	O
in	O
French	O
,	O
which	O
is	O
a	O
possible	O
translation	O
out	O
of	O
context	O
.	O
However	O
,	O
as	O
the	O
corresponding	O
product	O
image	O
shows	O
,	O
this	O
product	O
is	O
an	O
item	O
of	O
clothing	O
,	O
and	O
thus	O
the	O
machine	O
translation	O
is	O
incorrect	O
.	O
External	O
information	O
can	O
hence	O
help	O
identify	O
mismatches	O
between	O
translations	O
which	O
are	O
difficult	O
to	O
find	O
within	O
the	O
text	O
.	O
Progress	O
in	O
QE	O
is	O
mostly	O
benchmarked	O
as	O
part	O
of	O
the	O
Conference	O
on	O
Machine	O
Translation	O
(	O
WMT	O
)	O
Shared	O
Task	O
on	O
QE	O
.	O
This	O
paper	O
is	O
based	O
on	O
data	O
from	O
the	O
WMT'18	O
edition	O
's	O
Task	O
4	O
-documentlevel	O
QE	O
.	O
This	O
Task	O
4	O
aims	O
to	O
predict	O
a	O
translation	O
quality	O
score	O
for	O
short	O
documents	O
based	O
on	O
the	O
number	O
and	O
the	O
severity	O
of	O
translation	O
errors	O
at	O
the	O
word	O
level	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018a	O
)	O
.	O
This	O
data	O
was	O
chosen	O
as	O
it	O
is	O
the	O
only	O
one	O
for	O
which	O
meta	O
information	O
(	O
images	O
in	O
this	O
case	O
)	O
is	O
available	O
.	O
We	O
extend	O
this	O
dataset	O
by	O
computing	O
scores	O
for	O
each	O
sentence	O
for	O
a	O
sentence	O
-	O
level	O
prediction	O
task	O
.	O
We	O
consider	O
both	O
feature	O
-	O
based	O
and	O
neural	O
state	O
-	O
of	O
-	O
theart	O
models	O
for	O
QE	O
.	O
Having	O
these	O
as	O
our	O
starting	O
points	O
,	O
we	O
propose	O
different	O
ways	O
to	O
integrate	O
the	O
visual	O
modality	O
.	O

The	O
correlation	O
between	O
MQM	O
-	O
based	O
scores	O
and	O
metric	O
scores	O
,	O
measured	O
using	O
Pearson	O
and	O
Kendalltau	O
correlations	O
on	O
1400	O
segments	O
per	O
language	O
as	O
shown	O
in	O
Table	O
1	O
.	O
We	O
observe	O
that	O
out	O
of	O
the	O
overlap	O
-	O
based	O
metrics	O
,	O
chrF++	O
has	O
the	O
highest	O
correlation	O
across	O
all	O
languages	O
,	O
but	O
overall	O
overlapbased	O
metrics	O
are	O
the	O
worst	O
performing	O
which	O
is	O
in	O
line	O
with	O
the	O
findings	O
of	O
Kocmi	O
et	O
al	O
.	O
(	O
2022	O
)	O
.	O
Among	O
the	O
embedding	O
-	O
based	O
metrics	O
,	O
LabSE	B-MethodName
embeddings	O
yields	O
better	O
correlations	O
than	O
any	O
of	O
the	O
COMET	O
-	O
metric	O
variants	O
have	O
the	O
highest	O
overall	O
correlations	O
for	O
all	O
the	O
languages	O
.	O

In	O
this	O
section	O
,	O
we	O
analyze	O
the	O
memory	O
usage	O
of	O
the	O
end	O
-	O
to	O
-	O
end	O
method	O
LED	O
and	O
the	O
proposed	O
CGSN	O
.	O
Assuming	O
the	O
length	O
of	O
a	O
document	O
is	O
L	O
(	O
L	O
≥	O
4	O
K	O
)	O
,	O
the	O
local	O
window	O
size	O
9	O
is	O
W	O
(	O
W	O
≥	O
512	O
)	O
,	O
the	O
number	O
of	O
global	O
tokens	O
is	O
G	O
t	O
,	O
the	O
memory	O
usage	O
of	O
LED	O
method	O
is	O
O	O
(	O
L	O
(	O
W	O
+	O
G	O
t	O
)	O
)	O
.	O
When	O
G	O
t	O
≪	O
W	O
,	O
the	O
memory	O
usage	O
is	O
O	O
(	O
LW	O
)	O
.	O
For	O
CGSN	O
,	O
set	O
the	O
paragraph	O
number	O
in	O
a	O
segment	O
as	O
B.	O
For	O
a	O
fair	O
comparison	O
,	O
the	O
maximum	O
length	O
of	O
a	O
paragraph	O
is	O
9	O
Attention	O
to	O
the	O
W	O
2	O
tokens	O
ahead	O
and	O
W	O
2	O
tokens	O
behind	O
.	O

We	O
also	O
evaluate	O
the	O
DecT	O
on	O
CPM	B-MethodName
-	I-MethodName
Bee	I-MethodName
3	O
,	O
which	O
is	O
a	O
bilingual	O
generative	O
pre	O
-	O
trained	O
language	O
model	O
with	O
10B	O
parameters	O
.	O
Table	O
6	O
presents	O
the	O
results	O
of	O
CPM	B-MethodName
-	I-MethodName
Bee	I-MethodName
in	O
different	O
settings	O
.	O
The	O
results	O
show	O
that	O
DecT	O
strongly	O
enhances	O
the	O
adaptation	O
of	O
large	O
PLM	O
on	O
downstream	O
tasks	O
.	O
Moreover	O
,	O
CPM	B-MethodName
-	I-MethodName
Bee	I-MethodName
achieves	O
great	O
performance	O
on	O
NLI	O
tasks	O
,	O
which	O
flags	O
that	O
DecT	O
could	O
deal	O
with	O
more	O
difficult	O
tasks	O
with	O
powerful	O
backbone	O
models	O
.	O

Our	O
second	O
limitation	O
relates	O
to	O
the	O
estimation	O
of	O
legislator	O
's	O
ideology	O
.	O
Ideology	O
is	O
a	O
latent	O
concept	O
.	O
This	O
means	O
that	O
it	O
can	O
not	O
be	O
directly	O
measured	O
and	O
no	O
ground	O
-	O
truth	O
data	O
exists	O
.	O
Therefore	O
,	O
to	O
validate	O
that	O
our	O
legislator	O
representations	O
encode	O
ideology	O
,	O
we	O
need	O
to	O
prove	O
their	O
performance	O
in	O
a	O
variety	O
of	O
tasks	O
in	O
which	O
the	O
political	O
science	O
literature	O
suggests	O
ideology	O
is	O
important	O
.	O
In	O
our	O
work	O
,	O
we	O
studied	O
three	O
tasks	O
:	O
(	O
i	O
)	O
active	O
/	O
passive	O
cosponsorship	O
prediction	O
,	O
(	O
ii	O
)	O
party	O
affiliation	O
recovery	O
,	O
and	O
(	O
iii	O
)	O
voting	O
prediction	O
.	O
We	O
argue	O
that	O
this	O
is	O
a	O
representative	O
set	O
of	O
tasks	O
.	O
However	O
,	O
legislators	O
are	O
involved	O
in	O
additional	O
ideology	O
-	O
driven	O
tasks	O
,	O
e.g.	O
,	O
the	O
release	O
of	O
public	O
statements	O
.	O
Showing	O
that	O
our	O
representations	O
are	O
also	O
predictive	O
of	O
these	O
additional	O
tasks	O
might	O
be	O
considered	O
an	O
even	O
more	O
robust	O
and	O
convincing	O
validation	O
of	O
our	O
results	O
.	O

Unlike	O
20Newsgroups	O
,	O
Amazon	O
Clothes	O
does	O
not	O
seem	O
to	O
have	O
obvious	O
artifacts	O
.	O
Still	O
,	O
the	O
re	O
-	O
sponses	O
from	O
crowd	O
workers	O
suggested	O
that	O
we	O
disable	O
6	O
features	O
.	O
The	O
disabled	O
features	O
were	O
correlated	O
to	O
,	O
but	O
not	O
the	O
reason	O
for	O
,	O
the	O
associated	O
class	O
.	O
For	O
instance	O
,	O
one	O
of	O
the	O
disabled	O
features	O
was	O
highly	O
activated	O
by	O
the	O
pattern	O
"	O
my	O
....	O
year	O
old	O
"	O
which	O
often	O
appeared	O
in	O
positive	O
reviews	O
such	O
as	O
"	O
my	O
3	O
year	O
old	O
son	O
loves	O
this	O
.	O
"	O
.	O
However	O
,	O
these	O
correlated	O
features	O
are	O
not	O
very	O
useful	O
for	O
the	O
three	O
outof	O
-	O
distribution	O
datasets	O
(	O
Music	O
,	O
Mixed	O
,	O
and	O
Yelp	O
)	O
.	O
Disabling	O
them	O
made	O
the	O
model	O
focus	O
more	O
on	O
the	O
right	O
evidence	O
and	O
increased	O
the	O
average	O
macro	O
F1	O
for	O
the	O
three	O
datasets	O
,	O
as	O
shown	O
in	O
Figure	O
8	O
(	O
right	O
)	O
.	O
Nonetheless	O
,	O
the	O
performance	O
improvement	O
here	O
was	O
not	O
as	O
apparent	O
as	O
in	O
the	O
previous	O
task	O
because	O
,	O
even	O
without	O
feature	O
disabling	O
,	O
the	O
majority	O
of	O
the	O
features	O
are	O
relevant	O
to	O
the	O
task	O
and	O
can	O
lead	O
the	O
model	O
to	O
the	O
correct	O
predictions	O
in	O
most	O
cases	O
.	O
6	O

iv	O
We	O
release	O
the	O
code	O
and	O
the	O
pre	O
-	O
trained	O
models	O
as	O
part	O
of	O
an	O
open	O
-	O
source	O
framework	O
1	O
.	O
(	O
Kepler	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
However	O
,	O
the	O
current	O
state	O
of	O
the	O
art	O
in	O
word	O
-	O
level	O
QE	I-MethodName
is	O
based	O
on	O
transformers	O
like	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
where	O
a	O
simple	O
linear	O
layer	O
is	O
added	O
on	O
top	O
of	O
the	O
transformer	O
model	O
to	O
obtain	O
the	O
predictions	O
(	O
Lee	O
,	O
2020	O
)	O
.	O
All	O
of	O
these	O
approaches	O
consider	O
quality	O
estimation	O
as	O
a	O
language	O
-	O
specific	O
task	O
and	O
build	O
a	O
different	O
model	O
for	O
each	O
language	O
pair	O
.	O
This	O
approach	O
has	O
many	O
drawbacks	O
in	O
real	O
-	O
world	O
applications	O
,	O
some	O
of	O
which	O
are	O
discussed	O
in	O
Section	O
1	O
.	O

As	O
discussed	O
in	O
Section	O
3.3	O
,	O
we	O
use	O
authorship	O
and	O
citation	O
prediction	O
as	O
two	O
additional	O
self	O
-	O
supervised	O
tasks	O
to	O
train	O
our	O
model	O
.	O
Here	O
we	O
discuss	O
some	O
of	O
the	O
details	O
about	O
the	O
implementation	O
of	O
these	O
two	O
tasks	O
.	O
In	O
particular	O
,	O
we	O
first	O
discuss	O
how	O
the	O
data	O
are	O
generated	O
and	O
two	O
how	O
the	O
model	O
performances	O
on	O
these	O
tasks	O
are	O
.	O

Discussion	O
As	O
shown	O
in	O
Table	O
2	O
(	O
right	O
)	O
,	O
crossplatform	O
importance	O
of	O
tokens	O
for	O
the	O
hateful	O
class	O
demotes	O
scores	O
(	O
and	O
thus	O
,	O
ranks	O
)	O
of	O
lexical	O
artifacts	O
which	O
are	O
likely	O
to	O
be	O
more	O
indicative	O
on	O
some	O
platforms	O
only	O
(	O
e.g.	O
,	O
"	O
RT	O
"	O
)	O
,	O
while	O
consolidating	O
the	O
informativeness	O
of	O
cross	O
-	O
platform	O
items	O
(	O
e.g.	O
,	O
"	O
jews	O
"	O
,	O
"	O
hate	O
"	O
,	O
"	O
#	O
#	O
s	O
"	O
,	O
"	O
#	O
#	O
es	O
"	O
,	O
7	O
"	O
people	O
"	O
)	O
.	O
This	O
confirms	O
our	O
hypothesis	O
that	O
encompassing	O
multiple	O
platforms	O
is	O
beneficial	O
for	O
capturing	O
lexical	O
items	O
that	O
are	O
likely	O
to	O
be	O
predictive	O
across	O
distributions	O
.	O

The	O
average	O
validation	O
performances	O
of	O
the	O
8	O
classification	O
tasks	O
when	O
performing	O
GAP	O
on	O
the	O
OPT	O
LMs	O
are	O
shown	O
in	O
Figure	O
2	O
.	O
While	O
GAP	B-MethodName
fails	O
to	O
provide	O
consistent	O
improvements	O
for	O
350	O
M	O
LMs	O
and	O
2.7B	O
LMs	O
,	O
mostly	O
resulting	O
in	O
a	O
degradation	O
of	O
performance	O
as	O
shown	O
by	O
the	O
median	O
performance	O
underperforming	O
the	O
baselines	O
,	O
the	O
LMs	O
show	O
considerable	O
performance	O
gains	O
in	O
some	O
cases	O
for	O
the	O
larger	O
LMs	O
.	O
This	O
result	O
suggests	O
that	O
although	O
GAP	O
does	O
not	O
show	O
steady	O
improvement	O
of	O
generalization	O
for	O
the	O
classification	O
tasks	O
unlike	O
the	O
dialogue	O
5	O
Further	O
study	O
details	O
are	O
in	O
Appendix	O
F	O
.	O

In	O
this	O
paper	O
,	O
we	O
presented	O
a	O
novel	O
cross	O
-	O
lingual	O
position	O
encoding	O
to	O
augment	O
SANs	O
by	O
considering	O
cross	O
-	O
lingual	O
information	O
(	O
i.e.	O
,	O
reordering	O
indices	O
)	O
for	O
the	O
input	O
sentence	O
.	O
We	O
designed	O
two	O
strategies	O
to	O
integrate	O
it	O
into	O
SANs	O
.	O
Experiments	O
indicated	O
that	O
the	O
proposed	O
strategies	O
consistently	O
improve	O
the	O
translation	O
performance	O
.	O
In	O
the	O
future	O
,	O
we	O
plan	O
to	O
extend	O
the	O
cross	O
-	O
lingual	O
position	O
encoding	O
to	O
non	O
-	O
autoregressive	O
MT	O
(	O
Gu	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
unsupervised	O
NMT	B-MethodName
(	O
Lample	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

We	O
propose	O
a	O
novel	O
noisy	O
training	O
method	O
called	O
PATS	B-MethodName
to	O
optimize	O
fine	O
-	O
tuning	O
of	O
PLMs	O
.	O
Since	O
aggressive	O
fine	O
-	O
tuning	O
PLMs	O
will	O
leave	O
a	O
large	O
number	O
of	O
insensitive	O
parameters	O
which	O
contribute	O
little	O
to	O
the	O
overall	O
model	O
,	O
PATS	B-MethodName
activates	O
them	O
and	O
balance	O
the	O
contributions	O
of	O
all	O
parameters	O
in	O
downstream	O
tasks	O
by	O
adding	O
noise	O
to	O
each	O
parameter	O
according	O
to	O
its	O
sensitivity	O
in	O
the	O
process	O
of	O
training	O
.	O
PATS	O
is	O
a	O
simple	O
mechanism	O
without	O
much	O
computational	O
and	O
memory	O
overhead	O
compared	O
to	O
adversarial	O
training	O
which	O
requires	O
additional	O
backwards	O
passes	O
.	O
Extensive	O
experiments	O
on	O
eight	O
tasks	O
of	O
the	O
GLUE	O
benchmark	O
show	O
that	O
PATS	O
can	O
consistently	O
improve	O
the	O
performance	O
of	O
PLMs	O
on	O
downstream	O
tasks	O
with	O
the	O
sensitivity	O
of	O
the	O
pa	O
-	O
rameters	I-MethodName
more	O
concentrated	O
,	O
which	O
is	O
especially	O
pronounced	O
on	O
small	O
datasets	O
.	O

(	O
1	O
)	O
on	O
XNLI	O
,	O
we	O
concatenate	O
the	O
premise	O
with	O
the	O
hypothesis	O
,	O
and	O
add	O
a	O
[	O
SEP	O
]	O
token	O
in	O
between	O
.	O

We	O
present	O
the	O
statistical	O
analysis	O
of	O
all	O
sign	O
language	O
corpora	O
in	O
Table	O
5	O
and	O
Table	O
6	O
.	O
Out	O
-	O
of	O
-	O
Vocabulary	O
(	O
OOV	O
)	O
are	O
the	O
words	O
that	O
only	O
appear	O
in	O
development	O
or	O
test	O
set	O
and	O
singletons	O
are	O
the	O
least	O
frequent	O
words	O
appearing	O
only	O
once	O
.	O

MolXPT	O
80.0	O
±	O
0.5	O
77.1	O
±	O
0.2	O
95.3	O
±	O
0.2	O
78.1	O
±	O
0.4	O
88.4	O
±	O
1.0	O
71.7	O
±	O
0.2	O
81.9	O
Prompt	O
-	O
based	O
finetuning	O
:	O
MolXPT	B-MethodName
can	O
be	O
finetuned	O
for	O
downstream	O
tasks	O
about	O
molecules	O
and	O
text	O
.	O
Adding	O
classification	O
or	O
regression	O
heads	O
to	O
pre	O
-	O
trained	O
backbone	O
models	O
introduces	O
the	O
gap	O
between	O
pre	O
-	O
training	O
and	O
finetuning	O
(	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
;	O
Gu	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
Therefore	O
,	O
we	O
adopt	O
prompt	O
-	O
based	O
finetuning	O
(	O
Gao	O
et	O
al	O
.	O
,	O
2021	O
)	O
to	O
unify	O
different	O
tasks	O
into	O
a	O
sequence	O
generation	O
task	O
,	O
which	O
is	O
consistent	O
with	O
the	O
pre	O
-	O
training	O
objective	O
.	O
Briefly	O
,	O
given	O
a	O
task	O
,	O
we	O
convert	O
the	O
input	O
and	O
output	O
into	O
text	O
and	O
/	O
or	O
SMILES	O
sequences	O
,	O
equip	O
the	O
sequences	O
with	O
task	O
-	O
specific	O
prompts	O
and	O
finetune	O
using	O
language	O
modeling	O
loss	O
.	O

-DOCSTART-	O
Global	O
Entity	O
Disambiguation	O
with	O
BERT	B-MethodName

•	O
the	O
novel	O
method	O
used	O
for	O
developing	O
Wino	O
-	I-MethodName
Queer	I-MethodName
from	O
a	O
community	O
survey	O
,	O
which	O
can	O
be	O
extended	O
to	O
develop	O
bias	O
benchmarks	O
for	O
other	O
marginalized	O
communities	O
.	O

Entity	O
linking	O
consists	O
of	O
linking	O
mentions	O
of	O
entities	O
found	O
in	O
text	O
against	O
canonical	O
entities	O
found	O
in	O
a	O
target	O
knowledge	O
base	O
(	O
KB	O
)	O
.	O
Early	O
work	O
in	O
this	O
area	O
was	O
motivated	O
by	O
the	O
availability	O
of	O
large	O
KBs	O
with	O
millions	O
of	O
entities	O
(	O
Bunescu	O
and	O
Paşca	O
,	O
2006	O
)	O
.	O
Most	O
subsequent	O
work	O
has	O
followed	O
this	O
tradition	O
of	O
linking	O
to	O
a	O
handful	O
of	O
large	O
,	O
publicly	O
available	O
KBs	O
such	O
as	O
Wikipedia	O
,	O
DBPedia	O
(	O
Auer	O
et	O
al	O
.	O
,	O
2007	O
)	O
or	O
the	O
KBs	O
used	O
in	O
the	O
now	O
decade	O
-	O
old	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
challenges	O
(	O
McNamee	O
and	O
Dang	O
,	O
2009;Ji	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
As	O
a	O
result	O
,	O
previous	O
work	O
always	O
assumes	O
complete	O
knowledge	O
of	O
the	O
schema	O
of	O
the	O
target	O
KB	O
that	O
entity	O
linking	O
models	O
are	O
trained	O
for	O
,	O
i.e.	O
how	O
many	O
and	O
which	O
attributes	O
are	O
used	O
to	O
represent	O
entities	O
in	O
the	O
KB	O
.	O
This	O
allows	O
training	O
supervised	O
machine	O
learning	O
models	O
that	O
exploit	O
the	O
schema	O
along	O
with	O
labeled	O
data	O
that	O
link	O
mentions	O
to	O
this	O
a	O
priori	O
known	O
KB	O
.	O
However	O
,	O
this	O
strong	O
assumption	O
breaks	O
down	O
in	O
scenarios	O
which	O
require	O
linking	O
to	O
KBs	O
that	O
are	O
not	O
known	O
at	O
training	O
time	O
.	O
For	O
example	O
,	O
a	O
company	O
might	O
want	O
to	O
automatically	O
link	O
mentions	O
of	O
its	O
products	O
to	O
an	O
internal	O
KB	O
of	O
products	O
that	O
has	O
a	O
rich	O
schema	O
with	O
several	O
attributes	O
such	O
as	O
product	O
category	O
,	O
description	O
,	O
dimensions	O
,	O
etc	O
.	O
It	O
is	O
very	O
unlikely	O
that	O
the	O
company	O
will	O
have	O
training	O
data	O
of	O
this	O
nature	O
,	O
i.e.	O
mentions	O
of	O
products	O
linked	O
to	O
its	O
database	O
.	O

Data	O
Filter	O
.	O
All	O
these	O
raw	O
posts	O
are	O
then	O
preprocessed	O
by	O
employing	O
the	O
data	O
filtering	O
rule	O
.	O
For	O
text	O
data	O
,	O
we	O
remove	O
text	O
with	O
fewer	O
than	O
3	O
words	O
,	O
correct	O
the	O
spelling	O
mistakes	O
,	O
and	O
check	O
if	O
each	O
text	O
is	O
composed	O
of	O
illegible	O
characters	O
via	O
the	O
NLTK	O
package	O
(	O
Bird	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
For	O
their	O
visual	O
counterparts	O
,	O
we	O
remove	O
the	O
images	O
with	O
low	O
resolution	O
and	O
resize	O
all	O
images	O
to	O
the	O
same	O
size	O
.	O

The	O
results	O
of	O
this	O
experiment	O
are	O
displayed	O
in	O
Figure	O
7	O
.	O
For	O
Biosbias	O
,	O
on	O
average	O
,	O
the	O
participants	O
'	O
responses	O
suggested	O
us	O
to	O
disable	O
11.33	O
out	O
of	O
30	O
CNN	O
features	O
.	O
By	O
doing	O
so	O
,	O
the	O
FPED	O
of	O
the	O
models	O
decreased	O
from	O
0.250	O
to	O
0.163	O
,	O
and	O
the	O
FNED	O
decreased	O
from	O
0.338	O
to	O
0.149	O
.	O
After	O
investigating	O
the	O
word	O
clouds	O
of	O
the	O
CNN	O
features	O
,	O
we	O
found	O
that	O
some	O
of	O
them	O
detected	O
patterns	O
containing	O
both	O
gender	O
-	O
related	O
terms	O
and	O
occupation	O
-	O
related	O
terms	O
such	O
as	O
"	O
his	O
surgical	O
expertise	O
"	O
and	O
"	O
she	O
supervises	O
nursing	O
students	O
"	O
.	O
Most	O
of	O
the	O
MTurk	B-MethodName
participants	O
answered	O
that	O
these	O
word	O
clouds	O
were	O
relevant	O
to	O
the	O
occupations	O
,	O
and	O
thus	O
the	O
corresponding	O
features	O
were	O
not	O
disabled	O
.	O
However	O
,	O
we	O
believe	O
that	O
these	O
features	O
might	O
contain	O
gender	O
biases	O
.	O
So	O
,	O
we	O
asked	O
one	O
annotator	O
to	O
consider	O
all	O
the	O
word	O
clouds	O
again	O
and	O
disable	O
every	O
feature	O
for	O
which	O
the	O
prominent	O
n	O
-	O
gram	O
patterns	O
contained	O
any	O
genderrelated	O
terms	O
,	O
no	O
matter	O
whether	O
the	O
patterns	O
detect	O
occupation	O
-	O
related	O
terms	O
.	O
With	O
this	O
new	O
disabling	O
policy	O
,	O
12	O
out	O
of	O
30	O
features	O
were	O
disabled	O
on	O
average	O
,	O
and	O
the	O
model	O
biases	O
further	O
decreased	O
,	O
as	O
shown	O
in	O
Figure	O
7	O
(	O
Debugged	O
(	O
One	O
)	O
)	O
.	O
The	O
sideeffect	O
of	O
disabling	O
33	O
%	O
of	O
all	O
the	O
features	O
here	O
was	O
only	O
a	O
slight	O
drop	O
in	O
the	O
macro	O
F1	O
from	O
0.950	O
to	O
0.933	O
.	O
Hence	O
,	O
our	O
framework	O
was	O
successful	O
in	O
reducing	O
gender	O
biases	O
without	O
severe	O
negative	O
effects	O
in	O
classification	O
performance	O
.	O

Schema	O
translation	O
is	O
the	O
task	O
of	O
automatically	O
translating	O
headers	O
of	O
tabular	O
data	O
from	O
one	O
language	O
to	O
another	O
.	O
High	O
-	O
quality	O
schema	O
translation	O
plays	O
an	O
important	O
role	O
in	O
crosslingual	O
table	O
searching	O
,	O
understanding	O
and	O
analysis	O
.	O
Despite	O
its	O
importance	O
,	O
schema	O
translation	O
is	O
not	O
well	O
studied	O
in	O
the	O
community	O
,	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
can	O
not	O
work	O
well	O
on	O
this	O
task	O
because	O
of	O
two	O
intrinsic	O
differences	O
between	O
plain	O
text	O
and	O
tabular	O
data	O
:	O
morphological	O
difference	O
and	O
context	O
difference	O
.	O
To	O
facilitate	O
the	O
research	O
study	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
dataset	O
for	O
schema	O
translation	O
,	O
which	O
consists	O
of	O
3,158	O
tables	O
with	O
11,979	O
headers	O
written	O
in	O
6	O
different	O
languages	O
,	O
including	O
English	O
,	O
Chinese	O
,	O
French	O
,	O
German	O
,	O
Spanish	O
,	O
and	O
Japanese	O
.	O
Also	O
,	O
we	O
propose	O
the	O
first	O
schema	O
translation	O
model	O
called	O
CAST	B-MethodName
,	O
which	O
is	O
a	O
header	O
-	O
to	O
-	O
header	O
neural	O
machine	O
translation	O
model	O
augmented	O
with	O
schema	O
context	O
.	O
Specifically	O
,	O
we	O
model	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
to	O
represent	O
their	O
entity	O
types	O
and	O
relations	O
.	O
Then	O
CAST	B-MethodName
encodes	O
the	O
graph	O
with	O
a	O
relational	O
-	O
aware	O
transformer	O
and	O
uses	O
another	O
transformer	O
to	O
decode	O
the	O
header	O
in	O
the	O
target	O
language	O
.	O
Experiments	O
on	O
our	O
dataset	O
demonstrate	O
that	O
CAST	B-MethodName
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
.	O
Our	O
dataset	O
will	O
be	O
released	O
at	O
https://github.com/microsoft/ContextualSP	O
.	O

assuming	O
that	O
the	O
bias	O
term	O
b	O
k	O
is	O
distributed	O
equally	O
to	O
the	O
n	O
neurons	O
.	O
LRP	B-MethodName
works	O
by	O
propagating	O
the	O
activation	O
of	O
a	O
neuron	O
of	O
interest	O
back	O
through	O
the	O
previous	O
layers	O
in	O
the	O
network	O
proportionally	O
.	O
We	O
call	O
the	O
value	O
each	O
neuron	O
receives	O
a	O
relevance	O
score	O
(	O
R	O
)	O
of	O
the	O
neuron	O
.	O
To	O
back	O
propagate	O
,	O
if	O
the	O
relevance	O
score	O
of	O
the	O
neuron	O
k	O
is	O
R	O
k	O
,	O
the	O
relevance	O
score	O
that	O
the	O
neuron	O
j	O
receives	O
from	O
the	O
neuron	O

All	O
arguments	O
of	O
the	O
training	O
documents	O
are	O
tokenized	O
with	O
a	O
BPE	B-MethodName
model	O
(	O
Sennrich	O
et	O
al	O
.	O
,	O
2016	O
)	O
trained	O
by	O
the	O
authors	O
of	O
the	O
CTRL	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Both	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
CC	I-MethodName
and	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
REDDIT	I-MethodName
are	O
fine	O
-	O
tuned	O
on	O
a	O
Tesla	O
V100	O
with	O
32	O
GB	O
of	O
Memory	O
.	O
We	O
mainly	O
keep	O
the	O
default	O
hyperparameters	O
but	O
reduce	O
the	O
batch	O
size	O
to	O
4	O
and	O
train	O
both	O
models	O
for	O
1	O
epoch	O
.	O
Each	O
model	O
takes	O
around	O
five	O
days	O
to	O
train	O
on	O
the	O
1.6	O
M	O
training	O
sentences	O
.	O

Evaluation	O
Metrics	O
.	O
We	O
evaluate	O
the	O
performances	O
of	O
different	O
models	O
with	O
the	O
4	O
-	O
gram	O
BLEU	B-MethodName
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
score	O
of	O
the	O
translations	O
.	O
Following	O
the	O
evaluation	O
step	O
in	O
M2M-100	O
,	O
before	O
computing	O
BLEU	B-MethodName
,	O
we	O
de	O
-	O
tokenize	O
the	O
data	O
and	O
apply	O
standard	O
tokenizers	O
for	O
each	O
language	O
.	O
We	O
use	O
SacreBLEU	B-MethodName
tokenizer	O
for	O
Chinese	O
,	O
Kytea	O
4	O
for	O
Japanese	O
,	O
and	O
Moses	O
tokenizer	O
5	O
for	O
the	O
rest	O
of	O
the	O
languages	O
.	O
Besides	O
BLEU	B-MethodName
,	O
we	O
also	O
conduct	O
a	O
human	O
evaluation	O
for	O
a	O
more	O
precise	O
analysis	O
.	O

-DOCSTART-	O
Translating	O
Headers	O
of	O
Tabular	O
Data	O
:	O
A	O
Pilot	O
Study	O
of	O
Schema	O
Translation	O

This	O
section	O
includes	O
additional	O
results	O
from	O
our	O
analysis	O
of	O
knowledge	O
acquisition	O
during	O
multilingual	O
pretraining	O
:	O

We	O
demonstrate	O
that	O
our	O
measures	O
can	O
uncover	O
differences	O
in	O
imagined	O
and	O
recalled	O
stories	O
in	O
HIPPOCORPUS	O
.	O
Imagined	O
stories	O
contain	O
more	O
commonsense	O
events	O
and	O
elaborations	O
,	O
whereas	O
recalled	O
stories	O
are	O
more	O
dense	O
in	O
concrete	O
events	O
.	O
Additionally	O
,	O
imagined	O
stories	O
flow	O
substantially	O
more	O
linearly	O
than	O
recalled	O
stories	O
.	O
Our	O
findings	O
provide	O
evidence	O
that	O
surface	O
language	O
reflects	O
the	O
differences	O
in	O
cognitive	O
processes	O
used	O
in	O
imagining	O
and	O
remembering	O
.	O

We	O
pretrain	O
LMRec	B-MethodName
TL	I-MethodName
+	O
agnostic	O
with	O
OBS	B-MethodName
,	O
OTA	B-MethodName
,	O
and	O
ECOMM	B-MethodName
and	O
then	O
transfer	O
to	O
the	O
product	O
collection	O
recommendation	O
(	O
target	O
task	O
)	O
.	O
The	O
mean	O
pooled	O
task	O
-	O
specific	O
and	O
task	O
-	O
agnostic	O
user	O
features	O
are	O
used	O
as	O
the	O
final	O
user	O
features	O
.	O
During	O
the	O
14	O
days	O
of	O
online	O
experimentation	O
,	O
we	O
measured	O
two	O
important	O
metrics	O
for	O
the	O
online	O
recommender	O
system	O
,	O
CTR	O
and	O
GMV	O
,	O
to	O
track	O
user	O
satisfaction	O
with	O
the	O
platform	O
.	O
CTR	O
represents	O
the	O
click	O
/	O
view	O
rate	O
of	O
recommendation	O
,	O
and	O
GMV	O
is	O
the	O
total	O
value	O
of	O
sold	O
products	O
through	O
recommendation	O
.	O
All	O
models	O
take	O
the	O
same	O
amount	O
of	O
user	O
traffic	O
.	O
Section	O
3	O
descrbies	O
it	O
.	O
We	O
used	O
Amazon	O
review	O
dataset	O
proposed	O
in	O
https://nijianmo.github.io/amazon/.	O

As	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
we	O
propose	O
two	O
strategies	O
to	O
integrate	O
the	O
cross	O
-	O
lingual	O
position	O
encoding	O
(	O
XL	O
PE	O
)	O
into	O
SANs	O
:	O
inputting	O
-	O
level	O
XL	O
(	O
InXL	O
)	O
SANs	O
and	O
head	O
-	O
level	O
(	O
HeadXL	O
)	O
SANs	O
.	O

where	O
B	O
*	O
∈	O
R	O
K×H	O
and	O
b	O
*	O
o	O
∈	O
R	O
K	O
consist	O
of	O
the	O
entity	O
token	O
embeddings	O
and	O
the	O
bias	O
corresponding	O
to	O
the	O
entity	O
candidates	O
,	O
respectively	O
.	O
Note	O
that	O
B	O
*	O
and	O
b	O
*	O
o	O
are	O
the	O
subsets	O
of	O
B	O
and	O
b	O
o	O
,	O
respectively	O
.	O
Global	O
ED	O
Model	O
.	O
Our	O
global	O
ED	O
model	O
resolves	O
mentions	O
sequentially	O
for	O
N	O
steps	O
(	O
see	O
Algorithm	O
1	O
)	O
.	O
First	O
,	O
the	O
model	O
initializes	O
the	O
entity	O
of	O
each	O
mention	O
using	O
the	O
[	O
MASK	O
]	O
token	O
.	O
Then	O
,	O
for	O
each	O
step	O
,	O
it	O
predicts	O
an	O
entity	O
for	O
each	O
[	O
MASK	O
]	O
token	O
,	O
selects	O
the	O
prediction	O
with	O
the	O
highest	O
probability	O
produced	O
by	O
the	O
softmax	O
function	O
in	O
Eq.(3	O
)	O
,	O
and	O
resolves	O
the	O
corresponding	O
mention	O
by	O
assigning	O
the	O
predicted	O
entity	O
to	O
it	O
.	O
This	O
model	O
is	O
denoted	O
as	O
confidence	O
-	O
order	O
.	O
We	O
also	O
test	O
a	O
model	O
that	O
selects	O
mentions	O
according	O
to	O
their	O
order	O
of	O
appearance	O
in	O
the	O
document	O
and	O
denote	O
it	O
by	O
natural	O
-	O
order	O
.	O

Besides	O
,	O
previous	O
studies	O
have	O
probed	O
the	O
influence	O
of	O
word	O
order	O
perturbation	O
on	O
natural	O
lan	O
-	O
guage	O
understanding	O
(	O
NLU	O
)	O
tasks	O
(	O
Abdou	O
et	O
al	O
.	O
,	O
2022	O
;	O
Pham	O
et	O
al	O
.	O
,	O
2021	O
;	O
Clouâtre	O
et	O
al	O
.	O
,	O
2021	O
)	O
to	O
determine	O
whether	O
these	O
tasks	O
are	O
sensitive	O
to	O
word	O
order	O
.	O
The	O
findings	O
indicate	O
that	O
some	O
NLU	O
tasks	O
do	O
require	O
word	O
order	O
information	O
although	O
others	O
do	O
not	O
.	O
It	O
should	O
also	O
be	O
noted	O
that	O
word	O
order	O
is	O
particularly	O
important	O
for	O
natural	O
language	O
generating	O
(	O
NLG	O
)	O
tasks	O
,	O
such	O
as	O
machine	O
translation	O
.	O
This	O
is	O
because	O
metrics	O
used	O
to	O
evaluate	O
generated	O
results	O
,	O
such	O
as	O
BLEU	B-MethodName
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
,	O
are	O
sensitive	O
to	O
word	O
order	O
.	O
Therefore	O
,	O
word	O
order	O
is	O
a	O
critical	O
aspect	O
of	O
natural	O
language	O
processing	O
.	O

Previous	O
approaches	O
involving	O
actions	O
in	O
NLP	O
are	O
more	O
application	O
-	O
centric	O
and	O
usually	O
contain	O
specific	O
tasks	O
(	O
e.g.	O
instruction	O
following	O
,	O
prediction	O
)	O
(	O
Li	O
et	O
al	O
.	O
,	O
2021	O
;	O
Zellers	O
et	O
al	O
.	O
,	O
2021	O
)	O
without	O
considering	O
both	O
preconditions	O
and	O
effects	O
.	O
In	O
general	O
these	O
tasks	O
are	O
not	O
verified	O
logically	O
.	O
On	O
the	O
other	O
hand	O
,	O
there	O
exist	O
some	O
template	O
-	O
based	O
datasets	O
,	O
such	O
as	O
the	O
one	O
in	O
(	O
Clark	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
which	O
are	O
logically	O
sound	O
and	O
generated	O
from	O
several	O
simple	O
rules	O
.	O
Unfortunately	O
,	O
they	O
pay	O
more	O
attention	O
to	O
general	O
deduction	O
in	O
a	O
static	O
perspective	O
,	O
while	O
RAC	B-MethodName
problems	O
require	O
repeated	O
changes	O
.	O

Twitter	O
We	O
additionally	O
collect	O
a	O
dataset	O
of	O
2.1	O
M	O
political	O
tweets	O
from	O
Twitter	O
from	O
the	O
past	O
10	O
years	O
using	O
the	O
Twitter	O
Decahose	O
stream	O
,	O
selecting	O
tweets	O
by	O
political	O
figures	O
included	O
in	O
a	O
list	O
of	O
9,981	O
US	O
politicians	O
and	O
their	O
Twitter	O
handles	O
(	O
Panda	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
In	O
contrast	O
to	O
AllSides	O
,	O
Twitter	O
does	O
not	O
explicitly	O
annotate	O
discrete	O
ideologies	O
.	O
Thus	O
,	O
we	O
label	O
tweets	O
with	O
their	O
author	O
's	O
ideology	O
,	O
identified	O
based	O
on	O
their	O
DW	O
-	O
NOMINATE	O
9	O
dimension	O
(	O
Boche	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
a	O
measure	O
of	O
a	O
politician	O
's	O
voting	O
history	O
:	O
a	O
positive	O
number	O
indicates	O
conservative	O
leaning	O
(	O
e.g.	O
Donald	O
Trump	O
,	O
0.403	O
)	O
,	O
while	O
a	O
negative	O
number	O
indicates	O
liberal	O
leaning	O
(	O
e.g.	O
Barack	O
Obama	O
,	O
-0.343	O
)	O
.	O

The	O
forgetting	O
of	O
the	O
model	O
in	O
downstream	O
finetuning	O
is	O
caused	O
by	O
the	O
difference	O
between	O
the	O
direction	O
of	O
parameter	O
update	O
and	O
the	O
direction	O
of	O
historical	O
training	O
(	O
Lopez	O
-	O
Paz	O
and	O
Ranzato	O
,	O
2017	O
)	O
.	O
Inspired	O
by	O
Kurita	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
which	O
encourages	O
gradient	O
directions	O
to	O
be	O
close	O
to	O
each	O
other	O
through	O
regularization	O
,	O
we	O
further	O
take	O
a	O
better	O
look	O
at	O
backdoor	O
injection	O
process	O
from	O
a	O
multi	O
-	O
task	O
learning	O
perspective	O
and	O
project	O
the	O
gradient	O
direction	O
of	O
tasks	O
for	O
fewer	O
parameters	O
with	O
lower	O
learning	O
capabilities	O
,	O
instead	O
of	O
encouraging	O
.	O
We	O
propose	O
Intra	O
-	O
Layer	O
gradient	O
direction	O
Projection	O
(	O
ILProj	O
)	O
as	O
shown	O
in	O
Figure	O
6	O
.	O

We	O
generate	O
unnatural	O
paraphrase	O
x	O
′	O
i+1	O
by	O
replacing	O
randomly	O
sampled	O
non	O
-	O
stop	O
English	O
words	O
from	O
x	O
i+1	O
with	O
their	O
synonyms	O
from	O
Wordnet	O
.	O
For	O
synonym	O
sampling	O
,	O
we	O
rank	O
the	O
Wordnet	O
synonyms	O
according	O
to	O
word2vec	O
embedding	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
similarity	O
and	O
sample	O
from	O
the	O
top	O
k	O
synonyms	O
.	O
To	O
make	O
paraphrasing	O
unnatural	O
,	O
1	O
/	O
4	O
th	O
of	O
words	O
are	O
replaced	O
with	O
synonyms	O
which	O
are	O
least	O
likely	O
to	O
be	O
used	O
by	O
humans	O
while	O
keeping	O
it	O
grammatically	O
correct	O
.	O
(	O
See	O
the	O
table	O
2	O
for	O
example	O
.	O
)	O

For	O
evaluation	O
,	O
we	O
used	O
the	O
approach	O
proposed	O
in	O
the	O
WMT	B-MethodName
shared	O
tasks	O
in	O
which	O
the	O
classification	O
performance	O
is	O
calculated	O
using	O
the	O
multiplication	O
of	O
F1	O
-	O
scores	O
for	O
the	O
'	O
OK	O
'	O
and	O
'	O
BAD	O
'	O
classes	O
against	O
the	O
true	O
labels	O
independently	O
:	O
words	O
in	O
the	O
target	O
(	O
'	O
OK	O
'	O
for	O
correct	O
words	O
,	O
'	O
BAD	O
'	O
for	O
incorrect	O
words	O
)	O
,	O
gaps	O
in	O
the	O
target	O
(	O
'	O
OK	O
'	O
for	O
genuine	O
gaps	O
,	O
'	O
BAD	O
'	O
for	O
gaps	O
indicating	O
missing	O
words	O
)	O
and	O
source	O
words	O
(	O
'	O
BAD	O
'	O
for	O
words	O
that	O
lead	O
to	O
errors	O
in	O
the	O
target	O
,	O
'	O
OK	O
'	O
for	O
other	O
words	O
)	O
.	O
In	O
recent	O
WMT	O
shared	O
tasks	O
,	O
the	O
most	O
popular	O
category	O
was	O
predicting	O
quality	O
for	O
words	O
in	O
the	O
target	O
.	O
Therefore	O
,	O
in	O
Section	O
5	O
we	O
only	O
report	O
the	O
F1	O
-	O
score	O
for	O
words	O
in	O
the	O
target	O
.	O
Other	O
results	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O
Prior	O
to	O
WMT	O
2019	O
,	O
organisers	O
provided	O
separate	O
scores	O
for	O
gaps	O
and	O
words	O
in	O
the	O
target	O
,	O
while	O
after	O
WMT	O
2019	O
they	O
produce	O
a	O
single	O
result	O
for	O
target	O
gaps	O
and	O
words	O
.	O
We	O
follow	O
this	O
latter	O
approach	O
.	O

First	O
,	O
we	O
built	O
a	O
BTG	O
-	O
based	O
reordering	O
model	O
(	O
Neubig	O
et	O
al	O
.	O
,	O
2012	O
)	O
to	O
generate	O
a	O
reordered	O
source	O
sentence	O
according	O
to	O
the	O
word	O
order	O
of	O
its	O
corresponding	O
target	O
sentence	O
.	O
Second	O
,	O
we	O
obtained	O
the	O
reordered	O
word	O
indices	O
pos	O
XL	O
that	O
correspond	O
with	O
the	O
input	O
sentence	O
X.	O
To	O
output	O
the	O
cross	O
-	O
lingual	O
position	O
matrix	O
PE	O
XL	O
,	O
we	O
inherit	O
the	O
sinusoidal	O
function	O
in	O
Eq	O
.	O
(	O
1	O
)	O
.	O
Formally	O
,	O
the	O
process	O
is	O
:	O

For	O
the	O
final	O
answer	O
,	O
we	O
use	O
the	O
solve	O
rate	O
metric	O
to	O
evaluate	O
whether	O
the	O
model	O
generates	O
the	O
final	O
correct	O
answer	O
to	O
each	O
MWP	O
.	O
Since	O
generating	O
meaningful	O
steps	O
is	O
also	O
key	O
,	O
we	O
use	O
the	O
BLEU	B-MethodName
metric	O
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
to	O
evaluate	O
language	O
generation	O
quality	O
.	O
For	O
intermediate	O
steps	O
,	O
we	O
use	O
the	O
equation	O
match	O
accuracy	O
(	O
ACC	O
-	O
eq	O
)	O
metric	O
to	O
evaluate	O
whether	O
a	O
generated	O
step	O
contains	O
a	O
math	O
expression	O
(	O
including	O
numbers	O
)	O
that	O
matches	O
the	O
ground	O
truth	O
.	O
Since	O
LMs	O
generate	O
math	O
equations	O
as	O
strings	O
,	O
we	O
decompose	O
the	O
equation	O
string	O
into	O
tokens	O
and	O
calculate	O
the	O
token	O
level	O
match	O
rate	O
instead	O
of	O
the	O
overall	O
string	O
match	O
.	O
We	O
also	O
use	O
the	O
operation	O
match	O
accuracy	O
(	O
ACC	O
-	O
op	O
)	O
metric	O
to	O
evaluate	O
whether	O
a	O
generated	O
step	O
's	O
operation	O
label	O
matches	O
the	O
ground	O
truth	O
.	O

while	O
uniformity	O
measures	O
how	O
well	O
the	O
embeddings	O
are	O
uniformly	O
distributed	O
in	O
the	O
representation	O
space	O
:	O

As	O
computing	O
the	O
exact	O
likelihood	O
is	O
intractable	O
,	O
training	O
energy	O
-	O
based	O
models	O
such	O
as	O
Electric	O
with	O
standard	O
maximum	O
-	O
likelihood	O
estimation	O
is	O
not	O
possible	O
.	O
Instead	O
,	O
we	O
use	O
(	O
conditional	O
)	O
Noise	O
-	O
Contrastive	O
Estimation	O
(	O
NCE	O
)	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010;Ma	O
and	O
Collins	O
,	O
2018	O
)	O
,	O
which	O
provides	O
a	O
way	O
of	O
efficiently	O
training	O
an	O
unnormalized	O
model	O
that	O
does	O
not	O
compute	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
.	O
NCE	O
learns	O
the	O
parameters	O
of	O
a	O
model	O
by	O
defining	O
a	O
binary	O
classification	O
task	O
where	O
samples	O
from	O
the	O
data	O
distribution	O
have	O
to	O
be	O
distinguished	O
from	O
samples	O
generated	O
by	O
a	O
noise	O
distribution	O
q(x	O
t	O
|x	O
\t	O
)	O
.	O
First	O
,	O
we	O
define	O
the	O
un	O
-	O
normalized	O
output	O
p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
=	O
exp	O
(	O
−E(x	O
)	O
t	O
)	O

There	O
are	O
two	O
common	O
sampling	O
algorithms	O
for	O
contrastive	O
learning	O
:	O

Hello	O
everyone	O
,	O
thank	O
you	O
for	O
your	O
patience	O
as	O
we	O
waited	O
for	O
everyone	O
to	O
arrive	O
.	O
I	O
am	O
the	O
study	O
leader	O
.	O
You	O
are	O
about	O
to	O
participate	O
in	O
a	O
study	O
on	O
negotiation	O
,	O
and	O
you	O
will	O
be	O
paid	O
for	O
your	O
participation	O
via	O
an	O
Amazon	O
eGiftcard	O
,	O
privately	O
emailed	O
to	O
you	O
by	O
the	O
Yale	O
SOM	O
Behavioral	O
Lab	O
within	O
two	O
business	O
days	O
after	O
the	O
conclusion	O
of	O
the	O
study	O
.	O

Language	O
models	O
(	O
Bengio	O
et	O
al	O
.	O
,	O
2003	O
)	O
allow	O
to	O
generate	O
text	O
through	O
learned	O
distributions	O
of	O
a	O
language	O
and	O
have	O
been	O
applied	O
to	O
a	O
variety	O
of	O
areas	O
like	O
machine	O
translation	O
(	O
Bahdanau	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
summarization	O
(	O
Paulus	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
or	O
dialogue	O
systems	O
(	O
Wen	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
A	O
rather	O
new	O
field	O
for	O
these	O
models	O
is	O
the	O
task	O
of	O
producing	O
text	O
with	O
argumentative	O
content	O
(	O
Wang	O
and	O
Ling	O
,	O
2016	O
)	O
.	O
We	O
believe	O
this	O
technology	O
can	O
support	O
humans	O
in	O
the	O
challenging	O
task	O
of	O
finding	O
and	O
formulating	O
arguments	O
.	O
A	O
politician	O
might	O
use	O
this	O
to	O
prepare	O
for	O
a	O
debate	O
with	O
a	O
political	O
opponent	O
or	O
for	O
a	O
press	O
conference	O
.	O
It	O
may	O
be	O
used	O
to	O
support	O
students	O
in	O
writing	O
argumentative	O
essays	O
or	O
to	O
enrich	O
one	O
-	O
sided	O
discussions	O
with	O
counter	O
-	O
arguments	O
.	O
In	O
contrast	O
to	O
retrieval	O
methods	O
,	O
generation	O
allows	O
to	O
combine	O
and	O
stylistically	O
adapt	O
text	O
(	O
e.g.	O
arguments	O
)	O
based	O
on	O
a	O
given	O
input	O
(	O
usually	O
the	O
beginning	O
of	O
a	O
sentence	O
)	O
.	O
Current	O
argument	O
generation	O
models	O
,	O
however	O
,	O
produce	O
lengthy	O
texts	O
and	O
allow	O
the	O
user	O
little	O
control	O
over	O
the	O
aspect	O
the	O
argument	O
should	O
address	O
Hua	O
and	O
Wang	O
,	O
2018	O
)	O
.	O
We	O
show	O
that	O
argument	O
generation	O
can	O
be	O
enhanced	O
by	O
allowing	O
for	O
a	O
fine	O
-	O
grained	O
control	O
and	O
limiting	O
the	O
argument	O
to	O
a	O
single	O
but	O
concise	O
sentence	O
.	O

Quality	O
Estimation	O
(	O
QE	O
)	O
is	O
the	O
task	O
of	O
assessing	O
the	O
quality	O
of	O
a	O
translation	O
without	O
having	O
access	O
to	O
a	O
reference	O
translation	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
Translation	O
quality	O
can	O
be	O
estimated	O
at	O
different	O
levels	O
of	O
granularity	O
:	O
word	O
,	O
sentence	O
and	O
document	O
level	O
(	O
I	O
ve	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
So	O
far	O
the	O
most	O
popular	O
task	O
has	O
been	O
sentence	O
-	O
level	O
QE	O
,	O
in	O
which	O
QE	O
models	O
provide	O
a	O
score	O
for	O
each	O
pair	O
of	O
source	O
and	O
target	O
sentences	O
.	O
A	O
more	O
challenging	O
task	O
,	O
which	O
is	O
currently	O
receiving	O
a	O
lot	O
of	O
attention	O
from	O
the	O
research	O
community	O
,	O
is	O
word	O
-	O
level	O
quality	O
estimation	O
.	O
This	O
task	O
provides	O
more	O
fine	O
-	O
grained	O
information	O
about	O
the	O
quality	O
of	O
a	O
translation	O
,	O
indicating	O
which	O
words	O
from	O
the	O
source	O
have	O
been	O
incorrectly	O
translated	O
in	O
the	O
target	O
,	O
and	O
whether	O
the	O
words	O
inserted	O
between	O
these	O
words	O
are	O
correct	O
(	O
good	O
vs	O
bad	O
gaps	O
)	O
.	O
This	O
information	O
can	O
be	O
useful	O
for	O
post	O
-	O
editors	O
by	O
indicating	O
the	O
parts	O
of	O
a	O
sentence	O
on	O
which	O
they	O
have	O
to	O
focus	O
more	O
.	O

Text	O
features	O
:	O
For	O
the	O
feature	O
-	O
based	O
approach	O
,	O
we	O
extract	O
the	O
same	O
15	O
features	O
as	O
those	O
for	O
the	O
baseline	O
of	O
WMT'18	B-MethodName
at	O
document	O
level	O
.	O
For	O
the	O
neural	O
-	O
based	O
approaches	O
,	O
text	O
features	O
are	O
either	O
the	O
learned	O
word	O
embeddings	O
(	O
BiRNN	O
)	O
or	O
pre	O
-	O
trained	O
word	O
embeddings	O
(	O
BERT	O
-	O
BiRNN	O
)	O
.	O

In	O
this	O
section	O
,	O
we	O
provide	O
additional	O
details	O
to	O
facilitate	O
reproducing	O
our	O
results	O
and	O
findings	O
.	O
We	O
submit	O
data	O
and	O
code	O
as	O
supplementary	O
material	O
and	O
commit	O
to	O
make	O
them	O
publicly	O
available	O
upon	O
acceptance	O
to	O
facilitate	O
reproduction	O
.	O

Most	O
studies	O
on	O
word	O
-	O
level	O
Quality	O
Estimation	O
(	O
QE	O
)	O
of	O
machine	O
translation	O
focus	O
on	O
languagespecific	O
models	O
.	O
The	O
obvious	O
disadvantages	O
of	O
these	O
approaches	O
are	O
the	O
need	O
for	O
labelled	O
data	O
for	O
each	O
language	O
pair	O
and	O
the	O
high	O
cost	O
required	O
to	O
maintain	O
several	O
language	O
-	O
specific	O
models	O
.	O
To	O
overcome	O
these	O
problems	O
,	O
we	O
explore	O
different	O
approaches	O
to	O
multilingual	O
,	O
word	O
-	O
level	O
QE	O
.	O
We	O
show	O
that	O
multilingual	O
QE	O
models	O
perform	O
on	O
par	O
with	O
the	O
current	O
language	O
-	O
specific	O
models	O
.	O
In	O
the	O
cases	O
of	O
zeroshot	O
and	O
few	O
-	O
shot	O
QE	O
,	O
we	O
demonstrate	O
that	O
it	O
is	O
possible	O
to	O
accurately	O
predict	O
word	O
-	O
level	O
quality	O
for	O
any	O
given	O
new	O
language	O
pair	O
from	O
models	O
trained	O
on	O
other	O
language	O
pairs	O
.	O
Our	O
findings	O
suggest	O
that	O
the	O
word	O
-	O
level	O
QE	O
models	O
based	O
on	O
powerful	O
pre	O
-	O
trained	O
transformers	O
that	O
we	O
propose	O
in	O
this	O
paper	O
generalise	O
well	O
across	O
languages	O
,	O
making	O
them	O
more	O
useful	O
in	O
real	O
-	O
world	O
scenarios	O
.	O

The	O
neural	O
architectures	O
of	O
our	O
models	O
are	O
identical	O
to	O
BERT	B-MethodName
-	I-MethodName
Base	I-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
although	O
we	O
believe	O
incorporating	O
additions	O
such	O
as	O
relative	O
position	O
encodings	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
•	O
QNLI	O
:	O
Question	O
Natural	O
Language	O
Inference	O
;	O
constructed	O
from	O
SQuAD	B-MethodName
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
The	O
task	O
is	O
to	O
predict	O
whether	O
a	O
context	O
sentence	O
contains	O
the	O
answer	O
to	O
a	O
question	O
sentence	O
.	O
The	O
dataset	O
contains	O
108k	O
train	O
examples	O
from	O
Wikipedia	O
.	O

In	O
the	O
following	O
,	O
we	O
describe	O
the	O
architecture	O
and	O
the	O
training	O
process	O
of	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
and	O
analyze	O
its	O
performance	O
.	O

where	O
REPLACE(x	O
,	O
t	O
,	O
x	O
)	O
denotes	O
replacing	O
the	O
token	O
at	O
position	O
t	O
with	O
x	O
and	O
V	O
is	O
the	O
vocabulary	O
,	O
in	O
practice	O
usually	O
word	O
pieces	O
(	O
Sennrich	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
Unlike	O
with	O
BERT	B-MethodName
,	O
which	O
produces	O
the	O
probabilities	O
for	O
all	O
possible	O
tokens	O
x	O
using	O
a	O
softmax	O
layer	O
,	O
a	O
candidate	O
x	O
is	O
passed	O
in	O
as	O
input	O
to	O
the	O
transformer	O
.	O
As	O
a	O
result	O
,	O
computing	O
p	O
θ	O
is	O
prohibitively	O
expensive	O
because	O
the	O
partition	O
function	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
requires	O
running	O
the	O
transformer	O
|V|	O
times	O
;	O
unlike	O
most	O
EBMs	O
,	O
the	O
intractability	O
of	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
is	O
due	O
to	O
the	O
expensive	O
scoring	O
function	O
rather	O
than	O
having	O
a	O
large	O
sample	O
space	O
.	O

(	O
1	O
/	O
3	O
)	O
A	O
reference	O
to	O
Evil	O
Knievel	O
,	O
a	O
stuntman	O
who	O
jumps	O
motorcycles	O
over	O
cars	O
.	O
This	O
pile	O
of	O
cars	O
is	O
going	O
to	O
be	O
an	O
obstacle	O
in	O
an	O
Evil	O
Knievel	O
stunt	O
,	O
and	O
the	O
man	O
in	O
the	O
top	O
car	O
is	O
hoping	O
that	O
the	O
stuntman	O
coordinating	O
this	O
both	O
knows	O
how	O
to	O
jump	O
over	O
and	O
also	O
how	O
to	O
get	O
the	O
drivers	O
out	O
of	O
this	O
precarious	O
situation	O
.	O

Results	O
With	O
no	O
other	O
previous	O
work	O
on	O
explicit	O
control	O
of	O
argument	O
generation	O
(	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
)	O
,	O
we	O
decide	O
to	O
proof	O
our	O
concept	O
of	O
aspect	O
-	O
controlled	O
neural	O
argument	O
generation	O
by	O
7	O
Not	O
counting	O
non	O
-	O
arguments	O
from	O
the	O
splits	O
.	O

Token	O
type	O
(	O
ttype	O
)	O
predicts	O
the	O
type	O
of	O
a	O
word	O
.	O
This	O
requires	O
contextual	O
processing	O
since	O
a	O
word	O
might	O
consist	O
of	O
several	O
wordpieces	O
;	O
Token	O
position	O
(	O
token.ix	O
)	O
predicts	O
the	O
linear	O
position	O
of	O
a	O
word	O
,	O
cast	O
as	O
a	O
regression	O
task	O
over	O
the	O
first	O
20	O
words	O
in	O
the	O
sentence	O
.	O
Again	O
,	O
the	O
task	O
is	O
non	O
-	O
trivial	O
since	O
it	O
requires	O
the	O
words	O
to	O
be	O
assembled	O
from	O
the	O
wordpieces	O
.	O
Part	O
-	O
of	O
-	O
speech	O
(	O
pos	O
)	O
predicts	O
the	O
languagespecific	O
part	O
-	O
of	O
-	O
speech	O
tag	O
for	O
the	O
given	O
token	O
.	O
Lexical	O
unit	O
(	O
lex.unit	O
)	O
predicts	O
the	O
lemma	O
and	O
POS	O
of	O
the	O
given	O
word	O
-a	O
common	O
input	O
representation	O
for	O
the	O
entries	O
in	O
lexical	O
resources	O
.	O
We	O
extract	O
coarse	O
POS	O
tags	O
by	O
using	O
the	O
first	O
character	O
of	O
the	O
language	O
-	O
specific	O
POS	O
tag	O
.	O

(	O
ii	O
)	O
premise	O
and	O
hypothesis	O
contradict	O
;	O
or	O
(	O
iii	O
)	O
they	O
are	O
neutral	O
.	O
This	O
setting	O
makes	O
the	O
task	O
suitable	O
to	O
be	O
modeled	O
as	O
a	O
text	O
classification	O
task	O
.	O

The	O
framework	O
proposed	O
in	O
this	O
work	O
is	O
an	O
encoderdecoder	O
based	O
generative	O
model	O
.	O
It	O
is	O
thus	O
more	O
time	O
-	O
consuming	O
than	O
standard	O
discriminative	O
models	O
for	O
training	O
and	O
evaluation	O
,	O
which	O
in	O
turn	O
results	O
in	O
higher	O
carbon	O
footprint	O
.	O
Specifically	O
,	O
we	O
run	O
our	O
experiments	O
on	O
1	O
single	O
NVIDIA	O
RTX	O
A6000	O
with	O
significant	O
CPU	O
resources	O
.	O
The	O
training	O
time	O
for	O
our	O
model	O
is	O
usually	O
around	O
5	O
hours	O
.	O

The	O
gap	O
between	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
and	O
mBERT	B-MethodName
is	O
reduced	O
by	O
1	O
point	O
absolute	O
by	O
the	O
SlavicBERT	B-MethodName
's	O
additional	O
fine	O
-	O
tuning	O
on	O
downstream	O
tasks	O
.	O
Although	O
the	O
largest	O
improvement	O
is	O
observed	O
for	O
NER	B-MethodName
tasks	O
,	O
3	O
we	O
see	O
an	O
increase	O
by	O
1	O
-	O
2	O
points	O
also	O
on	O
Cred.-N	B-MethodName
,	O
Fake	B-MethodName
-	I-MethodName
N	I-MethodName
,	O
and	O
XNLI	B-MethodName
,	O
compared	O
to	O
mBERT	B-MethodName
.	O
However	O
,	O
we	O
also	O
see	O
that	O
the	O
downstream	O
pre	O
-	O
fine	O
-	O
tuning	O
is	O
not	O
beneficial	O
for	O
all	O
tasks	O
(	O
Poth	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
and	O
we	O
see	O
a	O
drop	O
in	O
performance	O
for	O
ranking	O
(	O
CT21.T1	O
)	O
and	O
question	O
answering	O
4	O
(	O
EXAMS	O
)	O
tasks	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
challenging	O
translation	O
task	O
called	O
schema	O
translation	O
,	O
and	O
construct	O
the	O
first	O
parallel	O
dataset	O
for	O
this	O
task	O
.	O
To	O
address	O
the	O
challenges	O
for	O
this	O
new	O
task	O
,	O
we	O
propose	O
CAST	B-MethodName
,	O
which	O
uses	O
a	O
relational	O
-	O
aware	O
transformer	O
to	O
encode	O
a	O
header	O
and	O
its	O
context	O
over	O
predefined	O
relationships	O
,	O
making	O
it	O
aware	O
of	O
the	O
table	O
context	O
.	O

Extensive	O
experiments	O
and	O
ablations	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
approach	O
.	O
Our	O
future	O
work	O
includes	O
exploration	O
of	O
various	O
text	O
segmentation	O
techniques	O
to	O
improve	O
our	O
understanding	O
of	O
the	O
latent	O
document	O
structure	O
.	O
Another	O
direction	O
would	O
be	O
to	O
extend	O
our	O
study	O
to	O
the	O
realm	O
of	O
neural	O
abstractive	O
summarization	O
with	O
the	O
help	O
of	O
learned	O
document	O
structure	O
.	O

We	O
follow	O
the	O
evaluation	O
method	O
of	O
the	O
WMT	O
QE	O
tasks	O
:	O
Pearson	O
's	O
r	O
correlation	O
as	O
the	O
main	O
metric	O
(	O
Graham	O
,	O
2015	O
)	O
,	O
Mean	O
-	O
Absolute	O
Error	O
(	O
MAE	O
)	O
and	O
Root	O
-	O
Mean	O
-	O
Squared	O
Error	O
(	O
RMSE	O
)	O
as	O
secondary	O
metrics	O
.	O
For	O
statistical	O
significance	O
on	O
Pearson	O
's	O
r	O
,	O
we	O
compute	O
Williams	O
test	O
(	O
Williams	O
,	O
1959	O
)	O
as	O
suggested	O
by	O
Graham	O
and	O
Baldwin	O
(	O
2014	O
)	O
.	O

Ablation	O
Table	O
5	O
shows	O
the	O
contribution	O
of	O
each	O
component	O
of	O
our	O
method	O
on	O
XNLI	O
.	O
Removing	O
TLM	B-MethodName
(	O
-TLM	O
)	O
consistently	O
leads	O
to	O
about	O
1	O
%	O
accuracy	O
drop	O
across	O
the	O
board	O
,	O
showing	O
positive	O
effects	O
of	O
the	O
word	O
-	O
alignment	O
objective	O
.	O
To	O
better	O
understand	O
TLM	B-MethodName
's	O
consistent	O
improvement	O
,	O
we	O
replace	O
TLM	B-MethodName
with	O
MLM	O
(	O
repl	O
TLM	O
w/	O
MLM	O
)	O
,	O
where	O
we	O
treat	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
from	O
the	O
parallel	O
corpora	O
as	O
separate	O
monolingual	O
sequences	O
and	O
perform	O
MLM	O
on	O
each	O
of	O
them	O
.	O
The	O
masking	O
scheme	O
is	O
the	O
same	O
as	O
TLM	B-MethodName
described	O
in	O
Section	O
2	O
.	O
We	O
observe	O
that	O
MLM	O
does	O
not	O
bring	O
significant	O
improvement	O
.	O
This	O
confirms	O
that	O
the	O
improvement	O
of	O
TLM	B-MethodName
is	O
not	O
from	O
the	O
encoders	O
being	O
trained	O
with	O
more	O
data	O
and	O
iterations	O
.	O
Instead	O
,	O
the	O
word	O
-	O
alignment	O
nature	O
of	O
TLM	B-MethodName
does	O
help	O
the	O
multilingual	O
training	O
.	O

In	O
the	O
past	O
years	O
,	O
deep	O
learning	O
models	O
have	O
greatly	O
improved	O
their	O
performances	O
on	O
a	O
large	O
range	O
of	O
question	O
answering	O
tasks	O
,	O
especially	O
using	O
pretrained	O
models	O
such	O
as	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
RoBERTa	B-MethodName
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
T5	B-MethodName
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
More	O
recently	O
,	O
these	O
models	O
have	O
shown	O
even	O
better	O
performances	O
when	O
fine	O
-	O
tuned	O
on	O
multiple	O
question	O
answering	O
datasets	O
at	O
once	O
.	O
Such	O
a	O
model	O
is	O
UnifiedQA	B-MethodName
(	O
Khashabi	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
which	O
,	O
starting	O
from	O
a	O
T5	O
model	O
,	O
is	O
trained	O
on	O
a	O
large	O
number	O
of	O
question	O
answering	O
datasets	O
including	O
multiple	O
choices	O
,	O
yes	O
/	O
no	O
,	O
extractive	O
and	O
abstractive	O
question	O
answering	O
.	O
UnifiedQA	B-MethodName
is	O
,	O
at	O
the	O
time	O
of	O
writing	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
a	O
large	O
number	O
of	O
question	O
answering	O
datasets	O
including	O
multiple	O
-	O
choice	O
datasets	O
like	O
OpenBookQA	B-MethodName
(	O
Mihaylov	O
et	O
al	O
.	O
,	O
2018	O
)	O
or	O
ARC	B-MethodName
.	O
However	O
,	O
even	O
if	O
Uni	B-MethodName
-	I-MethodName
fiedQA	I-MethodName
achieves	O
good	O
results	O
on	O
previously	O
unseen	O
datasets	O
,	O
it	O
often	O
fails	O
to	O
achieve	O
optimal	O
performances	O
on	O
these	O
datasets	O
until	O
it	O
is	O
further	O
finetuned	O
on	O
dedicated	O
human	O
annotated	O
data	O
.	O
This	O
tendency	O
is	O
increased	O
when	O
the	O
target	O
dataset	O
deals	O
with	O
questions	O
about	O
a	O
very	O
specific	O
domain	O
.	O

'	O
not	O
every	O
medicine	O
is	O
for	O
everyone	O
,	O
but	O
as	O
one	O
who	O
has	O
prescribed	O
most	O
of	O
the	O
major	O
pharmaceuticals	O
for	O
major	O
depression	O
,	O
panic	O
attacks	O
,	O
severe	O
anxiety	O
and	O
anxiety	O
related	O
bouts	O
of	O
obsessive	O
compulsive	O
disorder	O
,	O
i	O
can	O
tell	O
you	O
lexapro	O
is	O
the	O
only	O
medicine	O
that	O
i	O
've	O
been	O
able	O
to	O
stay	O
on	O
and	O
be	O
effective	O
for	O
my	O
mental	O
well	O
-	O
being	O
...	O
it	O
is	O
the	O
only	O
one	O
i	O
've	O
had	O
no	O
side	O
effects	O
.	O
pill	O
antidepressants	O
have	O
either	O
:	O
made	O
me	O
more	O
anxious	O
and	O
/	O
or	O
depressed	O
,	O
dry	O
mouth	O
,	O
bad	O
weight	O
gain	O
,	O
or	O
extreme	O
fatigue	O
making	O
me	O
into	O
a	O
walking	O
zombie	O
during	O
the	O
day	O
.	O
i	O
've	O
been	O
on	O
lexapro	O
6	O
years	O
F	O
(	O
s	O
adv	O
,	O
l	O
=	O
"	O
10.0	O
"	O
)	O
=	O
1.0	O
Cos	O
.	O
=	O
0.04	O

Translation	O
memory	O
(	O
TM	O
)	O
is	O
basically	O
a	O
database	O
of	O
segmented	O
and	O
paired	O
source	O
and	O
target	O
texts	O
that	O
translators	O
can	O
access	O
in	O
order	O
to	O
re	O
-	O
use	O
previous	O
translations	O
while	O
translating	O
new	O
texts	O
(	O
Christensen	O
and	O
Schjoldager	O
,	O
2010	O
)	O
.	O
For	O
human	O
translators	O
,	O
such	O
similar	O
translation	O
pieces	O
can	O
lead	O
to	O
higher	O
productivity	O
and	O
consistency	O
(	O
Yamada	O
,	O
2011	O
)	O
.	O
For	O
machine	O
translation	O
,	O
early	O
works	O
mainly	O
contributes	O
to	O
employ	O
TM	O
for	O
statistical	O
machine	O
translation	O
(	O
SMT	O
)	O
systems	O
(	O
Simard	O
and	O
Isabelle	O
,	O
2009	O
;	O
Utiyama	O
et	O
al	O
.	O
,	O
2011	O
;	O
Liu	O
et	O
al	O
.	O
,	O
2012	O
.	O
Recently	O
,	O
as	O
neural	O
machine	O
translation	O
(	O
NMT	O
)	O
model	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014	O
;	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
has	O
achieved	O
impressive	O
performance	O
in	O
many	O
*	O
Corresponding	O
author	O
.	O
translation	O
tasks	O
,	O
there	O
is	O
also	O
an	O
emerging	O
interest	O
(	O
Gu	O
et	O
al	O
.	O
,	O
2018	O
)	O
in	O
retrieval	O
-	O
augmented	O
NMT	O
model	O
.	O

Furthermore	O
,	O
as	O
reported	O
in	O
Table	O
6	O
,	O
we	O
observe	O
that	O
the	O
increment	O
in	O
the	O
multi	O
-	O
aspect	O
setting	O
is	O
much	O
larger	O
than	O
that	O
in	O
the	O
single	O
-	O
aspect	O
setting	O
when	O
compare	O
Exp	O
with	O
other	O
strategies	O
.	O
To	O
sum	O
up	O
,	O
the	O
strategy	O
of	O
context	O
augmentation	O
in	O
our	O
COM	B-MethodName
-	I-MethodName
MRC	I-MethodName
is	O
effective	O
.	O

As	O
a	O
reference	O
,	O
T0	O
(	O
Sanh	O
et	O
al	O
.	O
,	O
2022	O
)	O
models	O
andFlan	O
-	I-MethodName
T5	I-MethodName
(	O
Chung	O
et	O
al	O
.	O
,	O
2022	O
)	O
are	O
all	O
based	O
on	O
the	O
original	O
T5	O
model	O
by	O
Raffel	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
The	O
pretraining	O
corpus	O
is	O
the	O
C4	O
corpus	O
(	O
Raffel	O
et	O
al	O
.	O
,	O
2019	O
)	O
of	O
800	O
GB	O
of	O
texts	O
based	O
on	O
CommonCrawl	O
.	O
They	O
encode	O
the	O
corpus	O
with	O
a	O
cased	O
vocabulary	O
of	O
32k	O
BPE	O
tokens	O
.	O

During	O
inference	O
,	O
we	O
obtain	O
the	O
relation	O
(	O
s	O
)	O
of	O
a	O
given	O
entity	O
pair	O
by	O
thresholding	O
the	O
predicted	O
probabilities	O
,	O
following	O
most	O
previous	O
work	O
.	O

Our	O
extensive	O
experiments	O
on	O
a	O
wide	O
range	O
of	O
ED	O
datasets	O
demonstrate	O
its	O
effectiveness	O
.	O

Self	O
-	O
Attention	O
The	O
SANs	B-MethodName
compute	O
the	O
attention	O
of	O
each	O
pair	O
of	O
elements	O
in	O
parallel	O
.	O
It	O
first	O
converts	O
the	O
input	O
into	O
three	O
matrices	O
Q	O
,	O
K	O
,	O
V	O
,	O
representing	O
queries	O
,	O
keys	O
,	O
and	O
values	O
,	O
respectively	O
:	O

The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
(	O
i	O
)	O
we	O
introduce	O
the	O
task	O
of	O
Multimodal	B-MethodName
QE	I-MethodName
(	O
MQE	B-MethodName
)	O
for	O
MT	O
as	O
an	O
attempt	O
to	O
improve	O
QE	B-MethodName
by	O
using	O
external	O
sources	O
of	O
information	O
,	O
namely	O
images	O
;	O
(	O
ii	O
)	O
we	O
propose	O
several	O
ways	O
of	O
incorporating	O
visual	O
information	O
in	O
neural	O
-	O
based	O
and	O
featurebased	O
QE	O
architectures	O
;	O
and	O
(	O
iii	O
)	O
we	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
such	O
architectures	O
in	O
document	O
and	O
sentence	O
-	O
level	O
QE	O
.	O

where	O
n	O
-	O
best(f	O
,	O
s	O
)	O
consists	O
of	O
the	O
top	O
n	O
(	O
we	O
use	O
n	O
=	O
100	O
)	O
predictions	O
from	O
the	O
speech	O
recognition	O
model	O
found	O
with	O
beam	O
search	O
,	O
f	O
(	O
x|s	O
)	O
is	O
the	O
score	O
the	O
speech	O
model	O
assigns	O
the	O
candidate	O
output	O
sequence	O
x.	O
We	O
select	O
the	O
best	O
λ	O
on	O
the	O
dev	O
set	O
out	O
of	O
[	O
0.05	O
,	O
0.1	O
,	O
...	O
,	O
0.95	O
,	O
1.0	O
]	O
,	O
with	O
different	O
λs	O
selected	O
for	O
the	O
"	O
clean	O
"	O
and	O
"	O
other	O
"	O
portions	O
of	O
the	O
data	O
.	O

Our	O
method	O
has	O
the	O
advantage	O
of	O
being	O
more	O
robust	O
and	O
better	O
aware	O
of	O
its	O
own	O
competency	O
,	O
while	O
extra	O
-	O
estimation	O
is	O
able	O
to	O
capture	O
the	O
supervised	O
knowledge	O
of	O
the	O
labeled	O
data	O
.	O
One	O
interesting	O
question	O
is	O
whether	O
they	O
can	O
be	O
complementary	O
.	O

One	O
limitation	O
of	O
the	O
zero	O
-	O
shot	O
QE	O
is	O
its	O
inability	O
to	O
perform	O
when	O
the	O
language	O
direction	O
changes	O
.	O
In	O
the	O
scenario	O
where	O
we	O
performed	O
zero	O
-	O
shot	O
learning	O
from	O
De	B-MethodName
-	O
En	O
to	O
other	O
language	O
pairs	O
,	O
results	O
degraded	O
considerably	O
from	O
the	O
bilingual	O
result	O
.	O
Similarly	O
,	O
the	O
performance	O
is	O
rather	O
poor	O
when	O
we	O
test	O
on	O
De	B-MethodName
-	O
En	I-MethodName
for	O
the	O
multilingual	O
zero	O
-	O
shot	O
experiment	O
as	O
the	O
direction	O
of	O
all	O
the	O
other	O
pairs	O
used	O
for	O
training	O
is	O
different	O
.	O
This	O
is	O
in	O
line	O
with	O
results	O
reported	O
by	O
Ranasinghe	O
et	O
al	O
.	O
(	O
2020b	O
)	O
for	O
sentence	O
level	O
.	O

Electric	O
is	O
closely	O
related	O
to	O
the	O
ELECTRA	B-MethodName
pretraining	O
method	O
.	O
ELECTRA	B-MethodName
also	O
trains	O
a	O
binary	O
classifier	O
(	O
the	O
"	O
discriminator	O
"	O
)	O
to	O
distinguish	O
data	O
tokens	O
from	O
noise	O
tokens	O
produced	O
by	O
a	O
"	O
generator	O
"	O
network	O
.	O
However	O
,	O
ELECTRA	B-MethodName
's	O
classifier	O
is	O
simply	O
a	O
sigmoid	O
layer	O
on	O
top	O
of	O
the	O
transformer	O
:	O
it	O
models	O
the	O
probability	O
of	O
a	O
token	O
being	O
negative	O
(	O
i.e.	O
,	O
as	O
replaced	O
by	O
a	O
noise	O
sample	O
)	O
as	O
σ(E(x	O
)	O
t	O
)	O
where	O
σ	O
denotes	O
the	O
sigmoid	O
function	O
.	O
Electric	O
on	O
the	O
other	O
hand	O
models	O
this	O
probability	O
as	O

GLUE	B-MethodName
.	O
CoLA	I-MethodName
(	O
Warstadt	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
SST-2	B-MethodName
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
are	O
single	O
-	O
sentence	O
tasks	O
;	O
MRPC	B-MethodName
(	O
Dolan	O
and	O
Brockett	O
,	O
2005	O
)	O
and	O
QQP	B-MethodName
are	O
paraphrase	O
detection	O
tasks	O
;	O
MNLI	B-MethodName
(	O
Williams	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
QNLI	B-MethodName
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
andRTE	O
(	O
Dagan	O
andGlickman	O
,	O
2005	O
;	O
Haim	O
et	O
al	O
.	O
,	O
2006	O
;	O
Giampiccolo	O
et	O
al	O
.	O
,	O
2007Giampiccolo	O
et	O
al	O
.	O
,	O
,	O
2008Bentivogli	O
et	O
al	O
.	O
,	O
2009	O
)	O
are	O
inference	O
tasks	O
;	O
STS	O
-	O
B	O
(	O
Cer	O
et	O
al	O
.	O
,	O
2017	O
)	O
is	O
a	O
sentence	O
similarity	O
task	O
.	O
We	O
report	O
the	O
accuracy	O
for	O
SST-2	B-MethodName
,	O
MNLI	B-MethodName
,	O
QNLI	B-MethodName
,	O
RTE	B-MethodName
,	O
and	O
STS	B-MethodName
-	O
B	O
,	O
and	O
the	O
Matthews	O
correlation	O
coefficient	O
for	O
CoLA	B-MethodName
.	O
Both	O
the	O
accuracy	O
and	O
the	O
F-1	O
score	O
are	O
included	O
for	O
MRPC	B-MethodName
and	O
QQP	B-MethodName
.	O

A	O
For	O
every	O
submission	O
:	O
A1	O
.	O
Did	O
you	O
describe	O
the	O
limitations	O
of	O
your	O
work	O
?	O

Experiment	O
Settings	O
.	O
We	O
use	O
BioBERT	B-MethodName
as	O
the	O
PLM	O
on	O
SciDocs	O
,	O
and	O
BERT	B-MethodName
-	O
base	O
-	O
uncased	O
as	O
the	O
PLM	O
on	O
Amazon	O
and	O
Twitter	O
.	O
The	O
embedding	O
dimension	O
of	O
u	O
w	O
is	O
768	O
(	O
the	O
same	O
as	O
e	O
w	O
)	O
;	O
the	O
number	O
of	O
negative	O
samples	O
b	O
=	O
5	O
.	O
In	O
ensemble	O
ranking	O
,	O
the	O
length	O
of	O
the	O
general	O
/	O
local	O
ranking	O
list	O
M	O
=	O
100	O
;	O
the	O
hyperparameter	O
ρ	O
in	O
Eq	O
.	O
(	O
6	O
)	O
is	O
set	O
as	O
0.1	O
;	O
the	O
number	O
of	O
iterations	O
T	O
=	O
4	O
;	O
after	O
each	O
iteration	O
,	O
we	O
increase	O
the	O
size	O
of	O
S	O
i	O
by	O
N	O
=	O
3	O
.	O
We	O
use	O
the	O
top-10	O
ranked	O
terms	O
in	O
each	O
topic	O
for	O
final	O
evaluation	O
(	O
i.e.	O
,	O
|S	O
i	O
|	O
=	O
10	O
in	O
Eqs	O
.	O
(	O
8	O
)	O
-	O
(	O
11	O
)	O
)	O
.	O
Experiments	O
are	O
run	O
on	O
Intel	O
Xeon	O
E5	O
-	O
2680	O
v2	O
@	O
2.80GHz	O
and	O
one	O
NVIDIA	O
GeForce	O
GTX	O
1080	O
.	O

For	O
the	O
CoNLL	B-MethodName
dataset	O
,	O
we	O
also	O
test	O
the	O
performance	O
using	O
PPRforNED	O
entity	O
candidates	O
(	O
Pershina	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
We	O
report	O
the	O
in	O
-	O
KB	O
accuracy	O
for	O
the	O
CoNLL	B-MethodName
dataset	O
and	O
the	O
micro	O
F1	O
score	O
(	O
averaged	O
per	O
mention	O
)	O
for	O
the	O
other	O
datasets	O
.	O
Further	O
details	O
of	O
the	O
datasets	O
are	O
provided	O
in	O
Appendix	O
C.	O
Furthermore	O
,	O
we	O
optionally	O
fine	O
-	O
tune	O
the	O
model	O
by	O
maximizing	O
the	O
log	O
likelihood	O
of	O
the	O
ED	O
predictions	O
(	O
ŷ	O
ED	O
)	O
using	O
the	O
training	O
set	O
of	O
the	O
CoNLL	B-MethodName
dataset	O
with	O
the	O
KB+YAGO	O
candidates	O
.	O
We	O
mask	O
90	O
%	O
of	O
the	O
mentions	O
and	O
fix	O
the	O
entity	O
token	O
embeddings	O
(	O
B	O
and	O
B	O
*	O
)	O
and	O
the	O
bias	O
(	O
The	O
model	O
is	O
trained	O
for	O
two	O
epochs	O
using	O
AdamW.	O
Additional	O
details	O
are	O
provided	O
in	O
Appendix	O
B.	O
Our	O
global	O
models	O
consistently	O
perform	O
better	O
than	O
the	O
local	O
model	O
,	O
demonstrating	O
the	O
effectiveness	O
of	O
using	O
global	O
contextual	O
information	O
even	O
if	O
local	O
contextual	O
information	O
is	O
captured	O
using	O
expressive	O
BERT	B-MethodName
model	O
.	O
Moreover	O
,	O
the	O
confidenceorder	O
model	O
performs	O
better	O
than	O
the	O
natural	O
-	O
order	O
model	O
on	O
most	O
datasets	O
.	O
An	O
analysis	O
investigating	O
why	O
the	O
confidence	O
-	O
order	O
model	O
outperforms	O
the	O
natural	O
-	O
order	O
model	O
is	O
provided	O
in	O
the	O
next	O
section	O
.	O

We	O
thank	O
the	O
first	O
author	O
's	O
dissertation	O
committee	O
members	O
,	O
Drs	O
.	O
Mausam	O
and	O
Samar	O
Husain	O
,	O
as	O
well	O
as	O
the	O
Cornell	O
C.Psyd	O
members	O
for	O
their	O
insightful	O
comments	O
and	O
suggestions	O
on	O
this	O
work	O
.	O
We	O
thank	O
Rupesh	O
Pandey	O
's	O
logistical	O
assistance	O
in	O
gathering	O
the	O
human	O
judgment	O
data	O
for	O
this	O
work	O
.	O
We	O
are	O
also	O
grateful	O
for	O
the	O
thorough	O
feedback	O
provided	O
by	O
the	O
anonymous	O
reviewers	O
of	O
EMNLP	O
2022	O
,	O
ACL	O
ARR	O
2021	O
,	O
and	O
COMCO	O
2021	O
.	O
Finally	O
,	O
the	O
last	O
two	O
authors	O
also	O
thank	O
extramural	O
funding	O
from	O
the	O
Department	O
of	O
Science	O
and	O
Technology	O
of	O
India	O
through	O
the	O
Cognitive	O
Science	O
Research	O
Initiative	O
(	O
project	O
no	O
.	O
DST	O
/	O
CSRI	O
/	O
2018	O
/	O
263	O
)	O
.	O

We	O
collected	O
responses	O
from	O
MTurk	B-MethodName
workers	O
using	O
the	O
same	O
user	O
interfaces	O
as	O
in	O
Experiment	O
2	O
.	O
Simply	O
put	O
,	O
we	O
asked	O
the	O
workers	O
to	O
select	O
a	O
class	O
which	O
was	O
relevant	O
to	O
a	O
given	O
word	O
cloud	O
and	O
checked	O
if	O
the	O
majority	O
vote	O
agreed	O
with	O
the	O
weights	O
in	O
W.	O

The	O
models	O
also	O
use	O
the	O
text	O
embedding	O
at	O
each	O
layer	O
in	O
different	O
ways	O
.	O
In	O
MHGRN	B-MethodName
,	O
it	O
is	O
used	O
to	O
calculate	O
the	O
relevance	O
of	O
each	O
path	O
when	O
creating	O
the	O
new	O
embedding	O
for	O
each	O
node	O
.	O
In	O
QA	B-MethodName
-	I-MethodName
GNN	I-MethodName
,	O
a	O
pseudo	O
-	O
node	O
initialised	O
with	O
this	O
embedding	O
is	O
added	O
to	O
the	O
graph	O
,	O
allowing	O
it	O
to	O
participate	O
in	O
message	O
passing	O
with	O
the	O
other	O
nodes	O
.	O

In	O
Table	O
1	O
we	O
see	O
a	O
sudden	O
drop	O
in	O
correlations	O
for	O
N	O
RESLN	I-MethodName
.	O
Although	O
this	O
method	O
considers	O
vector	O
norms	O
and	O
residuals	O
,	O
incorporating	O
LN	O
#	I-MethodName
1	O
in	O
the	O
encoder	O
seems	O
to	O
have	O
deteriorated	O
the	O
accuracy	O
for	O
token	O
attribution	O
analysis	O
.	O
To	O
determine	O
whether	O
this	O
deterioration	O
of	O
correlation	O
in	O
aggregated	O
attributions	O
is	O
also	O
present	O
in	O
individual	O
single	O
layers	O
,	O
we	O
compare	O
the	O
HTA	B-MethodName
maps	O
as	O
a	O
baseline	O
with	O
the	O
attribution	O
matrices	O
extracted	O
from	O
different	O
analysis	O
methods	O
.	O
Figure	O
4	O
shows	O
the	O
correlation	O
of	O
HTA	B-MethodName
attribution	O
maps	O
with	O
the	O
maps	O
obtained	O
by	O
N	O
RES	O
,	O
N	O
RESLN	I-MethodName
,	O
and	O
N	O
ENC	O
methods	O
.	O
The	O
results	O
indicate	O
that	O
N	B-MethodName
RESLN	I-MethodName
exhibits	O
a	O
significantly	O
lower	O
association	O
.	O

1	O
Our	O
code	O
will	O
be	O
available	O
at	O
https	O
:	O
/	O
/	O
github.com	O
/	O
SupstarZh	O
/	O
WhitenedCSE	O
.	O
Meanwhile	O
,	O
in	O
(	O
d	O
)	O
,	O
the	O
positive	O
samples	O
after	O
SGW	B-MethodName
(	O
red	O
)	O
obtain	O
higher	O
diversity	O
than	O
the	O
original	O
bert	O
features	O
(	O
green	O
)	O
.	O
Using	O
these	O
diverse	O
positive	O
samples	O
for	O
contrastive	O
learning	O
,	O
the	O
proposed	O
WhitenedCSE	O
achieves	O
better	O
alignment	O
.	O

k•q(xt|x	O
\t	O
)	O
(	O
n−k)•p	O
θ	O
(	O
xt|x	O
noised	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
if	O
t	O
∈	O
R	O
−	O
log	O
(	O
n−k)•p	O
θ	O
(	O
xt|x	O
noised	O
\t	O
)	O
(	O
n−k)•p	O
θ	O
(	O
xt|x	O
noised	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
otherwise	O

To	O
see	O
the	O
impact	O
of	O
correctly	O
-	O
paired	O
inputs	O
and	O
labels	O
in	O
the	O
demonstrations	O
-	O
which	O
we	O
call	O
the	O
ground	O
truth	O
input	O
-	O
label	O
mapping	O
-	O
we	O
compare	O
the	O
following	O
three	O
methods	O
.	O
4	O
No	O
demonstrations	O
is	O
a	O
typical	O
zero	O
-	O
shot	O
method	O
that	O
does	O
not	O
use	O
any	O
labeled	O
data	O
.	O
A	O
prediction	O
is	O
made	O
via	O
argmax	O
y∈C	O
P	O
(	O
y|x	O
)	O
,	O
where	O
x	O
is	O
the	O
test	O
input	O
and	O
C	O
is	O
a	O
small	O
discrete	O
set	O
of	O
possible	O
labels	O
.	O

WMT'18	O
QE	O
Task	O
4	O
data	O
:	O
This	O
dataset	O
was	O
created	O
for	O
the	O
document	O
-	O
level	O
track	O
.	O
It	O
contains	O
a	O
sample	O
of	O
products	O
from	O
the	O
Amazon	O
Reviews	O
Dataset	O
(	O
McAuley	O
et	O
al	O
.	O
,	O
2015	O
)	O
taken	O
from	O
the	O
Sports	O
&	O
Outdoors	O
category	O
.	O
'	O
Documents	O
'	O
consist	O
of	O
the	O
English	O
product	O
title	O
and	O
its	O
description	O
,	O
its	O
French	O
machinetranslation	O
and	O
a	O
numerical	O
score	O
to	O
predict	O
,	O
namely	O
the	O
MQM	O
score	O
(	O
Multidimensional	O
Quality	O
Metrics	O
)	O
(	O
Lommel	O
et	O
al	O
.	O
,	O
2014	O
)	O
.	O
This	O
score	O
is	O
computed	O
by	O
annotating	O
and	O
weighting	O
each	O
word	O
-	O
level	O
translation	O
error	O
according	O
to	O
its	O
severity	O
(	O
minor	O
,	O
major	O
and	O
critical	O
):	O

B6	O
.	O
Did	O
you	O
report	O
relevant	O
statistics	O
like	O
the	O
number	O
of	O
examples	O
,	O
details	O
of	O
train	O
/	O
test	O
/	O
dev	O
splits	O
,	O
etc	O
.	O
for	O
the	O
data	O
that	O
you	O
used	O
/	O
created	O
?	O
Even	O
for	O
commonly	O
-	O
used	O
benchmark	O
datasets	O
,	O
include	O
the	O
number	O
of	O
examples	O
in	O
train	O
/	O
validation	O
/	O
test	O
splits	O
,	O
as	O
these	O
provide	O
necessary	O
context	O
for	O
a	O
reader	O
to	O
understand	O
experimental	O
results	O
.	O
For	O
example	O
,	O
small	O
differences	O
in	O
accuracy	O
on	O
large	O
test	O
sets	O
may	O
be	O
significant	O
,	O
while	O
on	O
small	O
test	O
sets	O
they	O
may	O
not	O
be	O
.	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O
D1	O
.	O
Did	O
you	O
report	O
the	O
full	O
text	O
of	O
instructions	O
given	O
to	O
participants	O
,	O
including	O
e.g.	O
,	O
screenshots	O
,	O
disclaimers	O
of	O
any	O
risks	O
to	O
participants	O
or	O
annotators	O
,	O
etc	O
.	O
?	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O

Although	O
we	O
are	O
not	O
aware	O
of	O
any	O
systematic	O
studies	O
dedicated	O
to	O
the	O
effect	O
of	O
formalism	O
on	O
probing	O
results	O
,	O
the	O
evidence	O
of	O
such	O
effects	O
is	O
scattered	O
across	O
the	O
related	O
work	O
:	O
for	O
example	O
,	O
the	O
aforementioned	O
results	O
in	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
show	O
a	O
difference	O
in	O
layer	O
utilization	O
between	O
constituents	O
-	O
and	O
dependency	O
-	O
based	O
syntactic	O
probes	O
and	O
semantic	O
role	O
and	O
proto	O
-	O
role	O
probes	O
.	O
It	O
is	O
not	O
clear	O
whether	O
this	O
effect	O
is	O
due	O
to	O
the	O
differences	O
in	O
the	O
underlying	O
datasets	O
and	O
task	O
architecture	O
or	O
the	O
formalism	O
per	O
se	O
.	O

The	O
BiRNN	B-MethodName
model	O
uses	O
an	O
encoder	O
-	O
decoder	O
architecture	O
:	O
it	O
takes	O
on	O
its	O
input	O
both	O
the	O
source	O
sentence	O
and	O
its	O
translation	O
which	O
are	O
encoded	O
separately	O
by	O
two	O
independent	O
bi	O
-	O
directional	O
Recurrent	B-MethodName
Neural	I-MethodName
Networks	I-MethodName
(	O
RNNs	O
)	O
.	O
The	O
two	O
resulting	O
sentence	O
representations	O
are	O
then	O
concatenated	O
as	O
a	O
weighted	O
sum	O
of	O
their	O
word	O
vectors	O
,	O
generated	O
by	O
an	O
attention	O
mechanism	O
.	O
For	O
sentence	O
-	O
level	O
predictions	O
,	O
the	O
weighted	O
representation	O
of	O
the	O
two	O
input	O
sentences	O
is	O
passed	O
through	O
a	O
dense	O
layer	O
with	O
sigmoid	O
activation	O
to	O
generate	O
the	O
quality	O
estimates	O
.	O
For	O
document	O
-	O
level	O
predictions	O
,	O
the	O
final	O
representation	O
of	O
a	O
document	O
is	O
generated	O
by	O
a	O
second	O
attention	O
mechanism	O
,	O
as	O
the	O
weighted	O
sum	O
of	O
the	O
weighted	O
sentence	O
-	O
level	O
representations	O
of	O
all	O
the	O
sentences	O
within	O
the	O
document	O
.	O
The	O
resulting	O
document	O
-	O
level	O
representation	O
is	O
then	O
passed	O
through	O
a	O
dense	O
layer	O
with	O
sigmoid	O
activation	O
to	O
generate	O
the	O
quality	O
estimates	O
.	O

Conventional	O
entity	O
linking	O
models	O
are	O
trained	O
and	O
evaluated	O
on	O
the	O
same	O
KB	O
,	O
which	O
is	O
typically	O
Wikipedia	O
,	O
or	O
derived	O
from	O
Wikipedia	O
(	O
Bunescu	O
and	O
Paşca	O
,	O
2006	O
;	O
.	O
This	O
limited	O
scope	O
allows	O
models	O
to	O
use	O
other	O
sources	O
of	O
information	O
to	O
improve	O
linking	O
,	O
including	O
alias	O
tables	O
,	O
frequency	O
statistics	O
,	O
and	O
rich	O
metadata	O
.	O

The	O
two	O
tables	O
show	O
the	O
downstream	O
performance	O
aligned	O
with	O
the	O
model	O
size	O
of	O
paraphrasers	O
.	O
We	O
found	O
it	O
that	O
large	O
models	O
(	O
davinci	O
)	O
models	O
only	O
with	O
a	O
reasonable	O
prompt	O
show	O
the	O
advantages	O
over	O
the	O
other	O
smaller	O
models	O
that	O
have	O
much	O
less	O
parameters	O
.	O

-DOCSTART-	O
FIND	O
:	O
Human	O
-	O
in	O
-	O
the	O
-	O
Loop	O
Debugging	O
Deep	O
Text	O
Classifiers	O

able	O
.	O
Unseen	O
languages	O
can	O
be	O
added	O
post	O
-	O
hoc	O
,	O
with	O
no	O
measurable	O
drop	O
in	O
performance	O
on	O
XNLI	O
.	O
By	O
pre	O
-	O
training	O
the	O
model	O
in	O
a	O
modular	O
fashion	O
,	O
we	O
thus	O
mitigate	O
negative	O
interference	O
of	O
idiosyncratic	O
information	O
,	O
while	O
simultaneously	O
preparing	O
the	O
model	O
to	O
be	O
extendable	O
to	O
unseen	O
languages	O
.	O

evolution	O
pattern	O
will	O
satisfy	O
the	O
Equation	O
20	O
.	O
Notice	O
that	O
our	O
relation	O
patterns	O
defined	O
are	O
unconcerned	O
with	O
some	O
specific	O
entities	O
,	O
but	O
focusing	O
on	O
the	O
general	O
rules	O
among	O
relations	O
inside	O
the	O
universal	O
entities	O
.	O

Step	O
2a	O
:	O
Data	O
preparation	O
for	O
ranking	O
To	O
create	O
training	O
data	O
for	O
the	O
ranker	O
,	O
we	O
use	O
a	O
simple	O
heuristic	O
to	O
calculate	O
scores	O
between	O
0	O
and	O
1	O
for	O
all	O
N	O
-	O
grams	O
of	O
a	O
sentence	O
by	O
dividing	O
the	O
number	O
of	O
aspect	O
tokens	O
within	O
an	O
N	O
-	O
gram	O
by	O
its	O
length	O
N	O
:	O
#	O
aspect	O
tokens	O
N	O
∈	O
[	O
0	O
,	O
1	O
]	O
.	O
Our	O
analysis	O
reveals	O
that	O
96	O
%	O
(	O
783	O
of	O
814	O
)	O
of	O
all	O
aspects	O
in	O
the	O
preliminary	O
annotation	O
dataset	O
only	O
contain	O
one	O
to	O
four	O
tokens	O
.	O
We	O
thus	O
decide	O
to	O
ignore	O
all	O
candidates	O
with	O
more	O
than	O
four	O
tokens	O
.	O
No	O
other	O
limitations	O
or	O
filtering	O
mechanisms	O
are	O
applied	O
.	O

To	O
explain	O
a	O
prediction	O
of	O
a	O
CNN	O
text	O
classifier	O
,	O
we	O
propagate	O
an	O
activation	O
value	O
of	O
the	O
output	O
node	O
back	O
to	O
the	O
word	O
embedding	O
matrix	O
.	O
After	O
that	O
,	O
the	O
relevance	O
score	O
of	O
an	O
input	O
word	O
equals	O
the	O
sum	O
of	O
relevance	O
scores	O
each	O
dimension	O
of	O
its	O
word	O
vector	O
receives	O
.	O
However	O
,	O
in	O
this	O
paper	O
,	O
we	O
want	O
to	O
analyze	O
the	O
hidden	O
features	O
rather	O
than	O
the	O
output	O
,	O
so	O
we	O
start	O
back	O
propagating	O
from	O
the	O
hidden	O
features	O
instead	O
to	O
capture	O
patterns	O
of	O
input	O
words	O
which	O
highly	O
activate	O
the	O
features	O
.	O

Unlike	O
the	O
interface	O
in	O
Figure	O
3	O
,	O
for	O
each	O
word	O
cloud	O
,	O
we	O
asked	O
the	O
participants	O
to	O
select	O
the	O
relevant	O
class	O
from	O
three	O
options	O
(	O
Biosbias	O
:	O
surgeon	O
,	O
nurse	O
,	O
it	O
could	O
be	O
either	O
/	O
Waseem	O
:	O
abusive	O
,	O
nonabusive	O
,	O
it	O
could	O
be	O
either	O
)	O
.	O
The	O
feature	O
will	O
be	O
disabled	O
if	O
the	O
majority	O
vote	O
does	O
not	O
select	O
the	O
class	O
suggested	O
by	O
the	O
weight	O
matrix	O
W.	O
To	O
ensure	O
that	O
the	O
participants	O
do	O
not	O
use	O
their	O
biases	O
while	O
answering	O
our	O
questions	O
,	O
we	O
firmly	O
mentioned	O
in	O
the	O
instructions	O
that	O
gender	O
-	O
related	O
terms	O
should	O
not	O
be	O
used	O
as	O
an	O
indicator	O
for	O
one	O
or	O
the	O
other	O
class	O
.	O

We	O
only	O
had	O
one	O
human	O
evaluator	O
.	O
Further	O
demographic	O
and	O
geographic	O
characteristics	O
are	O
not	O
relevant	O
to	O
the	O
experiment	O
,	O
given	O
the	O
current	O
state	O
of	O
research	O
,	O
and	O
would	O
unnecessarily	O
reveal	O
personal	O
information	O
of	O
the	O
evaluator	O
.	O

Furthermore	O
,	O
considering	O
the	O
prompt	O
tuning	O
method	O
does	O
predictions	O
by	O
decoding	O
label	O
tokens	O
,	O
we	O
need	O
to	O
check	O
whether	O
skill	O
neurons	O
depend	O
on	O
the	O
label	O
words	O
used	O
.	O
If	O
so	O
,	O
it	O
indicates	O
that	O
the	O
skill	O
neurons	O
do	O
not	O
encode	O
the	O
skills	O
for	O
handling	O
tasks	O
but	O
encode	O
the	O
skills	O
for	O
selectively	O
decoding	O
some	O
words	O
.	O
We	O
rule	O
out	O
this	O
possibility	O
by	O
finding	O
that	O
if	O
we	O
use	O
different	O
random	O
words	O
as	O
label	O
words	O
,	O
the	O
Table	O
3	O
:	O
Accuracies	O
(	O
%	O
)	O
on	O
various	O
tasks	O
of	O
top	O
skill	O
neurons	O
found	O
with	O
random	O
prompts	O
and	O
untuned	O
hard	O
prompts	O
,	O
compared	O
to	O
random	O
guess	O
and	O
random	O
model	O
.	O
We	O
also	O
report	O
standard	O
deviations	O
over	O
5	O
random	O
trials	O
.	O

Given	O
the	O
social	O
focus	O
of	O
our	O
stories	O
,	O
we	O
use	O
the	O
social	O
commonsense	O
knowledge	O
graph	O
ATOMIC	B-MethodName
(	O
Sap	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
4	O
For	O
each	O
story	O
,	O
we	O
first	O
match	O
possible	O
ATOMIC	B-MethodName
events	O
to	O
sentences	O
by	O
selecting	O
events	O
that	O
share	O
noun	O
chunks	O
and	O
verb	O
phrases	O
with	O
sentences	O
(	O
e.g.	O
,	O
"	O
getting	O
married	O
"	O
"	O
Per	O
-	O
sonX	O
gets	O
married	O
"	O
;	O
Figure	O
1	O
)	O
.	O
We	O
then	O
search	O
the	O
matched	O
sentences	O
'	O
surrounding	O
sentences	O
for	O
commonsense	O
inferences	O
(	O
e.g.	O
,	O
"	O
be	O
very	O
happy	O
"	O
"	O
happy	O
"	O
;	O
Figure	O
1	O
)	O
.	O
We	O
describe	O
this	O
algorithm	O
in	O
further	O
detail	O
in	O
Appendix	O
B.2	O
.	O
In	O
our	O
analyses	O
,	O
the	O
measure	O
quantifies	O
the	O
number	O
of	O
story	O
sentences	O
with	O
commonsense	O
tuple	O
matches	O
in	O
the	O
two	O
preceding	O
and	O
following	O
sentences	O
.	O

Informed	O
by	O
our	O
comprehensive	O
evaluation	O
,	O
we	O
augment	O
the	O
multilingual	O
XNLI	O
dataset	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2018	O
)	O
with	O
highlight	O
-	O
based	O
explanations	O
by	O
extracting	O
highlights	O
for	O
the	O
English	O
part	O
of	O
XNLI	O
and	O
projecting	O
along	O
word	O
alignments	O
to	O
other	O
languages	O
.	O
We	O
perform	O
a	O
plausibility	O
evaluation	O
with	O
the	O
resulting	O
dataset	O
,	O
which	O
we	O
dub	O
e	B-MethodName
-	O
XNLI	O
,	O
and	O
perform	O
a	O
human	O
evaluation	O
on	O
a	O
subset	O
of	O
the	O
dataset	O
to	O
validate	O
its	O
adequacy	O
.	O

We	O
provide	O
curriculum	O
samples	O
,	O
and	O
additional	O
details	O
for	O
quantitative	O
and	O
qualitative	O
experiments	O
.	O
For	O
quantitative	O
,	O
we	O
provide	O
details	O
about	O
parameter	O
ranges	O
for	O
model	O
selection	O
.	O
For	O
qualitative	O
experiments	O
,	O
we	O
provide	O
results	O
on	O
topic	O
modeling	O
,	O
show	O
counts	O
for	O
attended	O
courses	O
from	O
our	O
attention	O
module	O
,	O
comparative	O
word	O
cloud	O
analysis	O
with	O
TF	B-MethodName
-	I-MethodName
IDF	I-MethodName
,	O
and	O
attention	O
weights	O
for	O
the	O
best	O
baseline	O
competitor	O
.	O

Answer	O
generator	O
.	O
P	O
is	O
an	O
input	O
summary	O
representation	O
,	O
formed	O
by	O
concatenating	O
p	O
1	O
,	O
.	O
.	O
.	O
,	O
p	O
N	O
.	O
The	O
answer	O
generator	O
takesP	O
and	O
outputs	O
the	O
final	O
answer	O
autoregressively	O
.	O
Specifically	O
,	O
it	O
outputs	O
the	O
sequence	O
probability	O
for	O
y	O
as	O
follows	O
:	O
P	O
(	O
y|x	O
,	O
P	O
)	O
=	O
T	O
j=1	O
p	O
(	O
y	O
j	O
|y	O
<	O
j	O
,	O
x	O
,	O
P	O
)	O
.	O

Results	O
confirm	O
that	O
adding	O
structure	O
to	O
the	O
candidate	O
string	O
representations	O
via	O
[	O
SEP	O
]	O
tokens	O
leads	O
to	O
more	O
accurate	O
models	O
compared	O
to	O
generating	O
strings	O
by	O
concatenation	O
(	O
Table	O
3	O
)	O
.	O
Using	O
attributeseparators	O
instead	O
of	O
[	O
SEP	O
]	O
tokens	O
leads	O
to	O
an	O
absolute	O
gain	O
of	O
over	O
5	O
%	O
and	O
handling	O
unseen	O
attributes	O
via	O
attribute	O
-	O
OOV	O
further	O
increases	O
the	O
accuracy	O
to	O
56.2	O
%	O
,	O
a	O
7.1	O
%	O
increase	O
over	O
the	O
[	O
SEP	O
]	O
baseline	O
.	O
These	O
results	O
show	O
that	O
the	O
attributeseparators	O
capture	O
meaningful	O
information	O
about	O
attributes	O
,	O
even	O
when	O
only	O
a	O
small	O
number	O
of	O
attributes	O
from	O
the	O
training	O
data	O
(	O
15	O
)	O
are	O
observed	O
during	O
inference	O
.	O
Shuffling	O
attribute	O
-	O
value	O
pairs	O
before	O
converting	O
them	O
to	O
a	O
string	O
representation	O
using	O
attributeseparators	O
also	O
independently	O
provides	O
an	O
absolute	O
gain	O
of	O
3.5	O
%	O
over	O
the	O
model	O
which	O
uses	O
attribute	O
-	O
separators	O
without	O
shuffling	O
.	O
Overall	O
,	O
models	O
that	O
combine	O
attribute	O
-	O
shuffling	O
and	O
attribute	O
-	O
OOV	O
are	O
the	O
most	O
accurate	O
with	O
an	O
accuracy	O
of	O
61.6	O
%	O
,	O
which	O
represents	O
a	O
12	O
%	O
absolute	O
gain	O
over	O
the	O
best	O
baseline	O
model	O
.	O

B	O
Details	O
of	O
Fine	O
-	O
tuning	O
on	O
CoNLL	B-MethodName
Dataset	O

Contextualized	O
Representations	O
for	O
Entity	O
Linking	O
Models	O
in	O
this	O
work	O
are	O
based	O
on	O
BERT	B-MethodName
.	O
While	O
many	O
studies	O
have	O
tried	O
to	O
explain	O
the	O
effectiveness	O
of	O
BERT	B-MethodName
for	O
NLP	O
tasks	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
the	O
work	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019	O
)	O
is	O
most	O
relevant	O
as	O
they	O
use	O
probing	O
tasks	O
to	O
show	O
that	O
BERT	B-MethodName
encodes	O
knowledge	O
of	O
entities	O
.	O
This	O
has	O
also	O
been	O
shown	O
empirically	O
by	O
many	O
works	O
that	O
use	O
BERT	B-MethodName
and	O
other	O
contextualized	O
models	O
for	O
entity	O
linking	O
and	O
disambiguation	O
(	O
Broscheit	O
,	O
2019;Shahbazi	O
et	O
al	O
.	O
,	O
2019;Yamada	O
et	O
al	O
.	O
,	O
2020;Févry	O
et	O
al	O
.	O
,	O
2020;Poerner	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

where	O
τ	O
is	O
a	O
temperature	O
parameter	O
.	O
In	O
our	O
implementation	O
,	O
we	O
use	O
a	O
relatively	O
small	O
batch	O
size	O
of	O
128	O
,	O
resulting	O
in	O
more	O
frequent	O
parameter	O
updates	O
than	O
if	O
a	O
large	O
batch	O
size	O
were	O
used	O
.	O
Items	O
enqueued	O
early	O
on	O
can	O
thus	O
become	O
outdated	O
with	O
a	O
large	O
queue	O
,	O
so	O
we	O
scale	O
down	O
the	O
queue	O
size	O
to	O
K	O
=	O
32	O
,	O
000	O
to	O
prevent	O
the	O
queue	O
from	O
becoming	O
stale	O
.	O

In	O
this	O
case	O
,	O
the	O
adversarial	O
response	O
x	O
′	O
i+1	O
is	O
either	O
a	O
randomly	O
sampled	O
utterance	O
from	O
a	O
random	O
conversation	O
in	O
the	O
dataset	O
or	O
a	O
random	O
response	O
from	O
the	O
following	O
:	O
(	O
y	O
i+1	O
,	O
x	O
i+2	O
,	O
...	O
,	O
x	O
n	O
,	O
y	O
n	O
)	O
from	O
D.	O
(	O
See	O
Appendix	O
A	O
for	O
example	O
.	O
)	O
1	O
https	O
:	O
/	O
/	O
github.com	O
/	O
baber-sos	O
/	O
Explaining-Dialogue-Evaluation-Metrics-using-Adversarial-Behavioral-Analysis	O

(	O
4	O
)	O
.	O
DA	O
-	O
training	O
using	O
prompt	O
-	O
tuning	O
(	O
MLM	O
(	O
Prompt	O
)	O
)	O
(	O
Lester	O
et	O
al	O
.	O
,	O
2021	O
)	O
adds	O
a	O
sequence	O
of	O
prompt	O
tokens	O
to	O
the	O
end	O
of	O
the	O
original	O
sequence	O
.	O
In	O
DA	O
-	O
training	O
,	O
RoBERTa	B-MethodName
(	O
the	O
LM	O
)	O
is	O
fixed	O
and	O
only	O
the	O
prompt	O
tokens	O
are	O
trained	O
.	O
In	O
end	O
-	O
task	O
fine	O
-	O
tuning	O
,	O
both	O
LM	O
and	O
the	O
trained	O
prompt	O
are	O
trainable	O
.	O
We	O
initialize	O
100	O
tokens	O
and	O
set	O
the	O
learning	O
rate	O
of	O
the	O
prompt	O
token	O
to	O
0.3	O
in	O
DA	O
-	O
training	O
,	O
following	O
the	O
setting	O
in	O
Lester	O
et	O
al	O
.	O
(	O
2021	O
)	O
.	O

Our	O
research	O
's	O
potential	O
drawback	O
is	O
that	O
it	O
adds	O
to	O
the	O
training	O
burden	O
.	O
To	O
tackle	O
this	O
problem	O
,	O
we	O
introduce	O
two	O
techniques	O
to	O
reduce	O
training	O
costs	O
.	O
We	O
greatly	O
minimize	O
the	O
number	O
of	O
parameters	O
that	O
should	O
be	O
trained	O
as	O
well	O
as	O
the	O
training	O
time	O
without	O
sacrificing	O
performance	O
.	O
Notably	O
,	O
our	O
method	O
does	O
not	O
introduce	O
additional	O
overhead	O
for	O
inference	O
.	O
Therefore	O
,	O
we	O
can	O
achieve	O
a	O
large	O
performance	O
improvement	O
while	O
maintaining	O
the	O
original	O
fast	O
decoding	O
speed	O
.	O

Candidate	O
generation	O
Since	O
the	O
focus	O
of	O
our	O
experiments	O
is	O
on	O
re	O
-	O
ranking	O
,	O
we	O
use	O
a	O
fixed	O
candidate	O
generation	O
model	O
for	O
all	O
experiments	O
that	O
combines	O
the	O
architecture	O
of	O
Wu	O
et	O
al	O
.	O
(	O
2020	O
)	O
(	O
Section	O
3	O
)	O
with	O
[	O
SEP]-separation	O
to	O
generate	O
candidate	O
strings	O
.	O
This	O
model	O
also	O
has	O
no	O
knowledge	O
of	O
the	O
test	O
KB	O
and	O
is	O
trained	O
only	O
once	O
on	O
the	O
CoNLL	B-MethodName
-	O
Wikidata	O
dataset	O
.	O
It	O
achieves	O
a	O
recall@32	O
of	O
91.25	O
when	O
evaluated	O
on	O
the	O
unseen	O
TAC	B-MethodName
-	I-DatasetName
KBP	I-MethodName
2010	O
data	O
.	O

Effect	O
of	O
Positional	O
kernel	O
's	O
dimension	O
As	O
stated	O
previously	O
in	O
Equation	O
(	O
22	O
ferent	O
d	O
p	O
with	O
the	O
BLEU	B-MethodName
score	O
.	O
Figure	O
3	O
shows	O
the	O
result	O
of	O
ablation	O
experiment	O
on	O
the	O
validation	O
dataset	O
,	O
i.e.	O
the	O
newstest2013	O
dataset	O
.	O
Notably	O
,	O
d	O
p	O
=	O
96	O
has	O
a	O
detrimental	O
effect	O
on	O
the	O
performance	O
of	O
PosNet	B-MethodName
-	O
Embed	I-MethodName
and	O
d	O
p	O
=	O
128	O
with	O
the	O
best	O
performance	O
.	O
Thereby	O
,	O
we	O
conduct	O
the	O
experiments	O
on	O
the	O
PosNet	O
-	O
Embed	I-MethodName
in	O
Table	O
1	O
with	O

We	O
conduct	O
an	O
additional	O
experiment	O
to	O
analyze	O
the	O
behavior	O
of	O
baseline	O
models	O
on	O
single	O
-	O
time	O
granularity	O
datasets	O
.	O
We	O
partition	O
MULTITQ	B-MethodName
by	O
time	O
granularity	O
,	O
ensuring	O
that	O
there	O
is	O
only	O
single	O
granularity	O
of	O
time	O
in	O
each	O
divided	O
dataset	O
(	O
Day	O
,	O
Month	O
,	O
and	O
Year	O
)	O
.	O
At	O
the	O
setting	O
of	O
single	O
-	O
day	O
,	O
since	O
the	O
temporal	O
granularity	O
of	O
KG	B-MethodName
coincides	O
with	O
that	O
of	O
the	O
dataset	O
,	O
our	O
model	O
degenerates	O
to	O
CronKGQA	B-MethodName
.	O

Argument	O
Aspect	O
Detection	O
Early	O
work	O
by	O
Fujii	O
and	O
Ishikawa	O
(	O
2006	O
)	O
focuses	O
mainly	O
on	O
Japanese	O
and	O
restricts	O
aspects	O
to	O
noun	O
-	O
and	O
verb	O
-	O
phrases	O
,	O
extracted	O
via	O
hand	O
-	O
crafted	O
rules	O
.	O
Boltužić	O
and	O
Šnajder	O
(	O
2017	O
)	O
extract	O
noun	O
-	O
phrases	O
and	O
aggregate	O
them	O
into	O
concepts	O
to	O
analyze	O
the	O
microstructure	O
of	O
claims	O
.	O
Misra	O
et	O
al	O
.	O
(	O
2015	O
)	O
introduce	O
facets	O
as	O
low	O
level	O
issues	O
,	O
used	O
to	O
support	O
or	O
attack	O
an	O
argumentation	O
.	O
In	O
that	O
,	O
facets	O
are	O
conceptually	O
similar	O
to	O
aspects	O
,	O
but	O
not	O
explicitly	O
phrased	O
and	O
instead	O
seen	O
as	O
abstract	O
concepts	O
that	O
define	O
clusters	O
of	O
semantically	O
similar	O
text	O
-	O
spans	O
of	O
summaries	O
.	O
Bilu	O
et	O
al	O
.	O
(	O
2019	O
)	O
define	O
commonplace	O
arguments	O
that	O
are	O
valid	O
in	O
several	O
situations	O
for	O
specified	O
actions	O
(	O
e.g.	O
"	O
ban	O
"	O
)	O
and	O
topics	O
(	O
e.g.	O
"	O
smoking	O
"	O
)	O
.	O
These	O
actions	O
are	O
similar	O
to	O
aspects	O
,	O
but	O
limited	O
in	O
number	O
and	O
manually	O
defined	O
.	O
Gemechu	O
and	O
Reed	O
(	O
2019	O
)	O
detect	O
,	O
amongst	O
others	O
,	O
concepts	O
and	O
aspects	O
in	O
arguments	O
with	O
models	O
trained	O
on	O
expert	O
annotations	O
.	O
However	O
,	O
in	O
their	O
definition	O
,	O
aspects	O
have	O
to	O
point	O
to	O
a	O
target	O
concept	O
mentioned	O
in	O
the	O
argument	O
.	O
In	O
our	O
definition	O
,	O
aspects	O
refer	O
to	O
a	O
general	O
topic	O
which	O
is	O
not	O
necessarily	O
part	O
of	O
the	O
sentence	O
and	O
our	O
annotation	O
scheme	O
is	O
applicable	O
by	O
non	O
-	O
experts	O
.	O

Another	O
recent	O
advance	O
in	O
ICL	B-MethodName
,	O
namely	O
Calibrate	O
Before	I-MethodName
Use	O
(	O
CBU	O
)	O
,	O
involves	O
calibrating	O
the	O
output	O
likelihood	O
of	O
the	O
word	O
tokens	O
that	O
correspond	O
to	O
the	O
labels	O
(	O
Zhao	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
We	O
conduct	O
the	O
same	O
set	O
of	O
experiments	O
with	O
CBU	O
applied	O
and	O
report	O
all	O
three	O
metrics	O
.	O
As	O
shown	O
in	O
Figure	O
6	O
,	O
the	O
calibration	O
technique	O
reduces	O
the	O
label	O
sensitivity	O
while	O
generally	O
improving	O
the	O
ICL	B-MethodName
performance	O
on	O
both	O
GPT	B-MethodName
-	O
J	I-MethodName
and	O
GPT	B-MethodName
-	O
NeoX.	I-MethodName
Applying	O
CBU	O
can	O
be	O
an	O
effective	O
way	O
to	O
reduce	O
label	O
sensitivity	O
while	O
not	O
sacrificing	O
the	O
performance	O
.	O
Figure	O
6	O
:	O
The	O
effect	O
of	O
applying	O
Calibrate	O
Before	I-MethodName
Use	O
(	O
CBU	O
)	O
(	O
Zhao	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Label	O
sensitivity	O
decreases	O
but	O
the	O
ground	O
-	O
truth	O
label	O
accuracy	O
improves	O
,	O
making	O
CBU	O
ideal	O
for	O
sensitivity	O
reduction	O
.	O
This	O
trend	O
is	O
more	O
apparent	O
in	O
the	O
larger	O
GPT	O
-	O
variant	O
,	O
GPT	B-MethodName
-	I-MethodName
NeoX	I-MethodName
(	O
20B	O
)	O
.	O

This	O
section	O
motivates	O
the	O
importance	O
of	O
queryawareness	O
for	O
document	O
understanding	O
,	O
then	O
compares	O
and	O
contrasts	O
with	O
existing	O
approaches	O
.	O

Based	O
on	O
the	O
ranking	O
of	O
triples	O
,	O
ValCAT	B-MethodName
performs	O
perturbations	O
in	O
a	O
sequential	O
manner	O
,	O
where	O
each	O
step	O
a	O
vulnerable	O
position	O
in	O
the	O
original	O
text	O
is	O
replaced	O
by	O
or	O
inserted	O
with	O
a	O
set	O
of	O
adversarial	O
spans	O
generated	O
by	O
the	O
encoder	O
-	O
decoder	O
language	O
model	O
.	O
The	O
variable	O
-	O
length	O
feature	O
of	O
the	O
adversarial	O
spans	O
renders	O
the	O
language	O
model	O
enough	O
space	O
to	O
produce	O
more	O
contextually	O
appropriate	O
candi	O
-	O
dates	O
to	O
improve	O
fluency	O
.	O
Meanwhile	O
,	O
our	O
variablelength	O
method	O
expands	O
the	O
perturbation	O
units	O
,	O
for	O
it	O
supports	O
multi	O
-	O
word	O
transformations	O
while	O
is	O
compatible	O
with	O
traditional	O
one	O
-	O
to	O
-	O
one	O
transformations	O
.	O

Our	O
baseline	O
is	O
adopted	O
from	O
the	O
parsing	O
model	O
of	O
Kitaev	O
and	O
Klein	O
(	O
2018	O
)	O
and	O
.	O
Given	O
a	O
sentence	O
X	O
=	O
{	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
}	O
,	O
its	O
corresponding	O
constituency	O
parse	O
tree	O
T	O
is	O
composed	O
by	O
a	O
set	O
of	O
labeled	O
spans	O

Tab	O
.	O
1	O
shows	O
the	O
results	O
on	O
En	B-MethodName
-	O
De	I-MethodName
,	O
inputting	O
-	O
level	O
cross	O
-	O
lingual	O
PE	O
(	O
+	O
InXL	O
PE	O
)	O
and	O
head	O
-	O
level	O
crosslingual	O
PE	O
(	O
+	O
HeadXL	O
PE	O
)	O
outperform	O
Transformer	B-MethodName
BIG	O
by	O
0.30	O
and	O
0.36	O
BLEU	B-MethodName
points	O
,	O
and	O
combining	O
these	O
two	O
strategies	O
2	O
achieves	O
a	O
0.69	O
BLEU	B-MethodName
point	O
increase	O
.	O
For	O
Ja	B-MethodName
-	O
En	I-MethodName
,	O
Zh	B-MethodName
-	O
En	O
,	O
and	O
En	B-MethodName
-	O
Zh	O
(	O
Tab	O
.	O
2	O
)	O
,	O
we	O
observe	O
a	O
similar	O
phenomenon	O
,	O
demonstrating	O
that	O
XL	O
PE	I-MethodName
on	O
SANs	B-MethodName
do	O
improve	O
the	O
translation	O
performance	O
for	O
several	O
language	O
pairs	O
.	O
It	O
is	O
worth	O
noting	O
that	O
our	O
approach	O
introduces	O
nearly	O
no	O
additional	O
parameters	O
(	O
+0.01	O
M	O
over	O
282.55	O
M	O
)	O
.	O

To	O
evaluate	O
the	O
plausibility	O
of	O
attribution	O
methods	O
,	O
we	O
measure	O
agreement	O
with	O
human	O
rationales	O
,	O
following	O
Atanasova	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
This	O
evaluation	O
measures	O
how	O
much	O
the	O
attribution	O
scores	O
overlap	O
with	O
human	O
annotations	O
by	O
calculating	O
Mean	O
Average	O
Precision	O
(	O
MAP	O
)	O
across	O
a	O
dataset	O
.	O
For	O
each	O
instance	O
in	O
the	O
dataset	O
,	O
Average	O
Precision	O
(	O
AP	O
)	O
is	O
calculated	O
by	O
comparing	O
attribution	O
scores	O
ω	O
(	O
i	O
)	O
with	O
gold	O
rationales	O
,	O
w	O
(	O
i	O
)	O
,	O
where	O
ω	O
(	O
i	O
)	O
stands	O
for	O
the	O
attribution	O
scores	O
calculated	O
for	O
the	O
dataset	O
instance	O
x	O
(	O
i	O
)	O
and	O
w	O
(	O
i	O
)	O
stands	O
for	O
the	O
sequence	O
of	O
binary	O
labels	O
indicating	O
whether	O
the	O
token	O
is	O
annotated	O
as	O
the	O
rationale	O
.	O
For	O
a	O
dataset	O
X	O
=	O
{	O
x	O
(	O
i	O
)	O
|i	O
∈	O
[	O
1	O
,	O
M	O
]	O
}	O
,	O
the	O
MAP	O
score	O
is	O
defined	O
as	O
:	O

Given	O
:	O
Input	O
sequence	O
x	O
,	O
number	O
of	O
negative	O
samples	O
k	O
,	O
noise	O
distribution	O
q	O
,	O
modelp	O
θ	O
.	O
1	O
.	O
Pick	O
k	O
unique	O
random	O
positions	O
R	O
=	O
{	O
r	O
1	O
,	O
...	O
,	O
r	O
k	O
}	O
where	O
each	O
r	O
i	O
is	O
1	O
≤	O
r	O
i	O
≤	O
n.	O

Data	O
collection	O
processes	O
for	O
AER	B-MethodName
datasets	O
vary	O
in	O
terms	O
of	O
recording	O
conditions	O
,	O
emotional	O
elicitation	O
scheme	O
,	O
and	O
annotation	O
procedure	O
,	O
etc	O
.	O
This	O
work	O
was	O
tested	O
on	O
two	O
typical	O
datasets	O
:	O
IEMO	B-MethodName
-	I-MethodName
CAP	I-MethodName
and	O
MSP	B-MethodName
-	O
Podcast	O
.	O
The	O
two	O
datasets	O
are	O
both	O
publicly	O
available	O
and	O
differ	O
in	O
various	O
aspects	O
:	O

Task	O
2	O
:	O
Constrained	O
Sentence	O
Generation	O
(	O
CG	O
)	O
Generating	O
texts	O
is	O
a	O
direct	O
manifestation	O
of	O
a	O
model	O
's	O
belief	O
.	O
However	O
,	O
evaluating	O
generated	O
texts	O
is	O
notoriously	O
difficult	O
in	O
NLP	O
,	O
especially	O
without	O
references	O
.	O
Therefore	O
,	O
we	O
design	O
a	O
keywordto	O
-	O
sentence	O
task	O
to	O
make	O
the	O
probing	O
more	O
controllable	O
,	O
which	O
is	O
similar	O
to	O
COMMONGEN	O
(	O
Lin	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Given	O
a	O
triple	O
<	O
s	O
,	O
r	O
,	O
o	O
>	O
,	O
models	O
need	O
to	O
generate	O
sentences	O
grounded	O
in	O
(	O
negative	O
)	O
knowledge	O
,	O
i.e.	O
,	O
add	O
negation	O
cues	O
(	O
e.g.	O
,	O
not	O
,	O
unable	O
)	O
in	O
the	O
sentence	O
if	O
necessary	O
,	O
e.g.	O
,	O
Write	O
a	O
short	O
and	O
factual	O
sentence	O
according	O
to	O
commonsense	O
based	O
on	O
the	O
keywords	O
:	O
(	O
Examples	O
for	O
in	O
-	O
context	O
learning	O
)	O
Keywords	O
:	O
lion	O
,	O
located	O
at	O
,	O
ocean	O
Sentence	O
:	O
lions	O
do	O
n't	O
live	O
in	O
the	O
ocean	O
.	O

•	O
topic	O
:	O
The	O
topic	O
of	O
the	O
argument	O
.	O

A	O
second	O
type	O
of	O
approach	O
begins	O
with	O
various	O
methods	O
for	O
word	O
sense	O
induction	O
,	O
then	O
measures	O
change	O
in	O
terms	O
of	O
the	O
relative	O
prevalence	O
of	O
a	O
term	O
's	O
different	O
senses	O
(	O
Frermann	O
and	O
Lapata	O
,	O
2016	O
;	O
Hu	O
et	O
al	O
.	O
,	O
2019	O
;	O
Arefyev	O
and	O
Zhikov	O
,	O
2020	O
;	O
Arefyev	O
and	O
Bykov	O
,	O
2021	O
)	O
.	O
In	O
some	O
cases	O
,	O
authors	O
simply	O
cluster	O
contextual	O
representations	O
for	O
each	O
term	O
,	O
and	O
measure	O
differences	O
in	O
the	O
distributions	O
of	O
clusters	O
between	O
two	O
time	O
periods	O
,	O
rather	O
than	O
dealing	O
with	O
explicit	O
word	O
senses	O
(	O
Giulianelli	O
et	O
al	O
.	O
,	O
2020	O
;	O
Martinc	O
et	O
al	O
.	O
,	O
2020b	O
;	O
Montariol	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O

Step	O
2c	O
:	O
Creating	O
the	O
annotation	O
data	O
For	O
each	O
of	O
the	O
four	O
topics	O
that	O
are	O
part	O
of	O
the	O
preliminary	O
annotation	O
dataset	O
,	O
we	O
use	O
the	O
in	O
-	O
topic	O
model	O
to	O
predict	O
aspects	O
of	O
629	O
randomly	O
chosen	O
,	O
unseen	O
arguments	O
from	O
the	O
UKP	B-MethodName
-	O
Corpus	I-MethodName
.	O
For	O
the	O
other	O
four	O
topics	O
of	O
the	O
UKP	B-MethodName
-	I-MethodName
Corpus	I-MethodName
,	O
we	O
choose	O
the	O
best	O
cross	O
-	O
topic	O
model	O
to	O
predict	O
aspects	O
for	O
the	O
same	O
amount	O
of	O
samples	O
.	O
To	O
keep	O
a	O
recall	O
of	O
at	O
least	O
80	O
%	O
,	O
we	O
choose	O
the	O
ten	O
and	O
fifteen	O
highest	O
-	O
ranked	O
aspect	O
candidates	O
for	O
samples	O
as	O
predicted	O
by	O
the	O
in	O
-	O
topic	O
and	O
cross	O
-	O
topic	O
model	O
,	O
respectively	O
.	O
We	O
remove	O
aspect	O
candidates	O
that	O
include	O
punctuation	O
,	O
begin	O
or	O
end	O
with	O
stopwords	O
,	O
or	O
contain	O
digits	O
.	O

BERT	B-MethodName
is	O
a	O
Transformer	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
encoder	O
pre	O
-	O
trained	O
by	O
jointly	O
optimizing	O
two	O
unsupervised	O
objectives	O
:	O
masked	O
language	O
model	O
and	O
next	O
sentence	O
prediction	O
.	O
It	O
uses	O
WordPiece	O
(	O
WP	O
,	O
Wu	O
et	O
al	O
.	O
(	O
2016	O
)	O
)	O
subword	O
tokens	O
along	O
with	O
positional	O
embeddings	O
as	O
input	O
,	O
and	O
gradually	O
constructs	O
sentence	O
representations	O
by	O
applying	O
tokenlevel	O
self	O
-	O
attention	O
pooling	O
over	O
a	O
stack	O
of	O
layers	O
L.	O
The	O
result	O
of	O
BERT	B-MethodName
encoding	O
is	O
a	O
layer	O
-	O
wise	O
representation	O
of	O
the	O
input	O
wordpiece	O
tokens	O
with	O
higher	O
layers	O
representing	O
higher	O
-	O
level	O
abstractions	O
over	O
the	O
input	O
sequence	O
.	O
Thanks	O
to	O
the	O
joint	O
pre	O
-	O
training	O
objective	O
,	O
BERT	B-MethodName
can	O
encode	O
words	O
and	O
sentences	O
in	O
a	O
unified	O
fashion	O
:	O
the	O
encoding	O
of	O
a	O
sentence	O
or	O
a	O
sentence	O
pair	O
is	O
stored	O
in	O
a	O
special	O
token	O
[	O
CLS	O
]	O
.	O

Typically	O
,	O
models	O
for	O
candidate	O
generation	O
are	O
less	O
complex	O
(	O
and	O
hence	O
,	O
less	O
precise	O
)	O
than	O
those	O
used	O
in	O
the	O
following	O
(	O
re	O
-	O
ranking	O
)	O
stage	O
since	O
they	O
handle	O
all	O
entities	O
in	O
KB	O
.	O

Were	O
you	O
able	O
to	O
reproduce	O
the	O
results	O
of	O
the	O
paper	O
?	O

However	O
,	O
we	O
also	O
notice	O
that	O
concatenating	O
the	O
context	O
does	O
not	O
help	O
improve	O
the	O
performance	O
of	O
H2H+CXT	B-MethodName
based	O
on	O
MBart-50M2	B-MethodName
M	O
and	O
M2M100	O
in	O
the	O
setting	O
of	O
En	B-MethodName
-	O
De	I-MethodName
and	O
En	O
-	O
Ja	O
,	O
and	O
the	O
setting	O
of	O
En	B-MethodName
-	I-MethodName
Es	I-MethodName
and	O
En	B-MethodName
-	I-MethodName
Fr	I-MethodName
,	O
respectively	O
.	O
We	O
hypothesize	O
that	O
the	O
decrease	O
of	O
BLEU	B-MethodName
score	O
comes	O
from	O
the	O
noise	O
brought	O
by	O
the	O
context	O
.	O

Our	O
primary	O
experiments	O
focus	O
on	O
the	O
first	O
two	O
research	O
questions	O
and	O
study	O
the	O
accuracy	O
of	O
the	O
model	O
that	O
uses	O
the	O
re	O
-	O
ranking	O
architecture	O
from	O
Section	O
3	O
with	O
the	O
three	O
core	O
components	O
introduced	O
in	O
Section	O
4	O
viz	O
.	O
attribute	O
-	O
separators	O
to	O
generate	O
string	O
representations	O
of	O
candidates	O
,	O
along	O
with	O
attribute	O
-	O
OOV	O
and	O
attribute	O
-	O
shuffle	O
for	O
regularization	O
.	O
We	O
compare	O
this	O
against	O
two	O
baselines	O
without	O
these	O
components	O
that	O
use	O
the	O
same	O
architecture	O
and	O
use	O
concatenation	O
and	O
[	O
SEP]separation	O
instead	O
of	O
attribute	O
-	O
separators	O
.	O
As	O
a	O
reminder	O
,	O
all	O
models	O
are	O
trained	O
as	O
well	O
as	O
validated	O
on	O
CoNLL	B-MethodName
-	I-MethodName
Wikidata	I-MethodName
and	O
evaluated	O
on	O
the	O
completely	O
unseen	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
2010	O
test	O
set	O
.	O

Lastly	O
,	O
some	O
works	O
build	O
on	O
large	O
LMs	O
(	O
LLMs	O
)	O
via	O
special	O
fine	O
-	O
tuning	O
or	O
inference	O
techniques	O
.	O
Chain	O
-	O
of	O
-	O
thought	O
prompting	O
prompts	O
LLMs	O
to	O
generate	O
intermediates	O
steps	O
before	O
reaching	O
the	O
final	O
answer	O
.	O
Cobbe	O
et	O
al	O
.	O
(	O
2021	O
)	O
fine	O
-	O
tunes	O
a	O
model	O
as	O
a	O
verifier	O
and	O
applies	O
the	O
verifier	O
to	O
rank	O
outputs	O
in	O
the	O
decoding	O
phase	O
.	O
are	O
using	O
a	O
majority	O
vote	O
among	O
outputs	O
to	O
select	O
the	O
best	O
answer	O
.	O
Lewkowycz	O
et	O
al	O
.	O
(	O
2022	O
)	O
fine	O
-	O
tunes	O
an	O
LLM	O
by	O
a	O
large	O
collection	O
of	O
math	O
-	O
specific	O
datasets	O
combining	O
existing	O
tech	O
-	O
Table	O
4	O
:	O
Demonstrations	O
of	O
generated	O
solutions	O
comparing	O
planning	O
-	O
LM	O
and	O
chain	O
-	O
of	O
-	O
thought	O
.	O
Question	O
1	O
shows	O
the	O
intermediate	O
step	O
of	O
chain	O
-	O
of	O
-	O
thought	O
has	O
wrong	O
reasoning	O
but	O
still	O
reaches	O
the	O
final	O
answer	O
.	O
Question	O
2	O
shows	O
that	O
planning	O
-	O
LM	O
results	O
in	O
a	O
better	O
reasoning	O
strategy	O
since	O
the	O
calculation	O
process	O
is	O
simple	O
and	O
more	O
concrete	O
.	O

ing	O
amounts	O
of	O
parallel	O
data	O
,	O
we	O
observe	O
that	O
600k	O
per	O
language	O
is	O
our	O
sweet	O
spot	O
considering	O
the	O
trade	O
-	O
off	O
between	O
resource	O
and	O
performance	O
.	O
Going	O
up	O
to	O
2	O
M	O
helps	O
on	O
XNLI	O
,	O
but	O
less	O
significantly	O
compared	O
to	O
the	O
gain	O
going	O
from	O
250k	O
to	O
600k	O
.	O
On	O
MLQA	O
,	O
surprisingly	O
,	O
250k	O
slightly	O
outperforms	O
the	O
other	O
two	O
for	O
translate	O
-	O
train	O
.	O

Le	O
chronomètre	O
A601X	O
dispose	O
calendrier	O
cumulative	O
-	O
split	O
.	O
gold	O
MQM	O
score	O
0.167	O
BiRNN	O
-0.248	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
-0.002	O
Table	O
3	O
:	O
Example	O
of	O
performance	O
of	O
sentence	O
-	O
level	O
multimodal	O
QE	O
.	O
Compared	O
to	O
the	O
baseline	O
prediction	O
(	O
BiRNN	O
)	O
,	O
the	O
prediction	O
from	O
the	O
best	O
multimodal	O
model	O
(	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
)	O
is	O
closer	O
to	O
the	O
gold	O
MQM	O
score	O
.	O
This	O
could	O
be	O
because	O
the	O
word	O
stopwatch	O
is	O
correctly	O
translated	O
as	O
chronomètre	O
in	O
French	O
,	O
and	O
the	O
additional	O
visual	O
feature	O
confirms	O
it	O
.	O
This	O
could	O
lead	O
to	O
an	O
increase	O
in	O
the	O
predicted	O
score	O
to	O
reward	O
the	O
correct	O
part	O
,	O
despite	O
the	O
poor	O
translation	O
(	O
extracted	O
from	O
the	O
Amazon	O
Reviews	O
Dataset	O
of	O
McAuley	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O

The	O
intended	O
use	O
of	O
our	O
code	O
is	O
for	O
academic	O
research	O
.	O
We	O
consider	O
probing	O
publicly	O
available	O
PLMs	O
,	O
which	O
are	O
made	O
available	O
for	O
research	O
as	O
well	O
as	O
end	O
use	O
cases	O
,	O
to	O
be	O
within	O
the	O
intended	O
use	O
of	O
PLMs	O
.	O

3	O
.	O
We	O
conduct	O
extensive	O
experiments	O
on	O
three	O
benchmark	O
datasets	O
.	O
The	O
results	O
show	O
that	O
ASoul	B-MethodName
consistently	O
improves	O
the	O
OOD	B-MethodName
detection	O
performance	O
,	O
and	O
it	O
obtains	O
new	O
SOTA	O
results	O
.	O

When	O
implementing	O
AFLite	B-MethodName
,	O
we	O
follow	O
Sakaguchi	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
We	O
use	O
a	O
smaller	O
training	O
set	O
size	O
of	O
m	O
=	O
5620	O
,	O
but	O
keep	O
the	O
remaining	O
hyperparameters	O
unchanged	O
,	O
such	O
that	O
the	O
ensemble	O
consists	O
of	O
n	O
=	O
64	O
logistic	O
regression	O
models	O
,	O
the	O
filtering	O
cutoff	O
,	O
k	O
=	O
500	O
,	O
and	O
the	O
filtering	O
threshold	O
τ	O
=	O
0.75	O
.	O

Similarly	O
,	O
the	O
statistical	O
model	O
(	O
Table	O
4	O
)	O
shows	O
that	O
both	O
main	O
factor	O
of	O
DaV	B-MethodName
-	O
B	O
(	O
β	O
=	O
0.0106	O
,	O
p	O
<	O
1e-15	O
)	O
and	O
its	O
interaction	O
with	O
paraphrase	O
ratio	O
(	O
β	O
=	O
0.0078	O
,	O
p	O
<	O
1e-15	O
)	O
are	O
positive	O
and	O
significant	O
,	O
indicating	O
that	O
as	O
P	O
increases	O
DaV	B-MethodName
-	I-MethodName
B	I-MethodName
has	O
significantly	O
more	O
improvement	O
than	O
the	O
reference	O
model	O
(	O
Ada	O
-	O
A	O
)	O
but	O
other	O
paraphrases	O
do	O
not	O
show	O
such	O
a	O
pattern	O
as	O
the	O
main	O
factors	O
are	O
all	O
insignificant	O
and	O
interactions	O
are	O
inconsistent	O
.	O

-DOCSTART-	O
Multilingual	O
BERT	O
Post	O
-	O
Pretraining	O
Alignment	O

Next	O
,	O
we	O
find	O
that	O
,	O
in	O
most	O
situations	O
,	O
the	O
performance	O
of	O
H2H	O
can	O
be	O
further	O
boosted	O
by	O
concatenating	O
the	O
constructed	O
context	O
from	O
the	O
table	O
.	O
Taking	O
H2H+CXT	B-MethodName
based	O
on	O
M2M-100	O
as	O
an	O
example	O
,	O
comparing	O
with	O
H2H	O
,	O
H2H+CXT	B-MethodName
obtains	O
2.1	O
,	O
0.6	O
,	O
and	O
1.6	O
points	O
of	O
improvement	O
in	O
En	O
-	O
Zh	O
,	O
En	O
-	O
De	O
,	O
and	O
En	O
-	O
Ja	O
settings	O
,	O
respectively	O
.	O
In	O
terms	O
of	O
H2H+CXT	O
based	O
on	O
MBart-50M2	O
M	O
,	O
the	O
concatenation	O
of	O
context	O
also	O
boosts	O
the	O
BLEU	B-MethodName
score	O
for	O
translating	O
schema	O
from	O
En	O
to	O
Zh	O
and	O
Es	O
by	O
1.5	O
and	O
1.2	O
.	O
The	O
observations	O
demonstrate	O
the	O
benefits	O
of	O
making	O
good	O
use	O
of	O
the	O
constructed	O
context	O
.	O

Data	O
.	O
We	O
use	O
two	O
data	O
sources	O
:	O
the	O
Penn	O
Treebank	I-MethodName
(	O
Marcus	O
et	O
al	O
.	O
,	O
1993	O
)	O
for	O
English	O
constituency	O
parsing	O
and	O
Statistical	O
Parsing	O
of	O
Morphologically	O
Rich	O
Languages	O
(	O
SPMRL	O
)	O
2013	O
/	O
2014	O
shared	O
tasks	O
(	O
Seddah	O
et	O
al	O
.	O
,	O
2013	O
(	O
Seddah	O
et	O
al	O
.	O
,	O
,	O
2014	O
for	O
8	O
languages	O
:	O
Basque	O
,	O
French	O
,	O
German	O
,	O
Hebrew	O
,	O
Hungarian	O
,	O
Korean	O
,	O
Polish	O
,	O
and	O
Swedish	O
.	O
We	O
provide	O
the	O
dataset	O
statistics	O
in	O
Table	O
5	O
.	O
We	O
perform	O
similar	O
preprocessing	O
as	O
Kitaev	O
and	O
Klein	O
(	O
2020	O
)	O
,	O
which	O
we	O
explain	O
in	O
App	O
.	O
F.	O
For	O
evaluation	O
,	O
the	O
EVALB	B-MethodName
Perl	O
script	O
9	O
is	O
used	O
to	O
calculate	O
FMeasure	O
of	O
the	O
parse	O
tree	O
.	O
We	O
use	O
only	O
one	O
GPU	O
node	O
for	O
the	O
reported	O
inference	O
times	O
.	O
Further	O
experimental	O
details	O
can	O
be	O
found	O
in	O
App	O
.	O
G	O
.	O

Position	O
embedding	O
represents	O
the	O
position	O
of	O
the	O
token	O
in	O
a	O
word	O
sequence	O
.	O
A	O
word	O
and	O
an	O
entity	O
appearing	O
at	O
the	O
i	O
-	O
th	O
position	O
in	O
the	O
sequence	O
are	O
represented	O
as	O
D	O
i	O
and	O
E	O
i	O
,	O
respectively	O
.	O
If	O
an	O
entity	O
mention	O
contains	O
multiple	O
words	O
,	O
its	O
position	O
embedding	O
is	O
computed	O
by	O
averaging	O
the	O
embeddings	O
of	O
the	O
corresponding	O
positions	O
(	O
see	O
Figure	O
2	O
)	O
.	O
Following	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
we	O
tokenize	O
the	O
document	O
text	O
using	O
the	O
BERT	B-MethodName
's	O
wordpiece	O
tokenizer	O
,	O
and	O
insert	O
[	O
CLS	O
]	O
and	O
[	O
SEP	O
]	O
tokens	O
as	O
the	O
first	O
and	O
last	O
words	O
,	O
respectively	O
.	O

•	O
MRPC	O
:	O
Microsoft	O
Research	O
Paraphrase	O
Corpus	O
(	O
Dolan	O
and	O
Brockett	O
,	O
2005	O
)	O
.	O
The	O
task	O
is	O
to	O
predict	O
whether	O
two	O
sentences	O
are	O
semantically	O
equivalent	O
or	O
not	O
.	O
The	O
dataset	O
contains	O
3.7k	O
train	O
examples	O
from	O
online	O
news	O
sources	O
.	O

Although	O
we	O
view	O
this	O
work	O
as	O
an	O
important	O
step	O
towards	O
better	O
understanding	O
and	O
evaluation	O
of	O
coherence	O
in	O
summaries	O
,	O
we	O
acknowledge	O
there	O
is	O
much	O
more	O
to	O
do	O
here	O
.	O
In	O
this	O
work	O
,	O
we	O
only	O
collect	O
annotations	O
and	O
analyze	O
coherence	O
errors	O
in	O
summaries	O
of	O
English	O
language	O
books	O
and	O
movie	O
screenplays	O
.	O
Our	O
proposed	O
taxonomy	O
may	O
not	O
cover	O
errors	O
made	O
by	O
text	O
summarization	O
models	O
for	O
other	O
languages	O
and	O
our	O
trained	O
models	O
and	O
analysis	O
are	O
Englishspecific	O
.	O

The	O
first	O
scheme	O
,	O
which	O
we	O
call	O
attribute	O
-	O
OOV	O
,	O
prevents	O
models	O
from	O
overtly	O
relying	O
on	O
individual	O
[	O
K	O
i	O
]	O
tokens	O
and	O
generalize	O
to	O
attributes	O
that	O
are	O
not	O
seen	O
during	O
training	O
.	O
Analogous	O
to	O
how	O
out	O
-	O
of	O
-	O
vocabulary	O
tokens	O
are	O
commonly	O
handled	O
(	O
Dyer	O
et	O
al	O
.	O
,	O
2015	O
,	O
inter	O
alia	O
)	O
,	O
every	O
[	O
K	O
i	O
]	O
token	O
is	O
stochastically	O
replaced	O
with	O
the	O
[	O
SEP	O
]	O
token	O
during	O
training	O
with	O
probability	O
p	O
drop	O
.	O
This	O
encourages	O
the	O
model	O
to	O
encode	O
semantics	O
of	O
the	O
attributes	O
in	O
not	O
only	O
the	O
[	O
K	O
i	O
]	O
tokens	O
,	O
but	O
also	O
in	O
the	O
[	O
SEP	O
]	O
token	O
,	O
which	O
is	O
used	O
when	O
unseen	O
attributes	O
are	O
encountered	O
during	O
inference	O
.	O

Figure	O
2	O
:	O
The	O
screen	O
of	O
the	O
developed	O
grading	O
system	O
for	O
a	O
participant	O
to	O
annotate	O
an	O
answer	O
in	O
Study	O
1	O
:	O
1	O
gives	O
annotation	O
instruction	O
to	O
a	O
participant	O
;	O
2	O
displays	O
the	O
same	O
answer	O
that	O
the	O
participant	O
scored	O
in	O
the	O
previous	O
screen	O
;	O
and	O
3	O
allows	O
a	O
participant	O
to	O
remove	O
to	O
all	O
existing	O
annotations	O
and	O
start	O
the	O
annotation	O
from	O
scratch	O
again	O
,	O
and	O
the	O
participant	O
is	O
informed	O
that	O
annotation	O
is	O
not	O
mandatory	O
if	O
she	O
believes	O
that	O
there	O
is	O
nothing	O
contributing	O
/	O
hurting	O
the	O
quality	O
of	O
the	O
answer	O
.	O

Our	O
probing	O
methodology	O
builds	O
upon	O
the	O
edge	O
and	O
layer	O
probing	O
framework	O
.	O
The	O
encoding	O
produced	O
by	O
a	O
frozen	O
BERT	B-MethodName
model	O
can	O
be	O
seen	O
as	O
a	O
layer	O
-	O
wise	O
snapshot	O
that	O
reflects	O
how	O
the	O
model	O
has	O
constructed	O
the	O
high	O
-	O
level	O
abstractions	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
introduce	O
the	O
edge	O
probing	O
task	O
design	O
:	O
a	O
simple	O
classifier	O
is	O
tasked	O
with	O
predicting	O
a	O
linguistic	O
property	O
given	O
a	O
pair	O
of	O
spans	O
encoded	O
using	O
a	O
frozen	O
pre	O
-	O
trained	O
model	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
use	O
edge	O
probing	O
to	O
analyse	O
the	O
layer	O
utilization	O
of	O
a	O
pre	O
-	O
trained	O
BERT	B-MethodName
model	O
via	O
scalar	O
mixing	O
weights	O
learned	O
during	O
training	O
.	O
We	O
revisit	O
this	O
framework	O
in	O
Section	O
3	O
.	O

The	O
first	O
table	O
shows	O
some	O
representative	O
unnecessary	O
state	O
changes	O
that	O
EDH	O
tasks	O
require	O
for	O
"	O
task	O
success	O
'	O
in	O
evaluation	O
.	O
For	O
example	O
,	O
in	O
our	O
common	O
sense	O
,	O
it	O
is	O
not	O
necessary	O
that	O
we	O
leave	O
the	O
coffee	O
machine	O
on	O
to	O
successfully	O
make	O
coffee	O
(	O
indeed	O
,	O
it	O
is	O
better	O
to	O
turn	O
it	O
off	O
after	O
use	O
)	O
.	O
However	O
,	O
since	O
EDH	O
evaluation	O
requires	O
that	O
the	O
agent	O
exactly	O
follows	O
state	O
changes	O
done	O
in	O
the	O
demonstration	O
,	O
the	O
agent	O
will	O
have	O
to	O
leave	O
coffee	O
machine	O
turned	O
on	O
for	O
a	O
particular	O
validation	O
task	O
,	O
if	O
this	O
was	O
done	O
in	O
its	O
corresponding	O
demonstration	O
.	O

Most	O
evaluation	O
metrics	O
used	O
in	O
previous	O
paraphrase	O
generation	O
research	O
are	O
not	O
designed	O
for	O
the	O
task	O
itself	O
,	O
but	O
adopted	O
from	O
other	O
evaluation	O
tasks	O
,	O
such	O
as	O
machine	O
translation	O
(	O
MT	O
)	O
and	O
summarization	O
.	O
However	O
,	O
paraphrase	O
evaluation	O
is	O
inherently	O
different	O
from	O
the	O
evaluation	O
of	O
most	O
other	O
tasks	O
,	O
because	O
a	O
good	O
paraphrase	O
typically	O
obeys	O
two	O
criteria	O
(	O
Gleitman	O
and	O
Gleitman	O
,	O
1970;Chen	O
and	O
Dolan	O
,	O
2011;Bhagat	O
and	O
Hovy	O
,	O
2013	O
):	O
semantic	O
similarity	O
(	O
Sim	O
)	O
and	O
lexical	O
divergence	O
(	O
Div	O
)	O
.	O
Sim	O
means	O
that	O
the	O
paraphrase	O
maintains	O
similar	O
semantics	O
to	O
the	O
input	O
sentence	O
,	O
whereas	O
Div	O
requires	O
that	O
the	O
paraphrase	O
possesses	O
lexical	O
or	O
syntactic	O
differences	O
from	O
the	O
input	O
.	O
In	O
contrast	O
,	O
tasks	O
like	O
machine	O
translation	O
have	O
no	O
requirement	O
for	O
Div	O
.	O
It	O
is	O
therefore	O
uncertain	O
whether	O
the	O
metrics	O
borrowed	O
from	O
other	O
tasks	O
perform	O
well	O
in	O
paraphrase	O
evaluation	O
.	O

After	O
the	O
war	O
ended	O
,	O
his	O
mind	O
was	O
full	O
of	O
food	O
and	O
drink	O
,	O
and	O
he	O
was	O
ready	O
for	O
a	O
quick	O
trip	O
to	O
the	O
bar	O
.	O
He	O
had	O
been	O
to	O
the	O
bar	O
on	O
many	O
occasions	O
.	O
Only	O
in	O
there	O
that	O
he	O
could	O
fully	O
relax	O
and	O
forget	O
about	O
all	O
those	O
mess	O
things	O
...	O
0.16	O
0.14	O

where	O
L	O
sup	O
is	O
the	O
supervised	O
loss	O
,	O
L	O
rl	O
is	O
the	O
reinforcement	O
learning	O
loss	O
,	O
L	O
att	O
is	O
a	O
novel	O
attention	O
consistency	O
loss	O
and	O
L	O
td	O
is	O
a	O
loss	O
to	O
guide	O
the	O
attention	O
score	O
distributions	O
by	O
tree	O
constraints	O
.	O
λ	O
rl	O
,	O
λ	O
att	O
andλ	O
td	O
are	O
hyper	O
-	O
parameters	O
.	O

Bill	O
Text	O
As	O
mentioned	O
above	O
,	O
legislators	O
introduce	O
bills	O
to	O
propose	O
laws	O
or	O
amend	O
existing	O
ones	O
in	O
order	O
to	O
further	O
their	O
agenda	O
.	O
We	O
acquire	O
IDs	O
,	O
titles	O
,	O
and	O
introduction	O
dates	O
of	O
bills	O
using	O
the	O
API	O
of	O
propublica.org	O
,	O
a	O
non	O
-	O
profit	O
organisation	O
that	O
collects	O
and	O
provides	O
access	O
to	O
congressional	O
documents	O
.	O
We	O
further	O
collect	O
summaries	O
of	O
the	O
bill	O
's	O
content	O
,	O
which	O
the	O
API	O
provides	O
for	O
around	O
95	O
%	O
of	O
all	O
cases	O
.	O
For	O
bills	O
where	O
no	O
summary	O
is	O
available	O
,	O
we	O
use	O
the	O
full	O
-	O
body	O
texts	O
instead	O
.	O
As	O
we	O
create	O
our	O
data	O
set	O
to	O
study	O
active	O
and	O
passive	O
cosponsorship	O
,	O
we	O
discard	O
all	O
bills	O
for	O
which	O
no	O
cosponsorship	O
links	O
were	O
recorded	O
.	O
Overall	O
,	O
our	O
data	O
set	O
contains	O
information	O
on	O
over	O
50	O
,	O
000	O
bills	O
.	O

Knowledge	O
probing	O
works	O
such	O
as	O
LAMA	B-MethodName
(	O
Petroni	O
et	O
al	O
.	O
,	O
2019	O
)	O
aim	O
to	O
answer	O
the	O
following	O
question	O
:	O
can	O
models	O
(	O
e.g.	O
BERT	B-MethodName
)	O
which	O
are	O
pretrained	O
on	O
generic	O
text	O
corpora	O
with	O
a	O
language	O
modeling	O
objective	O
be	O
used	O
as	O
knowledge	O
bases	O
?	O
In	O
our	O
case	O
,	O
the	O
model	O
has	O
been	O
explicitly	O
trained	O
with	O
the	O
link	O
prediction	O
objective	O
,	O
and	O
a	O
knowledge	O
probing	O
experiment	O
would	O
be	O
akin	O
to	O
checking	O
train	O
set	O
performance	O
of	O
link	O
prediction	O
(	O
which	O
is	O
discussed	O
in	O
§	O
4.8	O
)	O
.	O
Furthermore	O
,	O
we	O
do	O
not	O
claim	O
that	O
KGT5	B-MethodName
is	O
as	O
general	O
purpose	O
as	O
large	O
LMs	O
,	O
or	O
that	O
it	O
contains	O
generic	O
world	O
knowledge	O
.	O
Hence	O
we	O
do	O
not	O
perform	O
knowledge	O
probing	O
experiments	O
on	O
datasets	O
such	O
as	O
T	B-MethodName
-	I-MethodName
Rex	I-MethodName
or	O
Google	B-MethodName
-	I-MethodName
RE	I-MethodName
(	O
Petroni	O
et	O
al	O
.	O
,	O
2019	O
(	O
Das	O
et	O
al	O
.	O
,	O
2021b	O
)	O
73.1	O
70.4	O

Since	O
our	O
submission	O
to	O
the	O
KILT	B-MethodName
leaderboard	O
for	O
the	O
Wizard	O
of	O
Wikipedia	O
,	O
a	O
new	O
system	O
called	O
Hindsight	O
[	O
Paranjape	O
et	O
al	O
.	O
,	O
2021	O
]	O
achieved	O
even	O
better	O
results	O
on	O
the	O
generation	O
metrics	O
on	O
that	O
particular	O
task	O
.	O
The	O
new	O
system	O
of	O
SEAL	O
has	O
also	O
achieved	O
top	O
results	O
for	O
some	O
metrics	O
on	O
the	O
Natural	O
Questions	O
and	O
TriviaQA	O
benchmarks	O
.	O

In	O
this	O
paper	O
,	O
we	O
explored	O
multilingual	O
,	O
word	O
-	O
level	O
QE	O
with	O
transformers	O
.	O
We	O
introduced	O
a	O
new	O
architecture	O
based	O
on	O
transformers	O
to	O
perform	O
wordlevel	O
QE	O
.	O
The	O
implementation	O
of	O
the	O
architecture	O
,	O
which	O
is	O
based	O
on	O
Hugging	O
Face	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
has	O
been	O
integrated	O
into	O
the	O
TransQuest	B-MethodName
framework	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020b	O
)	O
which	O
won	O
the	O
WMT	O
2020	O
QE	O
task	O
)	O
on	O
sentencelevel	O
direct	O
assessment	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020a	O
)	O
2	O
.	O

Besides	O
NMT	B-MethodName
models	O
,	O
we	O
also	O
trained	O
a	O
phrasebased	O
statistical	O
machine	O
translation	O
(	O
PB	O
-	O
SMT	O
)	O
schema	O
translation	O
model	O
with	O
Moses	O
3	O
(	O
Koehn	O
et	O
al	O
.	O
,	O
2007	O
)	O
,	O
with	O
the	O
same	O
data	O
split	O
.	O

First	O
,	O
we	O
ablate	O
the	O
influence	O
of	O
query	O
expansion	O
and	O
the	O
feedback	O
documents	O
on	O
lexical	O
retrieval	O
.	O
We	O
retrieve	O
only	O
using	O
the	O
query	O
and	O
remove	O
the	O
feedback	O
documents	O
from	O
the	O
retrieval	O
and	O
evaluation	O
,	O
i.e.	O
we	O
use	O
the	O
residual	O
collection	O
,	O
even	O
though	O
the	O
feedback	O
documents	O
are	O
not	O
used	O
.	O
From	O
the	O
first	O
section	O
of	O
Table	O
4	O
we	O
can	O
observe	O
a	O
large	O
performance	O
drop	O
.	O
This	O
shows	O
that	O
BM25	B-MethodName
-	I-MethodName
QE	I-MethodName
is	O
successfully	O
able	O
to	O
exploit	O
the	O
feedback	O
documents	O
and	O
retrieve	O
more	O
relevant	O
documents	O
.	O

MASKING	O
We	O
propose	O
a	O
novel	O
data	O
-	O
centric	O
debiasing	O
alternative	O
based	O
on	O
token	O
masking	O
.	O
Instead	O
of	O
removing	O
spurious	O
artifacts	O
altogether	O
,	O
we	O
reserve	O
a	O
special	O
token	O
in	O
the	O
vocabulary	O
of	O
the	O
model	O
that	O
we	O
use	O
as	O
replacement	O
for	O
spurious	O
artifacts	O
.	O
We	O
then	O
fine	O
-	O
tune	O
the	O
model	O
on	O
the	O
masked	O
data	O
.	O
Intuitively	O
,	O
this	O
way	O
we	O
encourage	O
the	O
model	O
to	O
blend	O
all	O
artifacts	O
to	O
a	O
single	O
contextualized	O
representation	O
that	O
will	O
never	O
appear	O
during	O
testing	O
,	O
also	O
avoiding	O
to	O
redistribute	O
the	O
informativeness	O
of	O
spurious	O
lexical	O
items	O
to	O
surrounding	O
tokens	O
.	O
As	O
for	O
REMOVAL	O
,	O
we	O
experiment	O
with	O
S	O
¬I	O
and	O
S	O
I	O
masking	O
variants	O
.	O

The	O
CNNs	O
for	O
the	O
Amazon	O
Products	O
dataset	O
also	O
behaved	O
in	O
a	O
similar	O
way	O
(	O
Figure	O
6	O
-bottom	O
)	O
,	O
except	O
that	O
disabling	O
rank	O
C	O
features	O
slightly	O
undermined	O
,	O
not	O
increased	O
,	O
performance	O
.	O
This	O
implies	O
that	O
even	O
the	O
rank	O
C	O
features	O
contain	O
a	O
certain	O
amount	O
of	O
useful	O
knowledge	O
for	O
this	O
classifier	O
.	O
4	O

In	O
this	O
section	O
,	O
we	O
conduct	O
experiments	O
on	O
our	O
proposed	O
schema	O
translation	O
dataset	O
to	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O
Furthermore	O
,	O
we	O
ablate	O
different	O
ways	O
of	O
context	O
modeling	O
in	O
our	O
approach	O
to	O
understand	O
their	O
contributions	O
.	O
At	O
last	O
,	O
we	O
conduct	O
a	O
qualitative	O
analysis	O
and	O
show	O
example	O
cases	O
and	O
their	O
predicting	O
results	O
.	O

Our	O
question	O
generation	O
method	O
uses	O
a	O
set	O
of	O
unannotated	O
sentences	O
from	O
which	O
the	O
questions	O
will	O
be	O
generated	O
.	O
We	O
compare	O
three	O
selection	O
methods	O
.	O
First	O
,	O
we	O
consider	O
a	O
scenario	O
where	O
the	O
application	O
developer	O
does	O
not	O
manually	O
collect	O
any	O
sentence	O
,	O
but	O
simply	O
gives	O
the	O
name	O
(	O
or	O
topic	O
)	O
of	O
the	O
target	O
domain	O
.	O
In	O
our	O
case	O
,	O
the	O
topics	O
are	O
"	O
Physics	O
"	O
,	O
"	O
Biology	O
"	O
and	O
"	O
Chemistry	O
"	O
since	O
these	O
are	O
the	O
main	O
domains	O
in	O
SciQ.	O
A	O
simple	O
information	O
retrieval	O
strategy	O
is	O
then	O
applied	O
to	O
automatically	O
mine	O
sentences	O
from	O
Wikipedia	O
.	O
We	O
first	O
compute	O
a	O
list	O
of	O
Wikipedia	O
categories	O
by	O
recursively	O
visiting	O
all	O
subcategories	O
starting	O
from	O
the	O
target	O
topic	O
names	O
.	O
The	O
maximum	O
recursion	O
number	O
is	O
limited	O
to	O
4	O
.	O
We	O
then	O
extract	O
the	O
summary	O
(	O
head	O
paragraph	O
of	O
each	O
Wikipedia	O
article	O
)	O
for	O
each	O
of	O
the	O
articles	O
matching	O
the	O
previously	O
extracted	O
categories	O
and	O
subcategories	O
.	O
We	O
only	O
keep	O
articles	O
with	O
more	O
than	O
800	O
average	O
visitors	O
per	O
day	O
for	O
the	O
last	O
ten	O
days	O
(	O
on	O
April	O
27	O
,	O
2021	O
)	O
,	O
resulting	O
in	O
12	O
656	O
pages	O
.	O

The	O
candidate	O
with	O
the	O
highest	O
score	O
is	O
chosen	O
as	O
the	O
correct	O
entity	O
,	O
i.e.	O

Manual	O
Paraphrase	O
.	O
Next	O
,	O
we	O
ask	O
human	O
annotators	O
to	O
paraphrase	O
the	O
templated	O
utterances	O
to	O
better	O
match	O
the	O
real	O
-	O
world	O
natural	O
language	O
distribution	O
.	O
We	O
design	O
an	O
interface	O
that	O
dynamically	O
displays	O
a	O
multimodal	O
scene	O
that	O
features	O
either	O
a	O
still	O
image	O
(	O
static	O
dialog	O
phase	O
)	O
or	O
a	O
user	O
egocentric	O
video	O
(	O
active	O
dialog	O
phase	O
)	O
.	O
When	O
clicking	O
on	O
a	O
specific	O
turn	O
of	O
a	O
dialog	O
,	O
the	O
corresponding	O
visual	O
input	O
is	O
shown	O
in	O
the	O
display	O
panel	O
to	O
help	O
annotators	O
navigate	O
through	O
the	O
entire	O
dialog	O
flow	O
.	O
We	O
ask	O
the	O
annotators	O
to	O
pay	O
attention	O
to	O
detailed	O
and	O
sophisticated	O
spatial	O
-	O
temporal	O
relations	O
of	O
objects	O
and	O
encourage	O
writing	O
interesting	O
shopping	O
experiences	O
.	O
The	O
paraphrases	O
are	O
collected	O
from	O
more	O
than	O
20	O
different	O
linguistic	O
experts	O
for	O
diverse	O
language	O
patterns	O
/	O
usages	O
.	O

We	O
propose	O
approaches	O
to	O
Quality	O
Estimation	O
(	O
QE	O
)	O
for	O
Machine	O
Translation	O
that	O
explore	O
both	O
text	O
and	O
visual	O
modalities	O
for	O
Multimodal	O
QE	I-MethodName
.	O
We	O
compare	O
various	O
multimodality	O
integration	O
and	O
fusion	O
strategies	O
.	O
For	O
both	O
sentence	O
-	O
level	O
and	O
document	O
-	O
level	O
predictions	O
,	O
we	O
show	O
that	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
and	O
feature	O
-	O
based	O
QE	O
frameworks	O
obtain	O
better	O
results	O
when	O
using	O
the	O
additional	O
modality	O
.	O

We	O
start	O
with	O
examining	O
the	O
relation	O
between	O
media	O
ideology	O
and	O
their	O
stances	O
.	O
We	O
first	O
study	O
do	O
media	O
tend	O
to	O
quote	O
people	O
of	O
the	O
same	O
or	O
opposite	O
ideologies	O
?	O
To	O
answer	O
this	O
question	O
,	O
we	O
count	O
the	O
average	O
number	O
of	O
political	O
figures	O
quoted	O
as	O
source	O
entities	O
in	O
each	O
article	O
.	O
Interestingly	O
,	O
media	O
from	O
both	O
sides	O
are	O
more	O
likely	O
to	O
quote	O
Republican	O
politicians	O
,	O
as	O
seen	O
in	O
Fig	O
.	O
4	O
.	O
This	O
is	O
consistent	O
with	O
recent	O
study	O
on	O
U.S.	O
TV	O
media	O
(	O
Hong	O
et	O
al	O
.	O
,9	O
2021	O
)	O
,	O
where	O
the	O
authors	O
show	O
that	O
Republicans	O
receive	O
more	O
screen	O
time	O
as	O
well	O
as	O
get	O
longer	O
TV	O
interviews	O
time	O
than	O
Democrats	O
.	O
10	O
Additionally	O
,	O
left	O
-	O
leaning	O
outlets	O
use	O
more	O
quotes	O
than	O
their	O
right	O
counterparts	O
,	O
which	O
also	O
aligns	O
with	O
previous	O
observations	O
(	O
Welch	O
et	O
al	O
.	O
,	O
1998	O
)	O
.	O

Given	O
a	O
multimodal	O
input	O
,	O
we	O
employ	O
a	O
sequenceto	O
-	O
sequence	O
model	O
BART	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
to	O
generate	O
the	O
output	O
index	O
sequence	O
y	O
.	O

Candidate	O
Re	O
-	O
ranking	O
The	O
candidate	O
reranking	O
approach	O
uses	O
a	O
BERT	O
-	O
based	O
crossattention	O
encoder	O
to	O
jointly	O
encode	O
a	O
mention	O
and	O
its	O
context	O
along	O
with	O
each	O
candidate	O
from	O
E	O
(	O
Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Specifically	O
,	O
the	O
mention	O
m	O
is	O
concatenated	O
with	O
its	O
context	O
on	O
the	O
left	O
(	O
c	O
l	O
)	O
,	O
its	O
context	O
on	O
the	O
right	O
(	O
c	O
r	O
)	O
,	O
and	O
a	O
single	O
candidate	O
entity	O
e	O
∈	O
E.	O
An	O
[	O
SEP	O
]	O
token	O
,	O
which	O
is	O
used	O
in	O
BERT	B-MethodName
to	O
separate	O
inputs	O
from	O
different	O
segments	O
,	O
is	O
used	O
here	O
to	O
separate	O
the	O
mention	O
in	O
context	O
,	O
from	O
the	O
candidate	O
.	O
This	O
concatenated	O
string	O
is	O
encoded	O
using	O
BERT	B-MethodName
3	O
to	O
obtain	O
,	O
h	O
m	O
,	O
e	O
a	O
representation	O
for	O
this	O
mention	O
/	O
candidate	O
pair	O
(	O
from	O
the	O
[	O
CLS	O
]	O
token	O
)	O
.	O
Given	O
a	O
candidate	O
list	O
E	O
of	O
size	O
K	O
generated	O
in	O
the	O
previous	O
stage	O
,	O
K	O
scores	O
are	O
generated	O
for	O
each	O
mention	O
,	O
which	O
are	O
subsequently	O
scored	O
using	O
a	O
dot	O
-	O
product	O
with	O
a	O
learned	O
weight	O
vector	O
(	O
w	O
)	O
.	O
Thus	O
,	O

Question	O
Representation	O
Unlike	O
standard	O
DKT	O
,	O
which	O
treats	O
questions	O
as	O
IDs	O
or	O
simple	O
handcrafted	O
features	O
,	O
we	O
represent	O
questions	O
fully	O
in	O
text	O
(	O
e.g.	O
"	O
she	O
eats	O
"	O
in	O
Figure	O
1	O
)	O
.	O
This	O
is	O
a	O
key	O
contribution	O
of	O
our	O
work	O
,	O
required	O
by	O
our	O
eventual	O
goal	O
of	O
generating	O
questions	O
in	O
text	O
,	O
and	O
allows	O
the	O
model	O
to	O
leverage	O
similarity	O
across	O
linguistic	O
features	O
.	O
We	O
thus	O
represent	O
a	O
question	O
q	O
as	O
a	O
sequence	O
of	O
words	O
,	O
with	O
prefix	O
and	O
suffix	O
tokens	O
:	O

-DOCSTART-	O
The	O
SOFC	O
-	O
Exp	O
Corpus	O
and	O
Neural	O
Approaches	O
to	O
Information	O
Extraction	O
in	O
the	O
Materials	O
Science	O
Domain	O

To	O
mitigate	O
the	O
risk	O
of	O
performance	O
overestimation	O
associated	O
with	O
annotation	O
artifacts	O
,	O
Zellers	O
et	O
al	O
.	O
(	O
2019	O
)	O
advocate	O
adversarial	O
dataset	O
construction	O
,	O
such	O
that	O
benchmarks	O
will	O
co	O
-	O
evolve	O
with	O
language	O
models	O
.	O
This	O
may	O
be	O
difficult	O
to	O
scale	O
in	O
knowledge	O
-	O
intensive	O
domains	O
,	O
as	O
expert	O
validation	O
of	O
adversarially	O
generated	O
benchmarks	O
is	O
typically	O
required	O
.	O
Additionally	O
,	O
in	O
high	O
-	O
stakes	O
domains	O
such	O
as	O
medicine	O
,	O
information	O
-	O
rich	O
inferences	O
should	O
be	O
preferred	O
over	O
correct	O
but	O
trivial	O
inferences	O
that	O
time	O
-	O
constrained	O
expert	O
annotators	O
may	O
be	O
rationally	O
incentivized	O
to	O
produce	O
,	O
because	O
entropy	O
-	O
reducing	O
inferences	O
are	O
more	O
useful	O
for	O
downstream	O
tasks	O
.	O

•	O
A	O
positive	O
data	O
point	O
is	O
a	O
text	O
sequence	O
x	O
from	O
the	O
data	O
and	O
position	O
in	O
the	O
sequence	O
t.	O

We	O
include	O
the	O
pseudocode	O
algorithm	O
of	O
the	O
proposed	O
decoding	O
method	O
in	O
Algorithm	O
1	O
.	O
Note	O
that	O
we	O
can	O
use	O
the	O
nonzero	O
operation	O
to	O
find	O
and	O
merge	O
adjacent	O
non	O
-	O
null	O
entries	O
as	O
it	O
returns	O
the	O
entries	O
sorted	O
in	O
lexicographic	O
order	O
.	O
This	O
ensures	O
that	O
the	O
order	O
of	O
entries	O
seen	O
in	O
consecutive	O
order	O
if	O
they	O
correspond	O
to	O
the	O
same	O
hyper	O
-	O
relational	O
fact	O
.	O

A	O
softmax	O
classifier	O
is	O
added	O
on	O
top	O
of	O
the	O
final	O
hidden	O
state	O
of	O
the	O
[	O
CLS	O
]	O
token	O
;	O
(	O
2	O
)	O
on	O
MLQA	O
,	O
we	O
concatenate	O
the	O
question	O
with	O
the	O
context	O
,	O
and	O
add	O
a	O
[	O
SEP	O
]	O
token	O
in	O
between	O
.	O
We	O
add	O
two	O
linear	O
layers	O
on	O
top	O
of	O
mBERT	O
followed	O
by	O
softmax	O
over	O
the	O
context	O
tokens	O
to	O
predict	O
answer	O
start	O
and	O
end	O
positions	O
,	O
respectively	O
.	O
We	O
conduct	O
experiments	O
in	O
two	O
settings	O
:	O
1	O
.	O
Zeroshot	O
cross	O
-	O
lingual	O
transfer	O
,	O
where	O
training	O
data	O
is	O
available	O
in	O
English	O
but	O
not	O
in	O
target	O
languages	O
.	O
2	O
.	O
Translate	O
-	O
train	O
,	O
where	O
the	O
English	O
training	O
set	O
is	O
(	O
machine	O
)	O
translated	O
to	O
all	O
the	O
target	O
languages	O
.	O
For	O
the	O
latter	O
setting	O
,	O
we	O
perform	O
data	O
augmentation	O
with	O
code	O
-	O
switched	O
inputs	O
,	O
when	O
training	O
on	O
languages	O
other	O
than	O
English	O
.	O
For	O
example	O
,	O
a	O
Spanish	O
question	O
q	O
es	O
and	O
context	O
c	O
es	O
pair	O
can	O
be	O
augmented	O
to	O
two	O
question	O
-	O
context	O
pairs	O
(	O
q	O
es	O
,	O
c	O
en	O
)	O
and	O
(	O
q	O
en	O
,	O
c	O
es	O
)	O
with	O
code	O
-	O
switching	O
,	O
resulting	O
in	O
2x	O
training	O
data	O
2	O
.	O
The	O
same	O
goes	O
for	O
XNLI	O
with	O
premises	O
and	O
hypotheses	O
.	O
The	O
code	O
-	O
switching	O
is	O
always	O
between	O
English	O
,	O
and	O
a	O
target	O
language	O
.	O
During	O
training	O
,	O
we	O
ensure	O
the	O
two	O
augmented	O
pairs	O
appear	O
in	O
the	O
same	O
batch	O
.	O

Position	O
emb	O
.	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
to	O
generate	O
referent	O
entity	O
titles	O
of	O
target	O
mentions	O
in	O
an	O
autoregressive	O
manner	O
.	O
Barba	O
et	O
al	O
.	O
(	O
2022	O
)	O
formulated	O
ED	B-MethodName
as	O
a	O
text	O
extraction	O
problem	O
;	O
they	O
fed	O
the	O
document	O
and	O
candidate	O
entity	O
titles	O
to	O
BART	B-MethodName
and	O
Longformer	B-MethodName
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
disambiguated	O
a	O
mention	O
in	O
the	O
document	O
by	O
extracting	O
the	O
referent	O
entity	O
title	O
of	O
the	O
mention	O
.	O
However	O
,	O
unlike	O
our	O
model	O
,	O
these	O
models	O
addressed	O
the	O
task	O
based	O
only	O
on	O
local	O
contextual	O
information	O
.	O

The	O
dataset	O
contains	O
130k	O
train	O
examples	O
,	O

Argument	O
Quality	O
We	O
introduce	O
a	O
novel	O
method	O
to	O
evaluate	O
generated	O
arguments	O
based	O
on	O
the	O
argument	O
quality	O
detection	O
approach	O
proposed	O
by	O
Gretz	O
et	O
al	O
.	O
(	O
2020b	O
)	O
.	O
They	O
create	O
an	O
argument	O
quality	O
dataset	O
that	O
contains	O
around	O
30,000	O
arguments	O
over	O
71	O
topics	O
.	O
For	O
each	O
argument	O
,	O
annotators	O
were	O
asked	O
whether	O
or	O
not	O
they	O
would	O
recommend	O
a	O
friend	O
to	O
use	O
the	O
displayed	O
argument	O
in	O
a	O
speech	O
.	O
The	O
quality	O
scores	O
for	O
each	O
argument	O
result	O
from	O
a	O
weighted	O
average	O
(	O
WA	O
)	O
or	O
MACE	O
Probability	O
function	O
of	O
all	O
annotations	O
and	O
range	O
between	O
0	O
(	O
lowest	O
quality	O
)	O
and	O
1.0	O
(	O
highest	O
quality	O
)	O
.	O
We	O
use	O
the	O
WA	O
-	O
score	O
as	O
label	O
,	O
the	O
same	O
model	O
(	O
BERT	O
BASE	O
)	O
and	O
hyperparameters	O
as	O
given	O
in	O
the	O
original	O
paper	O
,	O
and	O
reproduce	O
the	O
reported	O
correlations	O
of	O
.52	O
(	O
Pearson	O
)	O
and	O
.48	O
(	O
Spearman	O
)	O
on	O
the	O
test	O
dataset	O
(	O
averaged	O
over	O
five	O
different	O
seeds	O
)	O
.	O
The	O
model	O
predicts	O
an	O
average	O
argument	O
quality	O
of	O
.71	O
for	O
the	O
Arg	B-MethodName
-	O
CTRL	O
REDDIT	O
arguments	O
,	O
.75	O
for	O
the	O
training	O
arguments	O
of	O
the	O
UKP	O
-	O
Corpus	O
,	O
and	O
even	O
.76	O
for	O
the	O
Arg	O
-	O
CTRL	O
CC	O
arguments	O
.	O
It	O
shows	O
that	O
our	O
model	O
is	O
able	O
to	O
produce	O
arguments	O
that	O
are	O
generally	O
on	O
a	O
similar	O
quality	O
level	O
as	O
arguments	O
made	O
by	O
humans	O
.	O
The	O
difference	O
of	O
5	O
points	O
between	O
the	O
Arg	B-MethodName
-	O
CTRL	O
CC	O
and	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
,	O
however	O
,	O
shows	O
that	O
training	O
on	O
REDDIT	O
data	O
leads	O
to	O
a	O
lower	O
quality	O
of	O
generated	O
arguments	O
.	O
Exemplary	O
Human	O
:	O
Nuclear	O
energy	O
produces	O
waste	O
that	O
stays	O
radioactive	O
for	O
thousands	O
of	O
years	O
and	O
pollutes	O
the	O
environment	O
.	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
nuclear	O
energy	O
PRO	O
waste	O
.	O
)	O
The	O
only	O
thing	O
that	O
's	O
going	O
to	O
be	O
left	O
over	O
is	O
the	O
spent	O
fuel	O
rods	O
,	O
which	O
are	O
not	O
very	O
radioactive	O
and	O
can	O
be	O
reprocessed	O
[	O
...	O
]	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
nuclear	O
energy	O
PRO	O
radioactive	O
.	O
)	O
The	O
radioactivity	O
of	O
the	O
waste	O
is	O
not	O
a	O
problem	O
,	O
because	O
it	O
will	O
decay	O
away	O
in	O
about	O
300	O
years	O
or	O
so	O
[	O
...	O
]	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
nuclear	O
energy	O
PRO	O
environment	O
.	O
)	O
The	O
fact	O
that	O
the	O
radioactive	O
waste	O
is	O
not	O
only	O
stored	O
in	O
a	O
safe	O
manner	O
,	O
but	O
also	O
protected	O
from	O
any	O
potential	O
threat	O
to	O
human	O
health	O
or	O
the	O
environment	O
for	O
thousands	O
of	O
years	O
[	O
...	O
]	O
Human	O
:	O
School	O
uniforms	O
are	O
expensive	O
and	O
affect	O
the	O
pupil	O
's	O
individuality	O
.	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
school	O
uniforms	O
PRO	O
expensive	O
.	O
)	O
The	O
cost	O
of	O
the	O
uniform	O
is	O
not	O
that	O
much	O
more	O
than	O
a	O
regular	O
shirt	O
and	O
shorts	O
[	O
...	O
]	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
school	O
uniforms	O
PRO	O
individuality	O
.	O
)	O
The	O
uniform	O
is	O
a	O
symbol	O
of	O
unity	O
and	O
identity	O
,	O
which	O
helps	O
to	O
foster	O
an	O
environment	O
where	O
students	O
can	O
feel	O
comfortable	O
about	O
expressing	O
their	O
own	O
individual	O
style	O
without	O
being	O
judged	O
[	O
...	O
]	O
for	O
three	O
topics	O
,	O
we	O
show	O
the	O
generated	O
arguments	O
with	O
the	O
highest	O
and	O
lowest	O
argument	O
quality	O
in	O
Table	O
4	O
(	O
see	O
App	O
.	O
E	O
for	O
the	O
full	O
table	O
)	O
.	O

Next	O
,	O
we	O
project	O
the	O
secondary	O
features	O
into	O
primary	O
ones	O
to	O
obtain	O
additional	O
orthogonal	O
features	O
f	O
o	O
:	O

B5	O
.	O
Did	O
you	O
provide	O
documentation	O
of	O
the	O
artifacts	O
,	O
e.g.	O
,	O
coverage	O
of	O
domains	O
,	O
languages	O
,	O
and	O
linguistic	O
phenomena	O
,	O
demographic	O
groups	O
represented	O
,	O
etc	O
.	O
?	O
Section	O
3	O
and	O
Appendix	O
A.3	O
B6	O
.	O
Did	O
you	O
report	O
relevant	O
statistics	O
like	O
the	O
number	O
of	O
examples	O
,	O
details	O
of	O
train	O
/	O
test	O
/	O
dev	O
splits	O
,	O
etc	O
.	O
for	O
the	O
data	O
that	O
you	O
used	O
/	O
created	O
?	O
Even	O
for	O
commonly	O
-	O
used	O
benchmark	O
datasets	O
,	O
include	O
the	O
number	O
of	O
examples	O
in	O
train	O
/	O
validation	O
/	O
test	O
splits	O
,	O
as	O
these	O
provide	O
necessary	O
context	O
for	O
a	O
reader	O
to	O
understand	O
experimental	O
results	O
.	O
For	O
example	O
,	O
small	O
differences	O
in	O
accuracy	O
on	O
large	O
test	O
sets	O
may	O
be	O
significant	O
,	O
while	O
on	O
small	O
test	O
sets	O
they	O
may	O
not	O
be	O
.	O
Section	O
3	O
and	O
Appendix	O
A.3	O

B5	O
.	O
Did	O
you	O
provide	O
documentation	O
of	O
the	O
artifacts	O
,	O
e.g.	O
,	O
coverage	O
of	O
domains	O
,	O
languages	O
,	O
and	O
linguistic	O
phenomena	O
,	O
demographic	O
groups	O
represented	O
,	O
etc	O
.	O
?	O
Section3	O
and	O
Appendix	O
D	O
B6	O
.	O
Did	O
you	O
report	O
relevant	O
statistics	O
like	O
the	O
number	O
of	O
examples	O
,	O
details	O
of	O
train	O
/	O
test	O
/	O
dev	O
splits	O
,	O
etc	O
.	O
for	O
the	O
data	O
that	O
you	O
used	O
/	O
created	O
?	O
Even	O
for	O
commonly	O
-	O
used	O
benchmark	O
datasets	O
,	O
include	O
the	O
number	O
of	O
examples	O
in	O
train	O
/	O
validation	O
/	O
test	O
splits	O
,	O
as	O
these	O
provide	O
necessary	O
context	O
for	O
a	O
reader	O
to	O
understand	O
experimental	O
results	O
.	O
For	O
example	O
,	O
small	O
differences	O
in	O
accuracy	O
on	O
large	O
test	O
sets	O
may	O
be	O
significant	O
,	O
while	O
on	O
small	O
test	O
sets	O
they	O
may	O
not	O
be	O
.	O
Section3	O
and	O
Appendix	O
D.1	O

We	O
measure	O
inter	O
-	O
annotator	O
agreement	O
by	O
computing	O
Cohens	O
kappa	O
(	O
K	O
)	O
and	O
observe	O
substantial	O
to	O
high	O
agreement	O
across	O
all	O
metrics	O
.	O
Table	O
3	O
shares	O
the	O
averaged	O
ratings	O
from	O
both	O
evaluators	O
.	O
For	O
each	O
metric	O
,	O
we	O
highlight	O
in	O
bold	O
the	O
best	O
performing	O
model	O
(	O
s	O
)	O
and	O
mark	O
with	O
an	O
asterisk	O
the	O
model	O
(	O
s	O
)	O
where	O
the	O
difference	O
from	O
the	O
best	O
is	O
at	O
least	O
5	O
%	O
.	O
We	O
further	O
plot	O
(	O
in	O
Appendix	O
A	O
)	O
the	O
scores	O
by	O
each	O
metric	O
in	O
Figure	O
10	O
,	O
the	O
variation	O
of	O
each	O
metric	O
across	O
models	O
in	O
Figure	O
11	O
,	O
and	O
the	O
distribution	O
of	O
scores	O
for	O
each	O
metric	O
in	O
Figure	O
12	O
.	O

All	O
our	O
experiments	O
are	O
run	O
parallelly	O
on	O
4	O
NVIDIA	O
Tesla	O
V100	O
GPUs	O
;	O
for	O
smaller	O
K	O
values	O
(	O
e.g.	O
,	O
K	O
=	O
100	O
)	O
,	O
most	O
experiments	O
require	O
less	O
than	O
1	O
GPU	O
hour	O
,	O
while	O
a	O
setting	O
with	O
a	O
larger	O
K	O
value	O
(	O
e.g.	O
,	O
K	O
=	O
1000	O
)	O
may	O
require	O
2	O
GPU	O
hours	O
.	O

How	O
can	O
we	O
identify	O
when	O
a	O
model	O
is	O
unsure	O
of	O
its	O
prediction	O
?	O
The	O
self	O
-	O
consistency	O
method	O
provides	O
a	O
solution	O
.	O
In	O
sampling	O
diverse	O
reasoning	O
paths	O
and	O
answers	O
,	O
self	O
-	O
consistency	O
is	O
found	O
to	O
be	O
highly	O
correlated	O
with	O
accuracy	O
,	O
suggesting	O
that	O
it	O
could	O
provide	O
an	O
uncertainty	O
estimate	O
and	O
confer	O
abilities	O
for	O
the	O
model	O
to	O
"	O
know	O
when	O
it	O
does	O
n't	O
know	O
"	O
.	O
Thus	O
,	O
we	O
begin	O
the	O
VE	O
framework	O
by	O
using	O
the	O
consistency	O
method	O
to	O
sample	O
n	O
diverse	O
reasoning	O
paths	O
for	O
a	O
prediction	O
task	O
.	O
The	O
highly	O
consistent	O
predictions	O
are	O
left	O
as	O
-	O
is	O
.	O
When	O
consistency	O
is	O
lower	O
than	O
⌈n	O
/	O
2⌉	O
,	O
i.e.	O
the	O
majority	O
can	O
not	O
agree	O
on	O
the	O
same	O
answer	O
,	O
we	O
label	O
it	O
as	O
"	O
uncertain	O
"	O
.	O

Experiment	O
sentence	O
detection	O
.	O
Table	O
5	O
shows	O
our	O
results	O
on	O
the	O
detection	O
of	O
experimentdescribing	O
sentences	O
.	O
The	O
neural	O
models	O
with	O
bytepair	O
encoding	O
embeddings	O
or	O
BERT	B-MethodName
clearly	O
outperform	O
the	O
SVM	O
and	O
logistic	O
regression	O
models	O
.	O
Within	O
the	O
neural	O
models	O
,	O
BERT	B-MethodName
and	O
SciBERT	B-MethodName
add	O
the	O
most	O
value	O
,	O
both	O
when	O
using	O
their	O
embeddings	O
as	O
another	O
input	O
to	O
the	O
BiLSTM	O
and	O
when	O
finetuning	O
the	O
original	O
BERT	B-MethodName
models	O
.	O
Note	O
that	O
even	O
the	O
general	O
-	O
domain	O
BERT	B-MethodName
is	O
strong	O
enough	O
to	O
cope	O
with	O
non	O
-	O
standard	O
domains	O
.	O
Nevertheless	O
,	O
models	O
based	O
on	O
SciBERT	B-MethodName
outperform	O
BERT	O
-	O
based	O
models	O
,	O
indicating	O
that	O
in	O
-	O
domain	O
information	O
is	O
indeed	O
beneficial	O
.	O
For	O
performance	O
reasons	O
,	O
we	O
use	O
BERT	B-MethodName
-	I-MethodName
base	I-MethodName
in	O
our	O
experiments	O
,	O
but	O
for	O
the	O
sake	O
of	O
completeness	O
,	O
we	O
also	O
run	O
BERT	B-MethodName
-	I-MethodName
large	I-MethodName
for	O
the	O
task	O
of	O
detecting	O
experiment	O
sentences	O
.	O
Because	O
it	O
did	O
not	O
outperform	O
BERT	B-MethodName
-	I-MethodName
base	I-MethodName
in	O
our	O
cross	O
-	O
validation	O
based	O
development	O
setting	O
,	O
we	O
did	O
not	O
further	O
experiment	O
with	O
BERT	B-MethodName
-	I-MethodName
large	O
.	O
However	O
,	O
we	O
found	O
that	O
it	O
resulted	O
in	O
the	O
best	O
F1	O
-	O
score	O
achieved	O
on	O
our	O
test	O
set	O
.	O
In	O
general	O
,	O
SciBERT	O
-	O
based	O
models	O
provide	O
very	O
good	O
performance	O
and	O
seem	O
most	O
robust	O
across	O
dev	O
and	O
test	O
sets	O
.	O
Overall	O
,	O
achieving	O
F1	O
-	O
scores	O
around	O
67.0	O
-	O
68.6	O
,	O
such	O
a	O
retrieval	O
model	O
may	O
already	O
be	O
useful	O
in	O
production	O
.	O
However	O
,	O
there	O
certainly	O
is	O
room	O
for	O
improvement	O
.	O
Entity	O
mention	O
extraction	O
.	O
Table	O
6	O
provides	O
our	O
results	O
on	O
entity	O
mention	O
detection	O
and	O
typing	O
.	O

Knowledge	O
Tracing	I-MethodName
(	O
KT	O
)	O
seeks	O
to	O
model	O
a	O
student	O
's	O
knowledge	O
state	O
from	O
their	O
answer	O
history	O
in	O
order	O
to	O
help	O
individualize	O
exercise	O
sequences	O
(	O
Corbett	O
and	O
Anderson	O
,	O
1995	O
)	O
.	O
This	O
draws	O
inspiration	O
from	O
traditional	O
education	O
curriculum	O
practices	O
,	O
such	O
as	O
distributed	O
spacing	O
of	O
vocabulary	O
(	O
Bloom	O
and	O
Shuell	O
,	O
1981	O
)	O
and	O
mixed	O
review	O
in	O
mathematics	O
(	O
Rohrer	O
,	O
2009	O
)	O
.	O
To	O
address	O
simplifying	O
assumptions	O
in	O
earlier	O
KT	O
approaches	O
,	O
such	O
as	O
discrete	O
knowledge	O
representations	O
,	O
Piech	O
et	O
al	O
.	O
(	O
2015	O
)	O
introduced	O
Deep	O
Knowledge	I-MethodName
Tracing	I-MethodName
(	O
DKT	B-MethodName
)	O
,	O
which	O
uses	O
RNNs	O
to	O
enable	O
more	O
complex	O
knowledge	O
representations	O
for	O
students	O
.	O
Recently	O
,	O
SAINT+	B-MethodName
(	O
Shin	O
et	O
al	O
.	O
,	O
2020	O
)	O
showed	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
popular	O
EdNet	B-MethodName
KT	I-MethodName
task	O
using	O
a	O
Transformer	B-MethodName
model	O
to	O
capture	O
temporal	O
information	O
across	O
activities	O
,	O
motivating	O
our	O
use	O
of	O
Transformer	B-MethodName
LMs	O
.	O

Implementation	O
.	O
We	O
adopt	O
a	O
pretrained	O
transformer	O
encoder	O
-	O
decoder	O
(	O
sequence	O
-	O
to	O
-	O
sequence	O
)	O
WS	B-MethodName
-	I-MethodName
BART	I-MethodName
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020a	O
)	O
as	O
the	O
backbone	O
of	O
the	O
generator	O
in	O
our	O
proposed	O
method	O
MB	B-MethodName
-	I-MethodName
RPG	I-MethodName
.	O
To	O
improve	O
the	O
efficiency	O
of	O
reinforcement	O
learning	O
,	O
we	O
model	O
the	O
reinforced	O
data	O
valuator	O
model	O
M	O
ψ	O
as	O
a	O
pretrained	O
BERT	B-MethodName
followed	O
by	O
two	O
fullyconnected	O
trainable	O
layers	O
as	O
the	O
head	O
for	O
policy	O
output	O
.	O
BERT	B-MethodName
serves	O
as	O
a	O
feature	O
extractor	O
and	O
is	O
kept	O
fixed	O
during	O
policy	O
learning	O
.	O
We	O
present	O
other	O
details	O
for	O
our	O
method	O
in	O
appendix	O
.	O

Class	O
-	O
conditional	O
language	O
models	O
.	O
Classconditional	O
language	O
models	O
(	O
CC	O
-	O
LMs	O
)	O
,	O
as	O
the	O
Conditional	O
Transformer	I-MethodName
Language	O
(	O
CTRL	B-MethodName
)	O
model	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
train	O
or	O
fine	O
-	O
tune	O
the	O
weights	O
θ	O
of	O
a	O
single	O
neural	O
model	O
directly	O
for	O
controllable	O
generation	O
,	O
by	O
appending	O
a	O
control	O
code	O
in	O
the	O
beginning	O
of	O
a	O
training	O
sequence	O
.	O
The	O
control	O
code	O
indicates	O
the	O
constraint	O
to	O
verify	O
and	O
is	O
related	O
to	O
a	O
class	O
containing	O
texts	O
that	O
satisfy	O
the	O
constraint	O
.	O

Amazon	O
product	O
data	O
contains	O
customer	O
reviews	O
from	O
24	O
product	O
categories	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
.	O
Our	O
goal	O
is	O
to	O
predict	O
the	O
product	O
category	O
based	O
on	O
the	O
content	O
of	O
the	O
review	O
.	O
The	O
24	O
classes	O
are	O
split	O
into	O
10	O
,	O
5	O
,	O
9	O
for	O
training	O
,	O
validation	O
and	O
test	O
respectively	O
.	O

To	O
facilitate	O
the	O
research	O
study	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
dataset	O
for	O
schema	O
translation	O
written	O
in	O
six	O
different	O
languages	O
.	O
It	O
consists	O
of	O
3,158	O
tables	O
with	O
11,979	O
headers	O
written	O
in	O
six	O
differ	O
-	O
ent	O
languages	O
,	O
including	O
English	O
,	O
Chinese	O
,	O
French	O
,	O
German	O
,	O
Spanish	O
,	O
and	O
Japanese	O
.	O

(	O
2	O
)	O
He	O
said	O
this	O
could	O
not	O
be	O
confirmed	O
,	O
but	O
was	O
quoted	O
by	O
Reuters	O
.	O
Hide	O
Caption	O
:	O
A	O
woman	O
reacts	O
after	O
her	O
car	O
was	O
blown	O
up	O
near	O
an	O
Islamist	O
group	O
rally	O
in	O
Dhaka	O
.	O

To	O
evaluate	O
the	O
computation	O
complexity	O
of	O
different	O
positional	O
encoding	O
methods	O
,	O
we	O
manually	O
con-	O
Furthermore	O
,	O
we	O
conduct	O
an	O
analysis	O
of	O
the	O
GPU	O
memory	O
consumption	O
of	O
the	O
Transformer	B-MethodName
base	O
model	O
with	O
different	O
methods	O
on	O
the	O
WMT	B-MethodName
2014	O
En	O
-	O
De	O
and	O
En	O
-	O
Fr	O
tasks	O
.	O
This	O
is	O
done	O
to	O
determine	O
their	O
relative	O
space	O
complexity	O
.	O
The	O
results	O
of	O
this	O
analysis	O
can	O
be	O
found	O
in	O
Appendix	O
A.2	O
,	O
which	O
demonstrate	O
that	O
all	O
methods	O
exhibit	O
comparable	O
space	O
complexity	O
,	O
except	O
for	O
RPE	O
,	O
which	O
consumes	O
more	O
GPU	O
memory	O
on	O
the	O
WMT	O
2014	O
En	O
-	O
Fr	O
task	O
.	O

Few	O
-	O
shot	O
learning	O
for	O
natural	O
language	O
understanding	O
(	O
NLU	O
)	O
has	O
been	O
significantly	O
advanced	O
by	O
pretrained	O
language	O
models	O
(	O
PLMs	O
;	O
Brown	O
et	O
al	O
.	O
,	O
2020	O
;	O
Schick	O
and	O
Schütze	O
,	O
2021a	O
,	O
b	O
)	O
.	O
With	O
the	O
goal	O
of	O
learning	O
a	O
new	O
task	O
with	O
very	O
few	O
(	O
usually	O
less	O
than	O
a	O
hundred	O
)	O
samples	O
,	O
few	O
-	O
shot	O
learning	O
benefits	O
from	O
the	O
prior	O
knowledge	O
stored	O
in	O
PLMs	O
.	O
Various	O
few	O
-	O
shot	O
methods	O
based	O
on	O
PLMs	O
and	O
prompting	O
have	O
been	O
proposed	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2021b	O
;	O
Menon	O
et	O
al	O
.	O
,	O
2021	O
;	O
Gao	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

We	O
conduct	O
ablation	O
studies	O
on	O
CAST	B-MethodName
to	O
analyze	O
the	O
contributions	O
of	O
our	O
predefined	O
entity	O
types	O
and	O
structural	O
relationships	O
for	O
context	O
modeling	O
.	O
First	O
,	O
we	O
evaluate	O
the	O
variant	O
of	O
CAST	B-MethodName
without	O
entity	O
types	O
.	O
Next	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
CAST	B-MethodName
,	O
without	O
structural	O
relations	O
.	O
Finally	O
,	O
we	O
erase	O
all	O
kinds	O
of	O
relations	O
in	O
CAST	B-MethodName
which	O
is	O
identical	O
to	O
H2H+CXT	O
.	O
We	O
report	O
the	O
performance	O
of	O
models	O
based	O
on	O
M2M-100	O
in	O
the	O
setting	O
of	O
En	O
-	O
De	O
and	O
En	O
-	O
Fr	O
in	O
Table	O
6	O
.	O

In	O
this	O
section	O
,	O
we	O
present	O
extensive	O
empirical	O
evaluation	O
results	O
on	O
comparing	O
our	O
method	O
with	O
its	O
various	O
counterparts	O
on	O
four	O
commonly	O
used	O
paraphrase	O
generation	O
datasets	O
1	O
.	O

Our	O
analyses	O
were	O
sped	O
up	O
using	O
multiprocessing	O
and	O
fuzzy	O
regex	O
.	O
To	O
do	O
so	O
,	O
we	O
split	O
the	O
subcorpus	O
across	O
multiple	O
pieces	O
.	O
These	O
runs	O
take	O
about	O
3	O
days	O
across	O
40	O
CPU	O
Cores	O
,	O
60	O
GB	O
of	O
RAM	O
and	O
less	O
than	O
600	O
GB	O
hard	O
disk	O
space	O
.	O
We	O
report	O
the	O
mean	O
and	O
standard	O
deviation	O
for	O
the	O
number	O
of	O
tokenizations	O
a	O
word	O
has	O
across	O
the	O
portion	O
of	O
the	O
Pile	O
corpus	O
considered	O
.	O
These	O
are	O
also	O
reported	O
as	O
a	O
function	O
of	O
word	O
length	O
and	O
its	O
frequency	O
of	O
occurrence	O
in	O
the	O
corpus	O
.	O

For	O
these	O
experiments	O
,	O
models	O
from	O
Section	O
5.4	O
are	O
further	O
trained	O
with	O
increasing	O
amounts	O
of	O
data	O
from	O
the	O
TAC	B-MethodName
-	O
KBP	I-MethodName
2010	O
training	O
set	O
.	O
A	O
sample	O
of	O
200	O
documents	O
is	O
held	O
out	O
from	O
the	O
training	O
data	O
as	O
a	O
validation	O
set	O
.	O
The	O
models	O
are	O
trained	O
with	O
the	O
exact	O
same	O
configuration	O
as	O
the	O
base	O
models	O
,	O
except	O
with	O
a	O
smaller	O
constant	O
learning	O
rate	O
of	O
2	O
×	O
10	O
−6	O
to	O
not	O
overfit	O
on	O
the	O
small	O
amounts	O
of	O
data	O
.	O
Unsurprisingly	O
,	O
the	O
accuracy	O
of	O
all	O
models	O
increases	O
as	O
the	O
amount	O
of	O
TAC	B-MethodName
training	O
data	O
in-	O
Crucially	O
,	O
the	O
model	O
with	O
only	O
attribute	O
separators	O
is	O
the	O
most	O
accurate	O
model	O
across	O
the	O
spectrum	O
.	O
Moreover	O
,	O
the	O
difference	O
between	O
this	O
model	O
and	O
the	O
baseline	O
model	O
sharply	O
increases	O
as	O
the	O
amount	O
of	O
schema	O
-	O
aware	O
data	O
decreases	O
(	O
e.g.	O
when	O
using	O
13	O
annotated	O
documents	O
,	O
i.e.	O
1	O
%	O
of	O
the	O
training	O
data	O
,	O
we	O
get	O
a	O
9	O
%	O
boost	O
in	O
accuracy	O
over	O
the	O
model	O
that	O
does	O
not	O
see	O
any	O
schema	O
-	O
aware	O
data	O
)	O
.	O
These	O
trends	O
show	O
that	O
our	O
models	O
are	O
not	O
only	O
useful	O
in	O
settings	O
without	O
any	O
data	O
from	O
the	O
target	O
KB	O
,	O
but	O
also	O
in	O
settings	O
where	O
limited	O
data	O
is	O
available	O
.	O

In	O
this	O
section	O
,	O
we	O
study	O
the	O
effect	O
of	O
cube	O
-	O
pruning	O
and	O
identify	O
directions	O
for	O
future	O
research	O
.	O
Further	O
analysis	O
is	O
shown	O
in	O
Appendix	O
F	O
.	O

While	O
vanilla	O
distillation	O
and	O
meta	O
distillation	O
employ	O
a	O
two	O
-	O
stage	O
training	O
approach	O
,	O
online	O
distillation	O
and	O
LGTM	B-MethodName
employ	O
a	O
one	O
-	O
stage	O
joint	O
training	O
strategy	O
for	O
the	O
teacher	O
and	O
student	O
models	O
.	O
The	O
key	O
difference	O
is	O
whether	O
to	O
involve	O
fine	O
-	O
tuning	O
the	O
teacher	O
network	O
on	O
target	O
task	O
.	O
In	O
this	O
study	O
,	O
we	O
investigate	O
the	O
impact	O
of	O
the	O
teacher	O
network	O
's	O
state	O
on	O
the	O
student	O
network	O
.	O

Confidence	O
-	O
order	O
Model	O
Figure	O
3	O
shows	O
an	O
example	O
of	O
the	O
inference	O
performed	O
by	O
our	O
confidence	O
-	O
order	O
model	O
fine	O
-	O
tuned	O
on	O
the	O
CoNLL	B-MethodName
dataset	O
.	O
The	O
document	O
is	O
obtained	O
from	O
the	O
test	O
set	O
of	O
the	O
CoNLL	B-MethodName
dataset	O
.	O
As	O
shown	O
in	O
the	O
figure	O
,	O
the	O
model	O
starts	O
with	O
unambiguous	O
player	O
names	O
to	O
recognize	O
the	O
topic	O
of	O
the	O
document	O
,	O
and	O
subsequently	O
resolves	O
the	O
mentions	O
that	O
are	O
challenging	O
to	O
resolve	O
.	O
Notably	O
,	O
the	O
model	O
correctly	O
resolves	O
the	O
mention	O
"	O
Nigel	O
Walker	O
"	O
to	O
the	O
corresponding	O
former	O
rugby	O
player	O
instead	O
of	O
a	O
football	O
player	O
,	O
and	O
the	O
mention	O
"	O
Matthew	O
Burke	O
"	O
to	O
the	O
correct	O
former	O
Australian	O
rugby	O
player	O
born	O
in	O
1973	O
instead	O
of	O
the	O
former	O
Australian	O
rugby	O
player	O
born	O
in	O
1964	O
.	O
This	O
is	O
accomplished	O
by	O
resolving	O
other	O
contextual	O
mentions	O
,	O
including	O
their	O
colleague	O
players	O
,	O
in	O
advance	O
.	O
These	O
two	O
mentions	O
are	O
denoted	O
in	O
red	O
in	O
the	O
figure	O
.	O
Note	O
that	O
our	O
local	O
model	O
fails	O
to	O
resolve	O
both	O
mentions	O
,	O
and	O
our	O
natural	O
-	O
order	O
model	O
fails	O
to	O
resolve	O
"	O
Matthew	O
Burke	O
.	O
"	O

