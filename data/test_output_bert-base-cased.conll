-DOCSTART-	O
Jordan	O
was	O
in	O
charge	O
of	O
taking	O
the	O
food	O
on	O
the	O
camping	O
trip	O
and	O
left	O
all	O
the	O
food	O
at	O
home	O
.	O
Jordan	O
felt	O
horrible	O
that	O
he	O
let	O
his	O
friends	O
down	O
on	O
the	O
camping	O
trip	O
.	O

We	O
first	O
introduce	O
our	O
view	O
to	O
unify	O
RSE	O
problems	O
and	O
then	O
discuss	O
how	O
TAGPRIME	B-MethodName
approaches	O
this	O
problem	O
under	O
a	O
unified	O
framework	O
of	O
sequence	O
tagging	O
model	O
with	O
priming	O
.	O
1	O
,	O
r	O
c	O
2	O
,	O
...	O
,	O
r	O
c	O
l	O
]	O
towards	O
the	O
condition	O
c	O
,	O
where	O
r	O
c	O
i	O
∈	O
A	O
and	O
A	O
is	O
the	O
set	O
of	O
all	O
possible	O
relationships	O
or	O
attributes	O
.	O
Many	O
NLP	O
tasks	O
can	O
be	O
formulated	O
as	O
an	O
RSE	O
task	O
.	O
We	O
showcase	O
how	O
this	O
formulation	O
can	O
be	O
applied	O
to	O
event	O
extraction	O
,	O
entity	O
relation	O
extraction	O
,	O
and	O
taskoriented	O
semantic	O
parsing	O
below	O
.	O

In	O
this	O
section	O
,	O
we	O
re	O
-	O
introduce	O
premises	O
to	O
our	O
analysis	O
to	O
evaluate	O
a	O
set	O
of	O
hypotheses	O
regarding	O
latent	O
,	O
class	O
-	O
specific	O
annotator	O
heuristics	O
.	O
If	O
annotators	O
do	O
employ	O
class	O
-	O
specific	O
heuristics	O
,	O
we	O
should	O
expect	O
the	O
semantic	O
contents	O
,	O
ϕ	O
,	O
of	O
a	O
given	O
hypothesis	O
,	O
h	O
∈	O
H	O
,	O
to	O
be	O
influenced	O
not	O
only	O
by	O
the	O
semantic	O
contents	O
of	O
its	O
associated	O
premise	O
,	O
p	O
∈	O
P	O
,	O
but	O
also	O
by	O
the	O
target	O
class	O
,	O
c	O
∈	O
C.	O

Using	O
separate	O
scalar	O
mixes	O
for	O
source	O
and	O
target	O
tokens	O
allows	O
us	O
to	O
explore	O
the	O
cross	O
-	O
formalism	O
encoding	O
of	O
role	O
semantics	O
by	O
mBERT	O
in	O
detail	O
.	O
For	O
both	O
English	O
and	O
German	O
role	O
labeling	O
,	O
the	O
probe	O
's	O
layer	O
utilization	O
drastically	O
differs	O
for	O
predicate	O
and	O
4	O
Echoing	O
the	O
recent	O
findings	O
on	O
mBERT	O
's	O
multilingual	O
capacity	O
(	O
Pires	O
et	O
al	O
.	O
,	O
2019;Kondratyuk	O
and	O
Straka	O
,	O
2019	O
[	O
6.16	O
]	O
xnli	O
[	O
6.28	O
]	O
en	O
Layer	O
[	O
4.61	O
]	O
[	O
5.2	O
]	O
[	O
5.09	O
]	O
[	O
5.75	O
]	O
[	O
6.01	O
]	O
[	O
5.99	O
]	O
[	O
5.18	O
]	O
[	O
5.24	O
]	O
[	O
5.13	O
]	O
[	O
6.12	O
]	O
[	O
6.06	O
]	O
[	O
5.75	O
]	O
[	O
6.15	O
]	O
de	O
argument	O
tokens	O
.	O
While	O
the	O
argument	O
representation	O
role	O
*	O
tgt	O
mostly	O
focuses	O
on	O
the	O
same	O
layers	O
as	O
the	O
dependency	O
parsing	O
probe	O
,	O
the	O
layer	O
utilization	O
of	O
the	O
predicates	O
role	O
*	O
src	O
is	O
affected	O
by	O
the	O
chosen	O
formalism	O
.	O
In	O
English	O
,	O
PropBank	O
predicate	O
token	O
mixing	O
weights	O
emphasize	O
the	O
same	O
layers	O
as	O
dependency	O
parsing	O
-in	O
line	O
with	O
the	O
previously	O
published	O
results	O
.	O
However	O
,	O
the	O
probes	O
for	O
VerbNet	O
and	O
FrameNet	O
predicates	O
(	O
role.vn	O
src	O
and	O
role.fn	O
src	O
)	O
utilize	O
the	O
layers	O
associated	O
with	O
ttype	O
and	O
lex.unit	O
that	O
contain	O
lexical	O
information	O
.	O
Coupled	O
with	O
the	O
fact	O
that	O
both	O
VerbNet	B-MethodName
and	O
FrameNet	B-MethodName
assign	O
semantic	O
roles	O
based	O
on	O
lexical	O
-	O
semantic	O
predicate	O
groupings	O
(	O
frames	O
in	O
FrameNet	O
and	O
verb	O
classes	O
in	O
VerbNet	O
)	O
,	O
this	O
suggests	O
that	O
the	O
lower	O
layers	O
of	O
mBERT	O
implicitly	O
encode	O
predicate	O
sense	O
information	O
;	O
moreover	O
,	O
sense	O
encoding	O
for	O
VerbNet	O
utilizes	O
deeper	O
layers	O
of	O
the	O
model	O
associated	O
with	O
syntax	O
,	O
in	O
line	O
with	O
Verb	O
-	O
Net	O
's	O
predicate	O
classification	O
strategy	O
.	O
This	O
finding	O
confirms	O
that	O
the	O
formalism	O
can	O
indeed	O
have	O
linguistically	O
meaningful	O
effects	O
on	O
probing	O
results	O
.	O

We	O
show	O
part	O
of	O
the	O
analysis	O
results	O
below	O
due	O
to	O
the	O
limited	O
space	O
,	O
and	O
more	O
analysis	O
can	O
be	O
found	O
in	O
Appendix	O
§	O
A	O
and	O
§	O
D	O
.	O

where	O
θ	O
q	O
and	O
θ	O
k	O
are	O
model	O
parameters	O
of	O
f	O
q	O
and	O
f	O
k	O
,	O
respectively	O
.	O
m	O
is	O
the	O
momentum	O
coefficient	O
.	O

Sequential	O
vs.	O
parallel	O
.	O
In	O
the	O
main	O
experiments	O
,	O
we	O
used	O
a	O
'	O
sequential	O
'	O
(	O
seq	O
)	O
structure	O
where	O
our	O
tiny	O
-	O
attention	O
modules	O
are	O
placed	O
between	O
the	O
pretrained	O
attention	O
and	O
feed	O
-	O
forward	O
net	O
.	O
Another	O
option	O
is	O
to	O
put	O
the	O
tiny	O
-	O
attention	O
module	O
in	O
'	O
parallel	O
'	O
(	O
para	O
)	O
to	O
the	O
original	O
attention	O
layer	O
as	O
in	O
He	O
et	O
al	O
.	O
(	O
2021	O
)	O
.	O

To	O
evaluate	O
how	O
well	O
our	O
generation	O
model	O
achieves	O
target	O
difficulties	O
,	O
we	O
take	O
15	O
unseen	O
students	O
and	O
generate	O
30	O
questions	O
for	O
each	O
of	O
9	O
input	O
difficulties	O
(	O
0.1	O
-	O
0.9	O
)	O
.	O
We	O
then	O
use	O
LM	O
-	I-MethodName
KT	I-MethodName
(	O
a	O
wellcalibrated	O
proxy	O
for	O
true	O
difficulty	O
)	O
to	O
measure	O
the	O
difficulty	O
of	O
these	O
generated	O
questions	O
for	O
each	O
student	O
.	O
Figure	O
3	O
shows	O
that	O
we	O
are	O
able	O
to	O
achieve	O
fine	O
-	O
grained	O
control	O
over	O
target	O
difficulty	O
for	O
both	O
Spanish	O
and	O
French	O
students	O
,	O
with	O
an	O
average	O
Root	O
-	O
Mean	O
Squared	I-MethodName
Error	I-MethodName
(	O
RMSE	O
)	O
of	O
.052	O
across	O
all	O
students	O
and	O
target	O
difficulties	O
.	O
Adding	O
a	O
sampling	O
penalty	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
increases	O
the	O
variance	O
in	O
difficulty	O
(	O
RMSE	B-DatasetName
.062	O
)	O
in	O
exchange	O
for	O
more	O
novel	O
and	O
diverse	O
questions	O
,	O
as	O
discussed	O
next	O
.	O

Our	O
primary	O
experiments	O
are	O
cross	O
-	O
KB	O
and	O
focus	O
on	O
English	O
datasets	O
.	O
We	O
train	O
models	O
to	O
link	O
to	O
one	O
KB	O
during	O
training	O
(	O
viz	O
.	O
Wikidata	O
)	O
,	O
and	O
evaluate	O
them	O
for	O
their	O
ability	O
to	O
link	O
to	O
an	O
unseen	O
KB	O
(	O
viz	O
.	O
the	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
Knowledge	O
Base	O
)	O
.	O
These	O
experiments	O
reveal	O
that	O
our	O
model	O
with	O
attributeseparators	O
and	O
the	O
two	O
generalization	O
schemes	O
are	O
12	O
-	O
14	O
%	O
more	O
accurate	O
than	O
the	O
baseline	O
zero	O
-	O
shot	O
models	O
.	O
Ablation	O
studies	O
reveal	O
that	O
all	O
components	O
individually	O
contribute	O
to	O
this	O
improvement	O
,	O
but	O
combining	O
all	O
of	O
them	O
yields	O
the	O
most	O
accurate	O
models	O
.	O

To	O
detect	O
realis	O
events	O
in	O
our	O
stories	O
,	O
we	O
train	O
a	O
tagger	O
(	O
using	O
BERT	O
-	O
base	O
;	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
on	O
the	O
annotated	O
corpus	O
by	O
Sims	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
This	O
corpus	O
contains	O
8k	O
realis	O
events	O
annotated	O
by	O
experts	O
in	O
sentences	O
drawn	O
from	O
100	O
English	O
books	O
.	O
With	O
development	O
and	O
test	O
F	O
1	O
scores	O
of	O
83.7	O
%	O
and	O
75.8	O
%	O
,	O
respectively	O
,	O
our	O
event	O
tagger	O
slightly	O
outperforms	O
the	O
best	O
performing	O
model	O
in	O
Sims	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
reached	O
73.9	O
%	O
F	O
1	O
.	O
In	O
our	O
analyses	O
,	O
we	O
use	O
our	O
tagger	O
to	O
detect	O
the	O
number	O
of	O
realis	O
event	O
mentions	O
.	O

Besides	O
the	O
aforementioned	O
three	O
major	O
directions	O
,	O
Artetxe	O
and	O
Schwenk	O
(	O
2019	O
)	O
train	O
a	O
multilingual	O
sentence	O
encoder	O
on	O
93	O
languages	O
.	O
Their	O
stacked	O
BiLSTM	B-MethodName
encoder	O
is	O
trained	O
by	O
first	O
generating	O
embedding	O
of	O
a	O
source	O
sentence	O
and	O
then	O
decoding	O
the	O
embedding	O
into	O
the	O
target	O
sentence	O
in	O
other	O
languages	O
.	O

OK	O
.	O
Here	O
is	O
a	O
description	O
of	O
the	O
cartoon	O
followed	O
by	O
the	O
five	O
choices	O
.	O

So	O
far	O
,	O
we	O
have	O
analyzed	O
errors	O
in	O
predictions	O
for	O
all	O
the	O
answerable	O
questions	O
.	O
Next	O
,	O
we	O
focus	O
our	O
attention	O
on	O
questions	O
with	O
multi	O
-	O
span	O
and	O
multispeaker	O
answers	O
.	O
Within	O
the	O
multi	O
-	O
span	O
split	O
,	O
we	O
calculate	O
the	O
fraction	O
of	O
incorrect	O
predictions	O
(	O
as	O
per	O
exact	O
match	O
)	O
that	O
are	O
multi	O
-	O
span	O
,	O
denoted	O
by	O
multi	O
-	O
span	O
preds	O
(	O
%	O
)	O
.	O
Similarly	O
,	O
for	O
multi	O
-	O
speaker	O
split	O
,	O
we	O
calculate	O
the	O
fraction	O
of	O
incorrect	O
predictions	O
(	O
as	O
per	O
exact	O
match	O
)	O
that	O
are	O
multi	O
-	O
speaker	O
in	O
nature	O
,	O
denoted	O
by	O
multi	O
-	O
speaker	O
preds	O
(	O
%	O
)	O
.	O
Further	O
,	O
we	O
compare	O
the	O
list	O
of	O
speakers	O
in	O
the	O
reference	O
and	O
predicted	O
spans	O
using	O
Jaccard	O
similarity	O
(	O
IoU	O
)	O
denoted	O
as	O
speaker	O
IoU.	O
We	O
compute	O
and	O
report	O
these	O
metrics	O
for	O
all	O
the	O
aforementioned	O
models	O
in	O
Table	O
10	O
.	O

XNLI	O
Table	O
2	O
shows	O
results	O
on	O
XNLI	O
measured	O
by	O
accuracy	O
.	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
only	O
provide	O
results	O
on	O
a	O
few	O
languages	O
6	O
,	O
so	O
we	O
use	O
the	O
mBERT	B-MethodName
results	O
from	O
as	O
our	O
baseline	O
for	O
zeroshot	O
cross	O
-	O
lingual	O
transfer	O
,	O
and	O
Wu	O
and	O
Dredze	O
(	O
2019	O
)	O
for	O
translate	O
-	O
train	O
.	O
Our	O
best	O
model	O
,	O
trained	O
with	O
2	O
M	O
parallel	O
sentences	O
per	O
language	O
improves	O
over	O
mBERT	B-MethodName
baseline	O
by	O
4.7	O
%	O
for	O
zero	O
-	O
shot	O
transfer	O
,	O
and	O
3.2	O
%	O
for	O
translate	O
-	O
train	O
.	O

Step	O
We	O
show	O
the	O
process	O
of	O
Step	O
1	O
and	O
Step	O
2	O
in	O
Figure	O
3	O
(	O
a	O
)	O
and	O
Figure	O
3	O
(	O
b	O
)	O
,	O
respectively	O
.	O
Overall	O
,	O
the	O
collected	O
code	O
-	O
code	O
corpus	O
contains	O
23.4	O
million	O
pairs	O
.	O
We	O
provide	O
a	O
more	O
detailed	O
description	O
on	O
building	O
code	O
-	O
code	O
corpus	O
,	O
involved	O
hyperparameters	O
and	O
detailed	O
cross	O
-	O
language	O
statistics	O
of	O
code	O
-	O
code	O
pairs	O
in	O
Appendix	O
B	O
,	O
C	O
and	O
D	O
.	O

In	O
order	O
to	O
determine	O
which	O
questions	O
are	O
appropriate	O
for	O
a	O
given	O
sentence	O
,	O
we	O
examine	O
the	O
dependency	O
structure	O
of	O
the	O
original	O
sentence	O
and	O
check	O
if	O
it	O
contains	O
the	O
required	O
part	O
to	O
be	O
removed	O
before	O
parameterizing	O
the	O
realization	O
.	O
The	O
generated	O
questions	O
are	O
then	O
filtered	O
to	O
remove	O
any	O
question	O
for	O
which	O
the	O
answer	O
is	O
composed	O
of	O
a	O
single	O
stopword	O
.	O
Table	O
1	O
shows	O
the	O
number	O
of	O
questions	O
generated	O
for	O
each	O
dataset	O
.	O
An	O
example	O
of	O
a	O
synthetic	O
question	O
is	O
shown	O
in	O
Figure	O
3	O
.	O

Concretely	O
,	O
these	O
queries	O
are	O
encountered	O
during	O
scientific	O
literature	O
review	O
(	O
Voorhees	O
et	O
al	O
.	O
,	O
2021	O
;	O
Dasigi	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
when	O
looking	O
for	O
news	O
and	O
background	O
information	O
(	O
Soboroff	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
during	O
argument	O
retrieval	O
,	O
(	O
Bondarenko	O
et	O
al	O
.	O
,	O
2021	O
)	O
or	O
in	O
the	O
legal	O
context	O
for	O
case	O
law	O
retrieval	O
(	O
Locke	O
and	O
Zuccon	O
,	O
2018	O
)	O
.	O

,	O
and	O
d	O
k	O
is	O
set	O
to	O
300	O
.	O
The	O
model	O
is	O
trained	O
using	O
the	O
InfoNCE	B-MethodName
loss	O
:	O

Decoder	O
.	O
The	O
goal	O
of	O
the	O
decoder	O
is	O
to	O
autoregressively	O
generate	O
the	O
translated	O
column	O
header	O
Y	O
=	O
hy	O
1	O
,	O
.	O
.	O
.	O
,	O
y	O
m	O
i.	O
Specifically	O
,	O
taking	O
X	O
0	O
and	O
the	O
representation	O
of	O
previously	O
output	O
token	O
as	O
input	O
,	O
the	O
decoder	O
predicts	O
the	O
translation	O
token	O
by	O
token	O
until	O
an	O
ending	O
signal	O
hendi	O
is	O
generated	O
.	O
Similar	O
to	O
the	O
encoder	O
,	O
a	O
special	O
token	O
htgti	O
which	O
indicates	O
the	O
target	O
language	O
is	O
added	O
at	O
the	O
front	O
to	O
guide	O
the	O
prediction	O
of	O
the	O
target	O
language	O
.	O

2	O
.	O
Replace	O
the	O
k	O
random	O
positions	O
with	O
negative	O
samples	O
:	O

Anchor	O
tasks	O
.	O
We	O
employ	O
two	O
analytical	O
tools	O
from	O
the	O
original	O
layer	O
probing	O
setup	O
.	O
Mixing	O
weight	O
plotting	O
compares	O
layer	O
utilization	O
among	O
tasks	O
by	O
visually	O
aligning	O
the	O
respective	O
learned	O
weight	O
distributions	O
transformed	O
via	O
a	O
softmax	O
function	O
.	O
Layer	O
center	O
-	O
of	O
-	O
gravity	O
is	O
used	O
as	O
a	O
summary	O
statistic	O
for	O
a	O
task	O
's	O
layer	O
utilization	O
.	O
While	O
the	O
distribution	O
of	O
mixing	O
weights	O
along	O
the	O
layers	O
allows	O
us	O
to	O
estimate	O
the	O
order	O
in	O
which	O
information	O
is	O
processed	O
during	O
encoding	O
,	O
it	O
does	O
n't	O
allow	O
to	O
directly	O
assess	O
the	O
similarity	O
between	O
the	O
layer	O
utilization	O
of	O
the	O
probing	O
tasks	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
have	O
demonstrated	O
that	O
the	O
order	O
in	O
which	O
linguistic	O
information	O
is	O
stored	O
in	O
BERT	B-MethodName
mirrors	O
the	O
traditional	O
NLP	O
pipeline	O
.	O
A	O
prominent	O
property	O
of	O
the	O
NLP	O
pipelines	O
is	O
their	O
use	O
of	O
low	O
-	O
level	O
features	O
to	O
predict	O
downstream	O
phenomena	O
.	O
In	O
the	O
context	O
of	O
layer	O
probing	O
,	O
probing	O
tasks	O
can	O
be	O
seen	O
as	O
end	O
-	O
to	O
-	O
end	O
feature	O
extractors	O
.	O
Following	O
this	O
intuition	O
,	O
we	O
define	O
two	O
groups	O
of	O
probing	O
tasks	O
:	O
target	O
tasks	O
-the	O
main	O
tasks	O
under	O
investigation	O
,	O
and	O
anchor	O
tasks	O
-a	O
set	O
of	O
related	O
tasks	O
that	O
serve	O
as	O
a	O
basis	O
for	O
qualitative	O
comparison	O
between	O
the	O
targets	O
.	O
The	O
softmax	O
transformation	O
of	O
the	O
scalar	O
mixing	O
weights	O
allows	O
to	O
treat	O
them	O
as	O
probability	O
distributions	O
:	O
the	O
higher	O
the	O
mixing	O
weight	O
of	O
a	O
layer	O
,	O
the	O
more	O
likely	O
the	O
probe	O
is	O
to	O
utilize	O
information	O
from	O
this	O
layer	O
during	O
prediction	O
.	O
We	O
use	O
Kullback	O
-	O
Leibler	O
divergence	O
to	O
compare	O
target	O
tasks	O
(	O
e.g.	O
role	O
labeling	O
in	O
different	O
formalisms	O
)	O
in	O
terms	O
of	O
their	O
similarity	O
to	O
lowerlevel	O
anchor	O
tasks	O
(	O
e.g.	O
dependency	O
relation	O
and	O
lemma	O
)	O
.	O
Note	O
that	O
the	O
notion	O
of	O
anchor	O
task	O
is	O
contextual	O
:	O
the	O
same	O
task	O
can	O
serve	O
as	O
a	O
target	O
and	O
as	O
an	O
anchor	O
,	O
depending	O
on	O
the	O
focus	O
of	O
the	O
study	O
.	O
jections	O
in	O
the	O
background	O
,	O
but	O
do	O
not	O
investigate	O
the	O
differences	O
between	O
the	O
learned	O
projections	O
.	O

tional	O
words	O
.	O
Then	O
,	O
we	O
would	O
like	O
to	O
evaluate	O
the	O
accuracy	O
of	O
different	O
losses	O
on	O
different	O
types	O
of	O
syntactic	O
multi	O
-	O
modality	O
.	O
However	O
,	O
in	O
real	O
-	O
world	O
corpora	O
,	O
the	O
different	O
types	O
are	O
usually	O
entangled	O
,	O
making	O
it	O
difficult	O
to	O
control	O
and	O
analyse	O
one	O
aspect	O
without	O
changing	O
the	O
other	O
.	O
Thus	O
,	O
we	O
construct	O
synthesized	O
datasets	O
based	O
on	O
phrase	O
structure	O
rules	O
(	O
Chomsky	O
,	O
1959	O
)	O
to	O
manually	O
control	O
the	O
degree	O
of	O
syntactic	O
multi	O
-	O
modality	O
in	O
different	O
aspects	O
,	O
and	O
evaluate	O
the	O
performance	O
of	O
different	O
existing	O
techniques	O
.	O

The	O
first	O
iteration	O
for	O
the	O
foundation	O
of	O
the	O
MAS	O
-	O
SIVE	O
dataset	O
was	O
the	O
NLU	O
Evaluation	O
Benchmarking	O
Dataset	O
,	O
with	O
25k	O
utterances	O
across	O
18	O
domains	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019a	O
)	O
.	O
The	O
authors	O
updated	O
the	O
dataset	O
and	O
added	O
audio	O
and	O
ASR	B-TaskName
transcriptions	O
in	O
the	O
release	O
of	O
the	O
Spoken	O
Language	O
Understanding	O
Resource	O
Package	O
(	O
SLURP	O
)	O
(	O
Bastianelli	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
allowing	O
for	O
full	O
end	O
-	O
to	O
-	O
end	O
Spoken	O
Language	O
Understanding	O
(	O
SLU	O
)	O
evaluation	O
similar	O
to	O
the	O
Fluent	O
Speech	O
Commands	O
dataset	O
(	O
Lugosch	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Chinese	O
Audio	O
-	O
Textual	O
Spoken	I-MethodName
Language	O
Understanding	O
(	O
CATSLU	B-DatasetName
)	O
(	O
Zhu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
An	O
overview	O
of	O
selected	O
existing	O
NLU	O
datasets	O
can	O
be	O
seen	O
in	O
Table	O
1	O
.	O

•	O
STS	B-MethodName
:	O
Semantic	O
Textual	O
Similarity	O
(	O
Cer	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
The	O
tasks	O
is	O
to	O
predict	O
how	O
semantically	O
similar	O
two	O
sentences	O
are	O
on	O
a	O
1	O
-	O
5	O
scale	O
.	O
The	O
dataset	O
contains	O
5.8k	O
train	O
examples	O
drawn	O
from	O
new	O
headlines	O
,	O
video	O
and	O
image	O
captions	O
,	O
and	O
natural	O
language	O
inference	O
data	O
.	O

•	O
CoLA	O
:	O
Corpus	O
of	O
Linguistic	O
Acceptability	O
(	O
Warstadt	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
The	O
task	O
is	O
to	O
determine	O
whether	O
a	O
given	O
sentence	O
is	O
grammatical	O
or	O
not	O
.	O
The	O
dataset	O
contains	O
8.5k	O
train	O
examples	O
from	O
books	O
and	O
journal	O
articles	O
on	O
linguistic	O
theory	O
.	O

We	O
would	O
like	O
to	O
thank	O
Nontawat	O
Charoenphakdee	O
and	O
anonymous	O
reviewers	O
for	O
helpful	O
comments	O
.	O
Also	O
,	O
the	O
first	O
author	O
wishes	O
to	O
thank	O
the	O
support	O
from	O
Anandamahidol	O
Foundation	O
,	O
Thailand	O
.	O

Case	O
study	O
In	O
order	O
to	O
understand	O
the	O
performance	O
gain	O
of	O
our	O
model	O
over	O
sub	O
-	O
word	O
based	O
BERT	B-MethodName
on	O
cross	O
-	O
domain	O
tasks	O
,	O
we	O
look	O
into	O
the	O
cases	O
where	O
BERT	B-MethodName
makes	O
incorrect	O
predictions	O
.	O
We	O
found	O
that	O
many	O
of	O
these	O
cases	O
contain	O
excessively	O
fragmented	O
words	O
.	O
Table	O
5	O
shows	O
two	O
examples	O
from	O
the	O
NCBI	O
-	O
disease	O
NER	O
task	O
.	O
The	O
word	O
fragility	O
in	O
case	O
1	O
is	O
segmented	O
into	O
f	O
,	O
#	O
#	O
rag	O
,	O
#	O
#	O
ility	O
,	O
and	O
the	O
word	O
rupture	O
in	O
case	O
2	O
is	O
segmented	O
into	O
r	O
,	O
#	O
#	O
up	O
,	O
#	O
#	O
ture	O
.	O
We	O
think	O
these	O
tokenization	O
results	O

Based	O
on	O
this	O
,	O
we	O
model	O
a	O
gating	O
variable	O
g	O
as	O
:	O

Our	O
work	O
is	O
a	O
first	O
step	O
toward	O
showing	O
that	O
sequence	O
-	O
based	O
models	O
combined	O
with	O
domain	O
knowledge	O
,	O
such	O
as	O
pre	O
-	O
trained	O
LMs	O
,	O
can	O
be	O
leveraged	O
for	O
adaptive	O
learning	O
tasks	O
.	O
We	O
show	O
how	O
to	O
use	O
modern	O
LMs	O
to	O
generate	O
novel	O
reversetranslation	O
questions	O
that	O
achieve	O
a	O
target	O
difficulty	O
,	O
allowing	O
adaptive	O
education	O
methods	O
to	O
expand	O
beyond	O
limited	O
question	O
pools	O
.	O
Limitations	O
of	O
our	O
approach	O
include	O
the	O
compute	O
constraints	O
of	O
large	O
LMs	O
and	O
training	O
data	O
availability	O
.	O
More	O
detailed	O
student	O
data	O
will	O
be	O
crucial	O
to	O
future	O
model	O
development	O
.	O
For	O
instance	O
,	O
while	O
most	O
publicly	O
available	O
education	O
datasets	O
do	O
not	O
include	O
the	O
full	O
student	O
responses	O
(	O
e.g.	O
full	O
translation	O
response	O
in	O
Duolingo	O
)	O
,	O
such	O
information	O
could	O
significantly	O
improve	O
the	O
performance	O
of	O
our	O
LM	O
-	O
KT	O
model	O
.	O
Other	O
future	O
directions	O
include	O
exploring	O
non	O
-	O
language	O
domains	O
,	O
such	O
as	O
math	O
or	O
logic	O
exercises	O
,	O
and	O
controlling	O
for	O
auxiliary	O
objectives	O
such	O
as	O
question	O
topic	O
.	O

In	O
this	O
feasibility	O
study	O
,	O
we	O
assessed	O
the	O
effectiveness	O
of	O
word	O
clouds	O
as	O
visual	O
explanations	O
to	O
reveal	O
the	O
behavior	O
of	O
CNN	B-MethodName
features	O
.	O
We	O
trained	O
CNN	B-MethodName
models	O
using	O
small	O
training	O
datasets	O
and	O
evaluated	O
the	O
quality	O
of	O
CNN	B-MethodName
features	O
based	O
on	O
responses	O
from	O
MTurk	O
workers	O
to	O
the	O
feature	O
word	O
clouds	O
.	O

•	O
ALBEF	B-MethodName
mscoco	O
is	O
the	O
only	O
model	O
to	O
predict	O
ISA	O
(	O
99.4	O
%	O
)	O
on	O
the	O
caption	O
with	O
coherentbut	O
mostly	O
textual	O
-indicators	O
.	O
It	O
fails	O
on	O
foil	O
prediction	O
,	O
still	O
relying	O
on	O
the	O
same	O
textual	O
indicators	O
,	O
and	O
on	O
the	O
visual	O
side	O
focuses	O
on	O
counter	O
-	O
evidence	O
regions	O
,	O
erroneously	O
taking	O
them	O
as	O
positive	O
support	O
for	O
ISA	O
.	O

Compared	O
to	O
the	O
unsupervised	O
approaches	O
,	O
MB	B-MethodName
-	I-MethodName
RPG	I-MethodName
is	O
also	O
superior	O
especially	O
in	O
terms	O
of	O
the	O
iBLEU	B-MetricName
and	O
BLEU	B-MetricName
metrics	O
.	O
The	O
main	O
reason	O
might	O
be	O
that	O
the	O
word	O
editing	O
or	O
sampling	O
attempts	O
proposed	O
in	O
the	O
unsupervised	O
baselines	O
yield	O
less	O
desirable	O
target	O
paraphrases	O
and	O
thus	O
makes	O
the	O
performance	O
of	O
the	O
model	O
trained	O
under	O
the	O
unsupervised	O
data	O
fall	O
far	O
below	O
our	O
method	O
and	O
various	O
supervised	O
baselines	O
.	O
The	O
inferior	O
performance	O
of	O
the	O
unsupervised	O
methods	O
has	O
also	O
been	O
empirically	O
evaluated	O
and	O
discussed	O
by	O
Niu	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O

Paraphraser	O
We	O
finetune	O
the	O
paraphraser	O
using	O
a	O
batch	O
size	O
of	O
1	O
,	O
024	O
tokens	O
for	O
5	O
,	O
000	O
iterations	O
(	O
500	O
for	O
warm	O
-	O
up	O
)	O
,	O
with	O
a	O
learning	O
rate	O
of	O
3e	O
−	I-MetricValue
5	I-MetricValue
using	O
ADAM	B-MethodName
.	O
We	O
apply	O
label	O
smoothing	O
with	O
a	O
probability	O
of	O
0.1	O
.	O
Semantic	O
Parser	O
Our	O
semantic	O
parser	O
is	O
a	O
neural	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
with	O
dot	O
-	O
product	O
attention	O
(	O
Luong	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
using	O
a	O
BERT	B-MethodName
Base	O
encoder	O
and	O
an	O
LSTM	O
decoder	O
,	O
augmented	O
with	O
copying	O
mechanism	O
.	O
The	O
size	O
of	O
the	O
LSTM	O
hidden	O
state	O
is	O
256	O
.	O
We	O
decode	O
programs	O
using	O
beam	O
search	O
with	O
a	O
beam	O
size	O
of	O
5	O
.	O
Following	O
,	O
we	O
remove	O
hypotheses	O
from	O
the	O
beam	O
that	O
leads	O
to	O
error	O
executions	O
.	O

set	O
to	O
4	O
,	O
given	O
our	O
minimum	O
requirements	O
for	O
fusion	O
labels	O
.	O
The	O
final	O
evaluated	O
score	O
reported	O
was	O
an	O
average	O
score	O
over	O
20	O
different	O
trained	O
models	O
.	O
This	O
is	O
due	O
to	O
BART	B-MethodName
being	O
highly	O
sensitive	O
to	O
the	O
ordering	O
of	O
the	O
input	O
sentences	O
.	O
Both	O
baseline	O
models	O
were	O
trained	O
using	O
the	O
train	O
/	O
test	O
splits	O
that	O
were	O
reported	O
in	O
Thadani	O
and	O
McKeown	O
(	O
2013	O
)	O

We	O
propose	O
a	O
simple	O
method	O
to	O
align	O
multilingual	O
contextual	O
embeddings	O
as	O
a	O
postpretraining	O
step	O
for	O
improved	O
cross	O
-	O
lingual	O
transferability	O
of	O
the	O
pretrained	O
language	O
models	O
.	O
Using	O
parallel	O
data	O
,	O
our	O
method	O
aligns	O
embeddings	O
on	O
the	O
word	O
level	O
through	O
the	O
recently	O
proposed	O
Translation	O
Language	O
Modeling	O
objective	O
as	O
well	O
as	O
on	O
the	O
sentence	O
level	O
via	O
contrastive	O
learning	O
and	O
random	O
input	O
shuffling	O
.	O
We	O
also	O
perform	O
sentence	O
-	O
level	O
code	O
-	O
switching	O
with	O
English	O
when	O
finetuning	O
on	O
downstream	O
tasks	O
.	O
On	O
XNLI	B-DatasetName
,	O
our	O
best	O
model	O
(	O
initialized	O
from	O
mBERT	B-MethodName
)	O
improves	O
over	O
mBERT	B-MethodName
by	O
4.7	O
%	O
in	O
the	O
zero	O
-	O
shot	O
setting	O
and	O
achieves	O
comparable	O
result	O
to	O
XLM	O
for	O
translate	O
-	O
train	O
while	O
using	O
less	O
than	O
18	O
%	O
of	O
the	O
same	O
parallel	O
data	O
and	O
31	O
%	O
fewer	O
model	O
parameters	O
.	O
On	O
MLQA	O
,	O
our	O
model	O
outperforms	O
XLM	O
-	O
R	O
Base	O
,	O
which	O
has	O
57	O
%	O
more	O
parameters	O
than	O
ours	O
.	O

Q	O
:	O
who	O
was	O
last	O
person	O
to	O
be	O
executed	O
in	O
us	O
A	O
:	O
Ruben	O
Cardenas	O
Ramirez	O
Billy	O
Bailey	O
:	O
He	O
became	O
only	O
the	O
third	O
person	O
to	O
be	O
hanged	O
in	O
the	O
United	O
States	O
since	O
1965	O
(	O
the	O
previous	O
two	O
were	O
Charles	O
Rodman	O
Campbell	O
and	O
Westley	O
Allan	O
Dodd	O
,	O
both	O
in	O
Washington	O
)	O
and	O
the	O
first	O
person	O
hanged	O
in	O
Delaware	O
in	O
50	O
years	O
.	O
As	O
of	O
2018	O
,	O
he	O
remains	O
the	O
last	O
person	O
to	O
be	O
executed	O
by	O
hanging	O
in	O
the	O
United	O
States	O
.	O

Dataset	O
Statistics	O
Table	O
5	O
shows	O
the	O
detailed	O
statistics	O
of	O
HyperRED	O
,	O
such	O
as	O
the	O
number	O
of	O
unique	O
facts	O
and	O
entities	O
,	O
as	O
well	O
as	O
the	O
average	O
number	O
of	O
words	O
in	O
each	O
sentence	O
.	O
dataset	O
,	O
we	O
use	O
the	O
Wikidata	O
which	O
has	O
594,088	O
hyper	O
-	O
relational	O
facts	O
and	O
introductions	O
from	O
English	O
Wikipedia	O
which	O
has	O
4,650,000	O
articles	O
.	O

Subsequently	O
,	O
the	O
new	O
parameters	O
are	O
evaluated	O
on	O
their	O
ability	O
to	O
adapt	O
to	O
the	O
second	O
task	O
T	O
2	O
by	O
computing	O
the	O
loss	O
of	O
the	O
predictions	O
made	O
by	O
the	O
model	O
g	O
θ	O
′	O
.	O
By	O
backpropagating	O
through	O
this	O
entire	O
process	O
(	O
i.e.	O
computing	O
the	O
gradients	O
w.r.t	O
.	O
to	O
θ	O
)	O
,	O
the	O
original	O
parameters	O
of	O
the	O
model	O
are	O
optimized	O
:	O

Finally	O
,	O
designing	O
appropriate	O
user	O
studies	O
to	O
evaluate	O
our	O
method	O
is	O
a	O
complex	O
yet	O
critical	O
next	O
step	O
to	O
determine	O
its	O
suitability	O
in	O
a	O
real	O
-	O
world	O
education	O
setting	O
.	O
Our	O
techniques	O
allows	O
control	O
for	O
individual	O
student	O
difficulty	O
,	O
but	O
it	O
leaves	O
open	O
the	O
question	O
of	O
optimal	O
curriculum	O
design	O
using	O
difficulty	O
-	O
directed	O
question	O
generation	O
.	O

diverse	O
beam	O
search	O
is	O
a	O
diversity	O
-	O
promoting	O
variant	O
of	O
beam	O
search	O
(	O
Vijayakumar	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
We	O
experiment	O
with	O
different	O
numbers	O
of	O
beam	O
groups	O
for	O
diverse	O
beam	O
search	O
:	O
5	O
for	O
DBS	O
and	O
10	O
for	O
DBS+	O
.	O
Sample	O
is	O
represented	O
by	O
two	O
widelyadopted	O
strong	O
stochastic	O
sampling	O
methods	O
,	O
nucleus	O
sampling	O
(	O
NCLS	B-TaskName
)	O
(	O
Holtzman	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
typical	O
sampling	O
(	O
TYP	O
)	O
(	O
Meister	O
et	O
al	O
.	O
,	O
2022a	O
)	O
.	O

i=1	O
are	O
initial	O
embeddings	O
of	O
our	O
input	O
sequence	O
,	O
and	O
the	O
relational	O
matrix	O
R	O
is	O
induced	O
from	O
the	O
input	O
graph	O
,	O
where	O
r	O
ij	O
is	O
a	O
learned	O
embedding	O
according	O
to	O
the	O
type	O
of	O
edge	O
that	O
x	O
i	O
and	O
x	O
j	O
hold	O
in	O
the	O
directed	O
input	O
graph	O
.	O
The	O
following	O
section	O
will	O
describe	O
the	O
set	O
of	O
relations	O
our	O
model	O
uses	O
to	O
encode	O
a	O
target	O
header	O
concatenated	O
with	O
its	O
context	O
.	O

Physician	O
-	O
annotators	O
were	O
asked	O
to	O
write	O
a	O
definitely	O
true	O
,	O
maybe	O
true	O
,	O
and	O
definitely	O
false	O
set	O
of	O
hypotheses	O
for	O
each	O
premise	O
,	O
corresponding	O
to	O
entailment	O
,	O
neutral	O
and	O
contradiction	O
labels	O
,	O
respectively	O
.	O
The	O
resulting	O
dataset	O
has	O
cardinality	O
:	O
n	O
train	O
=	O
11232	O
;	O
n	O
dev	O
=	O
1395	O
;	O
n	O
test	O
=	O
1422	O
.	O

In	O
this	O
work	O
,	O
we	O
first	O
collect	O
and	O
annotate	O
an	O
E2E	O
stance	O
dataset	O
,	O
SEESAW	O
2	O
(	O
Stance	O
between	O
Entity	O
and	O
Entity	O
Supplemented	O
with	O
Article	O
-	O
level	O
vieWpoint	O
)	O
,	O
based	O
on	O
609	O
news	O
articles	O
crawled	O
from	O
AllSides	O
.	O
3	O
SEESAW	O
contains	O
10,619	O
stance	O
triplets	O
annotated	O
at	O
the	O
sentence	O
level	O
,	O
drawn	O
from	O
203	O
political	O
news	O
stories	O
,	O
with	O
each	O
"	O
story	O
"	O
consisting	O
of	O
3	O
articles	O
by	O
media	O
of	O
different	O
ideological	O
leanings	O
,	O
as	O
collected	O
,	O
coded	O
,	O
and	O
aligned	O
by	O
AllSides	O
.	O
Our	O
entities	O
cover	O
people	O
,	O
organizations	O
,	O
events	O
,	O
topics	O
,	O
and	O
other	O
objects	O
.	O

2	O
.	O
Probable	O
Cause	O
Heuristic	O
:	O
a	O
premisehypothesis	O
pair	O
satisfies	O
this	O
heuristic	O
if	O
:	O
(	O
1	O
)	O
the	O
premise	O
contains	O
one	O
or	O
more	O
MeSH	O
entities	O
belonging	O
to	O
high	O
-	O
level	O
categories	O
C	O
(	O
diseases	O
)	O
,	O
D	O
(	O
chemicals	O
and	O
drugs	O
)	O
,	O
E	O
(	O
analytical	O
,	O
diagnostic	O
and	O
therapeutic	O
techniques	O
,	O
and	O
equipment	O
)	O
or	O
F	O
(	O
psychiatry	O
and	O
psychology	O
)	O
;	O
and	O
(	O
2	O
)	O
the	O
hypothesis	O
contains	O
one	O
or	O
more	O
MeSH	O
entities	O
that	O
can	O
be	O
interpreted	O
as	O
providing	O
a	O
plausible	O
causal	O
or	O
behavioral	O
explanation	O
for	O
the	O
condition	O
,	O
finding	O
,	O
or	O
event	O
described	O
in	O
the	O
premise	O
(	O
e.g.	O
,	O
smoking	O
,	O
substance	O
-	O
related	O
disorders	O
,	O
mental	O
disorders	O
,	O
alcoholism	O
,	O
homelessness	O
,	O
obesity	O
)	O
.	O

Most	O
probing	O
studies	O
use	O
linguistics	O
as	O
a	O
theoretical	O
scaffolding	O
and	O
operate	O
on	O
a	O
task	O
level	O
.	O
However	O
,	O
there	O
often	O
exist	O
multiple	O
ways	O
to	O
represent	O
the	O
same	O
linguistic	O
phenomenon	O
:	O
for	O
example	O
,	O
English	O
dependency	O
syntax	O
can	O
be	O
encoded	O
using	O
a	O
variety	O
of	O
formalisms	O
,	O
incl	O
.	O
Universal	O
(	O
Schuster	O
and	O
Manning	O
,	O
2016	O
)	O
,	O
Stanford	O
(	O
de	O
Marneffe	O
and	O
Manning	O
,	O
2008	O
)	O
and	O
CoNLL-2009	O
dependencies	O
(	O
Hajič	O
et	O
al	O
.	O
,	O
2009	O
)	O
,	O
all	O
using	O
different	O
label	O
sets	O
and	O
syntactic	O
head	O
attachment	O
rules	O
.	O
Any	O
probing	O
study	O
inevitably	O
commits	O
to	O
the	O
specific	O
theoretical	O
framework	O
used	O
to	O
produce	O
the	O
underlying	O
data	O
.	O
The	O
differences	O
between	O
linguistic	O
formalisms	O
,	O
however	O
,	O
can	O
be	O
substantial	O
.	O

Similar	O
to	O
the	O
masked	O
language	O
model	O
(	O
MLM	O
)	O
objective	O
adopted	O
in	O
BERT	B-MethodName
,	O
our	O
model	O
is	O
trained	O
by	O
predicting	O
randomly	O
masked	O
entities	O
.	O
Specifically	O
,	O
we	O
randomly	O
replace	O
some	O
percentage	O
of	O
the	O
entities	O
with	O
special	O
[	O
MASK	O
]	O
entity	O
tokens	O
and	O
then	O
trains	O
the	O
model	O
to	O
predict	O
masked	O
entities	O
.	O

To	O
minimize	O
the	O
loss	O
,	O
the	O
expectations	O
could	O
be	O
approximated	O
by	O
sampling	O
as	O
shown	O
in	O
Algorithm	O
1	O
.	O
Taking	O
the	O
gradient	O
of	O
this	O
estimated	O
loss	O
produces	O
Algorithm	O
1	O
Naive	O
NCE	O
loss	O
estimation	O
Given	O
:	O
Input	O
sequence	O
x	O
,	O
number	O
of	O
negative	O
samples	O
k	O
,	O
noise	O
distribution	O
q	O
,	O
modelp	O
θ	O
.	O

•	O
(	O
Q1	O
)	O
How	O
could	O
different	O
adaptation	O
configurations	O
(	O
hyperparameters	O
,	O
tuning	O
methods	O
,	O
and	O
training	O
data	O
)	O
affect	O
PLM	O
's	O
mode	O
connectivity	O
?	O

We	O
now	O
turn	O
to	O
the	O
probing	O
results	O
for	O
decompositional	O
semantic	O
proto	O
-	O
role	O
labeling	O
tasks	O
.	O
Unlike	O
(	O
Tenney	O
et	O
al	O
.	O
,	O
2019b	O
)	O
who	O
used	O
a	O
multi	O
-	O
label	O
classification	O
probe	O
,	O
we	O
treat	O
SPR	B-TaskName
properties	O
as	O
separate	O
regression	O
tasks	O
.	O
The	O
results	O
in	O
Table	O
6	O
show	O
that	O
the	O
performance	O
varies	O
by	O
property	O
,	O
with	O
some	O
of	O
the	O
properties	O
attaining	O
reasonably	O
high	O
R	O
2	O
scores	O
despite	O
the	O
simplicity	O
of	O
the	O
probe	O
architecture	O
and	O
the	O
small	O
dataset	O
size	O
.	O
We	O
observe	O
that	O
properties	O
associated	O
with	O
Proto	O
-	O
Agent	O
tend	O
to	O
perform	O
better	O
.	O
The	O
untrained	O
mBERT	O
baseline	O
performs	O
poorly	O
which	O
we	O
attribute	O
to	O
the	O
lack	O
of	O
data	O
and	O
the	O
finegrained	O
semantic	O
nature	O
of	O
the	O
task	O
.	O
Our	O
fine	O
-	O
grained	O
,	O
property	O
-	O
level	O
task	O
design	O
allows	O
for	O
more	O
detailed	O
insights	O
into	O
the	O
layer	O
utilization	O
by	O
the	O
SPR	B-TaskName
probes	O
(	O
Fig	O
.	O
4	O
)	O
.	O
The	O
results	O
indicate	O
that	O
while	O
the	O
layer	O
utilization	O
on	O
the	O
predicate	O
side	O
(	O
src	O
)	O
shows	O
no	O
clear	O
preference	O
for	O
particular	O
layers	O
(	O
similar	O
to	O
the	O
results	O
obtained	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
)	O
,	O
some	O
of	O
the	O
proto	O
-	O
role	O
features	O
follow	O
the	O
pattern	O
seen	O
in	O
the	O
categorical	O
role	O
labeling	O
and	O
dependency	O
parsing	O
tasks	O
for	O
the	O
argument	O
tokens	O
tgt	O
.	O
With	O
few	O
exceptions	O
,	O
we	O
observe	O
that	O
the	O
properties	O
displaying	O
that	O
behavior	O
are	O
Proto	O
-	O
Agent	O
properties	O
;	O
moreover	O
,	O
a	O
close	O
examination	O
of	O
the	O
results	O
on	O
syntactic	O
preference	O
by	O
Reisinger	O
et	O
al	O
.	O
(	O
2015	O
,	O
p.	O
483	O
)	O
reveals	O
that	O
these	O
properties	O
are	O
also	O
the	O
ones	O
with	O
strong	O
preference	O
for	O
the	O
subject	O
position	O
,	O
including	O
the	O
outlier	O
case	O
of	O
stationary	O
which	O
in	O
their	O
data	O
behaves	O
like	O
a	O
Proto	O
-	O
Agent	O
property	O
.	O
The	O
correspondence	O
is	O
not	O
strict	O
,	O
and	O
we	O
leave	O
an	O
in	O
-	O
depth	O
investigation	O
of	O
the	O
reasons	O
behind	O
these	O
discrepancies	O
for	O
follow	O
-	O
up	O
work	O
.	O

To	O
make	O
predictions	O
on	O
personas	O
,	O
the	O
arg	O
max	O
function	O
is	O
used	O
for	O
the	O
estimated	O
distribution	O
of	O
persona	O
predictors	O
.	O
However	O
,	O
the	O
internal	O
distribution	O
conveys	O
crucial	O
information	O
about	O
how	O
the	O
persona	O
predictors	O
estimate	O
f	O
(	O
u	O
)	O
.	O
We	O
follow	O
the	O
setup	O
of	O
imbalanced	O
data	O
split	O
of	O
8	O
clusters	O
in	O
Section	O
5.5	O
to	O
examine	O
persona	O
predictors	O
of	O
attacker	O
A	O
and	O
fake	O
attacker	O
A	O
p	O
.	O

Our	O
model	O
is	O
based	O
on	O
BERT	B-MethodName
and	O
takes	O
words	O
and	O
entities	O
(	O
Wikipedia	O
entities	O
or	O
the	O
[	O
MASK	O
]	O
entity	O
)	O
.	O

Building	O
models	O
for	O
entity	O
linking	O
against	O
unseen	O
KBs	O
requires	O
that	O
such	O
models	O
do	O
not	O
overfit	O
to	O
the	O
training	O
data	O
by	O
memorizing	O
characteristics	O
of	O
the	O
training	O
KB	O
.	O
This	O
is	O
done	O
by	O
using	O
two	O
regularization	O
schemes	O
that	O
we	O
apply	O
on	O
top	O
of	O
the	O
candidate	O
string	O
generation	O
techniques	O
discussed	O
in	O
the	O
previous	O
section	O
.	O

-DOCSTART-	O
Question	O
Generation	O
for	O
Adaptive	O
Education	O

Our	O
main	O
probing	O
results	O
mirror	O
the	O
findings	O
of	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
about	O
the	O
sequential	O
processing	O
order	O
in	O
BERT	B-MethodName
.	O
We	O
observe	O
that	O
the	O
layer	O
utilization	O
among	O
tasks	O
(	O
Fig	O
.	O
2	O
)	O
generally	O
aligns	O
for	O
English	O
and	O
German	O
4	O
,	O
although	O
we	O
note	O
that	O
in	O
terms	O
of	O
center	O
-	O
of	O
-	O
gravity	O
mBERT	B-MethodName
tends	O
to	O
utilize	O
deeper	O
layers	O
for	O
German	O
probes	O
.	O
Basic	O
word	O
-	O
level	O
tasks	O
are	O
indeed	O
processed	O
early	O
by	O
the	O
model	O
,	O
and	O
XNLI	O
probes	O
focus	O
on	O
deeper	O
levels	O
,	O
suggesting	O
that	O
the	O
representation	O
of	O
higher	O
-	O
level	O
semantic	O
phenomena	O
follows	O
the	O
encoding	O
of	O
syntax	O
and	O
predicate	O
semantics	O
.	O

Slot	O
filling	O
.	O
As	O
described	O
in	O
Section	O
4	O
,	O
we	O
approach	O
the	O
slot	O
filler	O
extraction	O
task	O
as	O
fine	O
-	O
grained	O
entity	O
-	O
typing	O
-	O
in	O
-	O
context	O
,	O
assuming	O
that	O
each	O
sentence	O
represents	O
a	O
single	O
experiment	O
frame	O
.	O
We	O
use	O
the	O
same	O
sequence	O
tagging	O
architectures	O
as	O
above	O
for	O
tagging	O
the	O
tokens	O
of	O
each	O
experimentdescribing	O
sentence	O
with	O
the	O
set	O
of	O
slot	O
types	O
(	O
see	O
Table	O
11	O
)	O
.	O
Future	O
work	O
may	O
contrast	O
this	O
sequence	O
tagging	O
baseline	O
with	O
graph	O
-	O
induction	O
based	O
frame	O
extraction	O
.	O

A	O
training	O
dataset	O
D	O
=	O
{	O
(	O
x	O
1	O
,	O
y	O
1	O
)	O
,	O
.	O
.	O
.	O
,	O
(	O
x	O
N	O
,	O
y	O
N	O
)	O
}	O
is	O
given	O
,	O
where	O
x	O
i	O
is	O
the	O
i	O
-	O
th	O
document	O
containing	O
a	O
sequence	O
of	O
L	O
words	O
,	O
[	O
x	O
i1	O
,	O
x	O
i2	O
,	O
...	O
,	O
x	O
iL	O
]	O
,	O
and	O
y	O
i	O
∈	O
C	O
is	O
the	O
class	O
label	O
of	O

.	O
m	O
is	O
again	O
the	O
number	O
of	O
perturbation	O
samples	O
.	O
We	O
will	O
use	O
"	O
SVS	O
-	O
m	O
"	O
and	O
"	O
KS	O
-	O
m	O
"	O
in	O
the	O
rest	O
of	O
the	O
paper	O
to	O
indicate	O
the	O
sample	O
size	O
for	O
SVS	O
and	O
KS	O
.	O
In	O
practice	O
,	O
the	O
specific	O
perturbation	O
samples	O
depend	O
on	O
the	O
random	O
seed	O
of	O
the	O
sampler	O
,	O
and	O
we	O
will	O
show	O
that	O
the	O
explanation	O
scores	O
are	O
highly	O
sensitive	O
to	O
the	O
random	O
seed	O
under	O
a	O
small	O
sample	O
size	O
.	O

The	O
training	O
data	O
publicly	O
available	O
to	O
build	O
wordlevel	O
QE	O
models	O
is	O
limited	O
to	O
very	O
few	O
language	O
pairs	O
,	O
which	O
makes	O
it	O
difficult	O
to	O
build	O
QE	O
models	O
for	O
many	O
languages	O
.	O
From	O
an	O
application	O
perspective	O
,	O
even	O
for	O
the	O
languages	O
with	O
resources	O
,	O
it	O
is	O
difficult	O
to	O
maintain	O
separate	O
QE	O
models	O
for	O
each	O
language	O
since	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
QE	O
models	O
are	O
large	O
in	O
size	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020b	O
)	O
.	O

There	O
are	O
two	O
benefits	O
of	O
using	O
the	O
label	O
name	O
to	O
augment	O
utterances	O
.	O
First	O
,	O
we	O
make	O
use	O
of	O
different	O
appended	O
label	O
name	O
to	O
distinguish	O
the	O
same	O
utterance	O
with	O
multiple	O
labels	O
,	O
thus	O
obtaining	O
more	O
discriminative	O
representations	O
for	O
each	O
class	O
.	O
As	O
illustrated	O
in	O
Figure	O
3	O
,	O
we	O
can	O
obtain	O
different	O
prototypes	O
for	O
class	O
1	O
and	O
class	O
2	O
,	O
eliminating	O
the	O
problem	O
that	O
the	O
multi	O
-	O
label	O
utterances	O
share	O
the	O
same	O
representation	O
essentially	O
without	O
any	O
complex	O
architecture	O
or	O
parameters	O
.	O
Second	O
,	O
this	O
enables	O
us	O
to	O
utilize	O
the	O
label	O
name	O
information	O
as	O
well	O
as	O
increase	O
the	O
number	O
of	O
support	O
samples	O
to	O
eliminate	O
the	O
ambiguity	O
caused	O
by	O
the	O
scarcity	O
of	O
utterances	O
.	O
In	O
Section	O
4.4	O
,	O
we	O
analyze	O
the	O
experimental	O
results	O
to	O
verify	O
the	O
improvements	O
of	O
augmentation	O
.	O

When	O
it	O
comes	O
to	O
the	O
polysemy	O
headers	O
,	O
with	O
the	O
help	O
of	O
context	O
like	O
"	O
Height	O
"	O
,	O
"	O
Width	O
"	O
and	O
"	O
Depth	O
"	O
,	O
H2H+CXT	O
and	O
CAST	B-MethodName
can	O
disambiguate	O
polysemy	O
header	O
"	O
Area	O
"	O
from	O
region	O
or	O
zone	O
to	O
acreage	O
.	O
For	O
header	O
"	O
Volume	O
"	O
,	O
However	O
,	O
H2H+CXT	O
copies	O
the	O
source	O
language	O
column	O
,	O
which	O
is	O
not	O
a	O
valid	O
translation	O
,	O
because	O
the	O
translator	O
is	O
disturbed	O
by	O
the	O
context	O
.	O
On	O
the	O
other	O
hand	O
,	O
with	O
the	O
help	O
of	O
the	O
relational	O
-	O
aware	O
transformer	O
encoder	O
,	O
CAST	B-MethodName
generates	O
a	O
proper	O
translation	O
for	O
"	O
Volume	O
"	O
as	O
the	O
capacity	O
of	O
the	O
engine	O
.	O
Affected	O
by	O
the	O
context	O
,	O
H2H+CXT	O
only	O
translates	O
part	O
of	O
the	O
information	O
from	O
header	O
'	O
Film.1	O
'	O
and	O
'	O
Rank	O
of	O
the	O
year	O
'	O
,	O
while	O
M2M-100	B-DatasetName
,	O
H2H	O
,	O
and	O
CAST	B-MethodName
give	O
an	O
appropriate	O
translation	O
.	O

The	O
balancing	O
factor	O
λ	O
is	O
set	O
to	O
be	O
1	O
1	O
.	O

B6	O
.	O
Did	O
you	O
report	O
relevant	O
statistics	O
like	O
the	O
number	O
of	O
examples	O
,	O
details	O
of	O
train	O
/	O
test	O
/	O
dev	O
splits	O
,	O
etc	O
.	O
for	O
the	O
data	O
that	O
you	O
used	O
/	O
created	O
?	O
Even	O
for	O
commonly	O
-	O
used	O
benchmark	O
datasets	O
,	O
include	O
the	O
number	O
of	O
examples	O
in	O
train	O
/	O
validation	O
/	O
test	O
splits	O
,	O
as	O
these	O
provide	O
necessary	O
context	O
for	O
a	O
reader	O
to	O
understand	O
experimental	O
results	O
.	O
For	O
example	O
,	O
small	O
differences	O
in	O
accuracy	O
on	O
large	O
test	O
sets	O
may	O
be	O
significant	O
,	O
while	O
on	O
small	O
test	O
sets	O
they	O
may	O
not	O
be	O
.	O
In	O
Appendix	O
C	O
.	O

Tables	O
1	O
,	O
2	O
,	O
and	O
4	O
report	O
the	O
experimental	O
results	O
for	O
1	O
-	O
shot	O
and	O
5	O
-	O
shot	O
multi	O
-	O
label	O
intent	O
detection	O
tasks	O
on	O
TourSG	B-MethodName
and	O
StanfordLU	B-DatasetName
.	O
We	O
use	O
both	O
Electra	B-MethodName
-	I-MethodName
small	I-MethodName
(	O
+	O
E	O
)	O
and	O
Bert	O
-	O
base	O
(	O
+	O
B	O
)	O
as	O
feature	O
encoders	O
.	O
The	O
baseline	O
results	O
are	O
taken	O
from	O
(	O
Hou	O
et	O
al	O
.	O
,	O
2021	O
)	O
and	O
the	O
top	O
1	O
results	O
are	O
highlighted	O
in	O
bold	O
.	O

Finally	O
,	O
while	O
the	O
focus	O
of	O
this	O
work	O
is	O
only	O
on	O
English	O
entity	O
linking	O
,	O
challenges	O
associated	O
with	O
this	O
work	O
naturally	O
occur	O
in	O
multilingual	O
settings	O
as	O
well	O
.	O
Just	O
as	O
we	O
can	O
not	O
expect	O
labeled	O
data	O
for	O
every	O
target	O
KB	O
of	O
interest	O
,	O
we	O
also	O
can	O
not	O
expect	O
labeled	O
data	O
for	O
different	O
KBs	O
in	O
different	O
languages	O
.	O
In	O
future	O
work	O
,	O
we	O
aim	O
to	O
investigate	O
how	O
we	O
can	O
port	O
the	O
solutions	O
introduced	O
here	O
to	O
multilingual	O
settings	O
as	O
well	O
develop	O
novel	O
solutions	O
for	O
scenarios	O
where	O
the	O
documents	O
and	O
the	O
KB	O
are	O
in	O
languages	O
other	O
than	O
English	O
(	O
Sil	O
et	O
al	O
.	O
,	O
2018;Upadhyay	O
et	O
al	O
.	O
,	O
2018;Botha	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Previous	O
studies	O
(	O
Jagarlamudi	O
et	O
al	O
.	O
,	O
2012	O
;	O
Meng	O
et	O
al	O
.	O
,	O
2020a	O
)	O
have	O
tried	O
some	O
other	O
datasets	O
(	O
e.g.	O
,	O
RCV1	B-DatasetName
,	O
20	B-DatasetName
Newsgroups	I-DatasetName
,	O
NYT	B-DatasetName
,	O
and	O
Yelp	O
)	O
.	O
However	O
,	O
the	O
category	O
names	O
they	O
use	O
in	O
these	O
datasets	O
are	O
4	O
https	O
:	O
/	O
/	O
github.com	O
/	O
allenai	O
/	O
scidocs	O
5	O
http	O
:	O
/	O
/	O
jmcauley.ucsd.edu	O
/	O
data	O
/	O
amazon	O
/	O
index.html	O
6	O
https	O
:	O
/	O
/	O
github.com	O
/	O
franticnerd	O
/	O
geoburst	O
7	O
https	O
:	O
/	O
/	O
github.com	O
/	O
shangjingbo1226	O
/	O
AutoPhrase	O
all	O
picked	O
from	O
in	O
-	O
vocabulary	O
terms	O
.	O
Therefore	O
,	O
we	O
do	O
not	O
consider	O
these	O
datasets	O
for	O
evaluation	O
in	O
our	O
task	O
settings	O
.	O
Following	O
(	O
Sia	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
we	O
adopt	O
a	O
60	O
-	O
40	O
train	O
-	O
test	O
split	O
for	O
all	O
three	O
datasets	O
.	O
The	O
training	O
set	O
is	O
used	O
as	O
the	O
input	O
corpus	O
D	O
,	O
and	O
the	O
testing	O
set	O
is	O
used	O
for	O
calculating	O
topic	O
coherence	O
metrics	O
(	O
see	O
evaluation	O
metrics	O
for	O
details	O
)	O
.	O

Figure	O
2	O
presents	O
the	O
result	O
of	O
Williams	O
significance	O
test	O
for	O
BiRNN	B-MethodName
model	O
variants	O
.	O
It	O
is	O
a	O
correlation	O
matrix	O
that	O
can	O
be	O
read	O
as	O
follows	O
:	O
the	O
value	O
in	O
cell	O
(	O
i	O
,	O
j	O
)	O
is	O
the	O
p	O
-	O
value	O
of	O
Williams	O
test	O
for	O
the	O
change	O
in	O
performance	O
of	O
the	O
model	O
at	O
row	O
i	O
compared	O
to	O
the	O
model	O
at	O
column	O
j	O
(	O
Graham	O
,	O
2015	O
)	O
.	O

The	O
Responsible	O
NLP	O
Checklist	O
used	O
at	O
ACL	O
2023	O
is	O
adopted	O
from	O
NAACL	O
2022	O
,	O
with	O
the	O
addition	O
of	O
a	O
question	O
on	O
AI	O
writing	O
assistance	O
.	O

We	O
evaluate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
NOVEL	O
on	O
TO	O
-	O
MAR	O
dataset	O
,	O
followed	O
by	O
a	O
discus-	O
sion	O
of	O
NOVEL	O
's	O
property	O
with	O
controlled	O
studies	O
.	O

First	O
,	O
we	O
categorize	O
all	O
newly	O
correct	O
mentions	O
,	O
i.e.	O
mentions	O
that	O
are	O
correctly	O
linked	O
by	O
the	O
top	O
model	O
but	O
incorrectly	O
linked	O
by	O
the	O
[	O
SEP]-separation	O
baseline	O
by	O
the	O
entity	O
type	O
of	O
the	O
gold	O
entity	O
.	O
This	O
type	O
is	O
one	O
of	O
person	O
(	O
PER	O
)	O
,	O
organization	O
(	O
ORG	O
)	O
,	O
geo	O
-	O
political	O
entity	O
(	O
GPE	O
)	O
,	O
and	O
a	O
catchall	O
unknown	O
10	O
The	O
0	O
%	O
results	O
are	O
the	O
same	O
as	O
those	O
in	O
Table	O
3	O
.	O
category	O
(	O
UKN	O
)	O
.	O
11	O
This	O
categorization	O
reveals	O
that	O
the	O
newly	O
correct	O
mentions	O
represent	O
about	O
15	O
%	O
of	O
the	O
total	O
mentions	O
of	O
the	O
ORG	O
,	O
GPE	O
,	O
and	O
UKN	O
categories	O
and	O
as	O
much	O
as	O
25	O
%	O
of	O
the	O
total	O
mentions	O
of	O
the	O
PER	O
category	O
.	O
This	O
distributed	O
improvement	O
highlights	O
that	O
the	O
relatively	O
higher	O
accuracy	O
of	O
our	O
model	O
is	O
due	O
to	O
a	O
holistic	O
improvement	O
in	O
modeling	O
unseen	O
KBs	O
across	O
all	O
entity	O
types	O
.	O

The	O
pizza	O
problem	O
,	O
.	O
.	O
.	O
all	O
simple	O
correlations	O
between	O
input	O
features	O
and	O
output	O
labels	O
are	O
spurious	O
"	O
(	O
emphasis	O
in	O
the	O
original	O
)	O
.	O
The	O
property	O
that	O
individual	O
input	O
features	O
should	O
be	O
independent	O
of	O
labels	O
-which	O
I	O
will	O
call	O
marginally	O
uninformative	O
input	O
features	O
(	O
UIF	O
)	O
1	O
-is	O
treated	O
as	O
an	O
assumption	O
about	O
the	O
nature	O
of	O
language	O
processing	O
and	O
also	O
as	O
a	O
desideratum	O
that	O
datasets	O
should	O
satisfy	O
:	O
if	O
the	O
label	O
can	O
be	O
predicted	O
from	O
input	O
features	O
alone	O
,	O
then	O
the	O
dataset	O
is	O
in	O
some	O
sense	O
too	O
easy	O
.	O
2	O

B	O
Search	O
Query	O
and	O
Topic	O
Relevance	O
Synonyms	O

In	O
order	O
to	O
generalize	O
the	O
framework	O
beyond	O
CNNs	B-MethodName
,	O
there	O
are	O
two	O
questions	O
to	O
consider	O
.	O
First	O
,	O
what	O
is	O
an	O
effective	O
way	O
to	O
understand	O
each	O
feature	O
?	O
We	O
exemplified	O
this	O
with	O
two	O
word	O
clouds	O
representing	O
each	O
BiLSTM	O
feature	O
in	O
Appendix	O
C	O
,	O
and	O
we	O
plan	O
to	O
experiment	O
with	O
advanced	O
visualizations	O
such	O
as	O
LSTMVis	O
(	O
Strobelt	O
et	O
al	O
.	O
,	O
2018	O
)	O
in	O
the	O
future	O
.	O
Second	O
,	O
can	O
we	O
make	O
the	O
model	O
features	O
more	O
interpretable	O
?	O
For	O
example	O
,	O
using	O
ReLU	O
as	O
activation	O
functions	O
in	O
LSTM	O
cells	O
(	O
instead	O
of	O
tanh	O
)	O
renders	O
the	O
features	O
non	O
-	O
negative	O
.	O
So	O
,	O
they	O
can	O
be	O
summarized	O
using	O
one	O
word	O
cloud	O
which	O
is	O
more	O
practical	O
for	O
debugging	O
.	O

The	O
S	O
&	O
P	O
500	O
gauges	O
the	O
performance	O
of	O
the	O
stocks	O
of	O
the	O
500	O
largest	O
,	O
most	O
stable	O
companies	O
in	O
the	O
Stock	O
Exchange	O
.	O
It	O
is	O
often	O
considered	O
the	O
most	O
accurate	O
measure	O
of	O
the	O
stock	O
market	O
as	O
a	O
whole	O
.	O
The	O
current	O
average	O
annual	O
return	O
from	O
1926	O
,	O
the	O
year	O
of	O
the	O
S	O
&	O
Ps	O
inception	O
,	O
through	O
2011	O
is	O
11.69	O
%	O
.	O
That	O
's	O
a	O
long	O
look	O
back	O
,	O
and	O
most	O
people	O
are	O
n't	O
interested	O
in	O
what	O
happened	O
in	O
the	O
market	O
80	O
years	O
ago	O
.	O

We	O
did	O
not	O
use	O
any	O
AI	O
writing	O
assistants	O
.	O

For	O
our	O
framework	O
,	O
we	O
use	O
the	O
huggingface	O
implementation	O
of	O
GPT2	O
-	O
base	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
as	O
the	O
PLM	O
and	O
the	O
prefix	O
-	O
tuning	O
implementation	O
is	O
derived	O
from	O
OpenPrompt	O
.	O
All	O
results	O
are	O
averaged	O
over	O
5	O
different	O
seeds	O
.	O
The	O
prefix	O
length	O
has	O
an	O
essential	O
impact	O
on	O
the	O
results	O
,	O
so	O
we	O
search	O
it	O
from	O
{	O
10	O
,	O
50	O
,	O
100	O
,	O
200	O
,	O
300	O
,	O
400	O
,	O
500	O
}	O
.	O
For	O
PTO	O
+	O
Label	O
,	O
the	O
total	O
prefix	O
length	O
300	O
is	O
equally	O
allocated	O
to	O
each	O
label	O
.	O
For	O
PTO	O
+	O
OOD	O
,	O
the	O
OOD	O
prefix	O
length	O
is	O
also	O
set	O
to	O
300	O
.	O
The	O
hyper	O
-	O
parameters	O
of	O
PTO	O
+	O
Label	O
+	O
OOD	O
are	O
consistent	O
with	O
PTO	O
+	O
OOD	O
and	O
PTO	O
+	O
Label	O
.	O

Prompt	O
learning	O
has	O
been	O
demonstrated	O
to	O
be	O
a	O
successful	O
remedy	O
for	O
challenges	O
associated	O
with	O
pre	O
-	O
training	O
and	O
fine	O
-	O
tuning	O
paradigm	O
,	O
especially	O
in	O
zero	O
/	O
few	O
-	O
shot	O
scenarios	O
(	O
Gao	O
et	O
al	O
.	O
,	O
2021	O
;	O
Schick	O
and	O
Schütze	O
,	O
2021a	O
,	O
b	O
;	O
Tam	O
et	O
al	O
.	O
,	O
2021	O
;	O
Lu	O
et	O
al	O
.	O
,	O
2022a	O
)	O
.	O

Surprisal	O
Theory	O
(	O
Hale	O
,	O
2001	O
;	O
Levy	O
,	O
2008	O
)	O
posits	O
that	O
comprehenders	O
construct	O
probabilistic	O
interpretations	O
of	O
sentences	O
based	O
on	O
previously	O
encountered	O
structures	O
.	O
Mathematically	O
,	O
the	O
surprisal	O
of	O
the	O
k	O
th	O
word	O
,	O
w	O
k	O
,	O
is	O
defined	O
as	O
the	O
negative	O
log	O
probability	O
of	O
w	O
k	O
given	O
the	O
preceding	O
context	O
:	O

Natural	O
242	O
Translated	O
219	O
UNMT	O
:	O
style	O
gap	O
and	O
content	O
data	O
.	O
We	O
divide	O
the	O
test	O
sets	O
into	O
two	O
portions	O
:	O
the	O
natural	O
input	O
portion	O
with	O
source	O
sentences	O
originally	O
written	O
in	O
the	O
source	O
language	O
and	O
the	O
translated	O
input	O
portion	O
with	O
source	O
sentences	O
translated	O
from	O
the	O
target	O
language	O
.	O
Due	O
to	O
the	O
limited	O
space	O
,	O
we	O
conduct	O
the	O
experiments	O
with	O
pre	O
-	O
trained	O
XLM	O
initialization	O
and	O
perform	O
analysis	O
with	O
different	O
kinds	O
of	O
inputs	O
(	O
i.e.	O
,	O
natural	O
and	O
translated	O
inputs	O
)	O
on	O
De⇒En	O
newstest2013	O
-	O
2018	O
unless	O
otherwise	O
stated	O
.	O

Summary	O
-	O
level	O
Likert	O
scale	O
annotations	O
are	O
the	O
most	O
commonly	O
used	O
setup	O
for	O
collecting	O
coherence	O
in	O
single	O
-	O
document	O
news	O
summarization	O
research	O
(	O
Fabbri	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Here	O
,	O
we	O
run	O
an	O
analogous	O
study	O
for	O
our	O
longer	O
narrative	O
summaries	O
.	O
We	O
ask	O
3	O
Mechanical	O
Turk	O
workers	O
with	O
prior	O
experience	O
in	O
annotation	O
for	O
NLP	O
tasks	O
,	O
specifically	O
discourse	O
analysis	O
and	O
text	O
simplification	O
,	O
to	O
rate	O
the	O
overall	O
coherence	O
of	O
100	O
generated	O
summaries	O
on	O
a	O
5	O
-	O
point	O
scale	O
.	O
Table	O
1	O
reports	O
the	O
observed	O
agreement	O
,	O
measured	O
by	O
Kripendorff	O
's	O
α	O
.	O
Compared	O
to	O
newswire	O
summaries	O
collected	O
under	O
a	O
similar	O
setup	O
(	O
Fabbri	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
annotations	O
for	O
longer	O
narratives	O
have	O
a	O
much	O
lower	O
agreement	O
.	O
This	O
shows	O
the	O
difficulty	O
in	O
obtaining	O
a	O
consensus	O
on	O
coherence	O
for	O
a	O
500	O
+	O
word	O
summary	O
through	O
a	O
single	O
value	O
on	O
a	O
5	O
-	O
point	O
scale	O
.	O

Dependency	O
relation	O
(	O
deprel	O
)	O
predicts	O
the	O
dependency	O
relation	O
between	O
the	O
parent	O
src	O
and	O
dependent	O
tgt	O
tokens	O
;	O
Semantic	O
role	O
(	O
role.[frm	O
]	O
)	O
predicts	O
the	O
semantic	O
role	O
given	O
a	O
predicate	O
src	O
and	O
an	O
argument	O
tgt	O
token	O
in	O
one	O
of	O
the	O
three	O
role	O
labeling	O
formalisms	O
:	O
PropBank	O
pb	O
,	O
VerbNet	O
vn	O
and	O
FrameNet	O
fn	O
.	O
Note	O
that	O
we	O
only	O
probe	O
for	O
the	O
role	O
label	O
,	O
and	O
the	O
model	O
has	O
no	O
access	O
to	O
the	O
verb	O
sense	O
information	O
from	O
the	O
data	O
.	O
Semantic	O
proto	O
-	O
role	O
(	O
spr	O
.	O
[	O
prop	O
]	O
)	O
is	O
a	O
set	O
of	O
eleven	O
regression	O
tasks	O
predicting	O
the	O
values	O
of	O
the	O
proto	O
-	O
role	O
properties	O
as	O
defined	O
in	O
(	O
Reisinger	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
given	O
a	O
predicate	O
src	O
and	O
an	O
argument	O
tgt	O
.	O
XNLI	O
is	O
a	O
sentence	O
-	O
level	O
NLI	O
task	O
directly	O
sourced	O
from	O
the	O
corresponding	O
dataset	O
.	O
Given	O
two	O
sentences	O
,	O
the	O
goal	O
is	O
to	O
determine	O
whether	O
an	O
entailment	O
or	O
a	O
contradiction	O
relationship	O
holds	O
between	O
them	O
.	O
We	O
use	O
NLI	O
to	O
investigate	O
the	O
layer	O
utilization	O
of	O
mBERT	O
for	O
high	O
-	O
level	O
semantic	O
tasks	O
.	O
We	O
extract	O
the	O
sentence	O
pair	O
representation	O
via	O
the	O
[	O
CLS	O
]	O
token	O
and	O
treat	O
it	O
as	O
a	O
unary	O
probing	O
task	O
.	O

We	O
also	O
evaluated	O
how	O
the	O
QE	O
models	O
behave	O
with	O
a	O
limited	O
number	O
of	O
training	O
instances	O
.	O
For	O
each	O
language	O
pair	O
,	O
we	O
initiated	O
the	O
weights	O
of	O
the	O
bilingual	O
model	O
with	O
those	O
of	O
the	O
relevant	O
All-1	O
QE	O
and	O
trained	O
it	O
on	O
100	O
,	O
200	O
,	O
300	O
and	O
up	O
to	O
1000	O
training	O
instances	O
.	O
We	O
compared	O
the	O
results	O
with	O
those	O
obtained	O
having	O
trained	O
the	O
QE	O
model	O
from	O
scratch	O
for	O
that	O
language	O
pair	O
.	O
The	O
results	O
in	O
Figure	O
2	O
show	O

In	O
simultaneous	B-TaskName
machine	I-TaskName
translation	I-TaskName
(	O
SNMT	B-TaskName
)	O
models	O
,	O
the	O
probability	O
of	O
predicting	O
the	O
target	O
token	O
y	O
i	O
∈	O
y	O
depends	O
on	O
the	O
partial	O
source	O
and	O
target	O
sequences	O
(	O
x	O
≤j	O
∈	O
x	O
,	O
y	O
<	O
i	O
∈	O
y	O
)	O
.	O
In	O
sequence	O
-	O
tosequence	O
based	O
SNMT	B-TaskName
model	O
,	O
each	O
target	O
token	O
y	O
i	O
is	O
generated	O
as	O
follows	O
:	O

where	O
I	O
(	O
X	O
1	O
:	O
X	O
2	O
)	O
is	O
the	O
mutual	O
information	O
of	O
random	O
variables	O
X	O
1	O
and	O
X	O
2	O
,	O
H	O
(	O
X	O
)	O
represents	O
the	O
entropy	O
of	O
the	O
random	O
variable	O
X	O
,	O
and	O
ξ	O
represents	O
the	O
Lagrange	O
multiplier	O
.	O

Test	O
dataset	O
:	O
Yelp	O
Negative	O
F1	O

We	O
evaluate	O
seven	O
types	O
of	O
models	O
on	O
GQNLI	B-DatasetName
,	O
fine	O
-	O
tuned	O
with	O
different	O
combinations	O
of	O
NLI	O
datasets	O
.	O
As	O
data	O
creation	O
only	O
relied	O
on	O
RoBERTa	O
and	O
MNLI	B-MethodName
,	O
nothing	O
prevents	O
that	O
models	O
with	O
different	O
architectures	O
and	O
training	O
data	O
will	O
perform	O
well	O
.	O
They	O
do	O
not	O
,	O
however	O
.	O
The	O
results	O
are	O
shown	O
in	O
Table	O
8	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
the	O
following	O
question	O
:	O
How	O
to	O
shepherd	O
a	O
PLM	O
to	O
recall	O
a	O
series	O
of	O
stored	O
knowledge	O
(	O
e.g.	O
,	O
C1	O
and	O
C2	O
)	O
that	O
is	O
necessary	O
for	O
multi	O
-	O
step	O
inference	O
(	O
e.g.	O
,	O
answering	O
Q	O
)	O
,	O
analogous	O
to	O
how	O
humans	O
develop	O
a	O
"	O
chain	O
of	O
thought	O
"	O
for	O
complex	O
decision	O
making	O
?	O

Although	O
our	O
model	O
has	O
successfully	O
tackled	O
the	O
two	O
missing	O
patterns	O
,	O
it	O
may	O
still	O
fail	O
in	O
more	O
complicated	O
cases	O
.	O
For	O
example	O
,	O
if	O
missing	O
happens	O
randomly	O
in	O
terms	O
of	O
frames	O
(	O
some	O
timestamps	O
within	O
a	O
unimodal	O
clip	O
)	O
instead	O
of	O
instances	O
(	O
the	O
entire	O
unimodal	O
clip	O
)	O
,	O
then	O
our	O
proposed	O
approach	O
could	O
not	O
be	O
directly	O
used	O
to	O
deal	O
with	O
the	O
problem	O
,	O
since	O
we	O
need	O
at	O
least	O
several	O
instances	O
of	O
complete	O
parallel	O
data	O
to	O
learn	O
how	O
to	O
map	O
from	O
one	O
modality	O
sequences	O
to	O
the	O
other	O
.	O
However	O
,	O
we	O
believe	O
these	O
types	O
of	O
problems	O
can	O
still	O
be	O
properly	O
solved	O
by	O
adding	O
some	O
mathematical	O
tools	O
like	O
interpolation	O
,	O
etc	O
.	O
We	O
will	O
consider	O
this	O
idea	O
as	O
the	O
direction	O
of	O
our	O
future	O
work	O
.	O

in	O
the	O
schema	O
.	O
The	O
translation	O
of	O
H	O
i	O
is	O
denoted	O
as	O
Y	O
i	O
=	O
hy	O
1	O
,	O
.	O
.	O
.	O
,	O
y	O
m	O
i	O
,	O
where	O
y	O
j	O
is	O
the	O
jth	O
token	O
of	O
the	O
header	O
in	O
the	O
target	O
language	O
.	O
Taking	O
a	O
header	O
H	O
and	O
its	O
corresponding	O
context	O
C	O
as	O
input	O
,	O
the	O
model	O
outputs	O
the	O
header	O
Y	O
in	O
the	O
target	O
language	O
.	O

The	O
above	O
two	O
definitions	O
of	O
f	O
use	O
the	O
values	O
v	O
i	O
,	O
but	O
not	O
the	O
attributes	O
k	O
i	O
,	O
which	O
also	O
contain	O
meaningful	O
information	O
.	O
For	O
example	O
,	O
if	O
an	O
entity	O
seen	O
during	O
inference	O
has	O
a	O
capital	O
attribute	O
with	O
the	O
value	O
"	O
New	O
Delhi	O
"	O
,	O
seeing	O
the	O
capital	O
attribute	O
allows	O
us	O
to	O
infer	O
that	O
the	O
target	O
entity	O
is	O
likely	O
to	O
be	O
a	O
place	O
,	O
rather	O
than	O
a	O
person	O
,	O
especially	O
if	O
we	O
have	O
seen	O
the	O
capital	O
attribute	O
during	O
training	O
.	O
We	O
capture	O
this	O
information	O
using	O
attribute	O
separators	O
,	O
which	O
are	O
reserved	O
tokens	O
(	O
in	O
the	O
vein	O
of	O
[	O
SEP	O
]	O
tokens	O
)	O
corresponding	O
to	O
attributes	O
.	O
In	O
this	O
case	O
,	O

Everything	O
Is	O
Fine	O
Heuristic	O
This	O
heuristic	O
applies	O
when	O
the	O
premise	O
contains	O
condition(s	O
)	O
or	O
finding(s	O
)	O
,	O
the	O
target	O
class	O
is	O
contradiction	O
,	O
and	O
the	O
generated	O
hypothesis	O
negates	O
the	O
premise	O
or	O
asserts	O
unremarkable	O
finding(s	O
)	O
.	O
This	O
can	O
take	O
two	O
forms	O
:	O
repetition	O
of	O
premise	O
content	O
plus	O
negation	O
,	O
or	O
inclusion	O
of	O
modifiers	O
that	O
convey	O
good	O
health	O
.	O

It	O
is	O
challenging	O
to	O
make	O
exact	O
claims	O
about	O
what	O
can	O
cause	O
tokens	O
to	O
be	O
unargmaxable	O
because	O
the	O
models	O
we	O
tested	O
varied	O
in	O
so	O
many	O
ways	O
.	O
However	O
,	O
we	O
outline	O
some	O
general	O
trends	O
below	O
.	O

Since	O
obtaining	O
a	O
perfect	O
training	O
dataset	O
(	O
i.e.	O
,	O
a	O
dataset	O
which	O
is	O
considerably	O
large	O
,	O
unbiased	O
,	O
and	O
well	O
-	O
representative	O
of	O
unseen	O
cases	O
)	O
is	O
hardly	O
possible	O
,	O
many	O
real	O
-	O
world	O
text	O
classifiers	O
are	O
trained	O
on	O
the	O
available	O
,	O
yet	O
imperfect	O
,	O
datasets	O
.	O
These	O
classifiers	O
are	O
thus	O
likely	O
to	O
have	O
undesirable	O
properties	O
.	O
For	O
instance	O
,	O
they	O
may	O
have	O
biases	O
against	O
some	O
sub	O
-	O
populations	O
or	O
may	O
not	O
work	O
effectively	O
in	O
the	O
wild	O
due	O
to	O
overfitting	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
FINDa	O
framework	O
which	O
enables	O
humans	O
to	O
debug	O
deep	O
learning	O
text	O
classifiers	O
by	O
disabling	O
irrelevant	O
hidden	O
features	O
.	O
Experiments	O
show	O
that	O
by	O
using	O
FIND	O
,	O
humans	O
can	O
improve	O
CNN	O
text	O
classifiers	O
which	O
were	O
trained	O
under	O
different	O
types	O
of	O
imperfect	O
datasets	O
(	O
including	O
datasets	O
with	O
biases	O
and	O
datasets	O
with	O
dissimilar	O
traintest	O
distributions	O
)	O
.	O

Overall	O
,	O
our	O
method	O
enhances	O
the	O
lexical	O
-	O
level	O
information	O
captured	O
by	O
pretrained	O
MLMs	O
,	O
as	O
shown	O
empirically	O
.	O
This	O
is	O
consistent	O
with	O
our	O
intuition	O
that	O
cross	O
-	O
lingual	O
embeddings	O
capture	O
a	O
bilingual	O
signal	O
that	O
can	O
benefit	O
MLM	O
representations	O
.	O
1	O
-	O
gram	O
precision	O
scores	O
.	O
To	O
examine	O
whether	O
the	O
improved	O
translation	O
performance	O
is	O
a	O
result	O
of	O
the	O
lexical	O
-	O
level	O
information	O
provided	O
by	O
static	O
embeddings	O
,	O
we	O
present	O
1	O
-	O
gram	O
precision	O
scores	O
in	O
Ta-	O
ble	O
3	O
,	O
as	O
they	O
can	O
be	O
directly	O
attributed	O
to	O
lexical	O
alignment	O
.	O
The	O
biggest	O
performance	O
gains	O
(	O
up	O
to	O
+10.4	O
)	O
are	O
obtained	O
when	O
the	O
proposed	O
approach	O
is	O
applied	O
to	O
XLM	O
.	O
This	O
correlates	O
with	O
the	O
BLEU	B-MetricName
scores	O
of	O
Table	O
1	O
.	O
Moreover	O
,	O
the	O
En	O
-	O
Mk	O
language	O
pair	O
benefits	O
more	O
than	O
En	O
-	O
Sq	O
from	O
the	O
lexicallevel	O
alignment	O
both	O
in	O
terms	O
of	O
1	O
-	O
gram	O
precision	O
and	O
BLEU	B-MetricName
.	O
These	O
results	O
show	O
that	O
the	O
improved	O
BLEU	B-MetricName
scores	O
can	O
be	O
attributed	O
to	O
the	O
enhanced	O
lexical	O
representations	O
.	O
How	O
should	O
static	O
embeddings	O
be	O
integrated	O
in	O
the	O
MLM	O
training	O
?	O
We	O
explore	O
different	O
ways	O
of	O
incorporating	O
the	O
lexical	O
knowledge	O
of	O
pretrained	O
cross	O
-	O
lingual	O
embeddings	O
to	O
the	O
second	O
,	O
masked	O
language	O
modeling	O
stage	O
of	O
our	O
approach	O
(	O
§	O
2.2	O
)	O
.	O
Specifically	O
,	O
we	O
keep	O
the	O
aligned	O
embeddings	O
fixed	O
(	O
frozen	O
)	O
during	O
XLM	O
training	O
and	O
compare	O
the	O
performance	O
of	O
the	O
final	O
UNMT	B-TaskName
model	O
to	O
the	O
proposed	O
(	O
fine	O
-	O
tuned	O
)	O
method	O
.	O
We	O
point	O
out	O
that	O
,	O
after	O
we	O
transfer	O
the	O
trained	O
MLM	O
to	O
an	O
encoder	O
-	O
decoder	O
model	O
,	O
all	O
layers	O
are	O
trained	O
for	O
UNMT	B-TaskName
.	O

Sequential	O
neural	O
network	O
architectures	O
in	O
their	O
various	O
forms	O
have	O
become	O
the	O
mainstay	O
in	O
abstractive	O
summarization	O
(	O
See	O
et	O
al	O
.	O
,	O
2017	O
;	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
However	O
,	O
the	O
quality	O
of	O
machine	O
-	O
produced	O
summaries	O
still	O
lags	O
far	O
behind	O
the	O
quality	O
of	O
human	O
summaries	O
(	O
Huang	O
et	O
al	O
.	O
,	O
2020a	O
;	O
Xie	O
et	O
al	O
.	O
,	O
2021	O
;	O
Cao	O
et	O
al	O
.	O
,	O
2022	O
;	O
Lebanoff	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Due	O
to	O
their	O
sequential	O
nature	O
,	O
a	O
challenge	O
with	O
neural	O
summarizers	O
is	O
to	O
capture	O
hierarchical	O
and	O
inter	O
-	O
sentential	O
dependencies	O
in	O
the	O
summmarized	O
document	O
.	O

Figure	O
2	O
:	O
The	O
AdMIRaL	B-MethodName
pipeline	O
.	O
At	O
hop	O
t	O
,	O
given	O
the	O
claim	O
and	O
sentences	O
E	O
t	O
from	O
documents	O
D	O
t	O
,	O
a	O
proof	O
is	O
generated	O
to	O
predict	O
whether	O
the	O
evidence	O
E	O
t	O
is	O
sufficient	O
for	O
verification	O
or	O
whether	O
additional	O
evidence	O
is	O
needed	O
.	O
If	O
sufficient	O
,	O
the	O
retriever	O
terminates	O
,	O
otherwise	O
,	O
our	O
autoregressive	O
retriever	O
scores	O
documents	O
in	O
the	O
KB	O
jointly	O
with	O
E	O
t	O
updating	O
the	O
documents	O
to	O
D	O
t+1	O
,	O
before	O
they	O
are	O
passed	O
to	O
the	O
sentence	O
reranker	O
to	O
obtain	O
E	O
t+1	O
.	O

Deep	O
learning	O
has	O
become	O
the	O
dominant	O
approach	O
to	O
address	O
most	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
tasks	O
,	O
including	O
text	O
classification	O
.	O
With	O
sufficient	O
and	O
high	O
-	O
quality	O
training	O
data	O
,	O
deep	O
learning	O
models	O
can	O
perform	O
incredibly	O
well	O
.	O
However	O
,	O
in	O
real	O
-	O
world	O
cases	O
,	O
such	O
ideal	O
datasets	O
are	O
scarce	O
.	O
Often	O
times	O
,	O
the	O
available	O
datasets	O
are	O
small	O
,	O
full	O
of	O
regular	O
but	O
irrelevant	O
words	O
,	O
and	O
contain	O
unintended	O
biases	O
(	O
Wiegand	O
et	O
al	O
.	O
,	O
2019;Gururangan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
These	O
can	O
lead	O
to	O
suboptimal	O
models	O
with	O
undesirable	O
properties	O
.	O
For	O
example	O
,	O
the	O
models	O
may	O
have	O
biases	O
against	O
some	O
sub	O
-	O
populations	O
or	O
may	O
not	O
work	O
effectively	O
in	O
the	O
wild	O
as	O
they	O
overfit	O
the	O
imperfect	O
training	O
data	O
.	O

Human	O
Evaluation	O
We	O
conduct	O
an	O
expert	O
evaluation	O
on	O
a	O
subset	O
of	O
generated	O
arguments	O
with	O
two	O
researchers	O
(	O
field	O
of	O
expertise	O
is	O
natural	O
language	O
processing	O
)	O
not	O
involved	O
in	O
this	O
paper	O
.	O
Two	O
aspects	O
are	O
evaluated	O
:	O
fluency	O
and	O
persuasiveness	O
.	O
We	O
consider	O
a	O
sentence	O
as	O
fluent	O
if	O
it	O
is	O
grammatically	O
correct	O
,	O
i.e.	O
contains	O
neither	O
semantic	O
nor	O
syntactic	O
errors	O
,	O
and	O
arrange	O
this	O
as	O
a	O
binary	O
task	O
.	O
To	O
reduce	O
subjectivity	O
for	O
the	O
persuasiveness	O
evaluation	O
,	O
the	O
experts	O
do	O
not	O
annotate	O
single	O
arguments	O
but	O
instead	O
compare	O
pairs	O
(	O
Habernal	O
and	O
Gurevych	O
,	O
2016	O
)	O
of	O
generated	O
and	O
refer	O
-	O
ence	O
data	O
arguments	O
(	O
see	O
Section	O
5.2	O
)	O
.	O
The	O
experts	O
could	O
either	O
choose	O
one	O
argument	O
as	O
being	O
more	O
persuasive	O
or	O
both	O
as	O
being	O
equally	O
persuasive	O
.	O
In	O
total	O
,	O
the	O
experts	O
compared	O
100	O
(	O
randomly	O
sorted	O
and	O
ordered	O
)	O
argument	O
pairs	O
for	O
persuasiveness	O
and	O
fluency	O
(	O
50	O
from	O
both	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
and	O
the	O
Arg	O
-	O
CTRL	O
CC	O
)	O
.	O
A	O
pair	O
of	O
arguments	O
always	O
had	O
the	O
same	O
topic	O
and	O
stance	O
.	O
For	O
fluency	O
,	O
only	O
the	O
annotations	O
made	O
for	O
generated	O
arguments	O
were	O
extracted	O
and	O
taken	O
into	O
account	O
.	O
Averaged	O
results	O
of	O
both	O
experts	O
show	O
that	O
in	O
33	O
%	O
of	O
the	O
cases	O
,	O
the	O
generated	O
argument	O
is	O
either	O
more	O
convincing	O
(	O
29	O
%	O
)	O
or	O
as	O
convincing	O
(	O
4	O
%	O
)	O
as	O
the	O
reference	O
argument	O
.	O
Moreover	O
,	O
83	O
%	O
of	O
generated	O
arguments	O
are	O
fluent	O
.	O
The	O
inter	O
-	O
annotator	O
agreement	O
(	O
Cohen	O
,	O
1960	O
)	O
between	O
the	O
two	O
experts	O
is	O
Cohen	O
's	O
κ	O
=	O
.30	O
(	O
percentage	O
agreement	O
:	O
.62	O
)	O
for	O
persuasiveness	O
and	O
κ	O
=	O
.43	O
(	O
percentage	O
agreement	O
:	O
.72	O
)	O
for	O
fluency	O
,	O
which	O
can	O
be	O
interpreted	O
as	O
"	O
fair	O
"	O
and	O
"	O
moderate	O
"	O
agreement	O
,	O
respectively	O
(	O
Landis	O
and	O
Koch	O
,	O
1977	O
)	O
.	O
As	O
we	O
compare	O
to	O
high	O
-	O
quality	O
,	O
curated	O
data	O
,	O
the	O
perceived	O
persuasiveness	O
of	O
the	O
generated	O
arguments	O
shows	O
the	O
potential	O
of	O
the	O
work	O
-	O
further	O
strengthened	O
in	O
the	O
remainder	O
of	O
this	O
section	O
.	O

Computational	O
efficiency	O
is	O
an	O
important	O
factor	O
when	O
designing	O
pre	O
-	O
training	O
tasks	O
.	O
A	O
more	O
efficient	O
method	O
enables	O
models	O
to	O
train	O
on	O
a	O
larger	O
dataset	O
for	O
more	O
steps	O
.	O
We	O
calculate	O
the	O
feedforward	O
floating	O
point	O
operations	O
(	O
FLOPs	B-MetricName
)	O
for	O
our	O
method	O
and	O
TLM	O
,	O
respectively	O
.	O
In	O
addition	O
,	O
we	O
report	O
the	O
training	O
latency	O
in	O
our	O
training	O
environment	O
.	O
We	O
measure	O
the	O
latency	O
with	O
a	O
total	O
batch	O
size	O
of	O
512	O
on	O
8	O
Tesla	O
V100	O
GPUs	O
using	O
PyTorch	O
distributed	O
data	O
parallel	O
.	O

Datasets	O
.	O
For	O
ZH→EN	B-MethodName
(	O
News	O
)	O
,	O
we	O
follow	O
and	O
use	O
document	O
parallel	O
corpora	O
from	O
LDC	O
as	O
the	O
training	O
set	O
,	O
NIST2006	B-DatasetName
dataset	O
as	O
the	O
development	O
set	O
and	O
combination	O
of	O
NIST2002	B-DatasetName
,	O
2003NIST2002	O
,	O
,	O
2004NIST2002	O
,	O
,	O
2005NIST2002	O
,	O
and	O
2008	O
as	O
the	O
test	O
set	O
.	O
For	O
ZH→EN	B-MethodName
(	O
TED	O
)	O
,	O
the	O
training	O
set	O
is	O
from	O
the	O
IWSLT	O
2014	O
and	O
2015	O
evaluation	O
(	O
Cettolo	O
et	O
al	O
.	O
,	O
2012(Cettolo	O
et	O
al	O
.	O
,	O
,	O
2015	O
.	O
We	O
use	O
dev2010	O
as	O
the	O
development	O
and	O
combine	O
tst2010	O
-	O
2013	O
as	O
the	O
test	O
set	O
.	O
For	O
FR→EN	B-MethodName
(	O
TED	B-MethodName
)	O
,	O
the	O
training	O
set	O
is	O
from	O
the	O
2015	O
evaluation	O
(	O
Cettolo	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
We	O
use	O
dev2010	O
as	O
the	O
development	O
and	O
combine	O
tst2010	O
-	O
2013	O
as	O
the	O
test	O
set	O
.	O
More	O
statistics	O
and	O
preprocessing	O
of	O
the	O
experimental	O
datasets	O
are	O
in	O
Appendix	O
A.	O

-DOCSTART-	O
Aspect	O
-	O
Controlled	O
Neural	O
Argument	O
Generation	O

Token	O
type	O
embedding	O
represents	O
the	O
type	O
of	O
token	O
,	O
namely	O
word	O
(	O
C	O
word	O
)	O
or	O
entity	O
(	O
C	O
entity	O
)	O
.	O

We	O
introduced	O
Multimodal	O
Quality	I-TaskName
Estimation	I-TaskName
for	O
Machine	O
Translation	I-TaskName
,	O
where	O
an	O
external	O
modality	O
-visual	O
information	O
-is	O
incorporated	O
to	O
featurebased	O
and	O
neural	O
-	O
based	O
QE	O
approaches	O
,	O
on	O
sentence	O
and	O
document	O
levels	O
.	O
The	O
use	O
of	O
visual	O
features	O
extracted	O
from	O
images	O
has	O
led	O
to	O
significant	O
improvements	O
in	O
the	O
results	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
QE	O
approaches	O
,	O
especially	O
at	O
sentence	O
level	O
.	O

Neural	O
entity	O
tagging	O
and	O
slot	O
filling	O
.	O
The	O
neural	O
-	O
network	O
based	O
models	O
we	O
use	O
for	O
entity	O
tagging	O
and	O
slot	O
filling	O
bear	O
similarity	O
to	O
state	O
-	O
ofthe	O
-	O
art	O
models	O
for	O
named	O
entity	O
recognition	O
(	O
e.g.	O
,	O
Huang	O
et	O
al	O
.	O
,	O
2015;Lample	O
et	O
al	O
.	O
,	O
2016;Panchendrarajan	O
and	O
Amaresan	O
,	O
2018;Lange	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Other	O
related	O
work	O
exists	O
in	O
the	O
area	O
of	O
semantic	O
role	O
labeling	O
(	O
e.g.	O
,	O
Roth	O
and	O
Lapata	O
,	O
2015;Kshirsagar	O
et	O
al	O
.	O
,	O
2015;Hartmann	O
et	O
al	O
.	O
,	O
2017;Adel	O
et	O
al	O
.	O
,	O
2018;Swayamdipta	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

2	O
.	O
Infill	O
.	O
We	O
fine	O
-	O
tune	O
BART	B-MethodName
to	O
fill	O
the	O
masked	O
spans	O
of	O
input	O
sentences	O
.	O
The	O
model	O
learns	O
to	O
generate	O
hyperbolic	O
words	O
or	O
phrases	O
that	O
are	O
pertinent	O
to	O
the	O
context	O
.	O

To	O
represent	O
the	O
full	O
dataset	O
,	O
we	O
use	O
fastText	B-MethodName
MIMIC	B-DatasetName
-	I-DatasetName
III	I-DatasetName
embeddings	O
,	O
which	O
have	O
been	O
pretrained	O
on	O
deidentified	O
patient	O
notes	O
from	O
MIMIC	B-DatasetName
-	I-DatasetName
III	I-DatasetName
(	O
Romanov	O
and	O
Shivade	O
,	O
2018;Johnson	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
We	O
represent	O
each	O
example	O
as	O
the	O
average	O
of	O
its	O
component	O
token	O
vectors	O
.	O
We	O
proportionally	O
adjust	O
a	O
subset	O
of	O
the	O
hyperparameters	O
used	O
by	O
Sakaguchi	O
et	O
al	O
.	O
(	O
2020	O
)	O
to	O
account	O
for	O
the	O
fact	O
that	O
MedNLI	B-DatasetName
contains	O
far	O
fewer	O
examples	O
than	O
WINOGRANDE	O
2	O
:	O
specifically	O
,	O
we	O
set	O
the	O
training	O
size	O
for	O
each	O
ensemble	O
,	O
m	O
,	O
to	O
5620	O
,	O
which	O
represents	O
≈	O
2	O
5	O
of	O
the	O
MedNLI	B-DatasetName
combined	O
dataset	O
.	O
The	O
remaining	O
hyperparameters	O
are	O
unchanged	O
:	O
the	O
ensemble	O
consists	O
of	O
n	O
=	O
64	O
logistic	O
regression	O
models	O
,	O
the	O
filtering	O
cutoff	O
,	O
k	O
=	O
500	O
,	O
and	O
the	O
filtering	O
threshold	O
τ	O
=	O
0.75	O
.	O

Due	O
to	O
its	O
task	O
-	O
agnostic	O
architecture	O
,	O
edge	O
probing	O
can	O
be	O
applied	O
to	O
a	O
wide	O
variety	O
of	O
unary	O
(	O
by	O
omitting	O
tgt	O
)	O
and	O
binary	O
labeling	O
tasks	O
in	O
a	O
unified	O
manner	O
,	O
facilitating	O
the	O
cross	O
-	O
task	O
comparison	O
.	O
The	O
original	O
setup	O
has	O
several	O
limitations	O
that	O
we	O
address	O
in	O
our	O
implementation	O
.	O

This	O
work	O
has	O
been	O
funded	O
by	O
the	O
LOEWE	O
initiative	O
(	O
Hesse	O
,	O
Germany	O
)	O
within	O
the	O
emergenCITY	O
center	O
.	O

Results	O
of	O
rationale	O
generation	O
:	O
From	O
Tab	O
.	O
2	O
and	O
Tab	O
.	O
3	O
,	O
we	O
have	O
the	O
following	O
observations	O
:	O
1	O
)	O
Joint	O
generation	I-TaskName
mode	O
(	O
JGM	O
)	O
achieves	O
better	O
performance	O
than	O
the	O
separate	O
generation	I-TaskName
mode	O
(	O
SGM	O
)	O
,	O
which	O
indicates	O
the	O
shared	O
encoder	O
has	O
a	O
promoting	O
effect	O
on	O
rationale	O
generation	O
.	O
2	O
)	O
The	O
performance	O
of	O
charge	O
rationale	O
generation	O
is	O
better	O
than	O
that	O
of	O
penalty	O
rationale	O
generation	O
,	O
which	O
may	O
be	O
owing	O
to	O
the	O
complexity	O
of	O
the	O
discourse	O
of	O
penalty	O
rationale	O
.	O
3	O
)	O
The	O
performance	O
of	O
PGN	O
-	O
JGM	O
is	O
better	O
than	O
C3VG	B-MethodName
,	O
which	O
proves	O
the	O
advantage	O
of	O
splitting	O
the	O
rationale	O
generation	O
and	O
result	O
prediction	O
.	O
4	O
)	O
The	O
Kappa	O
coefficient	O
between	O
any	O
two	O
human	O
annotators	O
is	O
over	O
0.78	O
(	O
substantial	O
agreement	O
)	O
,	O
which	O
indicates	O
the	O
quality	O
of	O
human	O
evaluation	O
.	O

•	O
As	O
mentioned	O
in	O
above	O
,	O
a	O
few	O
arguments	O
that	O
express	O
little	O
information	O
and	O
whose	O
subjects	O
are	O
primarily	O
pronouns	O
,	O
in	O
which	O
case	O
our	O
ACE	O
module	O
may	O
be	O
limited	O
.	O
For	O
example	O
,	O
an	O
argument	O
is	O
"	O
no	O
offense	O
,	O
but	O
that	O
is	O
incredibly	O
stupid	O
/	O
selfish	O
.	O
"	O
.	O
Since	O
the	O
sentence	O
expresses	O
only	O
a	O
small	O
amount	O
of	O
information	O
,	O
semantic	O
similarity	O
may	O
not	O
fully	O
reflect	O
the	O
correlation	O
between	O
sentences	O
,	O
which	O
affects	O
the	O
ACE	O
module	O
to	O
some	O
extent	O
,	O
which	O
may	O
affect	O
the	O
ACE	O
module	O
to	O
some	O
extent	O
.	O
In	O
this	O
case	O
,	O
it	O
might	O
be	O
better	O
to	O
use	O
the	O
adjacent	O
context	O
block	O
directly	O
.	O

--	O
--	O
-Input	O
--	O
--	O
-First	O
line	O
of	O
input	O
contains	O
two	O
integers	O
,	O
$	O
N	O
$	O
(	O
$	O
1	O
\le	O
N	O
\le	O
1000	O
$	O
)	O
,	O
the	O
length	O
of	O
the	O
message	O
,	O
and	O
$	O
C	O
$	O
(	O
$	O
1	O
\le	O
C	O
\le	O
1000000000	O
$	O
)	O
,	O
the	O
number	O
from	O
the	O
task	O
description	O
above	O
.	O

We	O
assess	O
the	O
performance	O
of	O
the	O
MET	O
on	O
three	O
datasets	O
:	O
the	O
Amazon	O
Customer	O
Reviews	O
Dataset	O
,	O
Reddit	B-MethodName
Corpus	O
,	O
and	O
the	O
Cornell	O
Movie	O
-	O
Dialogs	O
Corpus	O
.	O

In	O
this	O
paper	O
,	O
we	O
demonstrate	O
that	O
MedNLI	B-MethodName
suffers	O
from	O
the	O
same	O
challenge	O
associated	O
with	O
annotation	O
artifacts	O
that	O
its	O
domain	O
-	O
agnostic	O
predecessors	O
have	O
encountered	O
:	O
namely	O
,	O
NLI	O
models	O
trained	O
on	O
{	O
Med	O
,	O
S	O
,	O
Multi}NLI	O
can	O
perform	O
well	O
even	O
without	O
access	O
to	O
the	O
training	O
examples	O
'	O
premises	O
,	O
indicating	O
that	O
they	O
often	O
exploit	O
shallow	O
heuristics	O
,	O
with	O
negative	O
implications	O
for	O
out	O
-	O
of	O
-	O
sample	O
generalization	O
.	O
Interestingly	O
,	O
many	O
of	O
the	O
high	O
-	O
level	O
lexical	O
characteristics	O
identified	O
in	O
MedNLI	B-MethodName
can	O
be	O
considered	O
domain	O
-	O
specific	O
variants	O
of	O
the	O
more	O
generic	O
,	O
classspecific	O
patterns	O
identified	O
in	O
SNLI	B-TaskName
.	O
This	O
observation	O
suggests	O
that	O
a	O
set	O
of	O
abstract	O
design	O
patterns	O
for	O
inference	O
example	O
generation	O
exists	O
across	O
domains	O
,	O
and	O
may	O
be	O
reinforced	O
by	O
the	O
prompts	O
provided	O
to	O
annotators	O
.	O
Creative	O
or	O
randomized	O
priming	O
,	O
such	O
as	O
Sakaguchi	O
et	O
al	O
.	O
(	O
2020	O
)	O
's	O
use	O
of	O
anchor	O
words	O
from	O
WikiHow	O
articles	O
,	O
may	O
help	O
to	O
decrease	O
reliance	O
on	O
such	O
design	O
patterns	O
,	O
but	O
it	O
appears	O
unlikely	O
that	O
they	O
can	O
be	O
systematically	O
sidestepped	O
without	O
introducing	O
new	O
,	O
"	O
corrective	O
"	O
artifacts	O
.	O

•	O
Industry	O
track	O
chairs	O
:	O
Beata	O
Beigman	O
Klebanov	O
,	O
Jason	O
Williams	O
,	O
and	O
Sunayana	O
Sitaram	O
.	O
An	O
addition	O
to	O
this	O
year	O
's	O
ACL	O
is	O
the	O
introduction	O
of	O
a	O
separate	O
industry	O
track	O
.	O
This	O
is	O
motivated	O
by	O
two	O
factors	O
.	O
First	O
,	O
ACL	O
is	O
held	O
in	O
North	O
America	O
this	O
year	O
(	O
and	O
thus	O
no	O
NAACL	O
)	O
,	O
and	O
NAACL	O
has	O
an	O
established	O
tradition	O
of	O
hosting	O
an	O
industry	O
track	O
.	O
Second	O
there	O
was	O
an	O
increasing	O
number	O
of	O
industry	O
track	O
submissions	O
at	O
EMNLP	O
last	O
year	O
from	O
previous	O
years	O
.	O
We	O
hope	O
that	O
a	O
separate	O
industry	O
track	O
can	O
foster	O
the	O
dissemination	O
of	O
research	O
on	O
real	O
-	O
world	O
applications	O
in	O
industry	O
settings	O
.	O
Thanks	O
to	O
the	O
industry	O
track	O
chairs	O
for	O
their	O
efforts	O
in	O
coordinating	O
all	O
the	O
logistics	O
associated	O
with	O
this	O
track	O
.	O

Central	O
Events	O
Annotation	O
We	O
manually	O
annotate	O
central	O
events	O
on	O
the	O
public	O
dataset	O
EventSto	O
-	O
ryLine	O
to	O
investigate	O
the	O
effect	O
of	O
centrality	O
.	O
In	O
specific	O
,	O
we	O
annotate	O
central	O
events	O
considering	O
the	O
following	O
rules	O
:	O

•	O
Group	O
5	O
:	O
AGNews	B-MethodName
.	O
AG	B-MethodName
News	I-MethodName
is	O
a	O
topic	O
classification	O
dataset	O
(	O
Zhang	O
et	O
al	O
.	O
,	O
2015	O
)	O
collected	O
from	O
various	O
news	O
sources	O
.	O
There	O
are	O
four	O
topics	O
in	O
total	O
.	O
Similar	O
to	O
Group	O
4	O
,	O
we	O
conduct	O
experiments	O
with	O
each	O
single	O
label	O
for	O
ID	O
and	O
others	O
for	O
OoD	O
,	O
respectively	O
.	O

B4	O
.	O
Did	O
you	O
discuss	O
the	O
steps	O
taken	O
to	O
check	O
whether	O
the	O
data	O
that	O
was	O
collected	O
/	O
used	O
contains	O
any	O
information	O
that	O
names	O
or	O
uniquely	O
identifies	O
individual	O
people	O
or	O
offensive	O
content	O
,	O
and	O
the	O
steps	O
taken	O
to	O
protect	O
/	O
anonymize	O
it	O
?	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O

We	O
collected	O
curricula	O
from	O
university	O
study	O
programs	O
from	O
different	O
countries	O
and	O
categorized	O
them	O
into	O
five	O
computing	O
disciplines	O
:	O
Computer	O
Science	O
(	O
CS	O
)	O
,	O
Computer	O
Engineering	O
(	O
CE	O
)	O
,	O
Information	O
Technology	O
(	O
IT	O
)	O
,	O
Information	O
Science	O
(	O
IS	O
)	O
,	O
and	O
Software	O
Engineering	O
(	O
SE	O
)	O
.	O

In	O
summary	O
,	O
our	O
analysis	O
provides	O
a	O
new	O
way	O
of	O
understanding	O
the	O
role	O
of	O
the	O
demonstrations	O
in	O
in	O
-	O
context	O
learning	O
.	O
We	O
empirically	O
show	O
that	O
the	O
model	O
(	O
1	O
)	O
counter	O
-	O
intuitively	O
does	O
not	O
rely	O
on	O
the	O
ground	O
truth	O
input	O
-	O
label	O
mapping	O
provided	O
in	O
the	O
demonstrations	O
as	O
much	O
as	O
we	O
thought	O
(	O
Section	O
4	O
)	O
,	O
and	O
(	O
2	O
)	O
nonetheless	O
still	O
benefits	O
from	O
knowing	O
the	O
label	O
space	O
and	O
the	O
distribution	O
of	O
inputs	O
specified	O
by	O
the	O
demonstrations	O
(	O
Section	O
5	O
)	O
.	O
We	O
also	O
include	O
a	O
discussion	O
of	O
broader	O
implications	O
,	O
e.g.	O
,	O
what	O
we	O
can	O
say	O
about	O
the	O
model	O
learning	O
at	O
test	O
time	O
,	O
and	O
avenues	O
for	O
future	O
work	O
(	O
Section	O
6	O
)	O
.	O

To	O
improve	O
the	O
models	O
,	O
previous	O
work	O
has	O
looked	O
into	O
different	O
techniques	O
beyond	O
standard	O
model	O
fitting	O
.	O
If	O
the	O
weaknesses	O
of	O
the	O
training	O
datasets	O
or	O
the	O
models	O
are	O
anticipated	O
,	O
strategies	O
can	O
be	O
tailored	O
to	O
mitigate	O
such	O
weaknesses	O
.	O
For	O
example	O
,	O
augmenting	O
the	O
training	O
data	O
with	O
genderswapped	O
input	O
texts	O
helps	O
reduce	O
gender	O
bias	O
in	O
the	O
models	O
(	O
Park	O
et	O
al	O
.	O
,	O
2018;Zhao	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Adversarial	O
training	O
can	O
prevent	O
the	O
models	O
from	O
exploiting	O
irrelevant	O
and/or	O
protected	O
features	O
(	O
Jaiswal	O
et	O
al	O
.	O
,	O
2019;Zhang	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
With	O
a	O
limited	O
number	O
of	O
training	O
examples	O
,	O
using	O
human	O
rationales	O
or	O
prior	O
knowledge	O
together	O
with	O
training	O
labels	O
can	O
help	O
the	O
models	O
perform	O
better	O
(	O
Zaidan	O
et	O
al	O
.	O
,	O
2007;Bao	O
et	O
al	O
.	O
,	O
2018;Liu	O
and	O
Avci	O
,	O
2019	O
)	O
.	O

Generally	O
,	O
deep	O
text	O
classifiers	O
can	O
be	O
divided	O
into	O
two	O
parts	O
.	O
The	O
first	O
part	O
performs	O
feature	O
extraction	O
,	O
transforming	O
an	O
input	O
text	O
into	O
a	O
dense	O
vector	O
(	O
i.e.	O
,	O
a	O
feature	O
vector	O
)	O
which	O
represents	O
the	O
input	O
.	O
There	O
are	O
several	O
alternatives	O
to	O
implement	O
this	O
part	O
such	O
as	O
using	O
convolutional	O
layers	O
,	O
recurrent	O
layers	O
,	O
and	O
transformer	O
layers	O
.	O
The	O
second	O
part	O
performs	O
classification	O
passing	O
the	O
feature	O
vector	O
through	O
a	O
dense	O
layer	O
with	O
softmax	O
activation	O
to	O
get	O
predicted	O
probability	O
of	O
the	O
classes	O
.	O
These	O
deep	O
classifiers	O
are	O
not	O
transparent	O
,	O
as	O
humans	O
can	O
not	O
interpret	O
the	O
meaning	O
of	O
either	O
the	O
intermediate	O
vectors	O
or	O
the	O
model	O
parameters	O
used	O
for	O
feature	O
extraction	O
.	O
This	O
prevents	O
humans	O
from	O
applying	O
their	O
knowledge	O
to	O
modify	O
or	O
debug	O
the	O
classifiers	O
.	O

"	O
male	O
"	O
,	O
"	O
males	O
"	O
,	O
"	O
boy	O
"	O
,	O
"	O
boys	O
"	O
,	O
"	O
man	O
"	O
,	O
"	O
men	O
"	O
,	O
"	O
gentleman	O
"	O
,	O
"	O
gentlemen	O
"	O
,	O
"	O
he	O
"	O
,	O
"	O
him	O
"	O
,	O
"	O
his	O
"	O
,	O
"	O
himself	O
"	O
,	O
"	O
brother	O
"	O
,	O
"	O
son	O
"	O
,	O
"	O
husband	O
"	O
,	O
"	O
boyfriend	O
"	O
,	O
"	O
father	O
"	O
,	O
"	O
uncle	O
"	O
,	O
"	O
dad	O
"	O
Female	O
gender	O
terms	O
:	O

We	O
summarize	O
the	O
differences	O
between	O
imagined	O
and	O
recalled	O
stories	O
in	O
HIPPOCORPUS	O
in	O
Table	O
2	O
.	O
For	O
our	O
narrative	O
flow	O
and	O
lexicon	O
-	O
based	O
analyses	O
,	O
4	O
ATOMIC	O
contains	O
social	O
and	O
inferential	O
knowledge	O
about	O
the	O
causes	O
(	O
e.g.	O
,	O
"	O
X	O
wants	O
to	O
start	O
a	O
family	O
"	O
)	O
and	O
effects	O
(	O
e.g.	O
,	O
"	O
X	O
throws	O
a	O
party	O
"	O
,	O
"	O
X	O
feels	O
loved	O
"	O
)	O
of	O
everyday	O
situations	O
like	O
"	O
PersonX	O
decides	O
to	O
get	O
married	O
"	O
.	O
5	O
See	O
liwc.wpengine.com/interpretingliwc-output/	O
for	O
more	O
information	O
on	O
LIWC	O
variables	O
.	O
we	O
perform	O
paired	O
t	O
-	O
tests	O
.	O
For	O
realis	O
and	O
commonsense	O
event	O
measures	O
,	O
we	O
perform	O
linear	O
regressions	O
controlling	O
for	O
story	O
length	O
.	O
6	O
We	O
Holmcorrect	O
for	O
multiple	O
comparisons	O
for	O
all	O
our	O
analyses	O
(	O
Holm	O
,	O
1979	O
)	O
.	O

where	O
H	O
is	O
the	O
number	O
of	O
heads	O
,	O
head	O
i	O
is	O
the	O
output	O
of	O
i	O
-	O
th	O
head	O
and	O
G	O
h	O
,	O
i	O
is	O
the	O
i	O
-	O
th	O
entry	O
of	O
the	O
gating	O
variables	O
G	O
h	O
∈	O
R	O
H	O
.	O
G	O
h	O
,	O
i	O
indicates	O
whether	O
the	O
head	O
i	O
will	O
be	O
pruned	O
.	O
G	O
h	O
,	O
i	O
is	O
set	O
to	O
1	O
to	O
retain	O
that	O
head	O
and	O
0	O
if	O
to	O
drop	O
it	O
.	O
Different	O
pruning	O
algorithms	O
will	O
have	O
their	O
own	O
ways	O
to	O
determine	O
the	O
values	O
of	O
G	O
h	O
.	O

Given	O
a	O
trained	O
amortized	O
model	O
,	O
there	O
is	O
no	O
randomness	O
when	O
generating	O
explanation	O
scores	O
.	O
However	O
,	O
there	O
is	O
still	O
some	O
randomness	O
in	O
the	O
training	O
process	O
,	O
including	O
the	O
training	O
data	O
,	O
the	O
random	O
initialization	O
of	O
the	O
output	O
layer	O
and	O
randomness	O
during	O
update	O
such	O
as	O
dropout	O
.	O
Therefore	O
,	O
similar	O
to	O
Section	O
4	O
,	O
we	O
study	O
the	O
sensitivity	O
of	O
the	O
amortized	O
model	O
.	O
Table	O
4	O
shows	O
the	O
results	O
with	O
different	O
training	O
data	O
and	O
random	O
seeds	O
.	O
We	O
observe	O
that	O
:	O
1	O
)	O
when	O
using	O
the	O
same	O
data	O
(	O
100	O
%	O
)	O
,	O
random	O
initialization	O
does	O
not	O
affect	O
the	O
outputs	O
of	O
amortized	O
models	O
-the	O
correlation	O
between	O
different	O
runs	O
is	O
high	O
(	O
i.e.	O
,	O
0.77	O
on	O
MNLI	O
and	O
0.76	O
on	O
Yelp	O
-	O
Polarity	O
)	O
.	O
2	O
)	O
With	O
more	O
training	O
samples	O
,	O
the	O
model	O
is	O
more	O
stable	O
.	O

(	O
2	O
)	O
sentence	O
+	O
context	O
:	O
target	O
sentence	O
with	O
surrounding	O
context	O
;	O
(	O
3	O
)	O
sentence	O
+	O
context	O
+	O
entities	O
:	O
additionally	O
appending	O
all	O
entities	O
in	O
their	O
canonical	O
names	O
as	O
extracted	O
in	O
§	O
4.1	O
,	O
same	O
as	O
our	O
model	O
's	O
input	O
.	O
We	O
further	O
consider	O
two	O
variants	O
of	O
our	O
model	O
as	O
baselines	O
.	O
We	O
first	O
design	O
a	O
pipeline	O
model	O
,	O
which	O
first	O
uses	O
the	O
node	O
prediction	O
module	O
to	O
identify	O
salient	O
entities	O
for	O
inclusion	O
in	O
the	O
stance	O
triplets	O
.	O

Argument	O
aspect	O
detection	O
is	O
necessary	O
for	O
our	O
argument	O
generation	O
pipeline	O
,	O
as	O
it	O
allows	O
for	O
a	O
finegrained	O
control	O
over	O
the	O
generation	O
process	O
.	O
We	O
create	O
a	O
new	O
dataset	O
,	O
as	O
existing	O
approaches	O
either	O
rely	O
on	O
coarse	O
-	O
grained	O
frames	O
or	O
can	O
not	O
be	O
applied	O
by	O
non	O
-	O
expert	O
annonators	O
in	O
a	O
scalable	O
manner	O
.	O

All	O
BERT	B-MethodName
models	O
are	O
uncased	O
BERT	B-MethodName
-	O
base	O
models	O
with	O
12	O
layers	O
,	O
768	O
hidden	O
units	O
,	O
and	O
12	O
heads	O
with	O
default	O
parameters	O
,	O
and	O
trained	O
on	O
English	O
Wikipedia	O
and	O
the	O
BookCorpus	B-DatasetName
.	O
The	O
probability	O
p	O
drop	O
for	O
attribute	O
-	O
OOV	O
is	O
set	O
to	O
0.3	O
.	O
Both	O
candidate	O
generation	O
and	O
re	O
-	O
ranking	O
models	O
are	O
trained	O
using	O
the	O
BERT	B-MethodName
Adam	O
optimizer	O
(	O
Kingma	O
and	O
Ba	O
,	O
2015	O
)	O
,	O
with	O
a	O
linear	O
warmup	O
for	O
10	O
%	O
of	O
the	O
first	O
epoch	O
to	O
a	O
peak	O
learning	O
rate	O
of	O
2	O
×	O
10	O
−5	O
and	O
a	O
linear	O
decay	O
from	O
there	O
till	O
the	O
learning	O
rate	O
approaches	O
zero	O
.	O
9	O
Candidate	O
generation	O
models	O
are	O
trained	O
for	O
200	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
256	O
.	O
Re	O
-	O
ranking	O
models	O
are	O
trained	O
for	O
4	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
2	O
,	O
and	O
operate	O
on	O
the	O
top	O
32	O
candidates	O
returned	O
by	O
the	O
generation	O
model	O
.	O
Hyperparameters	O
are	O
chosen	O
such	O
that	O
models	O
can	O
be	O
run	O
on	O
a	O
single	O
NVIDIA	O
V100	O
Tensor	O
Core	O
GPU	O
with	O
32	O
GB	O
RAM	O
,	O
and	O
are	O
not	O
extensively	O
tuned	O
.	O
All	O
models	O
have	O
the	O
same	O
number	O
of	O
parameters	O
except	O
the	O
ones	O
with	O
attribute	O
-	O
separators	O
which	O
have	O
100	O
extra	O
token	O
embeddings	O
(	O
of	O
size	O
768	O
each	O
)	O
.	O

Both	O
layer	O
and	O
anchor	O
task	O
analysis	O
reveal	O
a	O
prominent	O
discrepancy	O
between	O
English	O
and	O
German	O
role	O
probing	O
results	O
:	O
while	O
the	O
PropBank	B-MethodName
predicate	O
layer	O
utilization	O
for	O
English	O
mostly	O
relies	O
on	O
syntactic	O
information	O
,	O
German	O
PropBank	B-MethodName
predicates	O
behave	O
similarly	O
to	O
VerbNet	O
and	O
FrameNet	O
.	O
The	O
lack	O
of	O
systematic	O
cross	O
-	O
lingual	O
differences	O
between	O
layer	O
utilization	O
for	O
other	O
probing	O
tasks	O
6	O
allows	O
us	O
to	O
rule	O
out	O
the	O
effect	O
of	O
purely	O
typological	O
features	O
such	O
as	O
word	O
order	O
and	O
case	O
marking	O
as	O
a	O
likely	O
cause	O
.	O
The	O
difference	O
in	O
the	O
number	O
of	O
role	O
labels	O
for	O
English	O
and	O
German	O
PropBank	B-MethodName
,	O
however	O
,	O
points	O
at	O
possible	O
qualitative	O
differences	O
in	O
the	O
labeling	O
schemes	O
(	O
Table	O
3	O
)	O
.	O
The	O
data	O
for	O
English	O
stems	O
from	O
the	O
token	O
-	O
level	O
alignment	O
in	O
SemLink	B-MethodName
that	O
maps	O
the	O
original	O
PropBank	B-MethodName
roles	O
to	O
Verb	O
-	I-MethodName
Net	O
and	O
FrameNet	O
.	O
Role	O
annotations	O
for	O
German	O
have	O
a	O
different	O
lineage	O
:	O
they	O
originate	O
from	O
the	O
FrameNet	O
-	O
annotated	O
SALSA	O
corpus	O
(	O
Burchardt	O
et	O
al	O
.	O
,	O
2006	O
)	O
semi	O
-	O
automatically	O
converted	O
to	O
Prop	B-MethodName
-	O
Bank	O
style	O
for	O
the	O
CoNLL-2009	O
shared	O
task	O
(	O
Hajič	O
et	O
al	O
.	O
,	O
2009	O
)	O
,	O
and	O
enriched	O
with	O
VerbNet	O
labels	O
in	O
SR3de	O
(	O
Mújdricza	O
-	O
Maydt	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
As	O
a	O
result	O
,	O
while	O
English	O
PropBank	B-MethodName
labels	O
are	O
assigned	O
in	O
a	O
predicate	O
-	O
independent	O
manner	O
,	O
German	O
PropBank	B-MethodName
,	O
following	O
the	O
same	O
numbered	O
labeling	O
scheme	O
,	O
keeps	O
this	O
scheme	O
consistent	O
within	O
the	O
frame	O
.	O
We	O
assume	O
that	O
this	O
incentivizes	O
the	O
probe	O
to	O
learn	O
semantic	O
verb	O
groupings	O
and	O
reflects	O
in	O
our	O
probing	O
results	O
.	O
The	O
ability	O
of	O
the	O
probe	O
to	O
detect	O
subtle	O
differences	O
between	O
formalism	O
implementations	O
constitutes	O
a	O
new	O
use	O
case	O
for	O
probing	O
,	O
and	O
a	O
promising	O
direction	O
for	O
future	O
studies	O
.	O

Model	O
.	O
We	O
use	O
the	O
model	O
presented	O
in	O
Lee	O
et	O
al	O
.	O
(	O
2018a	O
)	O
with	O
RoBERTa	O
as	O
a	O
feature	O
extractor	O
.	O

Identity	O
-	O
related	O
(	O
A	O
I	O
)	O
Potentially	O
offensive	O
or	O
stereotyping	O
terms	O
towards	O
minority	O
identities	O
(	O
e.g.	O
,	O
"	O
n*gro	O
"	O
,	O
"	O
f*ggot	O
"	O
,	O
"	O
k*ke	O
"	O
,	O
"	O
wh*re	O
"	O
)	O
,	O
as	O
well	O
as	O
reclaimed	O
slurs	O
(	O
e.g.	O
,	O
"	O
n*gga	O
"	O
)	O
(	O
Figure	O
1	O
,	O
top	O
left	O
)	O
.	O

To	O
mitigate	O
the	O
effect	O
of	O
clinical	O
annotation	O
artifacts	O
,	O
we	O
employ	O
AFLite	O
,	O
an	O
adversarial	O
filtering	O
algorithm	O
introduced	O
by	O
Sakaguchi	O
et	O
AFLite	O
requires	O
distributed	O
representations	O
of	O
the	O
full	O
dataset	O
as	O
input	O
,	O
and	O
proceeds	O
in	O
an	O
iterative	O
fashion	O
.	O
At	O
each	O
iteration	O
,	O
an	O
ensemble	O
of	O
n	O
linear	O
classifiers	O
are	O
trained	O
and	O
evaluated	O
on	O
different	O
random	O
subsets	O
of	O
the	O
data	O
.	O
A	O
score	O
is	O
then	O
computed	O
for	O
each	O
premise	O
-	O
hypothesis	O
instance	O
,	O
reflecting	O
the	O
number	O
of	O
times	O
the	O
instance	O
is	O
correctly	O
labeled	O
by	O
a	O
classifier	O
,	O
divided	O
by	O
the	O
number	O
of	O
times	O
the	O
instance	O
appears	O
in	O
any	O
classifier	O
's	O
evaluation	O
set	O
.	O
The	O
top	O
-	O
k	O
instances	O
with	O
scores	O
above	O
a	O
threshold	O
,	O
τ	O
,	O
are	O
filtered	O
out	O
and	O
added	O
to	O
the	O
easy	O
partition	O
;	O
the	O
remaining	O
instances	O
are	O
retained	O
.	O
This	O
process	O
continues	O
until	O
the	O
size	O
of	O
the	O
filtered	O
subset	O
is	O
<	O
k	O
,	O
or	O
the	O
number	O
of	O
retained	O
instances	O
is	O
<	O
m	O
;	O
retained	O
instances	O
constitute	O
the	O
difficult	O
partition	O
.	O

The	O
amount	O
of	O
pretraining	O
data	O
and	O
in	O
-	O
task	O
training	O
data	O
are	O
strongly	O
correlated	O
with	O
overall	O
task	O
performance	O
for	O
most	O
of	O
the	O
considered	O
tasks	O
;	O
this	O
corroborates	O
similar	O
results	O
from	O
Wu	O
and	O
Dredze	O
(	O
2020	O
)	O
.	O
Language	O
similarity	O
with	O
English	O
is	O
also	O
correlated	O
with	O
better	O
in	O
-	O
task	O
performance	O
on	O
all	O
tasks	O
except	O
for	O
dependency	O
arc	O
prediction	O
,	O
suggesting	O
that	O
some	O
form	O
of	O
crosslingual	O
signal	O
supports	O
in	O
-	O
language	O
performance	O
for	O
linguistically	O
similar	O
languages	O
.	O

The	O
generation	O
of	O
questions	O
from	O
a	O
sentence	O
relies	O
on	O
the	O
jsRealB	O
text	O
realizer	O
(	O
Lapalme	O
,	O
2021	O
)	O
which	O
generates	O
an	O
affirmative	O
sentence	O
from	O
a	O
constituent	O
structure	O
.	O
It	O
can	O
also	O
be	O
parameterized	O
to	O
generate	O
variations	O
of	O
the	O
original	O
sentence	O
such	O
as	O
its	O
negation	O
,	O
its	O
passive	O
form	O
and	O
different	O
types	O
of	O
questions	O
such	O
as	O
who	O
,	O
what	O
,	O
when	O
,	O
etc	O
.	O
The	O
constituency	O
structure	O
of	O
a	O
sentence	O
is	O
most	O
often	O
created	O
by	O
a	O
user	O
or	O
by	O
a	O
program	O
from	O
data	O
.	O
In	O
this	O
work	O
,	O
it	O
is	O
instead	O
built	O
from	O
a	O
Universal	O
Dependency	O
(	O
UD	O
)	O
structure	O
using	O
a	O
technique	O
developed	O
for	O
SR'19	O
(	O
Lapalme	O
,	O
2019	O
)	O
.	O
The	O
UD	O
structure	O
of	O
a	O
sentence	O
is	O
the	O
result	O
of	O
a	O
dependency	O
parse	O
with	O
Stanza	O
(	O
Qi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
thus	O
have	O
a	O
pipeline	O
composed	O
of	O
a	O
neural	O
dependency	O
parser	O
,	O
followed	O
by	O
a	O
program	O
to	O
create	O
a	O
constituency	O
structure	O
used	O
as	O
input	O
for	O
a	O
text	O
realizer	O
,	O
both	O
in	O
JavaScript	O
.	O
Used	O
without	O
modification	O
,	O
this	O
would	O
create	O
a	O
complex	O
echo	O
program	O
for	O
the	O
original	O
affirmative	O
sentence	O
,	O
but	O
by	O
changing	O
parameters	O
,	O
its	O
output	O
can	O
vary	O
.	O

FairPrism	O
is	O
intended	O
to	O
be	O
used	O
by	O
researchers	O
and	O
practitioners	O
who	O
wish	O
to	O
diagnose	O
(	O
1	O
)	O
the	O
types	O
of	O
fairness	O
-	O
related	O
harms	O
that	O
AI	O
text	O
generation	I-TaskName
systems	O
cause	O
,	O
and	O
(	O
2	O
)	O
the	O
potential	O
limitations	O
of	O
mitigation	O
methods	O
.	O
In	O
this	O
section	O
,	O
we	O
suggest	O
possible	O
analyses	O
,	O
along	O
with	O
illustrative	O
case	O
studies	O
.	O

We	O
introduced	O
a	O
new	O
NLP	O
task	O
,	O
object	O
use	O
classification	O
,	O
which	O
identifies	O
whether	O
an	O
object	O
mentioned	O
in	O
a	O
sentence	O
has	O
been	O
used	O
or	O
likely	O
will	O
be	O
used	O
.	O
We	O
introduced	O
a	O
gold	O
standard	O
dataset	O
for	O
this	O
task	O
and	O
showed	O
that	O
all	O
3	O
categories	O
(	O
Used	O
,	O
Anticipated	O
Use	O
,	O
and	O
No	O
Use	O
)	O
are	O
common	O
in	O
real	O
sentences	O
.	O
Then	O
we	O
presented	O
a	O
transformer	O
-	O
based	O
architecture	O
for	O
this	O
task	O
that	O
uses	O
two	O
types	O
of	O
data	O
augmentation	O
techniques	O
(	O
synonym	O
/	O
hyponym	O
replacement	O
and	O
back	O
translation	O
)	O
and	O
also	O
exploits	O
exemplar	O
sentences	O
from	O
FrameNet	O
that	O
correspond	O
to	O
an	O
object	O
's	O
prototypical	O
function	O
.	O
The	O
resulting	O
classification	O
model	O
achieves	O
reasonably	O
good	O
performance	O
for	O
this	O
task	O
,	O
although	O
there	O
is	O
room	O
for	O
improvement	O
that	O
we	O
hope	O
will	O
inspire	O
future	O
work	O
on	O
this	O
problem	O
.	O

Given	O
a	O
training	O
ID	O
sequence	O
x	O
=	O
{	O
x	O
i	O
}	O
N	O
i=1	O
∈	O
D	O
in	O
,	O
the	O
learning	O
loss	O
for	O
prediction	O
layer	O
distillation	O
w.r.t	O
.	O
x	O
is	O
formulated	O
as	O
the	O
Kullback	O
-	O
Leibler	O
divergence	O
between	O
the	O
output	O
probability	O
distributions	O
over	O
the	O
vocabulary	O
V	O
output	O
by	O
the	O
teacher	O
model	O
and	O
by	O
the	O
student	O
model	O
.	O
Averaging	O
over	O
all	O
tokens	O
,	O
we	O
have	O
:	O

2	O
)	O
as	O
examples	O
.	O
The	O
underlined	O
words	O
are	O
with	O
the	O
top	O
-	O
k	O
highest	O
importance	O
predicted	O
by	O
the	O
proposed	O
pipeline	O
.	O
Reference	O
segment	O
Gross	O
margin	O
from	O
manufacturing	O
operations	O
as	O
a	O
percentage	O
of	O
manufacturing	O
revenues	O
increased	O
to	O
27	O
%	O
for	O
the	O
year	O
ended	O
December	O
31	O
,	O
2014	O
,	O
from	O
23	O
%	O
for	O
the	O
comparable	O
prior	O
year	O
period	O
.	O
Target	O
segment	O
Gross	O
margin	O
from	O
manufacturing	O
operations	O
as	O
a	O
percentage	O
of	O
manufacturing	O
revenues	O
decreased	O
to	O
15	O
%	O
for	O
the	O
year	O
ended	O
December	O
31	O
,	O
2016	O
from	O
23	O
%	O
for	O
the	O
comparable	O
prior	O
year	O
period	O
.	O

▷	O
FreeLB	O
training	O
15	O
Back	O
-	O
propagate	O
L	O
i	O
+	O
L	O
e	O
and	O
accumulate	O
gradient	O
of	O
parameters	O
θ	O
:	O

Zero	O
-	O
shot	O
EL	O
Linking	O
to	O
any	O
DB	O
This	O
work	O
(	O
Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
(	O
Sil	O
et	O
al	O
.	O
,	O
2012	O
)	O
Test	O
entities	O
not	O
seen	O
during	O
training	O
Test	O
KB	O
schema	O
unknown	O
Out	O
-	O
of	O
-	O
domain	O
test	O
data	O
Unrestricted	O
Candidate	O
Set	O
and	O
by	O
stochastically	O
removing	O
attribute	O
separators	O
to	O
generalize	O
to	O
unseen	O
attributes	O
(	O
Section	O
4.2	O
)	O
.	O

In	O
this	O
section	O
,	O
we	O
present	O
qualitative	O
studies	O
about	O
semantic	O
alignments	O
between	O
tokens	O
for	O
language	O
modeling	O
and	O
machine	O
translation	O
tasks	O
.	O
We	O
select	O
three	O
rare	O
token	O
from	O
each	O
datasets	O
:	O
"	O
homepage	O
"	O
,	O
"	O
Werewolf	O
"	O
,	O
and	O
"	O
policymakers	O
"	O
for	O
WikiText-103	B-DatasetName
dataset	O
,	O
and	O
"	O
optimum	O
"	O
,	O
"	O
criminal	O
"	O
,	O
and	O
"	O
happiness	O
"	O
for	O
WMT14	B-DatasetName
En→De	O
dataset	O
.	O
For	O
each	O
rare	O
token	O
,	O
we	O
extract	O
the	O
top-5	O
nearest	O
neighbor	O
token	O
predicted	O
by	O
the	O
cosine	O
distance	O
between	O
token	O
embeddings	O
.	O
Compared	O
with	O
baseline	O
MLE	B-MethodName
method	O
,	O
AGG	B-MethodName
shows	O
significant	O
improvement	O
to	O
train	O
semantic	O
alignments	O
for	O
rare	O
tokens	O
.	O
From	O
Table	O
13	O
,	O
we	O
notice	O
that	O
the	O
rare	O
tokens	O
trained	O
with	O
AGG	B-MethodName
are	O
semantically	O
well	O
aligned	O
and	O
not	O
biased	O
about	O
token	O
frequency	O
.	O
Table	O
14	O
demonstrates	O
that	O
token	O
embeddings	O
trained	O
with	O
AGG	B-MethodName
also	O
learn	O
the	O
cross	O
-	O
lingual	O
semantic	O
alignments	O
between	O
target	O
language	O
tokens	O
.	O

In	O
this	O
subsection	O
,	O
we	O
compare	O
the	O
empirical	O
results	O
of	O
different	O
variants	O
of	O
METRO	B-MethodName
-	I-MethodName
T0	I-MethodName
.	O
Table	O
4	O
shows	O
the	O
performance	O
of	O
each	O
variant	O
prompt	O
-	O
finetuned	O
on	O
T0	O
/	O
T0+/T0++	O
Train	O
and	O
evaluated	O
on	O
T0	O
Eval	O
.	O

As	O
we	O
know	O
,	O
the	O
translation	O
cost	O
is	O
expensive	O
,	O
and	O
we	O
provide	O
parallel	O
corpus	O
in	O
six	O
languages	O
,	O
which	O
limits	O
the	O
volume	O
of	O
translated	O
headers	O
.	O
On	O
the	O
basis	O
of	O
our	O
statistics	O
,	O
the	O
average	O
validating	O
speed	O
is	O
100	O
headers	O
/	O
hour	O
and	O
we	O
spend	O
159.34	O
⇤	O
5	O
hours	O
in	O
total	O
.	O
This	O
speed	O
is	O
much	O
slower	O
than	O
the	O
plain	O
text	O
translation	O
since	O
our	O
translators	O
need	O
to	O
read	O
large	O
amounts	O
of	O
different	O
domain	O
-	O
specific	O
contexts	O
to	O
help	O
disambiguation	O
.	O
To	O
this	O
end	O
,	O
we	O
make	O
our	O
best	O
effort	O
and	O
translate	O
11,979	O
headers	O
,	O
spending	O
6,625	O
USD	O
in	O
total	O
.	O
According	O
to	O
our	O
translators	O
'	O
feedback	O
,	O
the	O
context	O
is	O
quite	O
helpful	O
in	O
understanding	O
the	O
meaning	O
of	O
headers	O
.	O
We	O
will	O
also	O
release	O
these	O
contexts	O
together	O
with	O
our	O
schema	O
translation	O
dataset	O
to	O
facilitate	O
further	O
study	O
.	O

Complete	O
this	O
story	O
in	O
500	O
words	O
.	O
Miss	O
Manette	O
receives	O
a	O
letter	O
from	O
the	O
bank	O
informing	O
her	O
that	O
information	O
about	O
her	O
father	O
's	O
small	O
property	O
has	O
been	O
discovered	O
.	O

•	O
SQuAD	O
1.1	O
:	O
Stanford	O
Question	O
Answering	O
Dataset	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
Given	O
a	O
context	O
paragraph	O
and	O
a	O
question	O
,	O
the	O
task	O
is	O
to	O
select	O
the	O
span	O
of	O
text	O
in	O
the	O
paragraph	O
answering	O
the	O
question	O
.	O
The	O
dataset	O
contains	O
88k	O
train	O
examples	O
from	O
Wikipedia	O
.	O

We	O
rely	O
on	O
arguments	O
in	O
our	O
daily	O
lives	O
to	O
deliver	O
our	O
opinions	O
and	O
base	O
them	O
on	O
evidence	O
,	O
making	O
them	O
more	O
convincing	O
in	O
turn	O
.	O
However	O
,	O
finding	O
and	O
formulating	O
arguments	O
can	O
be	O
challenging	O
.	O
In	O
this	O
work	O
,	O
we	O
present	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
-	O
a	O
language	O
model	O
for	O
argument	O
generation	O
that	O
can	O
be	O
controlled	O
to	O
generate	O
sentence	O
-	O
level	O
arguments	O
for	O
a	O
given	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
.	O
We	O
define	O
argument	O
aspect	O
detection	O
as	O
a	O
necessary	O
method	O
to	O
allow	O
this	O
fine	O
-	O
granular	O
control	O
and	O
crowdsource	O
a	O
dataset	O
with	O
5,032	O
arguments	O
annotated	O
with	O
aspects	O
.	O
Our	O
evaluation	O
shows	O
that	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
is	O
able	O
to	O
generate	O
high	O
-	O
quality	O
,	O
aspectspecific	O
arguments	O
,	O
applicable	O
to	O
automatic	O
counter	O
-	O
argument	O
generation	O
.	O
We	O
publish	O
the	O
model	O
weights	O
and	O
all	O
datasets	O
and	O
code	O
to	O
train	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
.	O
1	O
Nuclear	O
reactors	O
produce	O
radioactive	O
waste	O
...	O

Basically	O
,	O
our	O
model	O
adopts	O
a	O
Transformer	B-MethodName
encoderdecoder	O
architecture	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
which	O
takes	O
the	O
source	O
language	O
header	O
with	O
its	O
corresponding	O
context	O
as	O
inputs	O
and	O
generates	O
the	O
translation	O
for	O
the	O
target	O
language	O
header	O
as	O
outputs	O
.	O
Specifically	O
,	O
we	O
model	O
the	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
and	O
use	O
the	O
transformer	O
self	O
-	O
attention	O
to	O
encode	O
them	O
over	O
two	O
predefined	O
structural	O
relationships	O
and	O
three	O
entity	O
types	O
.	O
Figure	O
2	O
depicts	O
the	O
overall	O
architecture	O
of	O
our	O
model	O
via	O
an	O
illustrative	O
example	O
.	O

D2	O
.	O
Did	O
you	O
report	O
information	O
about	O
how	O
you	O
recruited	O
(	O
e.g.	O
,	O
crowdsourcing	O
platform	O
,	O
students	O
)	O
and	O
paid	O
participants	O
,	O
and	O
discuss	O
if	O
such	O
payment	O
is	O
adequate	O
given	O
the	O
participants	O
'	O
demographic	O
(	O
e.g.	O
,	O
country	O
of	O
residence	O
)	O
?	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O

People	O
living	O
in	O
bristol	O
have	O
complained	O
about	O
a	O
vinegary	O
whiff	O
in	O
the	O
air	O
.	O

When	O
reasoning	O
with	O
LM	O
prompting	O
,	O
the	O
models	O
should	O
have	O
the	O
ability	O
of	O
semantic	O
understanding	O
(	O
e.g.	O
,	O
questions	O
)	O
and	O
complex	O
reasoning	O
(	O
e.g.	O
,	O
by	O
generating	O
reasoning	O
processes	O
)	O
;	O
however	O
,	O
we	O
can	O
not	O
have	O
both	O
fish	O
and	O
bear	O
's	O
paw	O
(	O
Hendrycks	O
et	O
al	O
.	O
,	O
2021	O
;	O
Nogueira	O
et	O
al	O
.	O
,	O
2021	O
;	O
Lewkowycz	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
To	O
tear	O
up	O
the	O
obstacle	O
,	O
external	O
reasoning	O
engines	O
lend	O
a	O
helping	O
hand	O
to	O
LMs	O
(	O
see	O
Figure	O
5	O
)	O
.	O

We	O
aim	O
to	O
train	O
a	O
model	O
that	O
is	O
able	O
to	O
transfer	O
argumentative	O
information	O
concisely	O
within	O
a	O
single	O
sentence	O
.	O
We	O
define	O
such	O
an	O
argument	O
as	O
the	O
combination	O
of	O
a	O
topic	O
and	O
a	O
sentence	O
holding	O
evidence	O
with	O
a	O
specific	O
stance	O
towards	O
this	O
topic	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
Consequently	O
,	O
the	O
following	O
preprocessing	O
steps	O
ultimately	O
target	O
retrieval	O
and	O
classification	O
of	O
sentences	O
.	O
To	O
evaluate	O
different	O
data	O
sources	O
,	O
we	O
use	O
a	O
dump	O
from	O
Common-	O
We	O
notice	O
that	O
many	O
sentences	O
are	O
not	O
relevant	O
with	O
regard	O
to	O
the	O
document	O
's	O
topic	O
.	O
To	O
enforce	O
topicrelevance	O
,	O
we	O
decide	O
to	O
filter	O
out	O
all	O
sentences	O
that	O
do	O
not	O
contain	O
at	O
least	O
one	O
token	O
of	O
the	O
respective	O
topic	O
or	O
its	O
defined	O
synonyms	O
(	O
see	O
App	O
.	O
B	O
)	O
.	O
We	O
use	O
the	O
ArgumenText	B-MethodName
API	I-MethodName
's	O
6	O
argument	O
and	O
stance	O
classification	O
models	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018a	O
)	O
to	O
classify	O
all	O
sentences	O
into	O
argument	O
or	O
non	O
-	O
argument	O
(	O
F	O
1	O
macro	O
=	O
.7384	O
)	O
,	O
and	O
remaining	O
arguments	O
into	O
pro	O
or	O
con	O
with	O
regard	O
to	O
the	O
topic	O
(	O
F	O
1	O
macro	O
=	O
.7661	O
)	O
.	O

an	O
unbiased	O
estimate	O
of	O
∇	O
θ	O
L(θ	O
)	O
.	O
However	O
,	O
this	O
algorithm	O
is	O
computationally	O
expensive	O
to	O
run	O
,	O
since	O
it	O
requires	O
k	O
+	O
1	O
forward	O
passes	O
through	O
the	O
transformer	O
to	O
compute	O
thep	O
θ	O
s	O
(	O
once	O
for	O
the	O
positive	O
samples	O
and	O
once	O
for	O
each	O
negative	O
sample	O
)	O
.	O
We	O
propose	O
a	O
much	O
more	O
efficient	O
approach	O
that	O
replaces	O
k	O
input	O
tokens	O
with	O
noise	O
samples	O
simultaneously	O
shown	O
in	O
Algorithm	O
2	O
.	O
It	O
requires	O
just	O

A	O
line	O
of	O
machine	O
translation	O
research	O
closely	O
related	O
to	O
our	O
task	O
is	O
the	O
phrase	O
-	O
to	O
-	O
phrase	O
translation	O
,	O
which	O
considers	O
phrases	O
in	O
multi	O
-	O
word	O
expressions	O
as	O
their	O
translation	O
unit	O
.	O
Traditional	O
phrase	O
-	O
based	O
SMT	O
models	O
(	O
Koehn	O
et	O
al	O
.	O
,	O
2007;Haddow	O
et	O
al	O
.	O
,	O
2015	O
)	O
get	O
phrase	O
table	O
translation	O
probabilities	O
by	O
counting	O
phrase	O
occurrences	O
and	O
use	O
local	O
context	O
through	O
a	O
smoothed	O
n	O
-	O
gram	O
language	O
model	O
.	O
Recently	O
,	O
some	O
works	O
explore	O
ways	O
to	O
adapt	O
NMT	B-TaskName
models	O
for	O
phrase	O
translation	O
.	O
For	O
example	O
,	O
Wang	O
et	O
al	O
.	O
(	O
2017	O
)	O
combined	O
the	O
phrase	O
-	O
based	O
statistical	O
machine	I-TaskName
translation	I-TaskName
(	O
SMT	B-TaskName
)	O
model	O
into	O
NMT	B-TaskName
and	O
shown	O
significant	O
improvements	O
on	O
Chineseto	O
-	O
English	O
translation	O
data	O
,	O
explored	O
the	O
use	O
of	O
phrase	O
structures	O
for	O
NMT	B-TaskName
systems	O
by	O
modeling	O
phrases	O
in	O
target	O
language	O
sequences	O
,	O
and	O
Feng	O
et	O
al	O
.	O
(	O
2018	O
)	O
used	O
a	O
phrase	O
attention	O
mechanism	O
to	O
enhance	O
the	O
decoder	O
in	O
relevant	O
source	O
segment	O
recognition	O
.	O
The	O
main	O
differences	O
between	O
these	O
studies	O
and	O
our	O
work	O
are	O
:	O
(	O
1	O
)	O
we	O
do	O
not	O
rely	O
on	O
external	O
phrase	O
dictionaries	O
or	O
phrase	O
tables	O
;	O
and	O
(	O
2	O
)	O
we	O
study	O
how	O
to	O
make	O
use	O
of	O
the	O
schema	O
context	O
for	O
word	O
-	O
sense	O
disambiguation	O
in	O
the	O
schema	O
translation	O
scenario	O
.	O

Recently	O
,	O
research	O
on	O
generating	O
arguments	O
with	O
language	O
models	O
gained	O
more	O
attention	O
.	O
use	O
a	O
sequence	O
to	O
sequence	O
model	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014	O
)	O
to	O
generate	O
argumentative	O
text	O
by	O
attending	O
to	O
the	O
input	O
and	O
keyphrases	O
automatically	O
extracted	O
for	O
the	O
input	O
from	O
,	O
for	O
example	O
,	O
Wikipedia	O
.	O
Other	O
work	O
focuses	O
on	O
generating	O
argumentative	O
dialogue	O
(	O
Le	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
counterarguments	O
(	O
Hidey	O
and	O
McKeown	O
,	O
2019	O
;	O
based	O
on	O
a	O
given	O
input	O
sentence	O
,	O
or	O
on	O
generating	O
summaries	O
from	O
a	O
set	O
of	O
arguments	O
(	O
Wang	O
and	O
Ling	O
,	O
2016	O
)	O
.	O
Contrarily	O
,	O
we	O
train	O
a	O
language	O
model	O
that	O
does	O
not	O
require	O
a	O
sentence	O
-	O
level	O
input	O
for	O
generation	O
and	O
allows	O
for	O
direct	O
control	O
over	O
the	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
of	O
the	O
produced	O
argument	O
.	O
Xing	O
et	O
al	O
.	O
(	O
2017	O
)	O
design	O
a	O
language	O
model	O
that	O
attends	O
to	O
topic	O
information	O
to	O
generate	O
responses	O
for	O
chatbots	O
.	O
Dathathri	O
et	O
al	O
.	O
(	O
2019	O
)	O
train	O
two	O
models	O
that	O
control	O
the	O
sentiment	O
and	O
topic	O
of	O
the	O
output	O
of	O
pre	O
-	O
trained	O
language	O
models	O
at	O
inference	O
.	O
Gretz	O
et	O
al	O
.	O
(	O
2020a	O
)	O
fine	O
-	O
tune	O
GPT-2	O
on	O
existing	O
,	O
labeled	O
datasets	O
to	O
generate	O
claims	O
for	O
given	O
topics	O
.	O
However	O
,	O
the	O
latter	O
works	O
do	O
not	O
explore	O
generation	O
for	O
such	O
a	O
fine	O
-	O
grained	O
and	O
explicit	O
control	O
as	O
proposed	O
in	O
this	O
work	O
.	O
We	O
show	O
that	O
argument	O
generation	O
requires	O
the	O
concept	O
of	O
argument	O
aspects	O
to	O
shape	O
the	O
produced	O
argument	O
's	O
perspective	O
and	O
to	O
allow	O
for	O
diverse	O
arguments	O
for	O
a	O
topic	O
of	O
interest	O
.	O

Furthermore	O
,	O
using	O
lexicon	O
-	O
based	O
measures	O
,	O
we	O
find	O
that	O
stories	O
with	O
high	O
FREQUENCYOFRE	O
-	O
CALL	O
tend	O
to	O
contain	O
more	O
self	O
references	O
(	O
Iwords	O
;	O
Pearson	O
's	O
|r|	O
=	O
0.07	O
,	O
p	O
<	O
0.001	O
)	O
.	O
Conversely	O
,	O
stories	O
that	O
are	O
less	O
frequently	O
recalled	O
are	O
more	O
logical	O
or	O
hierarchical	O
(	O
LIWC	O
's	O
ANALYTIC	O
;	O
Pearson	O
's	O
|r|	O
=	O
0.09	O
,	O
p	O
<	O
0.001	O
)	O
and	O
more	O
concrete	O
(	O
Pearson	O
's	O
|r|	O
=	O
0.05	O
,	O
p	O
=	O
0.03	O
)	O
.	O

Here	O
,	O
we	O
introduce	O
the	O
GuessWhat	O
?	O
!	O
visual	O
dialogue	O
game	O
(	O
De	O
Vries	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
We	O
use	O
this	O
game	O
as	O
a	O
running	O
example	O
to	O
ground	O
abstract	O
theoretical	O
concepts	O
in	O
practical	O
application	O
.	O
Importantly	O
,	O
our	O
theoretical	O
study	O
is	O
more	O
generally	O
applicable	O
(	O
i.e.	O
,	O
beyond	O
just	O
this	O
example	O
)	O
.	O
Statistics	O
on	O
object	O
distribution	O
and	O
dialogue	O
length	O
are	O
provided	O
in	O
Figure	O
3	O
.	O
After	O
applying	O
the	O
labeling	O
scheme	O
and	O
downsampling	O
(	O
as	O
just	O
described	O
)	O
,	O
our	O
dataset	O
consists	O
of	O
about	O
3200	O
(	O
half	O
with	O
a	O
=	O
1	O
)	O
when	O
F	O
is	O
the	O
protected	O
attribute	O
and	O
6400	O
(	O
half	O
with	O
a	O
=	O
1	O
)	O
when	O
M	O
is	O
the	O
protected	O
attribute	O
.	O
Note	O
,	O
this	O
also	O
indicates	O
that	O
the	O
ratio	O
of	O
M	O
to	O
F	O
in	O
the	O
original	O
dataset	O
is	O
about	O
2	O
to	O
1	O
.	O

We	O
used	O
subsets	O
of	O
two	O
datasets	O
:	O
(	O
1	O
)	O
Yelp	O
-predicting	O
sentiments	O
of	O
restaurant	O
reviews	O
(	O
positive	O
or	O
negative	O
)	O
and	O
(	O
2	O
)	O
Amazon	O
Products	O
-classifying	O
product	O
reviews	O
into	O
one	O
of	O
four	O
categories	O
(	O
Clothing	O
Shoes	O
and	O
Jewelry	O
,	O
Digital	O
Music	O
,	O
Office	O
Products	O
,	O
or	O
Toys	O
and	O
Games	O
)	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
.	O
We	O
sampled	O
500	O
and	O
100	O
examples	O
to	O
be	O
the	O
training	O
data	O
for	O
Yelp	O
and	O
Amazon	O
Products	O
,	O
respectively	O
.	O

C1	O
.	O
Did	O
you	O
report	O
the	O
number	O
of	O
parameters	O
in	O
the	O
models	O
used	O
,	O
the	O
total	O
computational	O
budget	O
(	O
e.g.	O
,	O
GPU	O
hours	O
)	O
,	O
and	O
computing	O
infrastructure	O
used	O
?	O
In	O
Appendix	O
D	O
.	O

Training	O
sentence	O
:	O
We	O
have	O
some	O
of	O
the	O
strongest	O
gun	O
laws	O
in	O
the	O
country	O
,	O
but	O
guns	O
do	O
n't	O
respect	O
boundaries	O
any	O
more	O
than	O
criminals	O
do	O
.	O
Cosine	O
similarity	O
/	O
edit	O
distance	O
/	O
rel	O
.	O
overlap	O
:	O
95.59	O
/	O
88	O
/	O
8	O
%	O
Generated	O
sentence	O
:	O
The	O
radioactivity	O
of	O
the	O
spent	O
fuel	O
is	O
a	O
concern	O
,	O
as	O
it	O
can	O
be	O
used	O
to	O
make	O
weapons	O
and	O
has	O
been	O
linked	O
to	O
cancer	O
in	O
humans	O
.	O
Training	O
sentence	O
:	O
However	O
,	O
it	O
does	O
produce	O
radioactive	O
waste	O
,	O
which	O
must	O
be	O
disposed	O
of	O
carefully	O
as	O
it	O
can	O
cause	O
health	O
problems	O
and	O
can	O
be	O
used	O
to	O
make	O
nuclear	O
weapons	O
Cosine	O
similarity	O
/	O
edit	O
distance	O
/	O
rel	O
.	O
overlap	O
:	O
92.40	O
/	O
99	O
/	O
17	O
%	O
the	O
cases	O
for	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
REDDIT	I-MethodName
and	O
in	O
74	O
%	O
of	O
the	O
cases	O
for	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
CC	I-MethodName
.	O
For	O
the	O
model	O
that	O
was	O
not	O
conditioned	O
on	O
aspects	O
,	O
however	O
,	O
it	O
is	O
only	O
true	O
in	O
8	O
%	O
of	O
the	O
cases	O
.	O
It	O
clearly	O
shows	O
the	O
necessity	O
to	O
condition	O
the	O
model	O
on	O
aspects	O
explicitly	O
,	O
implying	O
the	O
need	O
for	O
argument	O
aspect	O
detection	O
,	O
as	O
the	O
model	O
is	O
unable	O
to	O
learn	O
generating	O
aspect	O
-	O
related	O
arguments	O
otherwise	O
.	O
Moreover	O
,	O
without	O
prior	O
detection	O
of	O
aspects	O
,	O
we	O
have	O
no	O
means	O
for	O
proper	O
aggregation	O
over	O
aspects	O
.	O
We	O
notice	O
that	O
for	O
the	O
model	O
without	O
prior	O
knowledge	O
of	O
aspects	O
,	O
79	O
%	O
of	O
all	O
aspects	O
in	O
the	O
training	O
data	O
appear	O
in	O
only	O
one	O
argument	O
.	O
For	O
these	O
aspects	O
,	O
the	O
model	O
will	O
likely	O
not	O
pick	O
up	O
a	O
strong	O
enough	O
signal	O
to	O
learn	O
them	O
.	O

As	O
shown	O
in	O
fig	O
.	O
6	O
,	O
updating	O
the	O
teacher	O
model	O
first	O
could	O
lead	O
to	O
a	O
lower	O
entropy	O
gap	O
and	O
faster	O
convergence	O
speed	O
.	O
We	O
assume	O
that	O
the	O
teacher	O
could	O
formulate	O
an	O
appropriate	O
'	O
teaching	O
plan	O
'	O
for	O
the	O
student	O
in	O
this	O
updating	O
order	O
.	O

Building	O
on	O
the	O
success	O
of	O
monolingual	O
pretrained	O
language	O
models	O
(	O
LM	O
)	O
such	O
as	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
their	O
multilingual	O
counterparts	O
mBERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
are	O
trained	O
using	O
the	O
same	O
objectives	O
-	O
Masked	O
Language	O
Modeling	O
(	O
MLM	O
)	O
and	O
in	O
the	O
case	O
of	O
mBERT	B-MethodName
,	O
Next	O
Sentence	I-MethodName
Prediction	I-MethodName
(	O
NSP	B-TaskName
)	O
.	O
MLM	O
is	O
applied	O
to	O
monolingual	O
text	O
that	O
covers	O
over	O
100	O
languages	O
.	O
Despite	O
the	O
absence	O
of	O
parallel	O
data	O
and	O
explicit	O
alignment	O
signals	O
,	O
these	O
models	O
transfer	O
surprisingly	O
well	O
from	O
high	O
resource	O
languages	O
,	O
such	O
as	O
English	O
,	O
to	O
other	O
languages	O
.	O
On	O
the	O
Natural	O
Language	O
Inference	O
(	O
NLI	O
)	O
task	O
XNLI	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
a	O
text	O
classification	O
model	O
trained	O
on	O
English	O
training	O
data	O
can	O
be	O
directly	O
applied	O
to	O
the	O
other	O
14	O
languages	O
and	O
achieve	O
respectable	O
performance	O
.	O
Having	O
a	O
single	O
model	O
that	O
can	O
serve	O
over	O
100	O
languages	O
also	O
has	O
important	O
business	O
applications	O
.	O

We	O
compare	O
Electric	O
against	O
GPT-2	B-MethodName
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
two	O
baseline	O
systems	O
that	O
are	O
bidirectional	O
while	O
only	O
requiring	O
a	O
single	O
transformer	O
pass	O
like	O
Electric	O
.	O
TwoTower	O
is	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
similar	O
to	O
Electric	O
's	O
noise	O
distribution	O
,	O
but	O
of	O
the	O
same	O
size	O
as	O
Electric	O
.	O
ELECTRA	B-MethodName
-	I-MethodName
TT	I-MethodName
is	O
identical	O
to	O
ELECTRA	O
except	O
it	O
uses	O
a	O
two	O
-	O
tower	O
noise	O
distribution	O
rather	O
than	O
a	O
masked	O
language	O
model	O
.	O
5	O
The	O
noise	O
distribution	O
probabilities	O
and	O
binary	O
classifiers	O
scores	O
of	O
ELECTRA	O
can	O
be	O
combined	O
to	O
assign	O
probabilities	O
for	O
tokens	O
as	O
shown	O
in	O
Appendix	O
G	O
of	O
the	O
ELECTRA	O
paper	O
.	O

In	O
terms	O
of	O
teacher	O
model	O
,	O
it	O
should	O
not	O
only	O
impart	O
their	O
current	O
knowledge	O
to	O
the	O
student	O
,	O
but	O
also	O
actively	O
seek	O
out	O
new	O
information	O
and	O
perspectives	O
to	O
improve	O
their	O
own	O
understanding	O
.	O
As	O
can	O
be	O
seen	O
in	O
fig	O
.	O
2	O
(	O
c	O
)	O
,	O
LGTM	B-MethodName
allows	O
for	O
the	O
effective	O
transfer	O
of	O
knowledge	O
from	O
the	O
teacher	O
model	O
by	O
incorporating	O
the	O
teacher	O
auxiliary	O
loss	O
.	O
The	O
validation	O
accuracy	O
of	O
the	O
teacher	O
model	O
keeps	O
improving	O
for	O
LGTM	O
,	O
but	O
drops	O
quickly	O
for	O
Meta	O
Distill	O
.	O

We	O
evaluate	O
the	O
sufficiency	O
of	O
translation	O
policy	O
on	O
RWTH	O
De→En	O
alignment	O
dataset	O
4	O
,	O
where	O
reference	O
alignments	O
are	O
annotated	O
by	O
experts	O
and	O
seen	O
as	O
golden	O
alignments	O
5	O
.	O
The	O
results	O
are	O
shown	O
in	O
Figure	O
5	O
.	O
The	O
oracle	O
policy	O
performs	O
better	O
than	O
other	O
methods	O
in	O
sufficiency	O
evaluation	O
and	O
can	O
even	O
cover	O
75	O
%	O
of	O
the	O
aligned	O
source	O
tokens	O
under	O
low	O
latency	O
.	O
Wait	O
-	O
k	O
policy	O
is	O
worse	O
than	O
our	O
oracle	O
policy	O
under	O
low	O
latency	O
because	O
it	O
may	O
be	O
forced	O
to	O
output	O
translation	O
before	O
reading	O
the	O
aligned	O
source	O
tokens	O
.	O
MMA	O
gets	O
the	O
worst	O
performance	O
in	O
sufficiency	O
evaluation	O
,	O

The	O
fine	O
-	O
tuning	O
on	O
the	O
CoNLL	B-DatasetName
dataset	O
significantly	O
improves	O
the	O
performance	O
on	O
this	O
dataset	O
(	O
Table	O
1	O
)	O
.	O
However	O
,	O
it	O
generally	O
degrades	O
the	O
performance	O
on	O
the	O
other	O
datasets	O
(	O
Table	O
2	O
)	O
.	O
This	O
suggests	O
that	O
Wikipedia	O
entity	O
annotations	O
are	O
more	O
suitable	O
than	O
the	O
CoNLL	B-DatasetName
dataset	O
to	O
train	O
generalpurpose	O
ED	O
models	O
.	O

The	O
version	O
of	O
deepQuest	O
for	O
multimodal	O
QE	O
and	O
scripts	O
to	O
convert	O
document	O
into	O
sentencelevel	O
data	O
are	O
available	O
on	O
https://github.com/	O
sheffieldnlp	O
/	O
deepQuest	O
.	O

Beyond	O
the	O
quantitative	O
evaluations	O
above	O
,	O
we	O
further	O
qualitatively	O
analyze	O
the	O
predictions	O
of	O
the	O
best	O
model	O
from	O
Table	O
3	O
to	O
provide	O
insights	O
into	O
our	O
modeling	O
decisions	O
and	O
suggest	O
avenues	O
for	O
improvements	O
.	O

Each	O
row	O
of	O
the	O
data	O
consists	O
of	O
the	O
German	O
source	O
sentence	O
,	O
its	O
reference	O
English	O
translation	O
(	O
it	O
is	O
not	O
always	O
accurate	O
!	O
)	O
,	O
and	O
1	O
to	O
4	O
machine	O
translation	O
outputs	O
.	O
The	O
machine	O
translation	O
outputs	O
are	O
presented	O
in	O
a	O
random	O
order	O
,	O
to	O
exclude	O
the	O
possibility	O
of	O
bias	O
toward	O
any	O
specific	O
method	O
.	O

The	O
task	O
of	O
coreference	O
resolution	O
is	O
to	O
find	O
all	O
textual	O
expressions	O
referring	O
to	O
the	O
same	O
real	O
-	O
world	O
entities	O
.	O
We	O
train	O
on	O
Ontonotes	O
5.0	O
(	O
Weischedel	O
et	O
al	O
.	O
,	O
2013	O
)	O
and	O
test	O
on	O
the	O
Winobias	O
challenge	O
dataset	O
(	O
Zhao	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Winobias	O
consists	O
of	O
sentence	O
pairs	O
,	O
pro	O
-	O
and	O
anti	O
-	O
stereotypical	O
variants	O
,	O
with	O
individuals	O
referred	O
to	O
by	O
their	O
profession	O
.	O
For	O
example	O
,	O
"	O
The	O
physician	O
hired	O
the	O
secretary	O
be-	O
cause	O
he	O
/	O
she	O
was	O
busy	O
.	O
"	O
is	O
pro	O
/	O
anti	O
-	O
stereotypical	O
,	O
based	O
on	O
US	O
labor	O
statistics	O
.	O
4	O
A	O
coreference	O
system	O
is	O
measured	O
by	O
the	O
performance	O
gap	O
between	O
the	O
pro	O
-	O
and	O
anti	O
-	O
stereotypical	O
subsets	O
.	O

Rolling	O
out	O
is	O
costly	O
for	O
very	O
long	O
sequences	O
,	O
and	O
the	O
question	O
of	O
its	O
usefulness	O
necessarily	O
arises	O
.	O
We	O
study	O
how	O
rolling	O
out	O
for	O
only	O
a	O
fixed	O
number	O
of	O
tokens	O
(	O
instead	O
of	O
until	O
the	O
end	O
of	O
the	O
sequence	O
)	O
influences	O
the	O
performance	O
of	O
PPL	B-MethodName
-	I-MethodName
MCTS	I-MethodName
.	O
For	O
this	O
experiment	O
,	O
we	O
use	O
the	O
CLS	O
dataset	O
and	O
set	O
the	O
roll	O
-	O
out	O
to	O
0	O
(	O
original	O
result	O
)	O
,	O
3	O
,	O
5	O
,	O
10	O
and	O
20	O
tokens	O
.	O
As	O
one	O
can	O
note	O
in	O
Fig	O
.	O
4	O
,	O
only	O
5	O
tokens	O
allows	O
PPL	B-MethodName
-	I-MethodName
MCTS	I-MethodName
to	O
be	O
on	O
par	O
with	O
GeDi	O
on	O
this	O
dataset	O
.	O

We	O
provide	O
details	O
on	O
the	O
fine	O
-	O
tuning	O
datasets	O
below	O
.	O
All	O
datasets	O
are	O
in	O
English	O
.	O
GLUE	O
data	O
can	O
be	O
downloaded	O
at	O
https://	O
gluebenchmark.com/	O
and	O
SQuAD	O
data	O
can	O
be	O
downloaded	O
at	O
https://rajpurkar	O
.	O
github.io/SQuAD-explorer/.	O

Table	O
1	O
shows	O
the	O
results	O
of	O
few	O
-	O
shot	O
text	O
classification	O
,	O
from	O
which	O
we	O
have	O
3	O
observations	O
.	O
First	O
,	O
among	O
the	O
baselines	O
with	O
770	O
M	O
parameters	O
,	O
simply	O
further	O
training	O
the	O
model	O
on	O
our	O
corpus	O
with	O
language	O
modeling	O
improves	O
the	O
performance	O
(	O
ExtraLM	O
)	O
.	O
This	O
is	O
likely	O
due	O
to	O
the	O
higher	O
domain	O
diversity	O
of	O
our	O
corpus	O
.	O
MetaICL	B-MethodName
is	O
helpful	O
on	O
most	O
datasets	O
,	O
which	O
verifies	O
the	O
effectiveness	O
of	O
meta	O
-	O
training	O
for	O
ICL	B-MethodName
.	O
Self	O
-	O
Sup	O
fails	O
to	O
bring	O
benefits	O
on	O
most	O
datasets	O
against	O
VanillaICL	B-MethodName
,	O
probably	O
because	O
the	O
constrained	O
label	O
space	O
of	O
the	O
Classification	O
training	O
task	O
(	O
only	O
contains	O
"	O
True	O
"	O
and	O
"	O
False	O
"	O
)	O
brings	O
bias	O
to	O
the	O
model	O
's	O
output	O
.	O
This	O
emphasizes	O
the	O
importance	O
of	O
using	O
training	O
objectives	O
with	O
little	O
bias	O
.	O

Recent	O
work	O
improves	O
upon	O
these	O
pretrained	O
models	O
by	O
adding	O
cross	O
-	O
lingual	O
tasks	O
leveraging	O
parallel	O
data	O
that	O
always	O
involve	O
English	O
.	O
Conneau	O
and	O
Lample	O
(	O
2019	O
)	O
pretrain	B-MethodName
a	O
new	O
Transformerbased	B-MethodName
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
model	O
from	O
scratch	O
with	O
an	O
MLM	O
objective	O
on	O
monolingual	O
data	O
,	O
and	O
a	O
Translation	O
Language	O
Modeling	O
(	O
TLM	O
)	O
objective	O
on	O
parallel	O
data	O
.	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
align	O
mBERT	B-MethodName
embeddings	O
in	O
a	O
post	O
-	O
hoc	O
manner	O
:	O
They	O
first	O
apply	O
a	O
statistical	O
toolkit	O
,	O
FastAlign	O
(	O
Dyer	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
to	O
create	O
word	O
alignments	O
on	O
parallel	O
sentences	O
.	O
Then	O
,	O
mBERT	B-MethodName
is	O
tuned	O
via	O
minimizing	O
the	O
mean	O
squared	O
error	O
between	O
the	O
embeddings	O
of	O
English	O
words	O
and	O
those	O
of	O
the	O
corresponding	O
words	O
in	O
other	O
languages	O
.	O
Such	O
post	O
-	O
hoc	O
approach	O
suffers	O
from	O
the	O
limitations	O
of	O
word	O
-	O
alignment	O
toolkits	O
:	O
(	O
1	O
)	O
the	O
noises	O
from	O
FastAlign	O
can	O
lead	O
to	O
error	O
propagation	O
to	O
the	O
rest	O
of	O
the	O
pipeline	O
;	O
(	O
2	O
)	O
FastAlign	O
mainly	O
creates	O
the	O
alignments	O
with	O
word	O
-	O
level	O
translation	O
and	O
usually	O
overlooks	O
the	O
contextual	O
semantic	O
compositions	O
.	O
As	O
a	O
result	O
,	O
the	O
tuned	O
mBERT	B-MethodName
is	O
biased	O
to	O
shallow	O
cross	O
-	O
lingual	O
correspondence	O
.	O
Importantly	O
,	O
both	O
approaches	O
only	O
involve	O
word	O
-	O
level	O
alignment	O
tasks	O
.	O

In	O
the	O
error	O
detection	O
problem	O
,	O
we	O
have	O
to	O
detect	O
data	O
points	O
with	O
wrong	O
labels	O
.	O
Given	O
a	O
(	O
potentially	O
noisy	O
)	O
dataset	O
Z	O
,	O
we	O
have	O
to	O
rank	O
data	O
points	O
in	O
Z	O
by	O
how	O
likely	O
they	O
are	O
erroneous	O
.	O
Removing	O
or	O
correcting	O
errors	O
improves	O
the	O
performance	O
and	O
robustness	O
of	O
models	O
trained	O
on	O
that	O
dataset	O
.	O

We	O
have	O
also	O
done	O
error	O
analysis	O
of	O
model	O
performance	O
on	O
original	O
Hindi	O
test	O
data	O
already	O
present	O
in	O
XNLI	B-DatasetName
and	O
data	O
obtained	O
through	O
translations	O
from	O
IndicTrans	O
in	O
Figure	O
3	O
(	O
Appendix	O
)	O
.	O
We	O
observe	O
a	O
total	O
of	O
82	O
%	O
overlap	O
in	O
error	O
consistency	O
,	O
3	O
Further	O
Analysis	O
in	O
appendix	O
§	O
F	O
and	O
we	O
observe	O
that	O
the	O
greatest	O
number	O
of	O
correct	O
overlaps	O
is	O
for	O
the	O
entailment	O
label	O
,	O
whereas	O
the	O
greatest	O
number	O
of	O
incorrect	O
predictions	O
is	O
for	O
the	O
contradiction	O
label	O
.	O
We	O
see	O
the	O
maximum	O
overlap	O
in	O
neutral	O
prediction	O
and	O
the	O
least	O
overlap	O
in	O
contradiction	O
prediction	O
in	O
terms	O
of	O
consistency	O
.	O
This	O
demonstrates	O
that	O
the	O
model	O
performs	O
identically	O
on	O
both	O
the	O
original	O
Hindi	O
data	O
and	O
the	O
machinetranslated	O
Hindi	O
data	O
,	O
bolstering	O
the	O
legitimacy	O
of	O
our	O
dataset	O
.	O

Moreover	O
,	O
some	O
advanced	O
techniques	O
are	O
proposed	O
to	O
improve	O
embedding	O
models	O
,	O
such	O
as	O
graph	O
encoders	O
(	O
Schlichtkrull	O
et	O
al	O
.	O
,	O
2018	O
;	O
Shang	O
et	O
al	O
.	O
,	O
2019	O
;	O
Vashishth	O
et	O
al	O
.	O
,	O
2020	O
;	O
and	O
regularizers	O
(	O
Lacroix	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
Note	O
that	O
our	O
proposals	O
are	O
orthogonal	O
to	O
these	O
techniques	O
,	O
and	O
one	O
can	O
integrate	O
them	O
for	O
better	O
performance	O
.	O

7	O
Tes	O
Bahasa	O
Indonesia	O
sebagai	O
Bahasa	O
Asing	O
(	O
https	O
:	O
/	O
/	O
lbifib.ui.ac.id	O
/	O
archives	O
/	O
105	O
)	O
We	O
use	O
TOPIK	O
8	O
for	O
Korean	O
,	O
UKBI	O
9	O
and	O
BIPA	O
10	O
for	O
Indonesian	O
,	O
and	O
TOEIC	O
11	O
and	O
GRE	O
12	O
for	O
English	O
.	O
We	O
chose	O
nouns	O
and	O
verbs	O
from	O
annotation	O
questions	O
and	O
created	O
multiple	O
-	O
choice	O
questions	O
whose	O
answers	O
are	O
the	O
nouns	O
or	O
the	O
verbs	O
in	O
the	O
annotation	O
questions	O
.	O

where	O
x	O
k	O
is	O
the	O
value	O
of	O
the	O
neuron	O
k	O
,	O
g	O
is	O
a	O
nonlinear	O
activation	O
function	O
,	O
w	O
jk	O
and	O
b	O
k	O
are	O
weights	O
and	O
bias	O
in	O
the	O
network	O
,	O
respectively	O
.	O
We	O
can	O
see	O
that	O
the	O
contribution	O
of	O
a	O
single	O
node	O
j	O
to	O
the	O
value	O
of	O
the	O
node	O
k	O
is	O

To	O
compare	O
the	O
model	O
-	O
level	O
performance	O
of	O
evaluation	O
methods	O
,	O
we	O
leverage	O
two	O
ad	O
-	O
hoc	O
training	O
schema	O
to	O
synthesize	O
a	O
series	O
of	O
models	O
with	O
different	O
capability	O
ranks	O
.	O
Then	O
,	O
the	O
evaluation	O
methods	O
are	O
used	O
to	O
predict	O
the	O
ranking	O
of	O
trained	O
models	O
.	O
Seven	O
non	O
-	O
factual	O
and	O
factual	O
evaluation	O
methods	O
have	O
been	O
examined	O
,	O
followed	O
by	O
a	O
detailed	O
discussion	O
of	O
their	O
properties	O
.	O
The	O
effectiveness	O
of	O
FacEval	B-MethodName
is	O
also	O
proven	O
by	O
showing	O
a	O
strong	O
correlation	O
with	O
the	O
factual	O
correctness	O
of	O
summarization	O
models	O
.	O

x	O
⇒	O
⟨aspect⟩	O
a	O
⟨opinion⟩	O
o	O
ASTE	O
:	O

Datasets	O
.	O
We	O
conduct	O
experiments	O
on	O
English	O
-	O
Macedonian	O
(	O
En	O
-	O
Mk	O
)	O
and	O
English	O
-	O
Albanian	O
(	O
En	O
-	O
Sq	O
)	O
,	O
as	O
Mk	O
,	O
Sq	O
are	O
low	O
-	O
resource	O
languages	O
,	O
where	O
lexical	O
-	O
level	O
alignment	O
can	O
be	O
most	O
beneficial	O
.	O
We	O
use	O
3	O
K	O
randomly	O
sampled	O
sentences	O
of	O
SETIMES	O
(	O
Tiedemann	O
,	O
2012	O
)	O
as	O
validation	O
/	O
test	O
sets	O
.	O
We	O
also	O
use	O
68	O
M	O
En	O
sentences	O
from	O
NewsCrawl	O
.	O
For	O
Sq	O
and	O
Mk	O
we	O
use	O
all	O
the	O
CommonCrawl	O
corpora	O
from	O
Ortiz	O
Suárez	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
are	O
4	O
M	O
Sq	O
and	O
2.4	O
M	O
Mk	O
sentences	O
.	O

Is	O
our	O
query	O
q	O
effective	O
?	O
To	O
answer	O
this	O
question	O
,	O
we	O
conduct	O
experiments	O
with	O
three	O
types	O
of	O
queries	O
.	O
The	O
first	O
is	O
the	O
regular	O
query	O
adopted	O
in	O
our	O
COM	O
-	I-MethodName
MRC	I-MethodName
.	O
The	O
second	O
is	O
an	O
improper	O
query	O
by	O
removing	O
the	O
keyword	O
"	O
first	O
"	O
.	O
The	O
third	O
is	O
null	O
which	O
means	O
no	O
query	O
is	O
provided	O
.	O
The	O
experimental	O
re-	O
sults	O
are	O
reported	O
in	O
Table	O
9	O
.	O
The	O
performance	O
of	O
the	O
improper	O
query	O
decreases	O
by	O
a	O
mean	O
1.26	O
%	O
.	O
Compared	O
with	O
the	O
improper	O
query	O
,	O
a	O
null	O
query	O
drops	O
much	O
more	O
with	O
a	O
mean	O
decrement	O
of	O
2.60	O
%	O
.	O
This	O
shows	O
the	O
effectiveness	O
of	O
our	O
query	O
.	O

•	O
hash	O
:	O
Unique	O
identifier	O
.	O

We	O
represent	O
a	O
student	O
as	O
a	O
temporally	O
-	O
evolving	O
sequence	O
of	O
questions	O
and	O
their	O
responses	O
.	O
As	O
in	O
much	O
previous	O
KT	O
work	O
,	O
we	O
represent	O
the	O
student	O
response	O
as	O
simply	O
correct	O
/	O
incorrect	O
,	O
with	O
special	O
tokens	O
<	O
Y	O
>	O
and	O
<	O
N	O
>	O
.	O
A	O
student	O
's	O
current	O
state	O
is	O
thus	O
represented	O
as	O
a	O
sequence	O
of	O
all	O
past	O
question	O
and	O
response	O
pairs	O
:	O

We	O
now	O
consider	O
the	O
second	O
case	O
:	O
Suppose	O
we	O
have	O
a	O
cipher	O
and	O
a	O
key	O
,	O
but	O
the	O
cipher	O
is	O
nondeterministic	O
.	O
This	O
case	O
can	O
arise	O
in	O
practice	O
when	O
the	O
key	O
of	O
the	O
cipher	O
is	O
found	O
while	O
combing	O
through	O
historical	O
archives	O
,	O
for	O
example	O
.	O
Alternatively	O
,	O
the	O
key	O
could	O
have	O
been	O
found	O
by	O
a	O
cryptanalyst	O
by	O
solving	O
a	O
part	O
of	O
the	O
cipher	O
.	O
Although	O
the	O
cipher	O
key	O
exists	O
in	O
these	O
scenarios	O
,	O
the	O
nondeterministic	O
segmentation	O
makes	O
it	O
impossible	O
to	O
directly	O
apply	O
the	O
key	O
to	O
recover	O
the	O
plaintext	O
;	O
recall	O
the	O
ambiguous	O
segmentation	O
example	O
of	O
the	O
word	O
and	O
from	O
Section	O
2.4	O
.	O
In	O
this	O
case	O
,	O
it	O
is	O
very	O
challenging	O
to	O
manually	O
recover	O
the	O
whole	O
plaintext	O
,	O
especially	O
when	O
the	O
cipher	O
is	O
very	O
long	O
.	O

We	O
propose	O
a	O
new	O
global	O
ED	O
model	O
based	O
on	O
BERT	B-MethodName
.	O

However	O
,	O
controllable	O
argument	O
generation	O
can	O
also	O
be	O
used	O
to	O
support	O
finding	O
and	O
formulating	O
(	O
counter-)arguments	O
for	O
debates	O
,	O
for	O
writing	O
essays	O
,	O
to	O
enrich	O
one	O
-	O
sided	O
discussions	O
,	O
and	O
thus	O
,	O
to	O
make	O
discourse	O
more	O
diverse	O
overall	O
.	O
For	O
instance	O
,	O
anticipating	O
opposing	O
arguments	O
is	O
crucial	O
for	O
critical	O
thinking	O
,	O
which	O
is	O
the	O
foundation	O
for	O
any	O
democratic	O
society	O
.	O
The	O
skill	O
is	O
extensively	O
taught	O
in	O
school	O
and	O
university	O
education	O
.	O
However	O
,	O
confirmation	O
bias	O
(	O
or	O
myside	O
bias	O
)	O
(	O
Stanovich	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
i.e.	O
the	O
tendency	O
to	O
ignore	O
opposing	O
arguments	O
,	O
is	O
an	O
ever	O
-	O
present	O
issue	O
.	O
Technologies	O
like	O
ours	O
could	O
be	O
used	O
to	O
mitigate	O
this	O
issue	O
by	O
,	O
for	O
instance	O
,	O
automatically	O
providing	O
topic	O
-	O
and	O
aspectspecific	O
counter	O
-	O
arguments	O
for	O
all	O
arguments	O
of	O
a	O
given	O
text	O
(	O
this	O
has	O
been	O
shown	O
for	O
single	O
arguments	O
in	O
Section	O
7.2	O
)	O
.	O
We	O
believe	O
that	O
working	O
on	O
and	O
providing	O
access	O
to	O
such	O
models	O
is	O
of	O
major	O
importance	O
and	O
,	O
overall	O
,	O
a	O
benefit	O
to	O
society	O
.	O

Data	O
Privacy	O
and	O
Bias	O
:	O
This	O
research	O
mainly	O
focuses	O
on	O
translation	O
using	O
the	O
Europarl	O
(	O
Koehn	O
,	O
2005	O
)	O
corpus	O
,	O
which	O
is	O
widely	O
adopted	O
in	O
the	O
community	O
.	O
There	O
are	O
no	O
data	O
privacy	O
issues	O
or	O
bias	O
against	O
certain	O
demographics	O
with	O
regard	O
to	O
this	O
dataset	O
.	O

We	O
evaluated	O
the	O
generality	O
and	O
effectiveness	O
of	O
our	O
approach	O
on	O
the	O
large	O
-	O
scale	O
DocRED	B-MethodName
dataset	O
.	O
Experimental	O
results	O
show	O
that	O
the	O
proposed	O
approach	O
combines	O
well	O
with	O
various	O
recent	O
DocRE	B-MethodName
models	O
and	O
significantly	O
improves	O
the	O
performance	O
.	O
We	O
further	O
evaluated	O
our	O
approach	O
on	O
a	O
dialogue	O
relation	O
extraction	O
dataset	O
,	O
DialogRE	B-MethodName
(	O
Yu	O
et	O
al	O
.	O
,	O
2020	O
)	O
;	O
our	O
SIEF	B-MethodName
yields	O
consistent	O
improvement	O
,	O
showing	O
the	O
generality	O
of	O
our	O
approach	O
in	O
different	O
domains	O
.	O

m=1	O
are	O
retrieved	O
based	O
on	O
certain	O
criterion	O
C	O
and	O
NMT	B-TaskName
models	O
the	O
conditional	O
probability	O
of	O
target	O
sentence	O
y	O
conditioned	O
on	O
both	O
source	O
sentence	O
x	O
and	O
translation	O
memories	O
M	O
in	O
a	O
left	O
-	O
to	O
-	O
right	O
manner	O
:	O

We	O
now	O
use	O
the	O
scalar	O
mixes	O
of	O
the	O
role	O
labeling	O
probes	O
as	O
target	O
tasks	O
,	O
and	O
lower	O
-	O
level	O
probes	O
as	O
anchor	O
tasks	O
to	O
qualitatively	O
explore	O
the	O
differences	O
between	O
how	O
our	O
role	O
probes	O
learn	O
to	O
represent	O
predicates	O
and	O
semantic	O
arguments	O
5	O
(	O
Fig	O
.	O
3	O
)	O
.	O
The	O
results	O
reveal	O
a	O
distinctive	O
pattern	O
that	O
confirms	O
our	O
previous	O
observations	O
:	O
while	O
Verb	O
-	O
Net	O
and	O
FrameNet	O
predicate	O
layer	O
utilization	O
src	O
is	O
similar	O
to	O
the	O
scalar	O
mixes	O
learned	O
for	O
ttype	O
and	O
lex.unit	O
,	O
the	O
learned	O
argument	O
representations	O
tgt	O
and	O
the	O
PropBank	B-MethodName
predicate	O
attend	O
to	O
the	O
layers	O
associated	O
with	O
dependency	O
relation	O
and	O
POS	O
probes	O
.	O
Aside	O
from	O
the	O
PropBank	B-MethodName
predicate	O
encoding	O
which	O
we	O
address	O
below	O
,	O
the	O
pattern	O
reproduces	O
for	O
English	O
and	O
German	O
.	O
This	O
aligns	O
with	O
the	O
traditional	O
separation	O
of	O
the	O
semantic	O
role	O
labeling	O
task	O
into	O
predicate	O
disambiguation	O
followed	O
by	O
semantic	O
argument	O
identification	O
and	O
labeling	O
,	O
along	O
with	O
the	O
feature	O
sets	O
employed	O
for	O
these	O
tasks	O
(	O
Björkelund	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
Note	O
that	O
the	O
observation	O
about	O
the	O
pipeline	O
-	O
like	O
task	O
processing	O
within	O
the	O
BERT	B-MethodName
encoders	O
thereby	O
holds	O
,	O
albeit	O
on	O
a	O
sub	O
-	O
task	O
level	O
.	O

Moreover	O
,	O
we	O
observe	O
that	O
a	O
DocRE	B-MethodName
model	O
,	O
trained	O
on	O
the	O
entire	O
document	O
,	O
may	O
err	O
when	O
non	O
-	O
evidence	O
sentences	O
are	O
removed	O
.	O
In	O
Figure	O
1	O
,	O
for	O
example	O
,	O
we	O
need	O
to	O
identify	O
the	O
relation	O
"	O
MemberOf	O
"	O
between	O
the	O
entities	O
Brad	O
Wilk	O
and	O
Rage	O
Against	O
the	O
Machine	O
.	O
The	O
evidence	O
sentences	O
are	O
{	O
1,2	O
}	O
,	O
and	O
humans	O
can	O
easily	O
identify	O
such	O
a	O
relation	O
when	O
reading	O
sentences	O
{	O
1,2	O
}	O
only	O
.	O
However	O
,	O
the	O
recent	O
DocRE	B-MethodName
model	O
GAIN	O
identifies	O
the	O
relation	O
"	O
MemberOf	O
"	O
correctly	O
from	O
the	O
entire	O
document	O
{	O
1,2,3	O
}	O
,	O
but	O
predicts	O
"	O
not	O
MemberOf	O
"	O
from	O
sentences	O
{	O
1,2	O
}	O
.	O
Intuitively	O
,	O
removing	O
sentence	O
{	O
3	O
}	O
should	O
not	O
change	O
the	O
result	O
,	O
as	O
this	O
sentence	O
does	O
not	O
provide	O
information	O
regarding	O
whether	O
"	O
MemberOf	O
"	O
holds	O
or	O
not	O
for	O
the	O
two	O
entities	O
.	O
Such	O
model	O
behaviors	O
are	O
undesired	O
,	O
because	O
it	O
shows	O
that	O
the	O
model	O
is	O
not	O
robust	O
and	O
lacks	O
interpretability	O
.	O

We	O
focus	O
on	O
reducing	O
gender	O
bias	O
of	O
CNN	O
models	O
trained	O
on	O
two	O
datasets	O
-Biosbias	O
(	O
De	O
-	O
Arteaga	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Waseem	O
(	O
Waseem	O
and	O
Hovy	O
,	O
2016	O
)	O
.	O
For	O
Biosbias	O
,	O
the	O
task	O
is	O
predicting	O
the	O
occupation	O
of	O
a	O
given	O
bio	O
paragraph	O
,	O
i.e.	O
,	O
whether	O
the	O
person	O
is	O
'	O
a	O
surgeon	O
'	O
(	O
class	O
0	O
)	O
or	O
'	O
a	O
nurse	O
'	O
(	O
class	O
1	O
)	O
.	O
Due	O
to	O
the	O
gender	O
imbalance	O
in	O
each	O
occupation	O
,	O
a	O
classifier	O
usually	O
exploits	O
gender	O
information	O
when	O
making	O
predictions	O
.	O
As	O
a	O
result	O
,	O
bios	O
of	O
female	O
surgeons	O
and	O
male	O
nurses	O
are	O
often	O
misclassified	O
.	O
For	O
Waseem	O
,	O
the	O
task	O
is	O
abusive	O
language	O
detection	O
-assessing	O
if	O
a	O
given	O
text	O
is	O
abusive	O
(	O
class	O
1	O
)	O
or	O
not	O
abusive	O
(	O
class	O
0	O
)	O
.	O
Previous	O
work	O
found	O
that	O
this	O
dataset	O
contains	O
a	O
strong	O
negative	O
bias	O
against	O
females	O
(	O
Park	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
In	O
other	O
words	O
,	O
texts	O
related	O
to	O
females	O
are	O
usually	O
classified	O
as	O
abusive	O
although	O
the	O
texts	O
themselves	O
are	O
not	O
abusive	O
at	O
all	O
.	O
Also	O
,	O
we	O
tested	O
the	O
models	O
,	O
trained	O
on	O
the	O
Waseem	O
dataset	O
,	O
using	O
another	O
abusive	O
language	O
detection	O
dataset	O
,	O
Wikitoxic	O
(	O
Thain	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
to	O
assess	O
generalizability	O
of	O
the	O
models	O
.	O
To	O
quantify	O
gender	O
biases	O
,	O
we	O
adopted	O
two	O
metrics	O
-false	O
positive	O
equality	O
difference	O
(	O
FPED	O
)	O
and	O
false	O
negative	O
equality	O
difference	O
(	O
FNED	O
)	O
(	O
Dixon	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

Hyperparameters	O
and	O
training	O
.	O
The	O
BiLSTM	O
models	O
are	O
trained	O
with	O
the	O
Adam	B-MethodName
optimizer	O
(	O
Kingma	O
and	O
Ba	O
,	O
2015	O
)	O
with	O
a	O
learning	O
rate	O
of	O
1e-3	O
.	O
For	O
fine	O
-	O
tuning	O
the	O
original	O
BERT	B-MethodName
models	O
,	O
we	O
follow	O
the	O
configuration	O
published	O
by	O
Wolf	O
et	O
al	O
.	O
(	O
2019	O
)	O
and	O
use	O
AdamW	O
(	O
Loshchilov	O
and	O
Hutter	O
,	O
2019	O
)	O
as	O
optimizer	O
and	O
a	O
learning	O
rate	O
of	O
4e-7	O
for	O
sentence	O
classification	O
and	O
1e-5	O
for	O
sequence	O
tagging	O
.	O
When	O
adding	O
BERT	B-MethodName
tokens	O
to	O
the	O
BiLSTM	O
,	O
we	O
also	O
use	O
the	O
AdamW	B-MethodName
optimizer	O
for	O
the	O
whole	O
model	O
and	O
learning	O
rates	O
of	O
4e-7	O
or	O
1e-5	O
for	O
the	O
BERT	B-MethodName
part	O
and	O
1e-3	O
for	O
the	O
remainder	O
.	O
For	O
regularization	O
,	O
we	O
employ	O
early	O
stopping	O
on	O
the	O
development	O
set	O
.	O
We	O
use	O
a	O
stacked	O
BiLSTM	O
with	O
two	O
hidden	O
layers	O
and	O
500	O
hidden	O
units	O
for	O
all	O
tasks	O
with	O
the	O
exception	O
of	O
the	O
experiment	O
sentence	O
de-	O
tection	O
task	O
,	O
where	O
we	O
found	O
one	O
BiLSTM	O
layer	O
to	O
work	O
best	O
.	O
The	O
attention	O
layer	O
of	O
the	O
sentence	O
detection	O
model	O
has	O
a	O
hidden	O
size	O
of	O
100	O
.	O

The	O
destruction	O
of	O
a	O
President	O
with	O
its	O
collapse	O
of	O
executive	O
authority	O
was	O
too	O
staggering	O
to	O
contemplate	O
.	O

U	O
:	O
What	O
about	O
a	O
skirt	O
to	O
go	O
with	O
the	O
grey	O
jacket	O
in	O
front	O
of	O
me	O
?	O

Hyperparameters	O
.	O
We	O
fine	O
-	O
tune	O
all	O
of	O
our	O
NMT	B-TaskName
models	O
for	O
4	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
4	O
and	O
a	O
warmup	O
rate	O
of	O
0.2	O
.	O
To	O
avoid	O
over	O
-	O
fitting	O
,	O
we	O
set	O
the	O
early	O
stopping	O
patience	O
on	O
the	O
validation	O
set	O
as	O
2	O
.	O
In	O
the	O
context	O
construction	O
,	O
we	O
randomly	O
select	O
5	O
cell	O
values	O
for	O
each	O
target	O
column	O
.	O
The	O
Adam	O
optimizer	O
(	O
Kingma	O
and	O
Ba	O
,	O
2015	O
)	O
with	O
ß1	O
=	O
0.9	O
,	O
ß2	O
=	O
0.99	O
and	O
✏	O
=	O
1e-8	O
is	O
adopted	O
.	O
We	O
set	O
the	O
number	O
of	O
relation	O
-	O
aware	O
layers	O
as	O
2	O
,	O
and	O
we	O
set	O
the	O
learning	O
rate	O
of	O
the	O
decoder	O
and	O
the	O
relational	O
aware	O
layers	O
as	O
3e-5	O
,	O
and	O
decrease	O
the	O
learning	O
rate	O
of	O
the	O
Transformer	B-MethodName
encoder	O
to	O
4	O
times	O
and	O
8	O
times	O
smaller	O
for	O
M2M-100	B-DatasetName
and	O
MBart-50M2	B-DatasetName
M	O
respectively	O
.	O

For	O
our	O
work	O
,	O
we	O
consider	O
the	O
source	O
and	O
target	O
languages	O
as	O
the	O
X	O
to	O
Z	O
domains	O
to	O
be	O
aligned	O
.	O
Each	O
training	O
sample	O
corresponds	O
to	O
a	O
data	O
point	O
in	O
a	O
distribution	O
and	O
is	O
represented	O
by	O
its	O
sentencelevel	O
encoding	O
h	O
_	O
0	O
.	O
Following	O
prior	O
work	O
(	O
Pouran	O
Ben	O
Veyseh	O
and	O
Nguyen	O
,	O
2022	O
)	O
,	O
we	O
estimate	O
probability	O
distributions	O
P	O
(	O
x	O
)	O
and	O
P	O
(	O
z	O
)	O
using	O
a	O
singlelayer	O
FFNN	O
and	O
use	O
Euclidean	O
distance	O
as	O
the	O
cost	O
function	O
:	O

(	O
1	O
)	O
R2	O
:	O
Home	O
State	O
.	O
We	O
connect	O
political	O
actors	O
with	O
their	O
home	O
states	O
with	O
R2	O
:	O

Our	O
goal	O
is	O
to	O
construct	O
a	O
large	O
-	O
scale	O
and	O
generalpurpose	O
dataset	O
for	O
extracting	O
hyper	O
-	O
relational	O
facts	O
from	O
natural	O
language	O
text	O
.	O
However	O
,	O
it	O
is	O
seldom	O
practical	O
to	O
assume	O
to	O
have	O
an	O
ample	O
amount	O
of	O
high	O
-	O
quality	O
labeled	O
samples	O
in	O
real	O
applications	O
,	O
especially	O
for	O
complex	O
tasks	O
such	O
as	O
information	O
extraction	O
.	O
Hence	O
,	O
we	O
propose	O
a	O
weakly	O
supervised	O
(	O
Craven	O
and	O
Kumlien	O
,	O
1999	O
)	O
data	O
setting	O
which	O
enables	O
us	O
to	O
collect	O
a	O
larger	O
and	O
more	O
diverse	O
training	O
set	O
than	O
would	O
be	O
otherwise	O
possible	O
.	O
To	O
minimize	O
the	O
effect	O
of	O
noisy	O
samples	O
in	O
evaluation	O
,	O
we	O
then	O
perform	O
human	O
annotation	O
for	O
a	O
portion	O
of	O
the	O
collected	O
data	O
and	O
allocate	O
it	O
as	O
the	O
held	O
-	O
out	O
set	O
.	O
In	O
the	O
following	O
sections	O
,	O
we	O
first	O
introduce	O
the	O
process	O
of	O
collecting	O
the	O
distantly	O
supervised	O
data	O
,	O
followed	O
by	O
the	O
human	O
-	O
annotated	O
data	O
portion	O
.	O

where	O
dz	O
)	O
.	O
Shaw	O
et	O
al	O
.	O
(	O
2018	O
)	O
proposes	O
an	O
extension	O
to	O
selfattention	O
to	O
consider	O
the	O
pairwise	O
relationships	O
between	O
input	O
tokens	O
by	O
changing	O
Equation	O
(	O
1	O
)	O
as	O
follows	O
:	O

Then	O
we	O
disabled	O
features	O
based	O
on	O
their	O
average	O
quality	O
scores	O
.	O
The	O
assumption	O
was	O
:	O
if	O
the	O
scores	O
of	O
the	O
disabled	O
features	O
correlated	O
with	O
the	O
drop	O
in	O
the	O
model	O
predictive	O
performance	O
,	O
it	O
meant	O
that	O
humans	O
could	O
understand	O
and	O
accurately	O
assess	O
CNN	O
features	O
using	O
word	O
clouds	O
.	O
We	O
used	O
small	O
training	O
datasets	O
so	O
that	O
the	O
trained	O
CNNs	B-MethodName
had	O
features	O
with	O
different	O
levels	O
of	O
quality	O
.	O
Some	O
features	O
detected	O
useful	O
patterns	O
,	O
while	O
others	O
overfitted	O
the	O
training	O
data	O
.	O

The	O
detailed	O
annotation	O
results	O
are	O
shown	O
in	O
Figure	O
1	O
.	O
There	O
are	O
several	O
exciting	O
findings	O
:	O
1	O
)	O
the	O
human	O
annotations	O
contain	O
non	O
-	O
negligible	O
factual	O
errors	O
at	O
around	O
17	O
%	O
;	O
2	O
)	O
36	O
%	O
to	O
50	O
%	O
of	O
generated	O
summaries	O
from	O
dialogue	O
summarization	O
models	O
contain	O
at	O
least	O
one	O
factual	O
error	O
;	O
3	O
)	O
three	O
advanced	O
dialogue	O
summarization	O
models	O
perform	O
worse	O
than	O
their	O
baseline	O
on	O
factual	O
consistency	O
.	O

The	O
optimal	O
policy	O
ensures	O
that	O
the	O
SiMT	B-MethodName
model	O
gets	O
good	O
latency	O
-	O
quality	O
trade	O
-	O
offs	O
(	O
Iranzo	O
-	O
Sánchez	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
The	O
translation	O
model	O
plays	O
a	O
key	O
role	O
in	O
searching	O
for	O
the	O
optimal	O
policy	O
by	O
identifying	O
the	O
number	O
of	O
source	O
tokens	O
to	O
be	O
read	O
,	O
maximizing	O
the	O
gain	O
for	O
the	O
current	O
translation	O
.	O
However	O
,	O
considering	O
all	O
possible	O
numbers	O
of	O
source	O
tokens	O
for	O
each	O
target	O
token	O
would	O
be	O
computationally	O
expensive	O
and	O
may	O
not	O
effectively	O
balance	O
latency	O
and	O
translation	O
quality	O
(	O
Zhang	O
and	O
Feng	O
,	O
2023b	O
)	O
.	O
To	O
address	O
this	O
issue	O
,	O
we	O
employ	O
binary	O
search	O
to	O
determine	O
the	O
ideal	O
number	O
of	O
source	O
tokens	O
to	O
be	O
read	O
for	O
each	O
target	O
token	O
by	O
evaluating	O
the	O
midpoint	O
concavity	O
of	O
the	O
interval	O
.	O

To	O
make	O
the	O
relevance	O
propagation	O
more	O
stable	O
,	O
we	O
add	O
a	O
small	O
positive	O
number	O
(	O
as	O
a	O
stabilizer	O
)	O
to	O
the	O
denominator	O
of	O
the	O
propagation	O
rule	O
:	O

In	O
-	O
context	O
learning	O
,	O
as	O
first	O
proposed	O
by	O
Brown	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
is	O
a	O
straightforward	O
parameter	O
-	O
free	O
approach	O
,	O
where	O
the	O
downstream	O
task	O
of	O
interest	O
is	O
expressed	O
as	O
natural	O
text	O
demonstrations	O
and	O
used	O
to	O
conditionally	O
generate	O
from	O
a	O
language	O
model	O
.	O
Recently	O
,	O
Min	O
et	O
al	O
.	O
(	O
2022a	O
)	O
proposed	O
Noisy	O
Channel	O
(	O
denoted	O
as	O
Channel	O
)	O
that	O
exploits	O
the	O
language	O
generation	O
capability	O
of	O
language	O
models	O
for	O
discriminative	O
tasks	O
using	O
the	O
Bayes	O
'	O
Theorem	O
.	O
We	O
compare	O
the	O
two	O
ICL	O
methods	O
on	O
all	O
three	O
(	O
sensitivity	O
,	O
GLER	B-MetricName
,	O
and	O
the	O
ground	O
-	O
truth	O
label	O
ICL	B-TaskName
accuracy	O
)	O
measures	O
.	O

As	O
explained	O
earlier	O
,	O
we	O
want	O
to	O
know	O
whether	O
the	O
learned	O
features	O
are	O
valid	O
and	O
relevant	O
to	O
the	O
classification	O
task	O
and	O
whether	O
or	O
not	O
they	O
get	O
appropriate	O
weights	O
from	O
the	O
next	O
layer	O
.	O
This	O
is	O
possible	O
by	O
letting	O
humans	O
consider	O
the	O
word	O
cloud(s	O
)	O
of	O
each	O
feature	O
and	O
tell	O
us	O
which	O
class	O
the	O
feature	O
is	O
relevant	O
to	O
.	O
A	O
word	O
cloud	O
receiving	O
human	O
answers	O
that	O
are	O
different	O
from	O
the	O
class	O
it	O
should	O
support	O
(	O
as	O
indicated	O
by	O
W	O
)	O
exhibits	O
a	O
flaw	O
in	O
the	O
model	O
.	O
For	O
example	O
,	O
if	O
the	O
word	O
cloud	O
in	O
Figure	O
2	O
represents	O
the	O
feature	O
f	O
i	O
in	O
a	O
sentiment	O
analysis	O
task	O
but	O
the	O
i	O
th	O
column	O
of	O
W	O
implies	O
that	O
f	O
i	O
supports	O
the	O
negative	O
sentiment	O
class	O
,	O
we	O
know	O
the	O
model	O
is	O
not	O
correct	O
here	O
.	O
If	O
this	O
word	O
cloud	O
appears	O
in	O
a	O
product	O
categorization	O
task	O
,	O
this	O
is	O
also	O
problematic	O
because	O
the	O
phrases	O
in	O
the	O
word	O
cloud	O
are	O
not	O
discriminative	O
of	O
any	O
product	O
category	O
.	O
Hence	O
,	O
we	O
provide	O
options	O
for	O
the	O
users	O
to	O
disable	O
the	O
features	O
which	O
correspond	O
to	O
any	O
problematic	O
word	O
clouds	O
so	O
that	O
the	O
features	O
do	O
not	O
play	O
a	O
role	O
in	O
the	O
classification	O
.	O
To	O
enable	O
this	O
to	O
happen	O
,	O
we	O
modify	O
M	O
c	O
to	O
be	O
M	O
c	O
where	O
p	O
=	O
M	O
c	O
(	O
f	O
)	O
=	O
softmax((W	O
Q)f	O
+	O
b	O
)	O
and	O
Q	O
∈	O
R	O
|C|×d	O
is	O
a	O
masking	O
matrix	O
with	O
being	O
an	O
element	O
-	O
wise	O
multiplication	O
operator	O
.	O
Initially	O
,	O
all	O
elements	O
in	O
Q	O
are	O
ones	O
which	O
enable	O
all	O
the	O
connections	O
between	O
the	O
features	O
and	O
the	O
output	O
.	O
To	O
disable	O
feature	O
f	O
i	O
,	O
we	O
set	O
the	O
i	O
th	O
column	O
of	O
Q	O
to	O
be	O
a	O
zero	O
vector	O
.	O
After	O
disabling	O
features	O
,	O
we	O
then	O
freeze	O
the	O
parameters	O
of	O
M	O
f	O
and	O
fine	O
-	O
tune	O
the	O
parameters	O
of	O
M	O
c	O
(	O
except	O
the	O
masking	O
matrix	O
Q	O
)	O
with	O
the	O
original	O
training	O
dataset	O
D	O
in	O
the	O
final	O
step	O
.	O

We	O
thank	O
John	O
Hewitt	O
,	O
Yuhao	O
Zhang	O
,	O
Ashwin	O
Paranjape	O
,	O
Sergey	O
Levine	O
,	O
and	O
the	O
anonymous	O
reviewers	O
for	O
their	O
thoughtful	O
comments	O
and	O
suggestions	O
.	O
Kevin	O
is	O
supported	O
by	O
a	O
Google	O
PhD	O
Fellowship	O
.	O

As	O
described	O
in	O
Section	O
2	O
,	O
the	O
data	O
set	O
curated	O
by	O
Mysore	O
et	O
al	O
.	O
(	O
2019	O
)	O
contains	O
230	O
synthesis	O
procedures	O
annotated	O
with	O
entity	O
type	O
information	O
.	O
11	O
We	O
apply	O
our	O
models	O
to	O
this	O
entity	O
extraction	O
task	O
in	O
order	O
to	O
estimate	O
the	O
degree	O
of	O
transferability	O
of	O
our	O
findings	O
to	O
similar	O
data	O
sets	O
.	O
To	O
the	O
best	O
of	O
11	O
our	O
knowledge	O
,	O
there	O
have	O
not	O
yet	O
been	O
any	O
publications	O
on	O
the	O
automatic	O
modeling	O
of	O
this	O
data	O
set	O
.	O
We	O
hence	O
compare	O
to	O
the	O
previous	O
work	O
of	O
Mysore	O
et	O
al	O
.	O
(	O
2017	O
)	O
,	O
who	O
perform	O
action	O
graph	O
induction	O
on	O
a	O
similar	O
data	O
set	O
.	O
12	O
Our	O
implementation	O
of	O
BiLSTM	B-MethodName
-	O
CRF	O
mat2vec+word2vec	O
roughly	O
corresponds	O
to	O
their	O
BiLSTM	B-MethodName
-	I-MethodName
CRF	O
system	O
.	O

Baselines	O
.	O
We	O
compare	O
PROGRAMFC	O
to	O
seven	O
baselines	O
,	O
categorized	O
into	O
three	O
groups	O
.	O
(	O
i	O
)	O
Pretrained	O
models	O
:	O
BERT	B-MethodName
-	I-MethodName
FC	I-MethodName
(	O
Soleimani	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
LisT5	B-MethodName
(	O
Jiang	O
et	O
al	O
.	O
,	O
2021	O
)	O
are	O
two	O
models	O
that	O
leverage	O
BERT	B-MethodName
and	O
T5	B-MethodName
for	O
fact	O
verification	O
,	O
respectively	O
.	O
(	O
ii	O
)	O
FC	O
/	O
NLI	O
fine	O
-	O
tuned	O
models	O
:	O
we	O
choose	O
three	O
pretrained	O
models	O
that	O
are	O
fine	O
-	O
tuned	O
on	O
other	O
fact	O
-	O
checking	O
datasets	O
or	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
datasets	O
.	O
RoBERTa	O
-	O
NLI	O
(	O
Nie	O
et	O
al	O
.	O
,	O
2020	O
)	O
uses	O
fine	O
-	O
tuned	O
RoBERTa	O
-	O
large	O
on	O
four	O
NLI	O
datasets	O
;	O
DeBERTaV3	O
-	O
NLI	O
(	O
He	O
et	O
al	O
.	O
,	O
2021	O
)	O
We	O
use	O
these	O
examples	O
either	O
for	O
fine	O
-	O
tuning	O
pre	O
-	O
trained	O
models	O
(	O
BERT	B-MethodName
-	I-MethodName
FC	I-MethodName
and	O
LisT5	B-MethodName
)	O
,	O
for	O
continuous	O
fine	O
-	O
tuning	O
the	O
FC	O
/	O
NLI	O
fine	O
-	O
tuned	O
models	O
,	O
or	O
as	O
in	O
-	O
context	O
examples	O
for	O
FLAN	B-MethodName
-	I-MethodName
T5	I-MethodName
and	O
Codex	O
.	O
For	O
PROGRAMFC	O
,	O
we	O
use	O
them	O
as	O
in	O
-	O
context	O
examples	O
for	O
reasoning	O
program	O
generation	O
.	O

Frequency	O
of	O
recall	O
.	O
We	O
find	O
that	O
the	O
more	O
an	O
event	O
is	O
thought	O
or	O
talked	O
about	O
(	O
i.e.	O
,	O
higher	O
FRE	O
-	O
QUENCYOFRECALL	O
)	O
,	O
the	O
more	O
linearly	O
its	O
story	O
flows	O
(	O
∆	O
l	O
;	O
|β|	O
=	O
0.07	O
,	O
p	O
<	O
0.001	O
)	O
,	O
and	O
the	O
fewer	O
realis	O
events	O
(	O
|β|	O
=	O
0.09	O
,	O
p	O
<	O
0.001	O
)	O
it	O
contains	O
.	O

Knowledge	O
-	O
grounded	O
open	O
-	O
domain	O
dialogue	O
generation	I-TaskName
is	O
crucial	O
for	O
building	O
a	O
knowledgeable	O
dialogue	O
system	O
,	O
which	O
is	O
beyond	O
the	O
wildest	O
dreams	O
in	O
natural	O
language	O
process	O
field	O
.	O
All	O
our	O
experiments	O
are	O
conducted	O
on	O
public	O
available	O
datasets	O
to	O
avoid	O
ethical	O
concerns	O
.	O
All	O
terms	O
for	O
using	O
these	O
datasets	O
are	O
strictly	O
followed	O
in	O
our	O
study	O
.	O
There	O
are	O
no	O
direct	O
ethical	O
concerns	O
in	O
our	O
research	O
.	O

The	O
controller	O
is	O
a	O
sequence	B-TaskName
generation	I-TaskName
model	O
whose	O
input	O
is	O
a	O
linearized	O
state	O
and	O
whose	O
outputs	O
are	O
actions	O
.	O
The	O
input	O
sequence	O
is	O
the	O
concatenation	O
of	O
H	O
,	O
T	O
p	O
,	O
and	O
X.	O
The	O
linearized	O
T	O
p	O
is	O
a	O
series	O
of	O
steps	O
,	O
where	O
the	O
step	O
premises	O
are	O
connected	O
with	O
"	O
&	O
"	O
and	O
the	O
step	O
conclusion	O
comes	O
after	O
"	O
→.	O
"	O
For	O
each	O
state	O
,	O
the	O
controller	O
predicts	O
multiple	O
candidate	O
actions	O
and	O
their	O
likelihood	O
scores	O
.	O

Pre	O
-	O
trained	O
models	O
have	O
shown	O
very	O
good	O
performances	O
on	O
a	O
number	O
of	O
question	O
answering	O
benchmarks	O
especially	O
when	O
fine	O
-	O
tuned	O
on	O
multiple	O
question	O
answering	O
datasets	O
at	O
once	O
.	O
In	O
this	O
work	O
,	O
we	O
propose	O
an	O
approach	O
for	O
generating	O
a	O
fine	O
-	O
tuning	O
dataset	O
thanks	O
to	O
a	O
rule	O
-	O
based	O
algorithm	O
that	O
generates	O
questions	O
and	O
answers	O
from	O
unannotated	O
sentences	O
.	O
We	O
show	O
that	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
UnifiedQA	O
can	O
greatly	O
benefit	O
from	O
such	O
a	O
system	O
on	O
a	O
multiple	O
-	O
choice	O
benchmark	O
about	O
physics	O
,	O
biology	O
and	O
chemistry	O
it	O
has	O
never	O
been	O
trained	O
on	O
.	O
We	O
further	O
show	O
that	O
improved	O
performances	O
may	O
be	O
obtained	O
by	O
selecting	O
the	O
most	O
challenging	O
distractors	O
(	O
wrong	O
answers	O
)	O
,	O
with	O
a	O
dedicated	O
ranker	O
based	O
on	O
a	O
pretrained	O
RoBERTa	O
model	O
.	O

In	O
this	O
paper	O
,	O
we	O
limit	O
the	O
proposed	O
WhitenedCSE	O
for	O
sentence	O
embedding	O
learning	O
.	O
Conceptually	O
,	O
WhitenedCSE	B-MethodName
is	O
potential	O
to	O
benefit	O
contrastive	O
learning	O
on	O
some	O
other	O
tasks	O
,	O
e.g.	O
,	O
self	O
-	O
supervised	O
image	O
representation	O
learning	O
and	O
self	O
-	O
supervised	O
vision	O
-	O
language	O
contrastive	O
learning	O
.	O
However	O
,	O
we	O
did	O
not	O
investigate	O
the	O
self	O
-	O
supervised	O
image	O
representation	O
learning	O
because	O
this	O
domain	O
is	O
currently	O
dominated	O
by	O
masked	O
image	O
modeling	O
.	O
We	O
will	O
consider	O
extending	O
WhitenedCSE	O
for	O
visionlanguage	O
contrastive	O
learning	O
when	O
we	O
have	O
sufficient	O
training	O
resources	O
for	O
the	O
extraordinary	O
largescale	O
text	O
-	O
image	O
pairs	O
.	O
Since	O
the	O
number	O
of	O
pages	O
in	O
the	O
text	O
is	O
limited	O
and	O
our	O
model	O
does	O
not	O
have	O
significant	O
potential	O
risks	O
,	O
we	O
do	O
not	O
discuss	O
this	O
.	O

where	O
L	O
(	O
)	O
is	O
a	O
twice	O
-	O
differentiable	O
loss	O
function	O
andη	O
is	O
the	O
learnable	O
learning	O
rate	O
of	O
the	O
model	O
,	O
which	O
is	O
optimized	O
together	O
withD.	O
Given	O
initial	O
model	O
parameters	O
θ	O
0	O
,	O
we	O
can	O
represent	O
the	O
model	O
trained	O
with	O
the	O
distilled	O
datasetD	O
,	O
with	O
the	O
number	O
of	O
GD	O
steps	O
T	O
,	O
as	O

By	O
adding	O
adversarial	O
perturbations	O
to	O
word	O
embeddings	O
,	O
FreeLB	O
generates	O
virtual	O
adversarial	O
samples	O
inside	O
the	O
region	O
around	O
input	O
samples	O
.	O

For	O
CNNs	B-MethodName
,	O
the	O
classifiers	O
we	O
experiment	O
with	O
in	O
this	O
paper	O
,	O
each	O
feature	O
has	O
one	O
word	O
cloud	O
containing	O
the	O
n	O
-	O
grams	O
,	O
from	O
the	O
training	O
examples	O
,	O
which	O
were	O
selected	O
by	O
the	O
max	O
-	O
pooling	O
of	O
the	O
CNNs	B-MethodName
.	O
For	O
instance	O
,	O
Figure	O
2	O
,	O
corresponding	O
to	O
a	O
feature	O
of	O
filter	O
size	O
2	O
,	O
shows	O
bi	O
-	O
grams	O
(	O
e.g.	O
,	O
"	O
love	O
love	O
"	O
,	O
"	O
love	O
my	O
"	O
,	O
"	O
loves	O
his	O
"	O
,	O
etc	O
.	O
)	O
whose	O
font	O
size	O
corresponds	O
to	O
the	O
feature	O
values	O
of	O
the	O
bi	O
-	O
grams	O
.	O
This	O
is	O
similar	O
to	O
how	O
previous	O
works	O
analyze	O
CNN	O
features	O
(	O
Jacovi	O
et	O
al	O
.	O
,	O
2018;Lertvittayakumjorn	O
and	O
Toni	O
,	O
2019	O
)	O
,	O
and	O
it	O
is	O
equivalent	O
to	O
back	O
-	O
propagating	O
the	O
feature	O
values	O
to	O
the	O
input	O
using	O
LRP	O
and	O
cropping	O
the	O
consecutive	O
input	O
words	O
with	O
non	O
-	O
zero	O
LRP	O
scores	O
to	O
show	O
in	O
the	O
word	O
clouds	O
.	O

•	O
stance	O
:	O
Original	O
stance	O
label	O
of	O
the	O
argument	O
towards	O
the	O
topic	O
,	O
taken	O
from	O
the	O
UKP	O
-	O
Corpus	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
Either	O
"	O
Argument_for	O
"	O
or	O
"	O
Argument_against	O
"	O
.	O

In	O
this	O
subsection	O
,	O
we	O
apply	O
SACL	O
framework	O
to	O
the	O
task	O
of	O
emotion	O
recognition	I-TaskName
in	O
conversations	O
(	O
ERC	B-TaskName
)	O
,	O
and	O
present	O
a	O
sequence	O
-	O
based	O
method	O
SACL	B-MethodName
-	I-MethodName
LSTM	I-MethodName
.	O
The	O
overall	O
architecture	O
is	O
illustrated	O
in	O
Figure	O
3	O
.	O
With	O
the	O
guidance	O
of	O
SACL	O
with	O
CAT	O
,	O
the	O
method	O
can	O
learn	O
label	O
-	O
consistent	O
and	O
context	O
-	O
robust	O
emotional	O
features	O
for	O
better	O
emotion	O
recognition	O
.	O

Generation	O
At	O
inference	O
,	O
we	O
gather	O
multiple	O
generated	O
arguments	O
from	O
a	O
control	O
code	O
input	O
by	O
splitting	O
the	O
generated	O
output	O
text	O
into	O
sentences	O
with	O
NLTK	O
(	O
Bird	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
We	O
observe	O
that	O
for	O
the	O
first	O
generated	O
argument	O
,	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
mostly	O
outputs	O
very	O
short	O
phrases	O
,	O
as	O
it	O
tries	O
to	O
incorporate	O
the	O
control	O
code	O
into	O
a	O
meaningful	O
start	O
of	O
an	O
argument	O
.	O
We	O
prevent	O
this	O
by	O
adding	O
punctuation	O
marks	O
after	O
each	O
control	O
code	O
(	O
e.g.	O
a	O
period	O
or	O
colon	O
)	O
,	O
signaling	O
the	O
model	O
to	O
start	O
a	O
new	O
sentence	O
.	O
In	O
this	O
fashion	O
,	O
we	O
generate	O
proand	O
con	O
-	O
arguments	O
up	O
to	O
the	O
pre	O
-	O
defined	O
training	O
split	O
size	O
7	O
for	O
each	O
topic	O
of	O
the	O
UKP	O
-	O
Corpus	O
,	O
resulting	O
in	O
7,991	O
newly	O
generated	O
arguments	O
.	O
We	O
do	O
this	O
with	O
both	O
models	O
and	O
use	O
the	O
generated	O
arguments	O
as	O
a	O
basis	O
for	O
the	O
following	O
analysis	O
and	O
evaluation	O
methods	O
.	O
Examples	O
of	O
generated	O
arguments	O
can	O
be	O
found	O
in	O
Tables	O
4	O
,	O
6	O
,	O
and	O
7	O
(	O
as	O
part	O
of	O
the	O
evaluation	O
,	O
see	O
Section	O
7	O
)	O
.	O

Aspect	O
Detection	O
We	O
detect	O
aspects	O
on	O
all	O
remaining	O
arguments	O
.	O
To	O
speed	O
up	O
the	O
detection	O
on	O
millions	O
of	O
sentences	O
,	O
we	O
use	O
BERT	B-MethodName
BASE	O
instead	O
of	O
BERT	B-MethodName
LARGE	O
(	O
see	O
Table	O
3	O
)	O
.	O

Language	O
Models	O
We	O
use	O
two	O
language	O
models	O
to	O
train	O
our	O
proposed	O
modified	O
MMA	B-MethodName
model	O
.	O
Firstly	O
,	O
we	O
use	O
the	O
pretrained	O
XLM	O
-	O
RoBERTa	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2019	O
)	O
model	O
from	O
Huggingface	O
Transformers	O
1	O
model	O
repository	O
.	O
Since	O
the	O
LM	O
output	O
can	O
be	O
very	O
open	O
-	O
ended	O
and	O
might	O
not	O
directly	O
suit	O
/	O
cater	O
to	O
our	O
task	O
and	O
dataset	O
,	O
we	O
finetune	O
the	O
head	O
of	O
the	O
model	O
using	O
the	O
MuST	B-DatasetName
-	I-DatasetName
C	I-DatasetName
target	O
text	O
data	O
for	O
each	O
task	O
.	O

Formally	O
,	O
the	O
NCE	O
loss	O
L(θ	O
)	O
is	O

For	O
the	O
abbreviation	O
headers	O
,	O
when	O
translating	O
"	O
OS	O
"	O
(	O
the	O
abbreviation	O
of	O
operation	O
system	O
)	O
and	O
"	O
Jan	O
"	O
(	O
the	O
abbreviation	O
of	O
January	O
)	O
,	O
both	O
Base	O
and	O
H2H	O
fail	O
to	O
get	O
the	O
correct	O
result	O
.	O
However	O
,	O
being	O
aware	O
of	O
the	O
context	O
of	O
"	O
Jan	O
"	O
(	O
e.g.	O
,	O
Feb	O
,	O
Mar	O
and	O
Apr	O
,	O
etc	O
.	O
)	O
and	O
"	O
OS	O
"	O
(	O
e.g.	O
,	O
Computer	O
,	O
System	O
,	O
and	O
Core	O
,	O
etc	O
.	O
)	O
,	O
H2H+CXT	O
and	O
CAST	O
can	O
better	O
understand	O
and	O
translate	O
the	O
abbreviations	O
.	O

We	O
propose	O
a	O
method	O
for	O
generating	O
multiplechoice	O
questions	O
in	O
order	O
to	O
fine	O
-	O
tune	O
and	O
improve	O
UnifiedQA	B-MethodName
.	O
This	O
process	O
is	O
based	O
on	O
3	O
steps	O
.	O
First	O
,	O
a	O
set	O
of	O
sentences	O
is	O
being	O
selected	O
(	O
Section	O
2.1	O
)	O
from	O
which	O
a	O
generic	O
question	O
generation	O
system	O
is	O
applied	O
(	O
Section	O
2.2	O
)	O
.	O
Then	O
a	O
number	O
of	O
distractors	O
are	O
added	O
to	O
each	O
question	O
(	O
Section	O
2.3	O
)	O
.	O

This	O
paper	O
presents	O
a	O
new	O
challenging	O
information	O
extraction	O
task	O
in	O
the	O
domain	O
of	O
materials	O
science	O
.	O
We	O
develop	O
an	O
annotation	O
scheme	O
for	O
marking	O
information	O
on	O
experiments	O
related	O
to	O
solid	O
oxide	O
fuel	O
cells	O
in	O
scientific	O
publications	O
,	O
such	O
as	O
involved	O
materials	O
and	O
measurement	O
conditions	O
.	O
With	O
this	O
paper	O
,	O
we	O
publish	O
our	O
annotation	O
guidelines	O
,	O
as	O
well	O
as	O
our	O
SOFC	O
-	O
Exp	O
corpus	O
consisting	O
of	O
45	O
openaccess	O
scholarly	O
articles	O
annotated	O
by	O
domain	O
experts	O
.	O
A	O
corpus	O
and	O
an	O
inter	O
-	O
annotator	O
agreement	O
study	O
demonstrate	O
the	O
complexity	O
of	O
the	O
suggested	O
named	O
entity	O
recognition	O
and	O
slot	O
filling	O
tasks	O
as	O
well	O
as	O
high	O
annotation	O
quality	O
.	O
We	O
also	O
present	O
strong	O
neural	O
-	O
network	O
based	O
models	O
for	O
a	O
variety	O
of	O
tasks	O
that	O
can	O
be	O
addressed	O
on	O
the	O
basis	O
of	O
our	O
new	O
data	O
set	O
.	O
On	O
all	O
tasks	O
,	O
using	O
BERT	B-MethodName
embeddings	O
leads	O
to	O
large	O
performance	O
gains	O
,	O
but	O
with	O
increasing	O
task	O
complexity	O
,	O
adding	O
a	O
recurrent	O
neural	O
network	O
on	O
top	O
seems	O
beneficial	O
.	O
Our	O
models	O
will	O
serve	O
as	O
competitive	O
baselines	O
in	O
future	O
work	O
,	O
and	O
analysis	O
of	O
their	O
performance	O
highlights	O
difficult	O
cases	O
when	O
modeling	O
the	O
data	O
and	O
suggests	O
promising	O
research	O
directions	O
.	O

To	O
investigate	O
,	O
we	O
identify	O
a	O
set	O
of	O
heuristics	O
parameterized	O
by	O
ϕ(p	O
)	O
and	O
c	O
,	O
and	O
characterized	O
by	O
the	O
presence	O
of	O
a	O
set	O
of	O
heuristic	O
-	O
specific	O
Medical	O
Subject	I-MethodName
Headings	I-MethodName
(	O
MeSH	O
)	O
linked	O
entities	O
in	O
the	O
premise	O
and	O
hypothesis	O
of	O
each	O
heuristic	O
-	O
satisfying	O
example	O
.	O
These	O
heuristics	O
are	O
described	O
below	O
;	O
specific	O
MeSH	B-TaskName
features	O
are	O
detailed	O
in	O
the	O
Appendix	O
.	O

Figure	O
2	O
(	O
c	O
)	O
shows	O
an	O
example	O
.	O
When	O
the	O
text	O
inputs	O
are	O
given	O
a	O
prompt	O
that	O
is	O
unlikely	O
to	O
be	O
used	O
in	O
sentiment	O
analysis	O
texts	O
,	O
"	O
[	O
yellow	O
/	O
green	O
]	O
black	O
.	O
"	O
,	O
the	O
data	O
from	O
different	O
classes	O
is	O
not	O
well	O
separated	O
in	O
the	O
feature	O
space	O
(	O
as	O
compared	O
to	O
Figure	O
2	O
(	O
b	O
)	O
)	O
.	O
We	O
believe	O
that	O
this	O
is	O
because	O
models	O
rarely	O
encounter	O
the	O
text	O
"	O
yellow	O
black	O
"	O
or	O
"	O
green	O
black	O
"	O
prefixed	O
in	O
a	O
sentiment	O
-	O
bearing	O
text	O
in	O
the	O
pretraining	O
corpora	O
,	O
and	O
that	O
this	O
language	O
discrepancy	O
limits	O
the	O
model	O
's	O
ability	O
to	O
effectively	O
represent	O
the	O
data	O
.	O
In	O
contrast	O
,	O
expressions	O
like	O
"	O
[	O
very	O
/	O
not	O
]	O
pleased	O
.	O
"	O
(	O
Figure	O
2	O
(	O
b	O
)	O
)	O
are	O
often	O
used	O
in	O
context	O
related	O
to	O
emotions	O
and	O
therefore	O
appear	O
more	O
frequently	O
together	O
with	O
sentiment	O
-	O
bearing	O
text	O
in	O
the	O
pre	O
-	O
training	O
corpora	O
.	O
This	O
makes	O
it	O
easier	O
for	O
the	O
model	O
to	O
form	O
a	O
useful	O
pre	O
-	O
trained	O
feature	O
space	O
.	O

We	O
report	O
results	O
on	O
the	O
test	O
set	O
of	O
XNLI	O
and	O
MLQA	O
and	O
we	O
do	O
hyperparameter	O
searching	O
on	O
the	O
development	O
set	O
.	O
All	O
the	O
experiments	O
for	O
translatetrain	O
were	O
done	O
using	O
the	O
code	O
-	O
switching	O
technique	O
introduced	O
in	O
Section	O
2	O
.	O

open	O
-	O
access	O
scientific	O
publications	O
about	O
SOFCs	O
and	O
related	O
research	O
,	O
annotated	O
by	O
domain	O
experts	O
.	O

We	O
need	O
a	O
variety	O
of	O
different	O
metrics	O
to	O
understand	O
the	O
effectiveness	O
of	O
our	O
planning	O
-	O
LM	O
approach	O
.	O

Table	O
6	O
show	O
examples	O
in	O
BOLD	B-MethodName
and	O
StereoSet	B-MethodName
that	O
probe	O
for	O
bias	O
against	O
a	O
particular	O
group	O
,	O
but	O
differ	O
in	O
language	O
due	O
to	O
the	O
difference	O
in	O
sources	O
the	O
datasets	O
are	O
from	O
.	O

For	O
example	O
,	O
consider	O
a	O
multi	O
-	O
path	O
local	O
hierarchy	O
with	O
four	O
labels	O
:	O
1a	O
,	O
1b	O
,	O
2a	O
and	O
2b	O
,	O
where	O
2a	O
and	O
2b	O
are	O
the	O
child	O
labels	O
of	O
1a	O
and	O
1b	O
,	O
respectively	O
.	O
According	O
to	O
Eq	O
.	O
5	O
,	O
we	O
can	O
get	O
u	O
1	O
=	O
ŷ	O
1a	O
+	O
ŷ	O
1b	O
and	O
u	O
2	O
=	O
ŷ	O
2a	O
+	O
ŷ	O
2b	O
.	O
The	O
attention	O
score	O
α	O
21	O
in	O
BERT	B-MethodName
can	O
be	O
calculated	O
as	O
:	O

Context	O
Aware	O
Schema	O
Annotation	O
.	O
To	O
reduce	O
the	O
translation	O
effort	O
,	O
we	O
first	O
use	O
Google	O
translator	O
1	O
to	O
automatically	O
translate	O
the	O
English	O
headers	O
to	O
five	O
target	O
languages	O
,	O
header	O
by	O
header	O
.	O
Then	O
based	O
on	O
the	O
Google	O
translations	O
,	O
we	O
recruit	O
three	O
professional	O
translators	O
for	O
each	O
language	O
to	O
manually	O
check	O
and	O
modify	O
the	O
translations	O
if	O
inappropriate	O
.	O

Figure	O
4	O
shows	O
the	O
distribution	O
of	O
average	O
feature	O
scores	O
from	O
one	O
of	O
the	O
three	O
CNN	B-MethodName
instances	O
for	O
the	O
Yelp	O
dataset	O
.	O
Examples	O
of	O
the	O
word	O
clouds	O
from	O
each	O
rank	O
are	O
displayed	O
in	O
Figure	O
5	O
.	O
We	O
can	O
clearly	O
see	O
dissimilar	O
qualities	O
of	O
the	O
three	O
features	O
.	O
Some	O
participants	O
answered	O
that	O
the	O
rank	O
B	O
feature	O
in	O
Figure	O
5	O
was	O
relevant	O
to	O
the	O
positive	O
class	O
(	O
probably	O
due	O
to	O
the	O
word	O
'	O
delicious	O
'	O
)	O
,	O
and	O
the	O
weights	O
of	O
this	O
feature	O
in	O
W	O
agreed	O
(	O
Positive	O
:	O
Negative	O
=	O
0.137:-0.135	O
)	O
.	O
Interestingly	O
,	O
the	O
rank	O
C	O
feature	O
in	O
Figure	O
5	O
got	O
a	O
negative	O
score	O
because	O
some	O
participants	O
believed	O
that	O
this	O
word	O
cloud	O
was	O
relevant	O
to	O
the	O
positive	O
class	O
,	O
but	O
actually	O
the	O
model	O
used	O
this	O
feature	O
as	O
evidence	O
for	O
the	O
negative	O
class	O
(	O
Positive	O
:	O
Negative	O
=	O
0.209:0.385	O
)	O
.	O

With	O
the	O
pre	O
-	O
trained	O
token	O
-	O
level	O
representations	O
from	O
BERT	B-MethodName
(	O
second	O
half	O
of	O
Table	O
2	O
)	O
,	O
the	O
best	O
model	O
is	O
BERT	B-MethodName
-	I-MethodName
BiRNN+Vis	I-MethodName
-	O
annot	O
-	O
mult	O
,	O
achieving	O
a	O
Pear-	B-MethodName
BERT	I-MethodName
-	I-MethodName
BiRNN	I-MethodName
)	O
and	O
their	O
respective	O
top-3	O
best	O
performing	O
multimodal	O
variants	O
(	O
+	O
Vis	O
)	O
.	O
We	O
refer	O
the	O
reader	O
to	O
the	O
Appendix	O
for	O
the	O
full	O
set	O
of	O
results	O
.	O
Here	O
,	O
BERT	B-MethodName
,	O
ann	O
-	O
mul	O
and	O
emb	O
-	O
mul2	O
correspond	O
to	O
the	O
BERT	B-MethodName
-	I-MethodName
BiRNN	I-MethodName
,	O
the	O
BERT	B-MethodName
-	I-MethodName
BiRNN+Vis	I-MethodName
-	O
annot	O
-	O
mult	O
and	O
the	O
BiRNN+Vis	B-MethodName
-	O
embed	O
-	O
mult2	O
models	O
of	O
Table	O
2	O
.	O

We	O
now	O
turn	O
to	O
the	O
object	O
of	O
our	O
investigation	O
:	O
role	O
semantics	O
.	O
For	O
further	O
discussion	O
,	O
consider	O
the	O
following	O
synthetic	O
example	O
:	O

we	O
focus	O
on	O
the	O
English	O
language	O
.	O
As	O
of	O
the	O
writing	O
of	O
this	O
paper	O
,	O
there	O
is	O
no	O
equivalent	O
of	O
Simple	O
English	O
Wikipedia	O
for	O
other	O
languages	O
on	O
Wikipedia	O
,	O
and	O
creating	O
similar	O
resources	O
for	O
other	O
languages	O
would	O
require	O
finding	O
other	O
resources	O
.	O

The	O
feature	O
-	O
based	O
textual	O
features	O
contain	O
15	O
numerical	O
scores	O
,	O
while	O
the	O
visual	O
feature	O
vector	O
contains	O
4,096	O
dimensions	O
.	O
To	O
avoid	O
over	O
-	O
weighting	O
the	O
visual	O
features	O
,	O
we	O
reduce	O
their	O
dimensionality	O
using	O
Principal	O
Component	I-MethodName
Analysis	I-MethodName
(	O
PCA	O
)	O
.	O
We	O
consider	O
up	O
to	O
15	O
principal	O
components	O
in	O
order	O
to	O
keep	O
a	O
balance	O
between	O
the	O
visual	O
features	O
and	O
the	O
15	O
text	O
features	O
from	O
QuEst++	O
.	O
We	O
choose	O
the	O
final	O
number	O
of	O
principal	O
components	O
to	O
keep	O
according	O
to	O
the	O
explained	O
variance	O
with	O
the	O
PCA	O
,	O
so	O
this	O
number	O
is	O
treated	O
as	O
a	O
hyperparameter	O
.	O
After	O
analysing	O
the	O
explained	O
variance	O
for	O
up	O
to	O
15	O
kept	O
principal	O
components	O
(	O
see	O
Figure	O
4	O
in	O
Appendix	O
)	O
,	O
we	O
selected	O
six	O
numbers	O
of	O
principal	O
components	O
to	O
train	O
QE	O
models	O
with	O
(	O
1	O
,	O
2	O
,	O
3	O
,	O
5	O
,	O
10	O
,	O
and	O
15	O
)	O
.	O
As	O
fusion	O
strategy	O
,	O
we	O
concatenate	O
the	O
two	O
feature	O
vectors	O
.	O

(	O
2	O
)	O
the	O
dialog	O
can	O
stay	O
in	O
the	O
same	O
node	O
when	O
the	O
user	O
asks	O
for	O
a	O
clarification	O
and	O
the	O
agent	O
refers	O
to	O
an	O
FAQ	O
to	O
answer	O
it	O
,	O
and	O
(	O
3	O
)	O
the	O
dialog	O
can	O
randomly	O
jump	O
to	O
any	O
other	O
nodes	O
in	O
the	O
flowchart	O
with	O
a	O
very	O
low	O
probability	O
.	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
and	O
perplexity	O
to	O
evaluate	O
generation	O
performance	O
.	O
As	O
we	O
have	O
the	O
labels	O
for	O
the	O
documents	O
over	O
which	O
the	O
responses	O
are	O
grounded	O
,	O
we	O
measure	O
the	O
performance	O
of	O
the	O
retriever	O
using	O
the	O
standard	O
recall	B-MetricName
@	O
1	O
(	O
R	O
@	I-MetricName
1	O
)	O
and	O
a	O
task	O
-	O
specific	O
metric	O
called	O
success	O
rate	O
(	O
SR	O
)	O
(	O
Raghu	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
The	O
success	O
rate	O
measures	O
the	O
fraction	O
of	O
the	O
test	O
dialogs	O
for	O
which	O
the	O
system	O
retrieved	O
the	O
correct	O
document	O
for	O
all	O
the	O
agent	O
utterances	O
in	O
the	O
dialog	O
.	O

Media	O
-	O
source	O
ideology	O
values	O
are	O
from	O
{	O
Very	O
liberal	O
,	O
Liberal	O
,	O
Slightly	O
liberal	O
,	O
Moderate	O
,	O
Slightly	O
conservative	O
,	O
Conservative	O
,	O
Very	O
conservative	O
,	O
Un	O
-	O
known	O
}	O
.	O
Post	O
-	O
hoc	O
conversion	O
:	O
We	O
further	O
convert	O
finegrained	O
labels	O
obtained	O
in	O
steps	O
3	O
through	O
step	O
5	O
to	O
coarse	O
-	O
grained	O
labels	O
according	O
to	O
the	O
nature	O
of	O
each	O
task	O
.	O
For	O
sentiment	O
annotation	O
,	O
we	O
convert	O
them	O
as	O
3	O
-	O
way	O
labels	O
.	O
Specifically	O
,	O
we	O
convert	O
very	O
positive	O
and	O
positive	O
into	O
one	O
positive	O
category	O
,	O
and	O
similarly	O
for	O
very	O
negative	O
and	O
negative	O
.	O
Then	O
we	O
merge	O
slightly	O
positive	O
,	O
neutral	O
,	O
and	O
slightly	O
negative	O
into	O
neutral	O
.	O
For	O
ideological	O
labels	O
obtained	O
in	O
steps	O
4	O
and	O
5	O
,	O
in	O
light	O
of	O
the	O
5	O
-	O
way	O
annotation	O
provided	O
by	O
AllSides	O
,	O
we	O
also	O
convert	O
ours	O
as	O
5way	O
labels	O
by	O
merging	O
very	O
liberal	O
and	O
liberal	O
into	O
liberal	O
,	O
and	O
similarly	O
for	O
very	O
conservative	O
and	O
conservative	O
.	O

•	O
Entailment	O
Module	O
.	O
We	O
follow	O
to	O
implement	O
the	O
entailment	O
module	O
in	O
a	O
prefixed	O
manner	O
.	O
All	O
types	O
of	O
modules	O
are	O
implemented	O
with	O
a	O
single	O
T5	O
-	O
large	I-MethodName
model	O
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
A	O
type	O
-	O
specific	O
prefix	O
(	O
e.g.	O
,	O
"	O
deductive	O
substitution	O
:	O
"	O
)	O
is	O
added	O
to	O
specify	O
which	O
type	O
of	O
reasoning	O
the	O
model	O
should	O
perform	O
.	O
The	O
model	O
is	O
trained	O
on	O
the	O
entailment	O
steps	O
of	O
the	O
Entailment	O
-	O
Bank	O
training	O
split	O
.	O
The	O
reason	O
type	O
labels	O
of	O
steps	O
are	O
provided	O
by	O
.	O
Following	O
Yang	O
et	O
al	O
.	O
(	O
2022	O
)	O
,	O
we	O
take	O
the	O
hypothesis	O
as	O
additional	O
input	O
to	O
encourage	O
the	O
module	O
to	O
generate	O
a	O
more	O
relevant	O
conclusion	O
.	O
The	O
module	O
is	O
trained	O
with	O
a	O
learning	O
rate	O
of	O
3e-5	B-HyperparameterValue
and	O
a	O
batch	O
size	O
of	O
20	O
following	O
.	O

El	O
término	O
viene	O
de	O
la	O
palabra	O
"	O
ghost	O
"	O
,	O
que	O
en	O
inglés	O
es	O
'	O
fantasma	O
'	O

Here	O
,	O
N	O
denotes	O
the	O
batch	O
size	O
,	O
(	O
x	O
i	O
,	O
x	O
+	O
i	O
)	O
denotes	O
two	O
semantically	O
similar	O
sentences	O
,	O
and	O
h	O
i	O
=	O
E	O
(	O
x	O
i	O
)	O
is	O
the	O
sentence	O
embedding	O
from	O
encoder	O
E.	O
The	O
key	O
to	O
using	O
this	O
loss	O
is	O
how	O
to	O
define	O
the	O
semantically	O
similar	O
pairs	O
,	O
which	O
we	O
elaborate	O
on	O
in	O
the	O
following	O
section	O
.	O

Comparing	O
our	O
model	O
performance	O
using	O
vary-	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
L	O
is	O
the	O
number	O
of	O
Transformer	B-MethodName
layers	O
,	O
H	O
m	O
is	O
the	O
hidden	O
size	O
,	O
H	O
f	O
f	O
is	O
the	O
dimension	O
of	O
the	O
feed	O
-	O
forward	O
layer	O
,	O
A	O
is	O
the	O
number	O
of	O
attention	O
heads	O
,	O
and	O
V	O
is	O
the	O
vocabulary	O
size	O
.	O

Argument	O
Generation	O
Early	O
approaches	O
rely	O
on	O
rules	O
from	O
argumentation	O
theory	O
and	O
user	O
preference	O
models	O
(	O
Carenini	O
and	O
Moore	O
,	O
2006;Zukerman	O
et	O
al	O
.	O
,	O
1998	O
)	O
.	O
In	O
a	O
more	O
recent	O
work	O
,	O
Sato	O
et	O
al	O
.	O
(	O
2015	O
)	O
construct	O
rules	O
to	O
find	O
arguments	O
in	O
a	O
large	O
data	O
source	O
,	O
which	O
are	O
then	O
filtered	O
and	O
ordered	O
with	O
a	O
neural	O
network	O
based	O
ranker	O
.	O
Baff	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
a	O
clustering	O
and	O
regression	O
approach	O
to	O
assemble	O
discourse	O
units	O
(	O
major	O
claims	O
,	O
pro	O
and	O
con	O
statements	O
)	O
to	O
argumentative	O
texts	O
.	O
However	O
,	O
most	O
of	O
these	O
approaches	O
rely	O
on	O
hand	O
-	O
crafted	O
features	O
and	O
do	O
not	O
generalize	O
well	O
.	O
Moreover	O
,	O
they	O
all	O
require	O
permanent	O
access	O
to	O
large	O
data	O
sources	O
and	O
are	O
not	O
able	O
to	O
generate	O
new	O
arguments	O
.	O

As	O
the	O
saying	O
goes	O
,	O
"	O
a	O
chart	O
is	O
worth	O
a	O
thousand	O
words	O
"	O
.	O
Nowadays	O
,	O
tremendous	O
amounts	O
of	O
tabular	O
data	O
written	O
in	O
various	O
languages	O
are	O
widely	O
used	O
in	O
Wikipedia	O
pages	O
,	O
research	O
papers	O
,	O
finance	O
reports	O
,	O
file	O
systems	O
,	O
and	O
databases	O
,	O
which	O
are	O
informative	O
.	O
Schema	O
translation	O
is	O
the	O
task	O
of	O
automatically	O
translating	O
headers	O
of	O
tabular	O
data	O
from	O
one	O
language	O
to	O
another	O
.	O
High	O
-	O
quality	O
schema	O
translation	O
plays	O
an	O
essential	O
role	O
in	O
cross	O
-	O
lingual	O
table	O
⇤	O
Work	O
done	O
during	O
an	O
internship	O
at	O
Microsoft	O
Research	O
.	O

D5	O
.	O
Did	O
you	O
report	O
the	O
basic	O
demographic	O
and	O
geographic	O
characteristics	O
of	O
the	O
annotator	O
population	O
that	O
is	O
the	O
source	O
of	O
the	O
data	O
?	O
No	O
response	O
.	O

mentions	O
sequentially	O
using	O
words	O
and	O
already	O
resolved	O
entities	O
(	O
see	O
Figure	O
1	O
)	O
.	O
This	O
sequential	O
inference	O
effectively	O
accumulates	O
the	O
global	O
contextual	O
information	O
and	O
enhances	O
the	O
coherence	O
of	O
disambiguation	O
decisions	O
.	O
We	O
conducted	O
extensive	O
experiments	O
using	O
six	O
standard	O
ED	O
datasets	O
,	O
i.e.	O
,	O
AIDA	B-DatasetName
-	I-DatasetName
CoNLL	I-DatasetName
,	O
MSNBC	B-DatasetName
,	O
AQUAINT	B-DatasetName
,	O
ACE2004	B-DatasetName
,	O
WNED	B-DatasetName
-	O
WIKI	I-DatasetName
,	O
and	O
WNED	B-DatasetName
-	I-DatasetName
CWEB	I-MethodName
.	O
As	O
a	O
result	O
,	O
the	O
global	O
contextual	O
information	O
consistently	O
improved	O
the	O
performance	O
.	O
Furthermore	O
,	O
we	O
achieved	O
new	O
state	O
of	O
the	O
art	O
on	O
all	O
datasets	O
except	O
for	O
WNED	B-DatasetName
-	O
CWEB	I-MethodName
.	O
The	O
source	O
code	O
and	O
model	O
checkpoint	O
are	O
available	O
at	O
https://github.com/	O
studio	O
-	O
ousia	O
/	O
luke	O
.	O

Therefore	O
,	O
the	O
teacher	O
's	O
output	O
serves	O
as	O
a	O
dynamic	O
learning	O
target	O
for	O
each	O
sample	O
.	O
By	O
updating	O
based	O
on	O
the	O
student	O
's	O
feedback	O
in	O
advance	O
,	O
the	O
teacher	O
is	O
able	O
to	O
reach	O
a	O
state	O
that	O
is	O
optimal	O
for	O
the	O
student	O
's	O
learning	O
.	O
In	O
this	O
case	O
,	O
the	O
teacher	O
could	O
provide	O
an	O
appropriate	O
learning	O
signal	O
.	O
Leveraging	O
this	O
updated	O
supervision	O
signal	O
,	O
the	O
student	O
could	O
make	O
up	O
for	O
the	O
ability	O
gap	O
faster	O
.	O
For	O
the	O
other	O
two	O
updating	O
orders	O
,	O
the	O
teacher	O
has	O
n't	O
updated	O
yet	O
,	O
lacking	O
of	O
making	O
trade	O
-	O
offs	O
between	O
the	O
samples	O
that	O
are	O
more	O
beneficial	O
for	O
generalization	O
and	O
those	O
that	O
are	O
more	O
challenging	O
to	O
learn	O
from	O
.	O
This	O
may	O
lead	O
to	O
a	O
certain	O
degree	O
of	O
lag	O
in	O
knowledge	O
transfer	O
,	O
resulting	O
in	O
a	O
larger	O
entropy	O
gap	O
between	O
the	O
student	O
and	O
the	O
teacher	O
.	O

Probable	O
Cause	O
Heuristic	O
This	O
heuristic	O
applies	O
when	O
the	O
premise	O
contains	O
clinical	O
condition(s	O
)	O
,	O
the	O
target	O
class	O
is	O
neutral	O
,	O
and	O
the	O
generated	O
hypothesis	O
provides	O
a	O
plausible	O
,	O
often	O
subjective	O
or	O
behavioral	O
,	O
causal	O
explanation	O
for	O
the	O
condition	O
,	O
finding	O
,	O
or	O
event	O
described	O
in	O
the	O
premise	O
(	O
e.g.	O
,	O
associating	O
altered	O
mental	O
status	O
with	O
drug	O
overdose	O
)	O
.	O

Finally	O
,	O
we	O
investigate	O
to	O
what	O
extent	O
do	O
components	O
introduced	O
by	O
us	O
help	O
in	O
linking	O
when	O
there	O
is	O
training	O
data	O
available	O
that	O
links	O
to	O
the	O
inference	O
KB	O
,	O
KB	O
test	O
.	O
We	O
hypothesize	O
that	O
while	O
attributeseparators	O
will	O
still	O
be	O
useful	O
,	O
attribute	O
-	O
OOV	O
and	O
attribute	O
-	O
shuffle	O
will	O
be	O
less	O
useful	O
as	O
there	O
is	O
a	O
smaller	O
gap	O
between	O
training	O
and	O
test	O
scenarios	O
,	O
reducing	O
the	O
need	O
for	O
regularization	O
.	O

R4C	B-MethodName
(	O
Inoue	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
R4C	B-MethodName
is	O
another	O
recent	O
multi	O
-	O
hop	O
QA	O
dataset	O
containing	O
annotated	O
evidence	O
paths	O
.	O
The	O
dataset	O
contains	O
4.6k	O
examples	O
(	O
2.4k	O
train	O
,	O
2.2k	O
development	O
)	O
constructed	O
on	O
top	O
of	O
HotpotQA	O
,	O
where	O
the	O
authors	O
used	O
crowdsourcing	O
efforts	O
to	O
collect	O
the	O
evidence	O
paths	O
in	O
the	O
form	O
of	O
simple	O
subject	O
-	O
verb	O
-	O
object	O
natural	O
language	O
sentences	O
.	O
Again	O
,	O
we	O
randomly	O
split	O
the	O
development	O
set	O
(	O
there	O
's	O
no	O
test	O
set	O
given	O
)	O
into	O
our	O
development	O
and	O
test	O
set	O
(	O
1.1k	O
samples	O
each	O
)	O
.	O
We	O
use	O
the	O
question	O
as	O
our	O
query	O
q	O
and	O
use	O
the	O
annotated	O
evidence	O
sentences	O
as	O
C	O
q	O
.	O

Appendix	O
for	O
"	O
Global	O
Entity	O
Disambiguation	O
with	O
BERT	O
"	O
A	O
Details	O
of	O
Proposed	O
Model	O

the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
62076008	O
)	O
and	O
the	O
Key	O
Project	O
of	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
61936012	O
)	O
.	O

The	O
results	O
also	O
show	O
that	O
our	O
approach	O
is	O
better	O
than	O
neglecting	O
it	O
.	O
We	O
believe	O
that	O
ignoring	O
them	O
will	O
lead	O
to	O
insufficient	O
generalization	O
ability	O
of	O
the	O
model	O
.	O
In	O
general	O
,	O
it	O
is	O
problematic	O
to	O
employ	O
vague	O
instances	O
in	O
positive	O
-	O
negative	O
partition	O
,	O
and	O
our	O
multi	O
-	O
level	O
fashion	O
can	O
facilitate	O
the	O
learning	O
of	O
vague	O
samples	O
.	O

Topic	O
Units	O
(	O
Lan	O
et	O
al	O
.	O
,	O
2019	O
)	O
67.9	O
−	O
68.2	O
UHop	O
(	O
Chen	O
et	O
al	O
.	O
,	O
2019	O
)	O
68.5	O
−	O
−	O
NSM	O
(	O
Liang	O
et	O
al	O
.	O
,	O
2017	O
)	O
69.0	O
−	O
−	O
ReTrack	O
(	O
Chen	O
et	O
al	O
.	O
,	O
2021	O
)	O
71.0	O
−	O
71.6	O
STAGG	O
(	O
Yih	O
et	O
al	O
.	O
,	O
2015	O
)	O
71.7	O
63.9	O
−	O
CBR	O
(	O
Das	O
et	O
al	O
.	O
,	O
2021	O
)	O
72.8	O
70.0	O
−	O
QGG	O
(	O
Lan	O
and	O
Jiang	O
,	O
2020	O
)	O
74.0	O
−	O
−	O
RNG	O
-	O
KBQA	I-MethodName
(	O
Ours	O
)	O
75.6	O
71.1	O
−	O
ing	O
BERT	O
-	O
base	O
-	O
uncased	O
,	O
and	O
the	O
generator	O
using	O
T5	O
-	O
base	O
.	O
We	O
also	O
sample	O
96	O
negative	O
candidates	O
for	O
each	O
question	O
,	O
and	O
feed	O
the	O
top-5	O
candidates	O
to	O
the	O
generation	O
model	O
.	O
The	O
ranker	O
is	O
trained	O
for	O
10	O
epochs	O
and	O
we	O
run	O
bootstrapping	O
every	O
2	O
epochs	O
;	O
the	O
generator	O
is	O
trained	O
for	O
20	O
epochs	O
.	O

Unsupervised	O
curation	O
.	O
We	O
consider	O
explicitly	O
mining	O
AT	O
pairs	O
from	O
vip	O
-	O
AnT.	O
Because	O
this	O
zeroresource	O
method	O
uses	O
no	O
human	O
supervision	O
,	O
we	O
refer	O
to	O
it	O
as	O
"	O
unsupervised	O
curation	O
.	O
"	O
Concretely	O
,	O
for	O
each	O
video	O
segment	O
in	O
AudioSet	O
,	O
we	O
extract	O
a	O
video	O
frame	O
,	O
and	O
input	O
that	O
frame	O
to	O
the	O
original	O
CLIP	O
image	O
encoder	O
.	O
Then	O
,	O
we	O
encode	O
a	O
large	O
Unsupervised	O
(	O
Zero	O
-	O
resource	O
)	O
AC	O
Audio	O
-	O
focused	O
Captions	O
originate	O
from	O
the	O
training	O
captions	O
of	O
AudioCaps	B-MethodName
and	O
Clotho	O
.	O
We	O
perform	O
caption	O
retrieval	O
by	O
using	O
CLIP	B-DatasetName
and	O
the	O
prompt	O
"	O
the	O
sound	O
of	O
"	O
.	O
(	O
1080078	O
aligned	O
pairs	O
)	O
example	O
A	O
balloon	O
is	O
rubbed	O
quickly	O
and	O
slowly	O
to	O
make	O
squeaking	O
sounds	O
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
both	O
of	O
our	O
sentiment	O
analysis	O
datasets	O
are	O
the	O
first	O
of	O
their	O
kind	O
,	O
as	O
no	O
movie	O
reviews	O
of	O
comparable	O
size	O
were	O
collected	O
before	O
.	O
For	O
instance	O
,	O
a	O
similar	O
corpus	O
published	O
by	O
YTU	O
Kemik	O
NLP	O
Group	O
9	O
contains	O
reviews	O
of	O
mere	O
105	O
movies	O
classified	O
in	O
only	O
3	O
classes	O
(	O
negative	O
,	O
positive	O
,	O
and	O
neutral	O
)	O
.	O
Considering	O
that	O
modern	O
NLP	O
techniques	O
require	O
large	O
corpora	O
,	O
our	O
movie	O
reviews	O
datasets	O
are	O
sufficiently	O
large	O
and	O
can	O
thus	O
be	O
meaningfully	O
used	O
by	O
the	O
Turkish	O
NLP	O
community	O
.	O

The	O
first	O
analysis	O
involves	O
comparing	O
all	O
methods	O
on	O
long	O
-	O
term	O
success	O
rate	O
,	O
which	O
measures	O
the	O
percentage	O
of	O
control	O
words	O
in	O
generated	O
simulated	O
roll	O
-	O
outs	O
.	O
To	O
do	O
this	O
,	O
we	O
train	O
a	O
separate	O
user	O
model	O
with	O
the	O
training	O
dataset	O
.	O
We	O
perform	O
a	O
roll	O
-	O
out	O
per	O
test	O
example	O
with	O
10	O
generated	O
system	O
responses	O
and	O
10	O
generated	O
user	O
responses	O
and	O
compute	O
the	O
percentage	O
of	O
control	O
words	O
in	O
the	O
generated	O
system	O
responses	O
.	O
When	O
counting	O
the	O
number	O
of	O
generated	O
words	O
,	O
we	O
compare	O
word	O
stems	O
.	O

Each	O
of	O
the	O
role	O
labeling	O
formalisms	O
offers	O
certain	O
advantages	O
and	O
disadvantages	O
(	O
Giuglea	O
and	O
Moschitti	O
,	O
2006;Mújdricza	O
-	O
Maydt	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
While	O
being	O
close	O
to	O
syntax	O
and	O
thereby	O
easier	O
to	O
predict	O
,	O
PropBank	B-MethodName
does	O
n't	O
contribute	O
much	O
semantics	O
to	O
the	O
representation	O
.	O
On	O
the	O
opposite	O
side	O
of	O
the	O
spectrum	O
,	O
FrameNet	O
offers	O
rich	O
predicatesemantic	O
representations	O
for	O
verbs	O
and	O
nouns	O
,	O
but	O
suffers	O
from	O
high	O
granularity	O
and	O
coverage	O
gaps	O
(	O
Hartmann	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
VerbNet	O
takes	O
a	O
middle	O
ground	O
by	O
following	O
grammatical	O
criteria	O
while	O
still	O
encoding	O
coarse	O
-	O
grained	O
semantics	O
,	O
but	O
only	O
focuses	O
on	O
verbs	O
and	O
core	O
(	O
not	O
modifier	O
)	O
roles	O
.	O
SPR	B-MethodName
avoids	O
the	O
granularity	O
-	O
generalization	O
trade	O
-	O
off	O
of	O
the	O
categorical	O
inventories	O
,	O
but	O
is	O
yet	O
to	O
find	O
its	O
way	O
into	O
practical	O
NLP	O
applications	O
.	O

A	O
simple	O
answer	O
to	O
this	O
question	O
is	O
concatenation	O
of	O
the	O
values	O
v	O
i	O
,	O
given	O
by	O

Then	O
we	O
obtain	O
an	O
attribution	O
score	O
per	O
word	O
,	O
ω	O
(	O
i	O
)	O

In	O
this	O
section	O
,	O
we	O
empirically	O
validate	O
the	O
effectiveness	O
of	O
our	O
PQA	B-TaskName
-	I-MethodName
ColBERT	I-MethodName
,	O
with	O
respect	O
to	O
ranking	O
performance	O
on	O
passage	O
ranking	O
task	O
.	O
We	O
report	O
results	O
for	O
a	O
single	O
run	O
.	O

Figure	O
4	O
:	O
Pool	O
selection	O
(	O
for	O
one	O
student	O
)	O
suffers	O
worse	O
question	O
quality	O
vs.	O
latency	O
trade	O
-	O
off	O
than	O
question	O
generation	I-TaskName
,	O
especially	O
for	O
sampling	O
difficult	O
questions	O
.	O

Definition	O
2	O
Let	O
M	O
and	O
M	O
′	O
be	O
two	O
TDA	O
Mapper	O
graphs	O
with	O
vertices	O
V	O
=	O
{	O
C	O
1	O
,	O
.	O
.	O
.	O
,	O
C	O
n	O
}	O
;	O
V	O
′	O
=	O
{	O
C	O
′	O
1	O
,	O
.	O
.	O
.	O
,	O
C	O
′	O
m	O
}	O
;	O
and	O
edges	O
E	O
and	O
E	O
′	O
,	O
respectively	O
.	O
If	O
m	O
̸	O
=	O
n	O
,	O
then	O
empty	O
set	O
padding	O
is	O
added	O
to	O
the	O
smaller	O
vertex	O
set	O
so	O
that	O
m	O
=	O
n.	O
The	O
distance	O

A	O
solid	O
body	O
of	O
evidence	O
suggests	O
that	O
encoders	O
like	O
BERT	B-MethodName
capture	O
syntactic	O
and	O
lexical	O
-	O
semantic	O
properties	O
,	O
but	O
only	O
few	O
studies	O
have	O
considered	O
probing	O
for	O
predicate	O
-	O
level	O
semantics	O
(	O
Tenney	O
et	O
al	O
.	O
,	O
2019b;Kovaleva	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
we	O
are	O
the	O
first	O
to	O
conduct	O
a	O
cross	O
-	O
formalism	O
probing	O
study	O
on	O
role	O
semantics	O
,	O
thereby	O
contributing	O
to	O
the	O
line	O
of	O
research	O
on	O
how	O
and	O
whether	O
pre	O
-	O
trained	O
BERT	B-MethodName
encodes	O
higher	O
-	O
level	O
semantic	O
phenomena	O
.	O

We	O
evaluate	O
our	O
method	O
on	O
various	O
tasks	O
including	O
language	O
modeling	O
,	O
word	O
similarity	I-TaskName
,	O
and	O
machine	O
translation	I-TaskName
.	O
In	O
the	O
language	O
modeling	O
task	O
,	O
we	O
focus	O
on	O
verifying	O
the	O
diversity	O
of	O
the	O
generated	O
texts	O
.	O

We	O
build	O
an	O
amortized	O
explanation	O
model	O
for	O
text	O
classification	O
in	O
two	O
stages	O
.	O
In	O
the	O
first	O
stage	O
,	O
we	O
construct	O
a	O
training	O
set	O
for	O
the	O
amortized	O
model	O
.	O
We	O
compute	O
reliable	O
explanation	O
scores	O
as	O
the	O
reference	O
scores	O
for	O
training	O
using	O
the	O
existing	O
SV	O
estimator	O
.	O
As	O
shown	O
in	O
Section	O
4	O
,	O
SVS-25	O
is	O
the	O
most	O
stable	O
SV	O
estimator	O
and	O
we	O
use	O
it	O
to	O
obtain	O
reference	O
scores	O
.	O
In	O
the	O
second	O
stage	O
,	O
we	O
train	O
a	O
BERT	B-MethodName
-	O
based	O
amortized	O
model	O
that	O
takes	O
the	O
text	O
as	O
input	O
and	O
outputs	O
the	O
explanation	O
scores	O
using	O
MSE	O
loss	O
.	O

As	O
presented	O
in	O
Table	O
3	O
,	O
our	O
models	O
achieve	O
enhanced	O
performance	O
for	O
rare	O
entities	O
.	O
Furthermore	O
,	O
the	O
global	O
models	O
consistently	O
outperform	O
the	O
local	O
model	O
both	O
for	O
rare	O
and	O
frequent	O
entities	O
.	O

Models	O
.	O
We	O
experiment	O
with	O
12	O
models	O
in	O
total	O
.	O
We	O
include	O
6	O
language	O
models	O
(	O
Table	O
1	O
)	O
,	O
all	O
of	O
which	O
are	O
decoder	O
-	O
only	O
,	O
dense	O
LMs	O
.	O
We	O
use	O
each	O
LM	O
with	O
two	O
inference	O
methods	O
,	O
direct	O
and	O
channel	O
,	O
following	O
Min	O
et	O
al	O
.	O
(	O
2021a	O
)	O
.	O
The	O
sizes	O
of	O
LMs	O
vary	O
from	O
774	O
M	O
to	O
175B.	O
We	O
include	O
the	O
Figure	O
3	O
:	O
Results	O
when	O
using	O
no	O
-	O
demonstrations	O
,	O
demonstrations	O
with	O
gold	O
labels	O
,	O
and	O
demonstrations	O
with	O
random	O
labels	O
in	O
classification	O
(	O
top	O
)	O
and	O
multi	O
-	O
choice	O
tasks	O
(	O
bottom	O
)	O
.	O
The	O
first	O
eight	O
models	O
are	O
evaluated	O
on	O
16	O
classification	O
and	O
10	O
multi	O
-	O
choice	O
datasets	O
,	O
and	O
the	O
last	O
four	O
models	O
are	O
evaluated	O
on	O
3	O
classification	O
and	O
3	O
multi	O
-	O
choice	O
datasets	O
.	O
See	O
Figure	O
11	O
for	O
numbers	O
comparable	O
across	O
all	O
models	O
.	O
Model	O
performance	O
with	O
random	O
labels	O
is	O
very	O
close	O
to	O
performance	O
with	O
gold	O
labels	O
(	O
more	O
discussion	O
in	O
Section	O
4.1	O
)	O
.	O

The	O
echo	O
chamber	O
objective	O
is	O
motivated	O
by	O
the	O
echo	O
chamber	O
phenomenon	O
(	O
Jamieson	O
and	O
Cappella	O
,	O
2008	O
;	O
Barberá	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
where	O
social	O
entities	O
tend	O
to	O
reinforce	O
their	O
narratives	O
by	O
forming	O
small	O
and	O
closely	O
connected	O
interaction	O
circles	O
.	O
We	O
simulate	O
echo	O
chambers	O
by	O
assuming	O
that	O
neighboring	O
nodes	O
in	O
the	O
HIN	O
have	O
similar	O
representations	O
while	O
non	O
-	O
neighboring	O
nodes	O
have	O
different	O
representations	O
.	O
We	O
firstly	O
define	O
the	O
positive	O
and	O
negative	O
neighborhood	O
of	O
entity	O
e	O
i	O
:	O

•	O
Real	O
life	O
problems	O
&	O
societal	O
implications	O
(	O
e.g.	O
,	O
hallucinations	O
,	O
biases	O
,	O
future	O
job	O
market	O
)	O
;	O

The	O
schema	O
translation	O
dataset	O
presented	O
in	O
this	O
work	O
is	O
a	O
free	O
and	O
open	O
resource	O
for	O
the	O
community	O
to	O
study	O
the	O
newly	O
proposed	O
translation	O
task	O
.	O
English	O
tables	O
collected	O
are	O
from	O
three	O
sources	O
.	O
First	O
,	O
we	O
collect	O
all	O
tables	O
from	O
the	O
WikiTableQuestions	O
dataset	O
(	O
Pasupat	O
and	O
Liang	O
,	O
2015	O
)	O
,	O
which	O
is	O
a	O
free	O
and	O
open	O
dataset	O
for	O
the	O
research	O
of	O
question	O
answering	O
task	O
on	O
semi	O
-	O
structured	O
HTML	O
ta	O
-	O
bles	O
.	O
Since	O
all	O
of	O
the	O
tables	O
are	O
collected	O
from	O
open	O
-	O
access	O
Wikipedia	O
pages	O
,	O
there	O
is	O
no	O
privacy	O
issue	O
.	O
Second	O
,	O
we	O
collect	O
176	O
English	O
tables	O
from	O
the	O
search	O
engines	O
which	O
are	O
also	O
publicly	O
available	O
and	O
do	O
not	O
contain	O
personal	O
data	O
.	O
To	O
Further	O
enlarge	O
our	O
dataset	O
,	O
we	O
select	O
all	O
tables	O
from	O
the	O
training	O
set	O
and	O
development	O
set	O
of	O
the	O
Spider	O
dataset	O
(	O
Yu	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
which	O
is	O
also	O
a	O
free	O
and	O
open	O
dataset	O
for	O
research	O
use	O
.	O
Since	O
the	O
tables	O
from	O
the	O
Spider	O
dataset	O
are	O
mainly	O
collected	O
from	O
openaccess	O
online	O
csv	O
files	O
,	O
college	O
database	O
courses	O
and	O
SQL	O
websites	O
,	O
there	O
is	O
no	O
privacy	O
issue	O
either	O
.	O
For	O
the	O
translation	O
step	O
,	O
we	O
hire	O
professional	O
translators	O
to	O
translate	O
the	O
collected	O
English	O
tables	O
to	O
five	O
target	O
languages	O
and	O
the	O
details	O
can	O
be	O
found	O
in	O
Section	O
2	O
.	O

•	O
NonSim	O
-General	O
.	O
Any	O
other	O
edit	O
that	O
does	O
not	O
contribute	O
to	O
(	O
Lexical	O
,	O
Syntactic	O
,	O
Discourse	O
,	O
Semantic	O
)	O
simplification	O
,	O
but	O
does	O
not	O
fit	O
in	O
any	O
other	O
category	O
.	O

We	O
partition	O
politicians	O
into	O
left	O
,	O
center	O
,	O
and	O
right	O
ideologies	O
,	O
containing	O
those	O
whose	O
ideology	O
score	O
is	O
less	O
than	O
-0.2	O
,	O
between	O
-0.2	O
and	O
0.2	O
,	O
and	O
above	O
0.2	O
,	O
respectively	O
.	O
The	O
distribution	O
of	O
these	O
scores	O
is	O
shown	O
in	O
Figure	O
3	O
.	O
Finally	O
,	O
we	O
discard	O
tweets	O
without	O
images	O
,	O
leaving	O
57,093	O
tweets	O
from	O
1,422	O
politicians	O
as	O
our	O
final	O
evaluation	O
dataset	O
.	O
More	O
details	O
are	O
summarized	O
in	O
Table	O
2	O
.	O

Our	O
probing	O
kit	O
spans	O
a	O
wide	O
range	O
of	O
probing	O
tasks	O
,	O
from	O
primitive	O
surface	O
-	O
level	O
tasks	O
mostly	O
utilized	O
as	O
anchors	O
later	O
to	O
high	O
-	O
level	O
semantic	O
tasks	O
that	O
language	O
en	O
de	O
aim	O
to	O
provide	O
a	O
representational	O
upper	O
bound	O
to	O
predicate	O
semantics	O
.	O
We	O
follow	O
the	O
training	O
,	O
test	O
and	O
development	O
splits	O
from	O
the	O
original	O
SR3de	O
,	O
CoNLL-2009	B-DatasetName
and	O
SPR	B-TaskName
data	O
.	O
The	O
XNLI	O
task	O
is	O
sourced	O
from	O
the	O
development	O
set	O
and	O
only	O
used	O
for	O
scalar	O
mix	O
analysis	O
.	O
To	O
reduce	O
the	O
number	O
of	O
labels	O
in	O
some	O
of	O
the	O
probing	O
tasks	O
,	O
we	O
collect	O
frequency	O
statistics	O
over	O
the	O
corresponding	O
training	O
sets	O
and	O
only	O
consider	O
up	O
to	O
250	O
most	O
frequent	O
labels	O
.	O
Below	O
we	O
define	O
the	O
tasks	O
in	O
order	O
of	O
their	O
complexity	O
,	O
Table	O
2	O
provides	O
the	O
probing	O
task	O
statistics	O
,	O
Table	O
3	O
compares	O
the	O
categorical	O
role	O
labeling	O
formalisms	O
in	O
terms	O
of	O
granularity	O
,	O
and	O
Table	O
4	O
provides	O
examples	O
.	O
We	O
evaluate	O
the	O
classification	O
performance	O
using	O
Accuracy	O
,	O
while	O
regression	O
tasks	O
are	O
scored	O
via	O
R	O
2	O
.	O

For	O
each	O
sample	O
x	O
i	O
,	O
the	O
embedding	O
is	O
defined	O
as	O
follows	O
:	O

Given	O
a	O
biased	O
training	O
dataset	O
,	O
a	O
text	O
classifier	O
may	O
absorb	O
the	O
biases	O
and	O
produce	O
biased	O
predictions	O
against	O
some	O
sub	O
-	O
populations	O
.	O
We	O
hypothesize	O
that	O
if	O
the	O
biases	O
are	O
captured	O
by	O
some	O
of	O
the	O
learned	O
features	O
,	O
we	O
can	O
apply	O
FIND	O
to	O
disable	O
such	O
features	O
and	O
reduce	O
the	O
model	O
biases	O
.	O

While	O
our	O
work	O
illustrates	O
the	O
impact	O
of	O
formalism	O
using	O
a	O
single	O
task	O
and	O
a	O
single	O
probing	O
framework	O
,	O
the	O
influence	O
of	O
linguistic	O
formalism	O
per	O
se	O
is	O
likely	O
to	O
be	O
present	O
for	O
any	O
probing	O
setup	O
that	O
builds	O
upon	O
linguistic	O
material	O
.	O
An	O
investigation	O
of	O
how	O
,	O
whether	O
,	O
and	O
why	O
formalisms	O
and	O
their	O
implementations	O
affect	O
probing	O
results	O
for	O
tasks	O
beyond	O
role	O
labeling	O
and	O
for	O
frameworks	O
beyond	O
edge	O
probing	O
constitutes	O
an	O
exciting	O
avenue	O
for	O
future	O
research	O
.	O

VerbNet	O
follows	O
a	O
different	O
categorization	O
scheme	O
.	O
Motivated	O
by	O
the	O
regularities	O
in	O
verb	O
behavior	O
,	O
Levin	O
(	O
1993	O
)	O
has	O
introduced	O
the	O
group	O
-	O
ing	O
of	O
verbs	O
into	O
intersective	O
classes	O
(	O
ILC	O
)	O
.	O
This	O
methodology	O
has	O
been	O
adopted	O
by	O
VerbNet	O
:	O
for	O
example	O
,	O
the	O
VerbNet	O
class	O
get-13.5.1	O
would	O
include	O
verbs	O
earn	O
,	O
fetch	O
,	O
gain	O
etc	O
.	O
A	O
verb	O
in	O
Verb	O
-	O
Net	O
can	O
belong	O
to	O
several	O
classes	O
corresponding	O
to	O
different	O
senses	O
;	O
each	O
class	O
is	O
associated	O
with	O
a	O
set	O
of	O
roles	O
and	O
licensed	O
syntactic	O
transformations	O
.	O
Unlike	O
PropBank	B-MethodName
,	O
VerbNet	B-MethodName
uses	O
a	O
set	O
of	O
approx	O
.	O
30	O
thematic	O
roles	O
that	O
have	O
universal	O
definitions	O
and	O
are	O
shared	O
among	O
predicates	O
,	O
e.g.	O
Agent	O
,	O
Beneficiary	O
,	O
Instrument	O
.	O

Fine	O
-	O
tuned	O
:	O
This	O
approach	O
simply	O
generates	O
responses	O
using	O
the	O
fine	O
-	O
tuned	O
language	O
model	O
M	O
.	O

We	O
also	O
analyze	O
the	O
importance	O
of	O
local	O
hierarchyaware	O
text	O
encoder	O
by	O
comparing	O
it	O
with	O
two	O
methods	O
:	O
multi	O
-	O
label	O
and	O
seq2seq	O
.	O
For	O
multi	O
-	O
label	O
,	O
we	O
fine	O
-	O
tune	O
BERT	B-MethodName
as	O
the	O
multi	O
-	O
label	O
classifier	O
.	O
For	O
seq2seq	O
,	O
we	O
fine	O
-	O
tune	O
BERT	B-MethodName
as	O
the	O
seq2seq	O
model	O
following	O
s2s	O
-	O
ft	O
,	O
where	O
target	O
labels	O
are	O
sorted	O
according	O
to	O
their	O
levels	O
in	O
the	O
global	O
hierarchy	O
.	O
Local	O
hierarchy	O
-	O
aware	O
text	O
encoder	O
achieves	O
the	O
best	O
performance	O
in	O
Table	O
4	O
.	O

Table	O
4	O
presents	O
the	O
results	O
for	O
the	O
documentlevel	O
feature	O
-	O
based	O
and	O
BiRNN	B-MethodName
neural	O
QE	O
models	O
.	O
1	O
The	O
first	O
section	O
shows	O
the	O
official	O
models	O
from	O
the	O
WMT'18	B-DatasetName
QE	O
Task	O
4	O
report	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018a	O
)	O
.	O
The	O
neural	O
-	O
based	O
approach	O
SHEF	O
-	O
PT	O
is	O
the	O
winning	O
submission	O
,	O
outperforming	O
another	O
neural	O
-	O
based	O
approach	O
(	O
SHEF	O
-	O
mtl	O
-	O
bRNN	O
)	O
.	O
For	O
our	O
BiRNN	B-MethodName
models	O
(	O
second	O
section	O
)	O
,	O
BiRNN+Visembed	B-MethodName
-	O
conc	O
performs	O
only	O
slightly	O
better	O
than	O
the	O
monomodal	O
baseline	O
.	O
For	O
the	O
feature	O
-	O
based	O
models	O
(	O
third	O
section	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
the	O
baseline	O
monomodal	O
QuEst++	O
is	O
outperformed	O
by	O
various	O
multimodal	O
variants	O
by	O
a	O
large	O
margin	O
,	O
with	O
the	O
one	O
with	O
two	O
principal	O
components	O
(	O
QuEst+Vis-2	O
)	O
performing	O
the	O
best	O
.	O
The	O
more	O
PCA	O
components	O
kept	O
,	O
the	O
worse	O
the	O
results	O
(	O
see	O
Appendix	O
for	O
full	O
set	O
of	O
results	O
)	O
.	O
Figure	O
3	O
shows	O
the	O
Williams	O
significance	O
test	O
for	O
document	O
-	O
level	O
QuEst++	B-MethodName
on	O
the	O
WMT'18	B-DatasetName
dataset	O
.	O

In	O
this	O
section	O
,	O
we	O
elaborate	O
on	O
how	O
we	O
extend	O
SimCSE	B-MethodName
to	O
multilingual	O
and	O
illustrate	O
our	O
proposed	O
mSimCSE	B-MethodName
in	O
Figure	O
2	O
.	O
We	O
explore	O
four	O
different	O
multilingual	O
training	O
strategies	O
,	O
including	O
the	O
unsupervised	O
strategy	O
,	O
the	O
English	O
NLI	O
supervised	O
strategy	O
,	O
the	O
parallel	O
NLI	O
supervised	O
strategy	O
,	O
and	O
the	O
fully	O
supervised	O
strategy	O
.	O
The	O
difference	O
between	O
different	O
strategies	O
is	O
how	O
to	O
define	O
a	O
positive	O
training	O
pair	O
.	O
Here	O
,	O
both	O
unsupervised	O
and	O
English	O
NLI	O
supervised	O
strategies	O
can	O
be	O
recognized	O
as	O
an	O
"	O
unsupervised	O
"	O
setting	O
for	O
multilingual	O
training	O
because	O
both	O
of	O
them	O
only	O
use	O
English	O
data	O
and	O
do	O
not	O
use	O
any	O
parallel	O
data	O
.	O

Our	O
model	O
consists	O
of	O
approximately	O
440	O
million	O
parameters	O
.	O
To	O
reduce	O
the	O
training	O
time	O
,	O
the	O
parameters	O
that	O
are	O
shared	O
with	O
BERT	B-MethodName
are	O
initialized	O
using	O
BERT	B-MethodName
.	O
The	O
other	O
parameters	O
are	O
initialized	O
randomly	O
.	O
The	O
model	O
is	O
trained	O
via	O
iterations	O
over	O
Wikipedia	O
pages	O
in	O
a	O
random	O
order	O
for	O
seven	O
epochs	O
.	O
To	O
stabilize	O
the	O
training	O
,	O
we	O
update	O
only	O
those	O
parameters	O
that	O
are	O
randomly	O
initialized	O
(	O
i.e.	O
,	O
fixed	O
the	O
parameters	O
initialized	O
using	O
BERT	B-MethodName
)	O
at	O
the	O
first	O
epoch	O
,	O
and	O
update	O
all	O
parameters	O
in	O
the	O
remaining	O
six	O
epochs	O
.	O
We	O
implement	O
the	O
model	O
using	O
PyTorch	O
(	O
Paszke	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Hugging	O
Face	O
Transformers	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
and	O
the	O
training	O
takes	O
approximately	O
ten	O
days	O
using	O
eight	O
Tesla	O
V100	O
GPUs	O
.	O
We	O
optimize	O
the	O
model	O
using	O
AdamW.	O
The	O
hyper	O
-	O
parameters	O
used	O
in	O
the	O
training	O
are	O
detailed	O
in	O
Table	O
4	O
.	O

We	O
define	O
a	O
column	O
header	O
as	O
H	O
i	O
=	O
hh	O
1	O
,	O
.	O
.	O
.	O
,	O
h	O
n	O
i	O
,	O
where	O
h	O
j	O
is	O
the	O
jth	O
token	O
of	O
the	O
header	O
in	O
the	O
source	O
language	O
.	O

Electric	O
can	O
produce	O
PLLs	O
for	O
all	O
input	O
tokens	O
in	O
a	O
single	O
pass	O
like	O
a	O
LM	O
while	O
being	O
bidirectional	O
like	O
a	O
masked	O
LM	O
.	O
We	O
use	O
the	O
PLLs	O
from	O
Electric	O
for	O
re	O
-	O
ranking	O
the	O
100	O
-	O
best	O
hypotheses	O
of	O
a	O
5	O
-	O
layer	O
BLSTMP	B-MethodName
model	O
from	O
ESPnet	B-MethodName
(	O
Watanabe	O
et	O
al	O
.	O
,	O
2018	O
)	O
on	O
the	O
960	O
-	O
hour	O
LibriSpeech	O
corpus	O
(	O
Panayotov	O
et	O
al	O
.	O
,	O
2015	O
)	O
following	O
the	O
same	O
experimental	O
setup	O
and	O
using	O
the	O
same	O
n	O
-	O
best	O
lists	O
as	O
Salazar	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
Given	O
speech	O
features	O
s	O
and	O
speech	O
recognition	O
model	O
f	O
the	O
re	O
-	O
ranked	O
output	O
is	O
arg	O
max	O

Our	O
goal	O
is	O
to	O
mitigate	O
metric	O
bias	O
while	O
maintaining	O
a	O
considerable	O
performance	O
for	O
evaluating	O
text	O
generation	O
.	O
However	O
,	O
existing	O
bias	O
mitigation	O
methods	O
usually	O
modify	O
all	O
parameters	O
of	O
the	O
PLM	O
and	O
suffers	O
from	O
high	O
computational	O
cost	O
and	O
catastrophic	O
forgetting	O
(	O
French	O
,	O
1993	O
)	O
,	O
which	O
may	O
lead	O
to	O
degraded	O
performance	O
.	O
Instead	O
,	O
following	O
,	O
we	O
insert	O
lightweight	O
neural	O
adapters	O
(	O
Houlsby	O
et	O
al	O
.	O
,	O
2019	O
;	O
Pfeiffer	O
et	O
al	O
.	O
,	O
2021	O
)	O
into	O
the	O
PLM	O
layers	O
.	O
By	O
incorporating	O
debiasing	O
knowledge	O
into	O
the	O
injected	O
adapters	O
while	O
keeping	O
the	O
PLM	O
parameters	O
untouched	O
,	O
we	O
can	O
reduce	O
the	O
bias	O
of	O
interest	O
in	O
a	O
plug	O
-	O
and	O
-	O
play	O
style	O
while	O
retaining	O
most	O
of	O
the	O
original	O
performance	O
.	O

It	O
is	O
well	O
known	O
that	O
MP	O
is	O
the	O
key	O
bottleneck	O
for	O
scaling	O
MPNNs	B-TaskName
to	O
large	O
graphs	O
(	O
Jin	O
et	O
al	O
.	O
,	O
2021	O
;	O
Zhang	O
et	O
al	O
.	O
,	O
2022a	O
;	O
Zhao	O
et	O
al	O
.	O
,	O
2022	O

comparing	O
both	O
generation	O
models	O
to	O
a	O
retrieval	O
approach	O
as	O
a	O
strong	O
upper	O
bound	O
.	O
The	O
retrieval	O
approach	O
returns	O
all	O
arguments	O
from	O
the	O
classified	O
training	O
data	O
(	O
see	O
Section	O
4	O
)	O
that	O
match	O
a	O
given	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
.	O
Both	O
the	O
retrieval	O
and	O
generation	O
approaches	O
are	O
evaluated	O
against	O
reference	O
data	O
from	O
debate	O
portals	O
and	O
compared	O
via	O
METEOR	O
(	O
Lavie	O
and	O
Agarwal	O
,	O
2007	O
)	O
and	O
ROUGE	O
-	O
L	O
(	O
Lin	O
,	O
2004	O
)	O
metrics	O
.	O
The	O
retrieval	O
approach	O
has	O
an	O
advantage	O
in	O
this	O
setup	O
,	O
as	O
the	O
arguments	O
are	O
also	O
of	O
human	O
origin	O
and	O
aspects	O
are	O
always	O
explicitly	O
stated	O
within	O
a	O
belonging	O
argument	O
.	O

To	O
train	O
a	O
QG	O
model	O
to	O
generate	O
the	O
questions	O
that	O
cover	O
as	O
many	O
contextual	O
information	O
as	O
possible	O
,	O
we	O
use	O
the	O
question	O
that	O
contains	O
the	O
most	O
contextual	O
arguments	O
as	O
the	O
ground	O
truth	O
.	O
For	O
the	O
example	O
in	O
Figure	O
1	O
,	O
we	O
choose	O
the	O
question	O
'	O
Who	O
used	O
jets	O
in	O
the	O
attack	O
in	O
hills	O
?	O
'	O
,	O
because	O
it	O
contains	O
two	O
arguments	O
:	O
'	O
jets	O
'	O
and	O
'	O
hills	O
'	O
,	O
the	O
other	O
three	O
candidate	O
questions	O
listed	O
above	O
contain	O
one	O
or	O
zero	O
arguments	O
.	O
If	O
more	O
than	O
one	O
candidate	O
question	O
contains	O
the	O
most	O
contextual	O
arguments	O
,	O
we	O
then	O
pick	O
the	O
first	O
one	O
.	O
The	O
input	O
and	O
output	O
examples	O
for	O
the	O
QG	O
model	O
are	O
as	O
follows	O
:	O

p	O
∈	O
{	O
[	O
xReact	O
]	O
,	O
[	O
xIntent	O
]	O
,	O
[	O
xWant	O
]	O
,	O
[	O
xNeed	O
]	O
,	O
[	O
xEffect	O
]	O
}	O

(	O
2	O
)	O
The	O
test	O
KB	O
used	O
by	O
these	O
works	O
is	O
different	O
from	O
our	O
test	O
KB	O
.	O
Each	O
entry	O
in	O
the	O
KB	O
used	O
by	O
prior	O
work	O
simply	O
consists	O
of	O
the	O
name	O
of	O
the	O
entity	O
with	O
a	O
textual	O
description	O
,	O
while	O
each	O
entity	O
in	O
our	O
KB	O
is	O
represented	O
via	O
multiple	O
attribute	O
-	O
value	O
pairs	O
.	O
(	O
3	O
)	O
These	O
models	O
exploit	O
the	O
homogeneous	O
nature	O
of	O
the	O
KBs	O
and	O
usually	O
pre	O
-	O
train	O
models	O
on	O
millions	O
of	O
mentions	O
from	O
Wikipedia	O
.	O
This	O
is	O
beneficial	O
when	O
the	O
training	O
and	O
test	O
KBs	O
are	O
Wikipedia	O
or	O
similar	O
,	O
but	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
work	O
,	O
as	O
we	O
build	O
models	O
applicable	O
to	O
arbitrary	O
databases	O
.	O

•	O
Modal	O
-	O
Trans	O
Tang	O
et	O
al	O
.	O
,	O
2021	O
)	O
builds	O
a	O
cyclic	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
and	O
learns	O
bidirectional	O
reconstruction	O
.	O

What	O
are	O
the	O
important	O
entities	O
in	O
this	O
document	O
?	O
What	O
are	O
the	O
important	O
dates	O
in	O
this	O
document	O
?	O
What	O
events	O
are	O
happening	O
in	O
this	O
document	O
?	O
What	O
is	O
the	O
result	O
of	O
these	O
events	O
?	O
Please	O
answer	O
the	O
above	O
questions	O
:	O

•	O
Further	O
fine	O
-	O
tune	O
the	O
dialogue	O
response	O
generator	O
trained	O
with	O
ground	O
-	O
truth	O
partner	O
personas	O
to	O
adapt	O
to	O
noisy	O
partner	O
personas	O
generated	O
by	O
the	O
partner	O
personas	O
generator	O
.	O

Table	O
4	O
shows	O
the	O
results	O
on	O
the	O
GCDC	B-DatasetName
Clinton	O
and	O
TOEFL	O
P1	O
datasets	O
.	O
We	O
can	O
observe	O
from	O
the	O
table	O
that	O
eliminating	O
any	O
type	O
of	O
edges	O
would	O
hurt	O
the	O
performance	O
.	O
The	O
decline	O
in	O
performance	O
is	O
more	O
significant	O
when	O
removing	O
the	O
EDS	O
than	O
eliminating	O
the	O
ESS	O
.	O
The	O
results	O
are	O
reasonable	O
because	O
edges	O
between	O
documents	O
and	O
subgraphs	O
are	O
the	O
key	O
to	O
connecting	O
documents	O
with	O
similar	O
structures	O
,	O
while	O
edges	O
between	O
subgraphs	O
are	O
considered	O
to	O
further	O
assist	O
it	O
(	O
Kondor	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O

as	O
ELECTRA	B-MethodName
's	O
(	O
Clark	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
which	O
adds	O
some	O
additional	O
ideas	O
from	O
on	O
top	O
of	O
the	O
BERT	B-MethodName
codebase	O
,	O
such	O
as	O
dynamic	O
masking	O
and	O
removing	O
the	O
next	O
-	O
sentence	O
prediction	O
task	O
.	O
We	O
use	O
the	O
weight	O
sharing	O
trick	O
from	O
ELECTRA	O
,	O
where	O
the	O
transformers	O
producing	O
the	O
proposal	O
distribution	O
and	O
the	O
main	O
transformer	O
share	O
token	O
embeddings	O
.	O
We	O
do	O
not	O
use	O
whole	O
-	O
word	O
or	O
n	O
-	O
gram	O
masking	O
,	O
although	O
we	O
believe	O
it	O
would	O
improve	O
results	O
too	O
.	O
We	O
did	O
no	O
hyperparameter	O
tuning	O
,	O
directly	O
using	O
the	O
hyperparameters	O
from	O
ELECTRA	B-MethodName
-	I-MethodName
Base	I-MethodName
for	O
Electric	O
and	O
our	O
baselines	O
.	O
These	O
hyperparameters	O
are	O
slightly	O
modified	O
from	O
the	O
ones	O
used	O
in	O
BERT	B-MethodName
;	O
for	O
completeness	O
,	O
we	O
show	O
these	O
values	O
in	O
Table	O
3	O
.	O
The	O
hidden	O
sizes	O
,	O
feed	O
-	O
forward	O
hidden	O
sizes	O
,	O
and	O
number	O
of	O
attention	O
heads	O
of	O
the	O
two	O
transformers	O
T	O
LTR	O
and	O
T	O
RTL	O
used	O
to	O
produce	O
the	O
proposal	O
distribution	O
are	O
1/4	O
the	O
size	O
of	O
Electric	O
.	O
We	O
chose	O
this	O
value	O
because	O
it	O
keeps	O
the	O
compute	O
comparable	O
to	O
ELECTRA	O
;	O
running	O
two	O
1/4	O
-	O
sized	O
transformers	O
takes	O
roughly	O
the	O
same	O
compute	O
as	O
running	O
one	O
1/3sized	O
transformer	O
,	O
which	O
is	O
the	O
size	O
of	O
ELECTRA	O
's	O
generator	O
.	O
To	O
make	O
the	O
compute	O
exactly	O
equal	O
,	O
we	O
train	O
Electric	O
for	O
slightly	O
fewer	O
steps	O
than	O
ELEC	B-MethodName
-	I-MethodName
TRA	I-MethodName
.	O
This	O
same	O
generator	O
architecture	O
was	O
used	O
for	O
ELECTRA	B-MethodName
-	I-MethodName
TT	I-MethodName
.	O
The	O
TwoTower	B-MethodName
baseline	O
consists	O
of	O
two	O
transformers	O
2/3	O
the	O
size	O
of	O
BERT	B-MethodName
's	O
,	O
which	O
takes	O
approximately	O
the	O
same	O
compute	O
to	O
run	O
.	O
The	O
Electric	O
models	O
,	O
ELECTRA	B-MethodName
-	I-MethodName
Base	I-MethodName
,	O
and	O
BERT	B-MethodName
-	I-MethodName
Base	I-MethodName
all	O
use	O
the	O
same	O
amount	O
of	O
pre	O
-	O
train	O
compute	O
(	O
e.g.	O
,	O
Electric	O
is	O
trained	O
for	O
fewer	O
steps	O
than	O
BERT	B-MethodName
due	O
to	O
the	O
extra	O
compute	O
from	O
the	O
proposal	O
distribution	O
)	O
,	O
which	O
equates	O
to	O
approximately	O
three	O
days	O
of	O
training	O
on	O
16	O
TPUv2s	O
.	O

Our	O
annotation	O
scheme	O
comprises	O
16	O
slot	O
types	O
relevant	O
for	O
SOFC	O
experiments	O
.	O
Here	O
we	O
explain	O
a	O
few	O
of	O
these	O
types	O
for	O
illustration	O
.	O
A	O
full	O
list	O
of	O
these	O
slot	O
types	O
can	O
be	O
found	O
in	O
Supplementary	O
Material	O
Table	O
11	O
;	O
detailed	O
explanations	O
are	O
given	O
in	O
the	O
annotation	O
guidelines	O
published	O
along	O
with	O
our	O
corpus	O
.	O
PowerDensity	O
,	O
Resistance	O
,	O
WorkingTemperature	O
:	O
These	O
slots	O
are	O
generally	O
filled	O
by	O
mentions	O
of	O
type	O
VALUE	O
,	O
i.e.	O
,	O
a	O
numerical	O
value	O
plus	O
a	O
unit	O
.	O
Our	O
annotation	O
guidelines	O
give	O
examples	O
for	O
relevant	O
units	O
and	O
describe	O
special	O
cases	O
.	O
This	O
enables	O
any	O
materials	O
scientist	O
,	O
even	O
if	O
he	O
/	O
she	O
is	O
not	O
an	O
expert	O
on	O
SOFCs	O
,	O
to	O
easily	O
understand	O
and	O
apply	O
our	O
annotation	O
guidelines	O
.	O

In	O
this	O
section	O
,	O
we	O
detail	O
the	O
different	O
approaches	O
employed	O
for	O
document	O
re	O
-	O
ranking	O
:	O
kNN	O
,	O
Cross	B-MethodName
-	I-MethodName
Encoder	I-MethodName
,	O
and	O
Rank	O
Fusion	O
.	O

(	O
3	O
)	O
At	O
inference	O
,	O
passing	O
the	O
control	O
code	O
[	O
Topic	O
]	O
[	O
Stance	O
]	O
[	O
Aspect	O
]	O
to	O
the	O
model	O
will	O
generate	O
an	O
argument	O
that	O
follows	O
these	O
commands	O
.	O

Five	O
most	O
frequent	O
aspects	O
(	O
frequency	O
)	O
Gun	O
control	O
right	O
(	O
30	O
)	O
,	O
protect	O
(	O
18	O
)	O
,	O
background	O
checks	O
(	O
17	O
)	O
,	O
gun	O
violence	O
(	O
14	O
)	O
,	O
criminal	O
(	O
13	O
)	O
Death	O
penalty	O
cost	O
(	O
16	O
)	O
,	O
innocent	O
(	O
12	O
)	O
,	O
retribution	O
(	O
10	O
)	O
,	O
murder	O
rate	O
(	O
9	O
)	O
,	O
deterrent	O
(	O
8)	O
Abortion	O
right	O
(	O
21	O
)	O
,	O
pain	O
(	O
10	O
)	O
,	O
choice	O
(	O
10	O
)	O
,	O
right	O
to	O
life	O
(	O
9	O
)	O
,	O
risk	O
(	O
9	O
)	O
Marijuana	O
legalization	O
dangerous	O
(	O
16	O
)	O
,	O
cost	O
(	O
13	O
)	O
,	O
risk	O
(	O
12	O
)	O
,	O
harm	O
(	O
10	O
)	O
,	O
black	O
market	O
(	O
9	O
)	O
General	O
aspects	O
dangerous	O
(	O
in	O
8	O
of	O
8	O
topics	O
)	O
,	O
cost	O
/	O
life	O
/	O
risk	O
/	O
safety	O
(	O
in	O
7	O
of	O
8	O
topics	O
)	O
cross	O
-	O
topic	O
splits	O
using	O
a	O
leave	O
-	O
one	O
-	O
topic	O
-	O
out	O
strategy	O
.	O
The	O
cross	O
-	O
topic	O
setup	O
allows	O
us	O
to	O
estimate	O
the	O
ranker	O
's	O
performance	O
on	O
unseen	O
topics	O
of	O
the	O
UKP	O
-	O
Corpus	O
.	O

One	O
solution	O
to	O
this	O
problem	O
would	O
be	O
to	O
finetune	O
or	O
retrain	O
these	O
models	O
with	O
additionnal	O
human	O
annotated	O
data	O
.	O
However	O
,	O
this	O
is	O
expensive	O
both	O
in	O
time	O
and	O
resources	O
.	O
Instead	O
,	O
a	O
lot	O
of	O
work	O
has	O
been	O
done	O
lately	O
on	O
automatically	O
generating	O
training	O
data	O
for	O
fine	O
-	O
tuning	O
or	O
even	O
training	O
completely	O
unsupervised	O
models	O
for	O
question	O
answering	O
.	O
One	O
commonly	O
used	O
dataset	O
for	O
unsupervised	O
question	O
answering	O
is	O
the	O
extractive	O
dataset	O
SQUAD	B-TaskName
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
proposed	O
a	O
question	O
generation	O
method	O
for	O
SQUAD	B-TaskName
using	O
an	O
unsupervised	O
neural	O
based	O
translation	O
method	O
.	O
Fabbri	O
et	O
al	O
.	O
(	O
2020	O
)	O
and	O
further	O
gave	O
improved	O
unsupervised	O
performances	O
on	O
SQUAD	B-TaskName
and	O
showed	O
that	O
simple	O
rulebased	O
question	O
generation	O
could	O
be	O
as	O
effective	O
as	O
the	O
previously	O
mentioned	O
neural	O
method	O
.	O
These	O
approches	O
are	O
rarely	O
applied	O
to	O
multiple	O
-	O
choice	O
questions	O
answering	O
in	O
part	O
due	O
to	O
the	O
difficulty	O
of	O
selecting	O
distractors	O
.	O
A	O
few	O
research	O
papers	O
however	O
proposed	O
distractor	O
selection	O
methods	O
for	O
multiple	O
-	O
choice	O
questions	O
using	O
either	O
supervised	O
approaches	O
(	O
Sakaguchi	O
et	O
al	O
.	O
,	O
2013;Liang	O
et	O
al	O
.	O
,	O
2018	O
)	O
or	O
general	O
purpose	O
knowledge	O
bases	O
(	O
Ren	O
and	O
Q.	O
Zhu	O
,	O
2021	O
)	O
.	O

Elimination	O
of	O
templates	O
Prior	O
work	O
uses	O
human	O
-	O
authored	O
templates	O
to	O
transform	O
the	O
inputoutput	O
pair	O
to	O
a	O
natural	O
language	O
sentence	O
(	O
Zhong	O
et	O
al	O
.	O
,	O
2021	O
;	O
Mishra	O
et	O
al	O
.	O
,	O
2022	O
;	O
Wei	O
et	O
al	O
.	O
,	O
2022	O
;	O
Chen	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
They	O
require	O
expensive	O
manual	O
effort	O
(	O
as	O
136	O
different	O
templates	O
are	O
required	O
for	O
136	O
tasks	O
in	O
this	O
paper	O
)	O
and	O
cause	O
unstable	O
model	O
performance	O
due	O
to	O
many	O
different	O
ways	O
of	O
writing	O
(	O
Mishra	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
We	O
eliminate	O
templates	O
,	O
using	O
the	O
given	O
input	O
(	O
or	O
a	O
concatenation	O
of	O
inputs	O
if	O
there	O
are	O
multiple	O
)	O
and	O
label	O
words	O
provided	O
in	O
the	O
original	O
datasets	O
.	O
4	O
A	O
comparison	O
of	O
inputoutput	O
schemes	O
from	O
prior	O
work	O
and	O
our	O
approach	O
is	O
shown	O
in	O
Table	O
4	O
.	O

On	O
stability	O
,	O
DecT	B-MethodName
also	O
has	O
consistently	O
low	O
variance	O
and	O
some	O
baselines	O
(	O
ICL	B-MethodName
,	O
RLPrompt	B-MethodName
and	O
PromptBoosting	B-MethodName
)	O
are	O
unstable	O
.	O
Given	O
the	O
difficulty	O
of	O
few	O
-	O
shot	O
PTM	O
adaptation	O
,	O
it	O
is	O
of	O
great	O
significance	O
that	O
the	O
adaptation	O
method	O
is	O
robust	O
to	O
random	O
seeds	O
.	O

Although	O
DecT	B-MethodName
is	O
an	O
output	O
-	O
side	O
adaptation	O
method	O
,	O
the	O
choice	O
of	O
templates	O
also	O
affects	O
the	O
final	O
performance	O
.	O
To	O
assess	O
the	O
influence	O
of	O
templates	O
,	O
we	O
conduct	O
experiments	O
on	O
AG	B-MethodName
's	I-MethodName
News	I-MethodName
and	O
SST2	B-MethodName
and	O
show	O
results	O
in	O
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
run	O
each	O
experiment	O
over	O
5	O
random	O
seeds	O
and	O
report	O
average	O
accuracy	O
and	O
standard	O
deviation	O
(	O
%	O
)	O
.	O
mance	O
,	O
DecT	B-MethodName
largely	O
moderates	O
the	O
gaps	O
between	O
them	O
.	O
Additionally	O
,	O
we	O
try	O
two	O
templates	O
searched	O
from	O
RLPrompt	B-MethodName
(	O
Deng	O
et	O
al	O
.	O
,	O
2022	O
)	O
and	O
they	O
both	O
achieve	O
satisfying	O
results	O
.	O
On	O
SST2	O
,	O
the	O
template	O
from	O
RLPrompt	B-MethodName
is	O
even	O
better	O
than	O
manually	O
designed	O
ones	O
.	O
Therefore	O
,	O
we	O
highlight	O
that	O
DecT	B-MethodName
is	O
complementary	O
with	O
input	O
-	O
side	O
adaptation	O
algorithms	O
,	O
and	O
they	O
can	O
work	O
together	O
for	O
better	O
performance	O
.	O

Concurrent	O
to	O
our	O
work	O
,	O
Chi	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
Feng	O
et	O
al	O
.	O
(	O
2020	O
and	O
also	O
leverage	O
variants	O
of	O
contrastive	O
learning	O
for	O
cross	O
-	O
lingual	O
alignment	O
.	O
We	O
focus	O
on	O
a	O
smaller	O
model	O
and	O
improve	O
on	O
it	O
using	O
as	O
little	O
parallel	O
data	O
as	O
possible	O
.	O
We	O
also	O
explore	O
code	O
-	O
switching	O
during	O
finetuning	O
on	O
downtream	O
tasks	O
to	O
complement	O
the	O
post	O
-	O
pretraining	O
alignment	O
objectives	O
.	O

The	O
opaqueness	O
of	O
large	O
pre	O
-	O
trained	O
models	O
like	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
GPT	B-MethodName
(	O
Radford	O
and	O
Narasimhan	O
,	O
2018	O
)	O
motivates	O
developing	O
explanation	O
methods	O
,	O
which	O
aim	O
to	O
attribute	O
importance	O
to	O
particular	O
input	O
features	O
(	O
Springenberg	O
et	O
al	O
.	O
,	O
2015	O
;	O
Bach	O
et	O
al	O
.	O
,	O
2015	O
;	O
Ribeiro	O
et	O
al	O
.	O
,	O
2016	O
;	O
Sundararajan	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
such	O
as	O
words	O
in	O
a	O
textual	O
input	O
.	O
Two	O
main	O
criteria	O
for	O
evaluating	O
such	O
methods	O
are	O
plausibility	O
and	O
faithfulness	O
(	O
Jacovi	O
and	O
Goldberg	O
,	O
2020	O
)	O
.	O
Plausibility	O
can	O
be	O
defined	O
as	O
the	O
consistency	O
between	O
explanations	O
and	O
human	O
expectations	O
,	O
while	O
faithfulness	O
is	O
defined	O
as	O
the	O
consistency	O
between	O
explanations	O
and	O
the	O
model	O
's	O
underlying	O
decision	O
-	O
making	O
process	O
.	O

We	O
use	O
the	O
implementation	O
provided	O
by	O
(	O
Akyurek	O
and	O
Andreas	O
,	O
2021	O
)	O
,	O
increasing	O
the	O
number	O
of	O
training	O
iterations	O
from	O
8k	O
to	O
15k	O
for	O
augmented	O
training	O
runs	O
in	O
COGS	B-DatasetName
,	O
SCAN	B-DatasetName
datasets	O
.	O
For	O
the	O
ALCHEMY	O
dataset	O
,	O
we	O
optimize	O
iteration	O
count	O
over	O
{	O
8k	O
,	O
15k	O
,	O
25k	O
,	O
50k	O
}	O
based	O
on	O
validation	O
accuracy	O
,	O
and	O
found	O
25k	O
to	O
be	O
optimal	O
.	O
For	O
the	O
CLEVR	B-DatasetName
dataset	O
,	O
we	O
optimize	O
itreation	O
count	O
over	O
{	O
8k	O
,	O
15k	O
,	O
25k	O
,	O
50k	O
}	O
for	O
CLEVR	B-DatasetName
and	O
CLEVR	B-DatasetName
-	I-DatasetName
COGENT	I-DatasetName
dataset	O
based	O
on	O
CLEVR	B-DatasetName
's	O
validation	O
accuracy	O
.	O

We	O
adopt	O
a	O
model	O
equivalent	O
to	O
the	O
one	O
used	O
to	O
predict	O
words	O
in	O
MLM	O
.	O
Formally	O
,	O
we	O
predict	O
the	O
original	O
entity	O
corresponding	O
to	O
a	O
masked	O
entity	O
by	O
applying	O
softmax	O
over	O
all	O
entities	O
:	O

Ideally	O
,	O
the	O
task	O
chosen	O
for	O
a	O
cross	O
-	O
formalism	O
study	O
should	O
be	O
encoded	O
in	O
multiple	O
formalisms	O
using	O
the	O
same	O
textual	O
data	O
to	O
rule	O
out	O
the	O
influence	O
of	O
the	O
domain	O
and	O
text	O
type	O
.	O
While	O
many	O
linguistic	O
corpora	O
contain	O
several	O
layers	O
of	O
linguistic	O
information	O
,	O
having	O
the	O
same	O
textual	O
data	O
annotated	O
with	O
multiple	O
formalisms	O
for	O
the	O
same	O
task	O
is	O
rare	O
.	O
We	O
focus	O
on	O
role	O
semantics	O
-a	O
family	O
of	O
shallow	O
semantic	O
formalisms	O
at	O
the	O
interface	O
between	O
syntax	O
and	O
propositional	O
semantics	O
that	O
assign	O
roles	O
to	O
the	O
participants	O
of	O
natural	O
language	O
utterances	O
,	O
determining	O
who	O
did	O
what	O
to	O
whom	O
,	O
where	O
,	O
when	O
etc	O
.	O
Decades	O
of	O
research	O
in	O
theoretical	O
linguistics	O
have	O
produced	O
a	O
range	O
of	O
rolesemantic	O
frameworks	O
that	O
have	O
been	O
operationalized	O
in	O
NLP	O
:	O
syntax	O
-	O
driven	O
PropBank	B-MethodName
(	O
Palmer	O
et	O
al	O
.	O
,	O
2005	O
)	O
,	O
coarse	O
-	O
grained	O
VerbNet	B-MethodName
(	O
Kipper	O
-	O
Schuler	O
,	O
2005	O
)	O
,	O
fine	O
-	O
grained	O
FrameNet	B-MethodName
(	O
Baker	O
et	O
al	O
.	O
,	O
1998	O
)	O
,	O
and	O
,	O
recently	O
,	O
decompositional	O
Semantic	O
Proto	I-MethodName
-	I-MethodName
Roles	I-MethodName
(	O
SPR	B-MethodName
)	O
(	O
Reisinger	O
et	O
al	O
.	O
,	O
2015;White	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
The	O
SemLink	O
project	O
(	O
Bonial	O
et	O
al	O
.	O
,	O
2013	O
)	O
offers	O
parallel	O
annotation	O
for	O
PropBank	B-MethodName
,	O
VerbNet	B-MethodName
and	O
FrameNet	B-MethodName
for	O
English	O
.	O
This	O
allows	O
us	O
to	O
isolate	O
the	O
object	O
of	O
our	O
study	O
:	O
apart	O
from	O
the	O
rolesemantic	O
labels	O
,	O
the	O
underlying	O
data	O
and	O
conditions	O
for	O
the	O
three	O
formalisms	O
are	O
identical	O
.	O
SR3DE	B-MethodName
(	O
Mújdricza	O
-	O
Maydt	O
et	O
al	O
.	O
,	O
2016	O
)	O
provides	O
compatible	O
annotation	O
in	O
three	O
formalisms	O
for	O
German	O
,	O
enabling	O
cross	O
-	O
lingual	O
validation	O
of	O
our	O
results	O
.	O
Combined	O
,	O
these	O
factors	O
make	O
role	O
semantics	O
an	O
ideal	O
target	O
for	O
our	O
cross	O
-	O
formalism	O
probing	O
study	O
.	O

In	O
our	O
paper	O
,	O
we	O
address	O
this	O
problem	O
by	O
developing	O
multilingual	O
word	O
-	O
level	O
QE	O
models	O
which	O
perform	O
competitively	O
in	O
different	O
domains	O
,	O
MT	O
types	O
and	O
language	O
pairs	O
.	O
In	O
addition	O
,	O
for	O
the	O
first	O
time	O
,	O
we	O
propose	O
word	O
-	O
level	O
QE	O
as	O
a	O
zero	O
-	O
shot	O
crosslingual	O
transfer	O
task	O
,	O
enabling	O
new	O
avenues	O
of	O
research	O
in	O
which	O
multilingual	O
models	O
can	O
be	O
trained	O
once	O
and	O
then	O
serve	O
a	O
multitude	O
of	O
languages	O
and	O
domains	O
.	O
The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
the	O
following	O
:	O
i	O
We	O
introduce	O
a	O
simple	O
architecture	O
to	O
perform	O
word	O
-	O
level	O
quality	O
estimation	O
that	O
predicts	O
the	O
quality	O
of	O
the	O
words	O
in	O
the	O
source	O
sentence	O
,	O
target	O
sentence	O
and	O
the	O
gaps	O
in	O
the	O
target	O
sentence	O
.	O

Recently	O
,	O
there	O
have	O
been	O
new	O
attempts	O
to	O
use	O
explanations	O
and	O
human	O
feedback	O
to	O
debug	O
classifiers	O
in	O
general	O
.	O
Some	O
of	O
them	O
were	O
tested	O
on	O
traditional	O
text	O
classifiers	O
.	O
For	O
instance	O
,	O
Ribeiro	O
et	O
al	O
.	O
(	O
2016	O
)	O
showed	O
a	O
set	O
of	O
LIME	O
explanations	O
for	O
individual	O
SVM	O
predictions	O
to	O
humans	O
and	O
asked	O
them	O
to	O
remove	O
irrelevant	O
words	O
from	O
the	O
training	O
data	O
in	O
subsequent	O
training	O
.	O
The	O
process	O
was	O
run	O
for	O
three	O
rounds	O
to	O
iteratively	O
improve	O
the	O
classifiers	O
.	O
Teso	O
and	O
Kersting	O
(	O
2019	O
)	O
proposed	O
CAIPI	B-MethodName
,	O
which	O
is	O
an	O
explanatory	O
interactive	O
learning	O
framework	O
.	O
At	O
each	O
iteration	O
,	O
it	O
selects	O
an	O
unlabelled	O
example	O
to	O
predict	O
and	O
explain	O
to	O
users	O
using	O
LIME	O
,	O
and	O
the	O
users	O
respond	O
by	O
removing	O
irrelevant	O
features	O
from	O
the	O
explanation	O
.	O
CAIPI	B-MethodName
then	O
uses	O
this	O
feedback	O
to	O
generate	O
augmented	O
data	O
and	O
retrain	O
the	O
model	O
.	O
While	O
these	O
recent	O
works	O
use	O
feedback	O
on	O
lowlevel	O
features	O
(	O
input	O
words	O
)	O
and	O
individual	O
predictions	O
,	O
our	O
framework	O
(	O
FIND	O
)	O
uses	O
feedback	O
on	O
the	O
learned	O
features	O
with	O
respect	O
to	O
the	O
big	O
picture	O
of	O
the	O
model	O
.	O
This	O
helps	O
us	O
avoid	O
local	O
decision	O
pitfalls	O
which	O
usually	O
occur	O
in	O
interactive	O
machine	O
learning	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Overall	O
,	O
what	O
makes	O
our	O
contribution	O
different	O
from	O
existing	O
work	O
is	O
that	O
(	O
i	O
)	O
we	O
collect	O
the	O
feedback	O
on	O
the	O
model	O
,	O
not	O
the	O
individual	O
predictions	O
,	O
and	O
(	O
ii	O
)	O
we	O
target	O
deep	O
text	O
classifiers	O
which	O
are	O
more	O
complex	O
than	O
the	O
models	O
used	O
in	O
previous	O
work	O
.	O

In	O
this	O
section	O
,	O
we	O
describe	O
our	O
annotation	O
scheme	O
and	O
guidelines	O
for	O
marking	O
information	O
on	O
SOFCrelated	O
experiments	O
in	O
scientific	O
publications	O
.	O

We	O
conduct	O
experiments	O
of	O
translating	O
schema	O
from	O
English	O
(	O
En	O
)	O
to	O
five	O
different	O
languages	O
,	O
including	O
Chinese	O
(	O
Zh	O
)	O
,	O
French	O
(	O
Fr	O
)	O
,	O
German	O
(	O
De	O
)	O
,	O
Spanish	O
(	O
Es	O
)	O
,	O
and	O
Japanese	O
(	O
Ja	O
)	O
.	O
The	O
performances	O
of	O
different	O
translation	O
models	O
are	O
listed	O
in	O
Table	O
4	O
.	O

We	O
denote	O
the	O
number	O
of	O
XL	O
PE	O
equipped	O
heads	O
as	O
τ	O
∈	O
{	O
0	O
,	O
.	O
.	O
.	O
,	O
H	O
}	O
.	O
To	O
perform	O
the	O
attention	O
calculation	O
,	O

The	O
location	O
of	O
the	O
hotel	O
was	O
excellent	O
.	O
The	O
room	O
was	O
clean	O
and	O
comfortable	O
.	O

Following	O
Gururangan	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
to	O
identify	O
tokens	O
that	O
occur	O
disproportionately	O
in	O
hypotheses	O
associated	O
with	O
a	O
specific	O
class	O
,	O
we	O
compute	O
tokenclass	O
pointwise	O
mutual	O
information	O
(	O
PMI	O
)	O
with	O
add-50	O
smoothing	O
applied	O
to	O
raw	O
counts	O
,	O
and	O
a	O
filter	O
to	O
exclude	O
tokens	O
appearing	O
less	O
than	O
five	O
times	O
in	O
the	O
overall	O
training	O
dataset	O
.	O

During	O
training	O
,	O
we	O
freeze	O
the	O
pre	O
-	O
trained	O
model	O
's	O
parameters	O
θ	O
and	O
update	O
only	O
the	O
prefix	O
parameters	O
ϕ	O
to	O
optimize	O
the	O
following	O
objective	O
:	O

The	O
input	O
representation	O
of	O
a	O
word	O
or	O
an	O
entity	O
is	O
constructed	O
by	O
summing	O
the	O
token	O
,	O
token	O
type	O
,	O
and	O
position	O
embeddings	O
(	O
see	O
Figure	O
2	O
):	O

doctor	O
's	O
office	O
doctor	O
's	O
office	O
wiki	O
/	O
Physical_examination	O
wiki	O
/	O
Stethoscope	O
wiki	O
/	O
Safe	O
-	O
cracking	O
wiki	O
/	O
Safe	O
wiki	O
/	O
Stethoscope	O

Besides	O
that	O
,	O
PTW	B-MethodName
Masking	I-MethodName
also	O
does	O
well	O
in	O
several	O
NLU	O
tasks	O
in	O
GLUE	B-MethodName
.	O
PTW	B-MethodName
Masking	I-MethodName
is	O
a	O
time	O
-	O
variant	O
strategy	O
,	O
which	O
aggregates	O
the	O
advantages	O
of	O
both	O
Random	O
-	O
Token	O
Masking	O
and	O
Named	O
Entities	O
Masking	O
.	O
From	O
the	O
start	O
of	O
pretraining	O
,	O
models	O
can	O
learn	O
from	O
all	O
the	O
words	O
equiprobably	O
like	O
Random	O
-	O
Token	O
Masking	O
.	O
And	O
at	O
the	O
later	O
stage	O
,	O
models	O
memorize	O
more	O
knowledge	O
by	O
masking	O
important	O
words	O
instead	O
of	O
wasting	O
time	O
on	O
predicting	O
meanless	O
words	O
.	O
Thus	O
models	O
can	O
have	O
better	O
NLU	O
ability	O
with	O
memorization	O
of	O
more	O
knowledge	O
under	O
the	O
condition	O
of	O
training	O
with	O
the	O
same	O
number	O
of	O
tokens	O
.	O

Intuitively	O
,	O
the	O
forgetting	O
of	O
the	O
backdoor	O
in	O
the	O
retraining	O
process	O
must	O
be	O
related	O
to	O
the	O
way	O
in	O
which	O
the	O
backdoor	O
is	O
injected	O
.	O
Thus	O
,	O
we	O
conduct	O
pilot	O
experiments	O
to	O
observe	O
the	O
backdoor	O
injection	O
process	O
step	O
by	O
step	O
.	O

•	O
Reconstruction	O
stream	O
is	O
in	O
charge	O
of	O
the	O
source	O
-	O
side	O
reconstruction	O
.	O
This	O
stream	O
instead	O
captures	O
the	O
full	O
contextual	O
information	O
y	O
1	O
:	O
m	O
but	O
does	O
not	O
include	O
the	O
source	O
context	O
to	O
avoid	O
information	O
leaking	O
.	O

The	O
dataset	O
is	O
constructed	O
from	O
Wikipedia	O
and	O
Wikidata	O
,	O
containing	O
3053	O
documents	O
for	O
training	O
,	O
1000	O
for	O
development	O
,	O
and	O
1000	O
for	O
test	O
.	O
In	O
total	O
,	O
it	O
has	O
132,375	O
entities	O
and	O
56,354	O
relational	O
facts	O
in	O
96	O
relation	O
types	O
.	O
More	O
than	O
40	O
%	O
of	O
the	O
relational	O
facts	O
require	O
reasoning	O
over	O
multiple	O
sentences	O
.	O
The	O
standard	O
evaluation	O
metrics	O
are	O
F1	O
and	O
Ign	O
F1	O
,	O
where	O
Ign	O
F1	O
refers	O
to	O
the	O
F1	O
score	O
excluding	O
the	O
relational	O
facts	O
in	O
the	O
training	O
set	O
.	O

Table	O
4a	O
shows	O
human	O
analysis	O
over	O
evidentiality	O
positive	O
and	O
negative	O
labels	O
obtained	O
by	O
our	O
method	O
over	O
randomly	O
selected	O
samples	O
.	O
In	O
particular	O
,	O
we	O
randomly	O
sample	O
50	O
Natural	O
Questions	O
development	O
questions	O
and	O
sample	O
2	O
positive	O
passages	O
and	O
2	O
negative	O
passages	O
(	O
if	O
applicable	O
)	O
with	O
answer	O
strings	O
for	O
each	O
question	O
.	O
The	O
authors	O
manually	O
analyze	O
(	O
i	O
)	O
if	O
the	O
positive	O
passages	O
actually	O
provide	O
sufficient	O
evidence	O
to	O
answer	O
,	O
and	O
(	O
ii	O
)	O
if	O
the	O
negative	O
passages	O
actually	O
do	O
not	O
provide	O
sufficient	O
evidence	O
to	O
answer	O
,	O
despite	O
the	O
existence	O
of	O
the	O
gold	O
answer	O
strings	O
.	O
We	O
found	O
that	O
in	O
95	O
%	O
of	O
the	O
mined	O
positive	O
passages	O
provide	O
sufficient	O
evidence	O
to	O
answer	O
,	O
while	O
only	O
4	O
%	O
of	O
the	O
negative	O
passages	O
do	O
not	O
;	O
in	O
other	O
words	O
,	O
the	O
predictions	O
are	O
correct	O
95	O
%	O
of	O
the	O
positive	O
passages	O
and	O
96	O
%	O
of	O
the	O
negative	O
passages	O
.	O

Models	O
are	O
trained	O
and	O
results	O
are	O
reported	O
on	O
the	O
subset	O
of	O
sentences	O
marked	O
as	O
experimentdescribing	O
in	O
the	O
gold	O
standard	O
,	O
amounting	O
to	O
4,590	O
entity	O
mentions	O
in	O
total	O
.	O
9	O
The	O
CRF	B-MethodName
baseline	O
achieves	O
comparable	O
or	O
better	O
results	O
than	O
the	O
Bi	O
-	O
LSTM	O
with	O
word2vec	O
and/or	O
mat2vec	O
embeddings	O
.	O
However	O
,	O
adding	O
subword	O
-	O
based	O
embeddings	O
(	O
bpe	O
and/or	O
BERT	B-MethodName
)	O
significantly	O
increases	O
performance	O
of	O
the	O
BiLSTM	O
,	O
indicating	O
that	O
there	O
are	O
many	O
rare	O
words	O
.	O
Again	O
,	O
the	O
best	O
results	O
are	O
obtained	O
when	O
using	O
BERT	B-MethodName
or	O
SciBERT	B-MethodName
embeddings	O
or	O
when	O
using	O
the	O
original	O
SciBERT	B-MethodName
model	O
.	O
It	O
is	O
relatively	O
easy	O
for	O
all	O
model	O
variants	O
to	O
recognize	O
VALUE	O
as	O
these	O
mentions	O
usually	O
consist	O
of	O
a	O
number	O
and	O
unit	O
which	O
the	O
model	O
can	O
easily	O
memorize	O
.	O
Recognizing	O
the	O
types	O
MATERIAL	O
and	O
DEVICE	O
,	O
in	O
contrast	O
,	O
is	O
harder	O
and	O
may	O
profit	O
from	O
using	O
gazetteer	O
-	O
based	O
extensions	O
.	O

For	O
training	O
,	O
the	O
ground	O
truth	O
partner	O
personas	O
p	O
is	O
used	O
and	O
we	O
train	O
our	O
generator	O
to	O
maximise	O
the	O
likelihood	O
P	O
(	O
p	O
|	O
s	O
,	O
c	O
)	O
.	O
We	O
generate	O
the	O
complete	O
partner	O
personas	O
profiles	O
in	O
an	O
one	O
-	O
off	O
shot	O
for	O
all	O
the	O
dialogue	O
samples	O
.	O

We	O
use	O
T5	B-MethodName
-	I-MethodName
large	I-MethodName
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
as	O
the	O
backbone	O
PLM	O
for	O
all	O
methods	O
,	O
and	O
consider	O
the	O
following	O
baselines	O
to	O
compare	O
with	O
our	O
MODULARPROMPT	O
:	O

[	O
CONTEXT	O
]	O
Based	O
on	O
the	O
conversation	O
above	O
,	O
did	O
anyone	O
answer	O

Compared	O
to	O
existing	O
methods	O
,	O
HBGL	B-MethodName
achieves	O
significant	O
improvements	O
on	O
all	O
three	O
datasets	O
,	O
while	O
only	O
parameters	O
corresponding	O
to	O
label	O
embeddings	O
are	O
required	O
except	O
BERT	B-MethodName
.	O

Let	O
us	O
consider	O
a	O
text	O
classification	O
task	O
with	O
|C|	O
classes	O
where	O
C	O
is	O
the	O
set	O
of	O
all	O
classes	O
and	O
let	O
V	O
be	O
a	O
set	O
of	O
unique	O
words	O
in	O
the	O
corpus	O
(	O
the	O
vocabulary	O
)	O
.	O

The	O
starting	O
point	O
(	O
and	O
baselines	O
)	O
for	O
our	O
work	O
are	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
zero	O
-	O
shot	O
entity	O
linking	O
,	O
which	O
we	O
briefly	O
describe	O
here	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2020;Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
2	O
Candidate	O
Generation	O
Our	O
baseline	O
candidate	O
generation	O
approach	O
relies	O
on	O
similarities	O
between	O
mentions	O
and	O
candidates	O
in	O
a	O
vector	O
space	O
to	O
identify	O
the	O
candidates	O
for	O
each	O
mention	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2020	O
)	O
using	O
two	O
BERT	B-MethodName
models	O
.	O
The	O
first	O
BERT	B-MethodName
model	O
encodes	O
a	O
mention	O
m	O
along	O
with	O
its	O
context	O
c	O
into	O
a	O
vector	O
representation	O
v	O
m	O
.	O
v	O
m	O
is	O
obtained	O
from	O
the	O
pooled	O
representation	O
captured	O
by	O
the	O
[	O
CLS	O
]	O
token	O
used	O
in	O
BERT	O
models	O
to	O
indicate	O
the	O
start	O
of	O
a	O
sequence	O
.	O
In	O
this	O
encoder	O
,	O
a	O
binary	O
(	O
0/1	O
)	O
indicator	O
vector	O
is	O
used	O
to	O
identify	O
the	O
mention	O
span	O
.	O
The	O
embeddings	O
for	O
this	O
indicator	O
vector	O
(	O
indicator	O
embeddings	O
)	O
are	O
added	O
to	O
the	O
token	O
embeddings	O
of	O
the	O
mention	O
as	O
in	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

Concerning	O
the	O
abusive	O
language	O
detection	O
task	O
,	O
on	O
average	O
,	O
the	O
MTurk	O
participants	O
'	O
responses	O
suggested	O
us	O
to	O
disable	O
12	O
out	O
of	O
30	O
CNN	O
features	O
.	O
Unlike	O
Biosbias	O
,	O
disabling	O
features	O
based	O
on	O
MTurk	O
responses	O
unexpectedly	O
increased	O
the	O
gender	O
bias	O
for	O
both	O
Waseem	O
and	O
Wikitoxic	O
datasets	O
.	O
However	O
,	O
we	O
found	O
one	O
similar	O
finding	O
to	O
Biosbias	O
,	O
that	O
many	O
of	O
the	O
CNN	O
features	O
captured	O
n	O
-	O
grams	O
which	O
were	O
both	O
abusive	O
and	O
related	O
to	O
a	O
gender	O
such	O
as	O
'	O
these	O
girls	O
are	O
terrible	O
'	O
and	O
'	O
of	O
raping	O
slave	O
girls	O
'	O
,	O
and	O
these	O
features	O
were	O
not	O
yet	O
disabled	O
.	O
So	O
,	O
we	O
asked	O
one	O
annotator	O
to	O
disable	O
the	O
features	O
using	O
the	O
new	O
"	O
brutal	O
"	O
policy	O
-disabling	O
all	O
which	O
involved	O
gender	O
words	O
even	O
though	O
some	O
of	O
them	O
also	O
detected	O
abusive	O
words	O
.	O
By	O
disabling	O
18	O
out	O
of	O
30	O
features	O
on	O
average	O
,	O
the	O
gender	O
biases	O
were	O
reduced	O
for	O
both	O
datasets	O
(	O
except	O
FPED	O
on	O
Wikitoxic	O
which	O
stayed	O
close	O
to	O
the	O
original	O
value	O
)	O
.	O
Another	O
consequence	O
was	O
that	O
we	O
sacrificed	O
4	O
%	O
and	O
1	O
%	O
macro	O
F1	O
on	O
the	O
Waseem	O
and	O
Wikitoxic	O
datasets	O
,	O
respectively	O
.	O
This	O
finding	O
is	O
consistent	O
with	O
(	O
Park	O
et	O
al	O
.	O
,	O
2018	O
)	O
that	O
reducing	O
the	O
bias	O
and	O
maintaining	O
the	O
classification	O
performance	O
at	O
the	O
same	O
time	O
is	O
very	O
challenging	O
.	O

This	O
paper	O
presents	O
a	O
new	O
method	O
for	O
improving	O
the	O
zero	O
-	O
shot	O
generalization	O
of	O
T5	B-MethodName
-	O
like	O
text	O
-	O
to	O
-	O
text	O
Transformers	O
by	O
incorporating	O
model	O
-	O
generated	O
signals	O
in	O
the	O
pretraining	O
process	O
.	O
METRO	B-MethodName
-	I-MethodName
T0	I-MethodName
,	O
the	O
model	O
sufficiently	O
trained	O
using	O
our	O
redesigned	O
pretraining	O
method	O
,	O
is	O
highly	O
parameter	O
efficient	O
and	O
compute	O
efficient	O
.	O
We	O
hope	O
that	O
the	O
success	O
of	O
our	O
approach	O
could	O
inspire	O
further	O
work	O
on	O
efficient	O
big	O
LM	O
pretraining	O
and	O
prompt	O
-	O
based	O
learning	O
.	O

Controllable	O
language	O
models	O
like	O
the	O
CTRL	B-MethodName
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
allow	O
to	O
condition	O
the	O
model	O
at	O
training	O
time	O
to	O
certain	O
control	O
codes	O
.	O
At	O
inference	O
,	O
these	O
can	O
be	O
used	O
to	O
direct	O
the	O
model	O
's	O
output	O
with	O
regard	O
to	O
content	O
or	O
style	O
.	O
We	O
build	O
upon	O
this	O
architecture	O
to	O
control	O
argument	O
generation	O
based	O
solely	O
on	O
a	O
given	O
topic	O
,	O
stance	O
,	O
and	O
argument	O
aspect	O
.	O
For	O
instance	O
,	O
to	O
enforce	O
focus	O
on	O
the	O
aspect	O
of	O
cancer	O
for	O
the	O
topic	O
of	O
nuclear	O
energy	O
,	O
we	O
input	O
a	O
control	O
code	O
"	O
Nuclear	O
Energy	O
CON	O
cancer	O
"	O
that	O
creates	O
a	O
contra	O
argument	O
discussing	O
this	O
aspect	O
,	O
for	O
instance	O
:	O
"	O
Studies	O
show	O
that	O
people	O
living	O
next	O
to	O
nuclear	O
power	O
plants	O
have	O
a	O
higher	O
risk	O
of	O
developing	O
cancer	O
.	O
"	O
.	O

Since	O
the	O
target	O
texts	O
contain	O
lesser	O
than	O
250k	O
examples	O
,	O
we	O
use	O
additional	O
data	O
augmentation	O
techniques	O
to	O
upsample	O
the	O
target	O
data	O
.	O
We	O
also	O
use	O
additional	O
data	O
to	O
avoid	O
overfitting	O
on	O
the	O
MuST	B-DatasetName
-	I-DatasetName
C	I-DatasetName
target	O
text	O
.	O
Details	O
have	O
been	O
provided	O
in	O
B.2.1	O
.	O

The	O
micro	O
F1	O
-	O
score	O
achieved	O
by	O
the	O
fastText	B-MethodName
classifier	O
significantly	O
exceeds	O
that	O
of	O
the	O
majority	O
class	O
baseline	O
,	O
confirming	O
the	O
findings	O
of	O
Romanov	O
and	O
Shivade	O
(	O
2018	O
)	O
,	O
who	O
report	O
a	O
micro	O
-	O
F1	O
score	O
of	O
61.9	O
but	O
do	O
not	O
identify	O
or	O
analyze	O
artifacts	O
:	O

The	O
BLEU	B-MetricName
scores	O
of	O
models	O
with	O
CTC	B-MethodName
,	O
OAXE	B-DatasetName
and	O
CoCO	B-MethodName
loss	I-MethodName
on	O
different	O
languages	O
pairs	O
are	O
shown	O
in	O
Table	O
4	O
.	O

•	O
PubMed	O
:	O
We	O
use	O
the	O
same	O
pre	O
-	O
processing	O
script	O
in	O
https	O
:	O
/	O
/	O
github.com	O
/	O
HHousen	O
/	O
A	O
rXiv	O
-	O
PubMed	O
-	O
Sum	O
.	O
We	O
remove	O
the	O
instances	O
with	O
article	O
have	O
less	O
3	O
sentences	O
or	O
abstract	O
have	O
less	O
2	O
sentences	O
.	O
We	O
also	O
remove	O
three	O
special	O
tokens	O
:	O
newlines	O
,	O
<	O
S	O
>	O
and	O
<	O
/	O
S	O
>	O
.	O

Analyzing	O
deep	O
NLP	O
models	O
-There	O
has	O
been	O
substantial	O
work	O
in	O
gaining	O
better	O
understanding	O
of	O
complex	O
,	O
deep	O
neural	O
NLP	O
models	O
.	O
By	O
visualizing	O
dense	O
hidden	O
vectors	O
,	O
Li	O
et	O
al	O
.	O
(	O
2016	O
)	O
found	O
that	O
some	O
dimensions	O
of	O
the	O
final	O
representation	O
learned	O
by	O
recurrent	O
neural	O
networks	O
capture	O
the	O
effect	O
of	O
intensification	O
and	O
negation	O
in	O
the	O
input	O
text	O
.	O
Karpathy	O
et	O
al	O
.	O
(	O
2015	O
)	O
revealed	O
the	O
existence	O
of	O
interpretable	O
cells	O
in	O
a	O
character	O
-	O
level	O
LSTM	O
model	O
for	O
language	O
modelling	O
.	O
For	O
example	O
,	O
they	O
found	O
a	O
cell	O
acting	O
as	O
a	O
line	O
length	O
counter	O
and	O
cells	O
checking	O
if	O
the	O
current	O
letter	O
is	O
inside	O
a	O
parenthesis	O
or	O
a	O
quote	O
.	O
Jacovi	O
et	O
al	O
.	O
(	O
2018	O
)	O
presented	O
interesting	O
findings	O
about	O
CNNs	B-MethodName
for	O
text	O
classification	O
including	O
the	O
fact	O
that	O
one	O
convolutional	O
filter	O
may	O
detect	O
more	O
than	O
one	O
n	O
-	O
gram	O
pattern	O
and	O
may	O
also	O
suppress	O
negative	O
n	O
-	O
grams	O
.	O
Many	O
recent	O
papers	O
studied	O
several	O
types	O
of	O
knowledge	O
in	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
a	O
deep	O
transformer	O
-	O
based	O
model	O
for	O
language	O
understanding	O
,	O
and	O
found	O
that	O
syntactic	O
information	O
is	O
mostly	O
captured	O
in	O
the	O
middle	O
BERT	O
layers	O
while	O
the	O
final	O
BERT	B-MethodName
layers	O
are	O
the	O
most	O
task	O
-	O
specific	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Inspired	O
by	O
many	O
findings	O
,	O
we	O
make	O
the	O
assumption	O
that	O
each	O
dimension	O
of	O
the	O
final	O
representation	O
(	O
i.e.	O
,	O
the	O
vector	O
before	O
the	O
output	O
layer	O
)	O
captures	O
patterns	O
or	O
qualities	O
in	O
the	O
input	O
which	O
are	O
useful	O
for	O
classification	O
.	O
Therefore	O
,	O
understanding	O
the	O
roles	O
of	O
these	O
dimensions	O
(	O
we	O
refer	O
to	O
them	O
as	O
features	O
)	O
is	O
a	O
prerequisite	O
for	O
effective	O
human	O
-	O
in	O
-	O
the	O
-	O
loop	O
model	O
debugging	O
,	O
and	O
we	O
exploit	O
an	O
explanation	O
method	O
to	O
gain	O
such	O
an	O
understanding	O
.	O
Explaining	O
predictions	O
from	O
text	O
classifiers	O
-Several	O
methods	O
have	O
been	O
devised	O
to	O
generate	O
explanations	O
supporting	O
classifications	O
in	O
many	O
forms	O
,	O
such	O
as	O
natural	O
language	O
texts	O
,	O
rules	O
(	O
Ribeiro	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
extracted	O
rationales	O
(	O
Lei	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
and	O
attribution	O
scores	O
(	O
Lertvittayakumjorn	O
and	O
Toni	O
,	O
2019	O
)	O
.	O
Some	O
explanation	O
methods	O
,	O
such	O
as	O
LIME	O
(	O
Ribeiro	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
SHAP	O
(	O
Lundberg	O
and	O
Lee	O
,	O
2017	O
)	O
,	O
are	O
model	O
-	O
agnostic	O
and	O
do	O
not	O
require	O
access	O
to	O
model	O
parameters	O
.	O
Other	O
methods	O
access	O
the	O
model	O
architectures	O
and	O
parameters	O
to	O
generate	O
the	O
explanations	O
,	O
such	O
as	O
DeepLIFT	O
(	O
Shrikumar	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
LRP	O
(	O
layer	O
-	O
wise	O
relevance	O
propagation	O
)	O
(	O
Bach	O
et	O
al	O
.	O
,	O
2015;Arras	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
In	O
this	O
work	O
,	O
we	O
use	O
LRP	O
to	O
explain	O
not	O
the	O
predictions	O
but	O
the	O
learned	O
features	O
so	O
as	O
to	O
expose	O
the	O
model	O
behavior	O
to	O
humans	O
and	O
enable	O
informed	O
model	O
debugging	O
.	O

Figure	O
12	O
shows	O
performance	O
gap	O
between	O
using	O
gold	O
labels	O
and	O
using	O
random	O
labels	O
per	O
dataset	O
.	O
We	O
find	O
that	O
the	O
trend	O
that	O
the	O
gap	O
is	O
smaller	O
than	O
previously	O
thought	O
is	O
consistant	O
across	O
most	O
datasets	O
.	O
Nonetheless	O
,	O
there	O
are	O
a	O
few	O
outlier	O
datasets	O
where	O
performance	O
gap	O
is	O
non	O
-	O
negligible	O
,	O
such	O
as	O
finan	O
-	O
cial_phrasebank	O
and	O
a	O
few	O
hate	O
speech	O
detection	O
datasets	O
.	O
Future	O
work	O
may	O
investigate	O
on	O
which	O
tasks	O
the	O
model	O
makes	O
more	O
use	O
of	O
the	O
correctly	O
paired	O
training	O
data	O
.	O

We	O
use	O
TLM	O
for	O
word	O
-	O
level	O
alignment	O
.	O
TLM	O
is	O
an	O
extension	O
of	O
MLM	O
that	O
operates	O
on	O
bilingual	O
data	O
-	O
parallel	O
sentences	O
are	O
concatenated	O
and	O
MLM	O
is	O
applied	O
to	O
the	O
combined	O
bilingual	O
sequence	O
.	O
Different	O
from	O
Conneau	O
and	O
Lample	O
(	O
2019	O
)	O
,	O
we	O
do	O
not	O
reset	O
positional	O
embeddings	O
when	O
forming	O
the	O
bilingual	O
sequence	O
,	O
and	O
we	O
also	O
do	O
not	O
use	O
language	O
embeddings	O
.	O
In	O
addition	O
,	O
the	O
order	O
of	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
during	O
concatenation	O
is	O
determined	O
by	O
the	O
random	O
input	O
shuffling	O
from	O
the	O
sentence	O
-	O
level	O
alignment	O
step	O
and	O
we	O
add	O
a	O
[	O
SEP	O
]	O
token	O
between	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
.	O
We	O
randomly	O
mask	O
15	O
%	O
of	O
the	O
WordPiece	O
tokens	O
in	O
each	O
combined	O
sequence	O
.	O
Masking	O
is	O
done	O
by	O
using	O
a	O
special	O
[	O
MASK	O
]	O
token	O
80	O
%	O
of	O
the	O
times	O
,	O
a	O
random	O
token	O
in	O
the	O
vocabulary	O
10	O
%	O
of	O
the	O
times	O
,	O
and	O
unchanged	O
for	O
the	O
remaining	O
10	O
%	O
.	O
TLM	O
is	O
performed	O
using	O
the	O
query	O
encoder	O
of	O
MoCo	O
.	O
Our	O
final	O
PPA	O
model	O
is	O
trained	O
in	O
a	O
multi	O
-	O
task	O
manner	O
with	O
both	O
sentence	O
-	O
level	O
objective	O
and	O
TLM	O
:	O

In	O
addition	O
,	O
we	O
fine	O
-	O
tune	O
the	O
original	O
(	O
uncased	O
)	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
as	O
well	O
as	O
SciBERT	B-MethodName
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2019	O
)	O
models	O
on	O
our	O
dataset	O
.	O
Sci	B-MethodName
-	I-MethodName
BERT	I-MethodName
was	O
trained	O
on	O
a	O
large	O
corpus	O
of	O
scientific	O
text	O
.	O
We	O
use	O
the	O
implementation	O
of	O
the	O
BERT	B-MethodName
sentence	O
classifier	O
by	O
Wolf	O
et	O
al	O
.	O
(	O
2019	O
)	O
that	O
uses	O
the	O
CLS	O
token	O
of	O
BERT	B-MethodName
as	O
input	O
to	O
the	O
classification	O
layer	O
.	O
5	O
Finally	O
,	O
we	O
compare	O
the	O
neural	O
network	O
models	O
with	O
traditional	O
classification	O
models	O
,	O
namely	O
a	O
support	O
vector	O
machine	O
(	O
SVM	O
)	O
and	O
a	O
logistic	O
regression	O
classifier	O
.	O
For	O
both	O
models	O
,	O
we	O
use	O
the	O
following	O
set	O
of	O
input	O
features	O
:	O
bag	O
-	O
of	O
-	O
words	O
vectors	O
indicating	O
which	O
1	O
-	O
to	O
4	O
-	O
grams	O
and	O
part	O
-	O
of	O
-	O
speech	O
tags	O
occur	O
in	O
the	O
sentence	O
.	O
6	O
Entity	O
mention	O
extraction	O
.	O
For	O
entity	O
and	O
concept	O
extraction	O
,	O
we	O
use	O
a	O
sequence	O
-	O
tagging	O
approach	O
similar	O
to	O
(	O
Huang	O
et	O
al	O
.	O
,	O
2015;Lample	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
namely	O
a	O
BiLSTM	O
model	O
.	O
We	O
use	O
the	O
same	O
input	O
representation	O
(	O
stacked	O
embeddings	O
)	O
as	O
above	O
,	O
which	O
are	O
fed	O
into	O
a	O
BiLSTM	O
.	O
The	O
subsequent	O
conditional	O
random	O
field	O
(	O
CRF	O
,	O
Lafferty	O
et	O
al	O
.	O
,	O
2001	O
)	O
output	O
layer	O
extracts	O
the	O
most	O
probable	O
label	O
sequence	O
.	O
To	O
cope	O
with	O
multi	O
-	O
token	O
entities	O
,	O
we	O
convert	O
the	O
labels	O
into	O
BIO	O
format	O
.	O

Our	O
approach	O
is	O
also	O
amenable	O
to	O
online	O
learning	O
,	O
as	O
decisions	O
about	O
productivity	O
are	O
revised	O
as	O
more	O
training	O
data	O
is	O
evaluated	O
.	O
Replacing	O
existing	O
exceptions	O
with	O
more	O
general	O
rules	O
when	O
possible	O
is	O
concordant	O
with	O
Yang	O
's	O
(	O
2016	O
)	O
Maximize	O
Productivity	O
learning	O
strategy	O
,	O
where	O
the	O
most	O
general	O
valid	O
rule	O
is	O
adopted	O
over	O
narrower	O
competitors	O
.	O

D4	O
.	O
Was	O
the	O
data	O
collection	O
protocol	O
approved	O
(	O
or	O
determined	O
exempt	O
)	O
by	O
an	O
ethics	O
review	O
board	O
?	O

Fig	O
.	O
3	O
reports	O
the	O
results	O
of	O
different	O
τ	O
for	O
Head	O
XL	O
SANs	O
.	O
With	O
increasing	O
of	O
XL	O
PE	O
-	O
informed	O
heads	O
,	O
the	O
best	O
BLEU	B-MetricName
is	O
achieved	O
when	O
#	O
heads	O
=	O
4	O
,	O
which	O
is	O
therefore	O
left	O
as	O
the	O
default	O
setting	O
for	O
HeadXL	B-MetricName
.	O
Then	O
,	O
the	O
BLEU	B-MetricName
score	O
gradually	O
decreases	O
as	O
the	O
#	O
System	O
Architecture	O
BLEU	B-MetricName
#	O
Param	O
.	O
number	O
of	O
APE	O
-	O
informed	O
heads	O
decrease	O
(	O
τ	O
↑	O
)	O
,	O
indicating	O
that	O
sequential	O
position	O
embedding	O
is	O
still	O
essential	O
for	O
SANs	O
.	O

4	O
.	O
We	O
use	O
community	O
detection	O
techniques	O
to	O
automatically	O
identify	O
regions	O
of	O
interest	O
in	O
large	O
Mapper	O
graphs	O
.	O

To	O
help	O
better	O
understand	O
the	O
domains	O
of	O
the	O
collected	O
tables	O
,	O
we	O
firstly	O
use	O
a	O
44	O
-	O
category	O
ontology	O
presented	O
in	O
Wikipedia	O
:	O
WikiProject	O
Council	O
/	O
Directory	O
as	O
our	O
domain	O
category	O
.	O
Then	O
we	O
randomly	O
sample	O
500	O
tables	O
in	O
the	O
training	O
set	O
and	O
manually	O
label	O
the	O
domains	O
.	O
According	O
to	O
our	O
statistics	O
,	O
our	O
dataset	O
covers	O
all	O
44	O
domains	O
.	O
In	O
detail	O
,	O
the	O
Sports	O
,	O
Countries	O
,	O
Economics	O
,	O
and	O
Music	O
topics	O
together	O
comprise	O
44.6	O
%	O
of	O
our	O
dataset	O
,	O
but	O
the	O
other	O
55.4	O
%	O
is	O
composed	O
of	O
broader	O
topics	O
such	O
as	O
Business	O
,	O
Education	O
,	O
Science	O
,	O
and	O
Government	O
.	O

We	O
compare	O
two	O
End2End	O
methods	O
:	O
First	O
,	O
we	O
directly	O
fine	O
-	O
tune	O
a	O
multi	O
-	O
lingual	O
model	O
on	O
⟨D	O
src	O
,	O
S	O
tgt	O
⟩	O
(	O
DialogSumX	B-DatasetName
)	O
and	O
⟨	O
{	O
Q	O
tgt	O
;	O
D	O
src	O
}	O
,	O
S	O
tgt	O
⟩	O
(	O
QMSumX	O
)	O
,	O
marked	O
as	O
E2E	O
;	O
Second	O
,	O
inspired	O
by	O
Bai	O
et	O
al	O
.	O
(	O
2021	O
)	O
,	O
where	O
an	O
End2End	O
model	O
first	O
generates	O
mono	O
-	O
lingual	O
summary	O
and	O
then	O
cross	O
-	O
lingual	O
summary	O
in	O
an	O
auto	O
-	O
regressive	O
way	O
and	O
shows	O
good	O
performance	O
in	O
few	O
-	O
shot	O
setting	O
,	O
we	O
fine	O
-	O
tune	O
a	O
multi	O
-	O
lingual	O
model	O
on	O
⟨D	O
src	O
,	O
{	O
S	O
src	O
;	O
S	O
tgt	O
}	O
⟩	O
(	O
DialogSumX	B-DatasetName
)	O
and	O
⟨	O
{	O
Q	O
tgt	O
;	O
D	O
src	O
}	O
,	O
{	O
S	O
src	O
;	O
S	O
tgt	O
}	O
⟩	O
(	O
QMSumX	O
)	O
,	O
marked	O
as	O
E2	O
M	O
(	O
M	O
means	O
mixed	O
)	O
.	O

Considering	O
all	O
the	O
three	O
runs	O
,	O
Figure	O
6	O
(	O
top	O
)	O
shows	O
the	O
average	O
macro	O
F1	O
score	O
of	O
the	O
original	O
model	O
(	O
the	O
blue	O
line	O
)	O
and	O
of	O
each	O
modified	O
model	O
.	O
The	O
order	O
of	O
the	O
performance	O
drops	O
is	O
AB	O
>	O
A	O
>	O
AC	O
>	O
BC	O
>	O
B	O
>	O
Original	O
>	O
C.	O
This	O
makes	O
sense	O
because	O
disabling	O
important	O
features	O
(	O
rank	O
A	O
and/or	O
B	O
)	O
caused	O
larger	O
performance	O
drops	O
,	O
and	O
the	O
overall	O
results	O
are	O
consistent	O
with	O
the	O
average	O
fea-	O
ture	O
scores	O
given	O
by	O
the	O
participants	O
(	O
as	O
in	O
Figure	O
4	O
)	O
.	O
It	O
confirms	O
that	O
using	O
word	O
clouds	O
is	O
an	O
effective	O
way	O
to	O
assess	O
CNN	O
features	O
.	O
Also	O
,	O
it	O
is	O
worth	O
noting	O
that	O
the	O
macro	O
F1	O
of	O
the	O
model	O
slightly	O
increased	O
when	O
we	O
disabled	O
the	O
low	O
-	O
quality	O
features	O
(	O
rank	O
C	O
)	O
.	O
This	O
shows	O
that	O
humans	O
can	O
improve	O
the	O
model	O
by	O
disabling	O
irrelevant	O
features	O
.	O

Impact	O
of	O
schema	O
-	O
aware	O
training	O
data	O

In	O
Figure	O
3	O
,	O
we	O
compare	O
the	O
per	O
-	O
task	O
performance	O
of	O
PICL	B-MethodName
and	O
MetaICL	B-MethodName
because	O
they	O
share	O
the	O
most	O
similar	O
setting	O
where	O
human	O
-	O
annotated	O
downstream	O
datasets	O
are	O
used	O
.	O
We	O
observe	O
that	O
PICL	B-MethodName
outperforms	O
MetaICL	B-MethodName
on	O
about	O
3/4	O
of	O
evaluation	O
tasks	O
,	O
indicating	O
that	O
compared	O
to	O
fine	O
-	O
tuning	O
directly	O
on	O
downstream	O
tasks	O
,	O
pre	O
-	O
training	O
on	O
intrinsic	O
tasks	O
constructed	O
from	O
the	O
general	O
plain	O
-	O
text	O
corpus	O
brings	O
better	O
ICL	O
ability	O
and	O
ensures	O
higher	O
generalization	O
performance	O
across	O
a	O
broad	O
range	O
of	O
tasks	O
(	O
see	O
Appendix	O
E.2	O
for	O
more	O
details	O
)	O
.	O

often	O
small	O
or	O
even	O
negative	O
.	O
REFILL	O
continues	O
to	O
yield	O
positive	O
gains	O
even	O
for	O
smaller	O
workload	O
sizes	O
-In	O
Figure	O
3	O
,	O
we	O
plot	O
the	O
fraction	O
of	O
the	O
total	O
SQL	O
workload	O
used	O
on	O
the	O
x	O
-	O
axis	O
and	O
the	O
EM	O
of	O
the	O
fine	O
-	O
tuned	O
parsers	O
averaged	O
across	O
all	O
the	O
four	O
groups	O
,	O
on	O
the	O
y	O
-	O
axis	O
.	O
When	O
using	O
the	O
data	O
synthesized	O
by	O
REFILL	O
,	O
the	O
performance	O
of	O
the	O
parser	O
improves	O
steadily	O
with	O
an	O
increasing	O
size	O
of	O
the	O
SQL	O
workload	O
.	O
In	O
contrast	O
,	O
the	O
baseline	O
SQL	O
-	O
to	O
-	O
Text	O
generation	O
methods	O
fail	O
to	O
provide	O
significant	O
improvements	O
.	O
Interestingly	O
,	O
the	O
data	O
synthesized	O
by	O
REFILL	O
using	O
the	O
30	O
%	O
SQL	O
workload	O
leads	O
to	O
better	O
downstream	O
performance	O
of	O
the	O
adapted	O
parsers	O
than	O
any	O
of	O
the	O
baselines	O
utilizing	O
70	O
%	O
SQL	O
workload	O
for	O
SQL	O
-	O
to	O
-	O
Text	O
generation	O
.	O

We	O
extensively	O
evaluate	O
our	O
efficient	O
pretrained	O
models	O
on	O
well	O
-	O
established	O
downstream	O
tasks	O
(	O
e.g.	O
,	O
Wang	O
et	O
al	O
.	O
,	O
2018	O
;	O
Tjong	O
Kim	O
Sang	O
and	O
De	O
Meulder	O
,	O
2003	O
.	O
)	O
We	O
find	O
that	O
our	O
modifications	O
result	O
in	O
almost	O
no	O
drop	O
in	O
downstream	O
performance	O
,	O
while	O
providing	O
substantial	O
pretraining	O
and	O
inference	O
speedups	O
(	O
§	O
3	O
)	O
.	O
While	O
efficient	O
attention	O
variants	O
are	O
a	O
promising	O
research	O
direction	O
,	O
this	O
work	O
presents	O
a	O
different	O
and	O
simple	O
approach	O
to	O
making	O
transformers	O
efficient	O
,	O
with	O
minimal	O
changes	O
in	O
architecture	O
.	O

-DOCSTART-	O
For	O
both	O
PPA	O
and	O
finetuning	O
on	O
downstream	O
tasks	O
,	O
we	O
use	O
the	O
AdamW	B-MethodName
optimizer	O
with	O
0.01	O
weight	O
decay	O
and	O
a	O
linear	O
learning	O
rate	O
scheduler	O
.	O
For	O
PPA	O
,	O
we	O
use	O
a	O
batch	O
size	O
of	O
128	B-HyperparameterValue
,	O
mBERT	O
max	O
sequence	O
length	O
128	B-HyperparameterValue
and	O
learning	O
rate	O
warmup	O
for	O
the	O
first	O
10	O
%	O
of	O
the	O
total	O
iterations	O
,	O
peaking	O
at	O
0.00003	O
.	O
The	O
MoCo	O
momentum	O
is	O
set	O
to	O
0.999	O
,	O
queue	O
size	O
32000	O
and	O
temperature	O
0.05	O
.	O
Our	O
PPA	O
models	O
are	O
trained	O
for	O
10	O
epochs	O
,	O
except	O
for	O
the	O
2	O
M	O
setting	O
where	O
5	O
epochs	O
are	O
trained	O
.	O
On	O
XNLI	O
,	O
we	O
use	O
a	O
batch	O
size	O
of	O
32	B-HyperparameterValue
,	O
mBERT	O
max	O
sequence	O
length	O
128	B-HyperparameterValue
and	O
finetune	O
the	O
PPA	O
model	O
for	O
2	O
epochs	O
.	O
Learning	O
rate	O
peaks	O
at	O
0.00005	O
and	O
warmup	O
is	O
done	O
to	O
the	O
first	O
1000	O
iterations	O
.	O
On	O
MLQA	O
,	O
mBERT	O
max	O
sequence	O
length	O
is	O
set	O
to	O
386	O
and	O
peak	O
learning	O
rate	O
0.00003	O
.	O
The	O
other	O
parameters	O
are	O
the	O
same	O
as	O
XNLI	B-DatasetName
.	O
Our	O
experiments	O
are	O
run	O
on	O
a	O
single	O
32	O
GB	O
V100	O
GPU	O
,	O
except	O
for	O
PPA	O
training	O
that	O
involves	O
either	O
MLM	O
or	O
TLM	O
,	O
where	O
two	O
such	O
GPUs	O
are	O
used	O
.	O
We	O
also	O
use	O
mixed	O
-	O
precision	O
training	O
to	O
save	O
on	O
GPU	O
memory	O
and	O
speed	O
up	O
experiments	O
.	O

We	O
also	O
propose	O
a	O
method	O
for	O
solving	O
nondeterministic	O
substitution	O
ciphers	O
with	O
existing	O
keys	O
using	O
a	O
lattice	O
and	O
a	O
pretrained	O
language	O
model	O
.	O
Our	O
method	O
achieves	O
a	O
TER	B-MethodName
of	O
1.12	O
%	I-MetricValue
on	O
the	O
IA	O
cipher	O
,	O
a	O
real	O
historical	O
cipher	O
that	O
has	O
not	O
been	O
fully	O
solved	O
until	O
this	O
work	O
.	O

In	O
our	O
experiments	O
,	O
we	O
observed	O
that	O
multilingual	O
QE	O
models	O
deliver	O
excellent	O
results	O
on	O
the	O
language	O
pairs	O
they	O
were	O
trained	O
on	O
.	O
In	O
addition	O
,	O
the	O
multilingual	O
QE	O
models	O
perform	O
well	O
in	O
the	O
majority	O
of	O
the	O
zero	O
-	O
shot	O
scenarios	O
where	O
the	O
multilingual	O
QE	O
model	O
is	O
tested	O
on	O
an	O
unseen	O
language	O
pair	O
.	O
Furthermore	O
,	O
multilingual	O
models	O
perform	O
very	O
well	O
with	O
few	O
-	O
shot	O
learning	O
on	O
an	O
unseen	O
language	O
pair	O
when	O
compared	O
to	O
training	O
from	O
scratch	O
for	O
that	O
language	O
pair	O
,	O
proving	O
that	O
multilingual	O
QE	O
models	O
are	O
effective	O
even	O
with	O
a	O
limited	O
number	O
of	O
training	O
instances	O
.	O
While	O
we	O
centered	O
our	O
analysis	O
around	O
the	O
F1	O
-	O
score	O
of	O
the	O
target	O
words	O
,	O
these	O
findings	O
are	O
consistent	O
with	O
the	O
F1	O
-	O
score	O
of	O
the	O
target	O
gaps	O
and	O
the	O
F1	O
-	O
score	O
of	O
the	O
source	O
words	O
too	O
.	O
This	O
suggests	O
that	O
we	O
can	O
train	O
a	O
single	O
multilingual	O
QE	O
model	O
on	O
as	O
many	O
languages	O
as	O
possible	O
and	O
apply	O
it	O
on	O
other	O
language	O
pairs	O
as	O
well	O
.	O
These	O
findings	O
can	O
be	O
beneficial	O
to	O
perform	O
QE	O
in	O
low	O
-	O
resource	O
languages	O
for	O
which	O
the	O
training	O
data	O
is	O
scarce	O
and	O
when	O
maintaining	O
several	O
QE	O
models	O
for	O
different	O
language	O
pairs	O
is	O
arduous	O
.	O

Input	O
Graph	O
.	O
We	O
model	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
to	O
represent	O
their	O
entity	O
types	O
and	O
structural	O
relations	O
.	O
Firstly	O
,	O
we	O
induce	O
two	O
kinds	O
of	O
edges	O
to	O
denote	O
the	O
structural	O
relationships	O
between	O
the	O
target	O
header	O
and	O
its	O
context	O
:	O
sibling	O
header	O
(	O
i.e.	O
,	O
an	O
edge	O
point	O
from	O
tokens	O
in	O
S	O
to	O
tokens	O
in	O
the	O
target	O
header	O
.	O
)	O
,	O
and	O
belonging	O
value	O
(	O
i.e.	O
,	O
an	O
edge	O
point	O
from	O
tokens	O
in	O
V	O
to	O
tokens	O
in	O
the	O
target	O
header	O
.	O
)	O
.	O
In	O
this	O
sense	O
,	O
it	O
could	O
incorporate	O
the	O
structural	O
information	O
into	O
the	O
contextualized	O
representation	O
of	O
the	O
target	O
header	O
.	O

Models	O
for	O
argument	O
and	O
claim	O
generation	I-TaskName
have	O
been	O
discussed	O
in	O
our	O
related	O
work	O
and	O
are	O
widely	O
available	O
.	O
Gretz	O
et	O
al	O
.	O
(	O
2020a	O
)	O
suggest	O
that	O
,	O
in	O
order	O
to	O
allow	O
for	O
a	O
fine	O
-	O
grained	O
control	O
over	O
claim	O
/	O
argument	O
generation	I-TaskName
,	O
aspect	O
selection	O
needs	O
to	O
be	O
handled	O
carefully	O
,	O
which	O
is	O
what	O
we	O
have	O
focused	O
on	O
in	O
this	O
work	O
.	O
The	O
dangers	O
of	O
misuse	O
of	O
language	O
models	O
like	O
the	O
CTRL	O
have	O
been	O
extensively	O
discussed	O
by	O
its	O
authors	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
ethical	O
impact	O
of	O
these	O
works	O
has	O
been	O
weighed	O
and	O
deemed	O
justifiable	O
.	O
Argument	O
generation	I-TaskName
-	O
and	O
natural	O
language	O
generation	O
as	O
a	O
whole	O
-	O
is	O
subject	O
to	O
dual	O
use	O
.	O
The	O
technology	O
can	O
be	O
used	O
to	O
create	O
arguments	O
that	O
can	O
not	O
be	O
distinguished	O
from	O
human	O
-	O
made	O
arguments	O
.	O
While	O
our	O
intentions	O
are	O
to	O
support	O
society	O
,	O
to	O
foster	O
diversity	O
in	O
debates	O
,	O
and	O
to	O
encourage	O
research	O
on	O
this	O
important	O
topic	O
,	O
we	O
are	O
aware	O
of	O
the	O
possibility	O
of	O
harmful	O
applications	O
this	O
model	O
can	O
be	O
used	O
for	O
.	O
For	O
instance	O
,	O
the	O
model	O
could	O
be	O
used	O
to	O
generate	O
only	O
opposing	O
(	O
or	O
supporting	O
)	O
arguments	O
on	O
one	O
of	O
the	O
pretrained	O
topics	O
and	O
aspects	O
and	O
,	O
as	O
such	O
,	O
bias	O
a	O
debate	O
into	O
a	O
certain	O
direction	O
.	O
Also	O
,	O
bots	O
could	O
use	O
the	O
generated	O
arguments	O
to	O
spread	O
them	O
via	O
social	O
media	O
.	O
The	O
same	O
is	O
true	O
,	O
however	O
,	O
for	O
argument	O
search	O
engines	O
,	O
which	O
can	O
be	O
used	O
by	O
malicious	O
parties	O
to	O
retrieve	O
(	O
and	O
then	O
spread	O
)	O
potentially	O
harmful	O
information	O
.	O

The	O
prediction	O
for	O
the	O
action	O
chain	O
A	O
requires	O
rigorous	O
layer	O
-	O
by	O
-	O
layer	O
logical	O
reasoning	O
ability	O
.	O
Considering	O
the	O
symbolic	O
network	O
's	O
reasoning	O
ability	O
(	O
Yi	O
et	O
al	O
.	O
,	O
2018	O
;	O
Li	O
et	O
al	O
.	O
,	O
2020c	O
)	O
,	O
we	O
design	O
a	O
traditional	O
graph	O
theory	O
based	O
symbolic	O
module	O
for	O
searching	O
targeted	O
nodes	O
(	O
actions	O
)	O
.	O

We	O
measure	O
the	O
retrieval	O
performances	O
of	O
models	O
with	O
standard	O
ranking	O
metrics	O
,	O
which	O
are	O
calculated	O
by	O
ranks	O
of	O
correctly	O
retrieved	O
triplets	O
.	O
In	O
particular	O
,	O
we	O
use	O
Hits	O
@	O
K	O
which	O
measures	O
whether	O
retrieved	O
Top	O
-	O
K	O
triplets	O
include	O
a	O
correct	O
answer	O
or	O
not	O
,	O
and	O
Mean	O
Reciprocal	I-MethodName
Rank	O
(	O
MRR	O
)	O
which	O
measures	O
the	O
rank	O
of	O
the	O
first	O
correct	O
triplet	O
for	O
each	O
input	O
text	O
and	O
then	O
computes	O
the	O
average	O
of	O
reciprocal	O
ranks	O
of	O
all	O
results	O
.	O
Following	O
exiting	O
document	O
retrieval	O
work	O
(	O
Xiong	O
et	O
al	O
.	O
,	O
2021	O
;	O
Jeong	O
et	O
al	O
.	O
,	O
2022	O
)	O
,	O
we	O
consider	O
top-1000	O
retrieved	O
triplets	O
when	O
calculating	O
MRR	O
,	O
since	O
considering	O
ranks	O
of	O
all	O
triplets	O
in	O
KGs	O
are	O
computationally	O
prohibitive	O
.	O

While	O
absolute	O
performance	O
is	O
secondary	O
to	O
our	O
analysis	O
,	O
we	O
report	O
the	O
probing	O
task	O
scores	O
on	O
respective	O
development	O
sets	O
in	O
Table	O
5	O
.	O
We	O
observe	O
that	O
grammatical	O
tasks	O
score	O
high	O
,	O
while	O
core	O
role	O
labeling	O
lags	O
behind	O
-in	O
line	O
with	O
the	O
findings	O
of	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
3	O
We	O
observe	O
lower	O
scores	O
for	O
German	O
role	O
labeling	O
which	O
we	O
attribute	O
to	O
the	O
lack	O
of	O
training	O
data	O
.	O
Surprisingly	O
,	O
as	O
we	O
show	O
below	O
,	O
this	O
does	O
n't	O
prevent	O
the	O
edge	O
probe	O
from	O
task	O
en	O
de	O
*	O
token.ix	O
0.95	O
(	O
0.93	O
)	O
0.92	O
(	O
0	O
.	O
learning	O
to	O
locate	O
relevant	O
role	O
-	O
semantic	O
information	O
in	O
mBERT	O
's	O
layers	O
.	O

We	O
evaluate	O
four	O
different	O
aspects	O
of	O
our	O
question	B-TaskName
generation	I-TaskName
model	O
:	O
(	O
i	O
)	O
successful	O
control	O
for	O
difficulty	O
,	O
(	O
ii	O
)	O
novelty	O
,	O
(	O
iii	O
)	O
fluency	O
,	O
and	O
(	O
iv	O
)	O
latency	O
.	O

To	O
this	O
end	O
,	O
we	O
focus	O
on	O
the	O
attention	O
mechanism	O
,	O
which	O
is	O
the	O
core	O
component	O
of	O
transformers	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Several	O
current	O
studies	O
utilized	O
supervision	O
of	O
the	O
attention	O
probabilities	O
to	O
effectively	O
train	O
the	O
model	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2016	O
;	O
Mi	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
Moreover	O
,	O
it	O
is	O
also	O
used	O
for	O
the	O
model	O
distillation	O
to	O
efficiently	O
transfer	O
the	O
knowledge	O
of	O
a	O
transformer	O
model	O
to	O
another	O
one	O
via	O
attention	O
probabilities	O
(	O
Aguilar	O
et	O
al	O
.	O
,	O
2020	O
;	O
Jiao	O
et	O
al	O
.	O
,	O
2020	O
;	O
Sun	O
et	O
al	O
.	O
,	O
2020	O
;	O
Wang	O
et	O
al	O
.	O
,	O
,	O
2021	O
.	O
Inspired	O
by	O
this	O
,	O
we	O
propose	O
distilled	O
attention	O
labels	O
,	O
which	O
are	O
the	O
supervision	O
of	O
attention	O
probabilities	O
optimized	O
as	O
a	O
part	O
of	O
the	O
distilled	O
dataset	O
,	O
to	O
enhance	O
the	O
effectiveness	O
of	O
the	O
distilled	O
dataset	O
for	O
training	O
the	O
transformer	O
models	O
.	O

For	O
sentence	O
-	O
level	O
,	O
we	O
observe	O
on	O
the	O
one	O
hand	O
quite	O
significant	O
improvements	O
with	O
a	O
gain	O
of	O
almost	O
8	O
points	O
in	O
Pearson	O
's	O
r	O
over	O
BiRNN	B-MethodName
,	O
our	O
monomodal	O
baseline	O
without	O
pre	O
-	O
trained	O
word	O
embedding	O
.	O
multimodal	O
variants	O
achieve	O
better	O
performance	O
compared	O
to	O
the	O
monomodal	O
BiRNN	B-MethodName
baseline	O
,	O
with	O
a	O
peak	O
when	O
the	O
visual	O
features	O
are	O
fused	O
with	O
the	O
word	O
embedding	O
representations	O
by	O
elementwise	O
multiplication	O
.	O
On	O
the	O
other	O
hand	O
,	O
we	O
do	O
not	O
observe	O
any	O
gain	O
in	O
using	O
visual	O
features	O
on	O
the	O
WMT'19	B-DatasetName
test	O
set	O
compared	O
to	O
our	O
monomodal	O
baseline	O
with	O
pre	O
-	O
trained	O
word	O
-	O
embedding	O
(	O
BERT	B-MethodName
-	I-MethodName
BiRNN	I-MethodName
)	O
.	O
Here	O
that	O
the	O
BERT	B-MethodName
-	I-MethodName
BiRNN	I-MethodName
baseline	O
model	O
already	O
performs	O
very	O
well	O
.	O
According	O
to	O
the	O
task	O
organisers	O
,	O
the	O
mean	O
MQM	O
value	O
on	O
the	O
WMT'19	B-DatasetName
test	O
set	O
is	O
higher	O
than	O
on	O
the	O
WMT'18	B-DatasetName
test	O
set	O
,	O
but	O
actually	O
closer	O
to	O
the	O
training	O
data	O
(	O
Fonseca	O

Experiment	O
slot	O
filling	O
.	O
Table	O
7	O
shows	O
the	O
macro	O
-	O
average	O
F1	O
scores	O
for	O
our	O
different	O
models	O
on	O
the	O
slot	O
identification	O
task	O
.	O
10	O
As	O
for	O
entity	O
typing	O
,	O
we	O
train	O
and	O
evaluate	O
our	O
model	O
on	O
the	O
subset	O
of	O
sentences	O
marked	O
as	O
experiment	O
-	O
describing	O
,	O
which	O
contain	O
4,263	O
slot	O
instances	O
.	O
Again	O
,	O
the	O
CRF	O
baseline	O
outperforms	O
the	O
BiLSTM	O
when	O
using	O
only	O
mat2vec	O
and/or	O
word2vec	O
embeddings	O
.	O
The	O
addition	O
of	O
BERT	B-MethodName
or	O
SciBERT	B-MethodName
embeddings	O
improves	O
performance	O
.	O
However	O
,	O
on	O
this	O
task	O
,	O
the	O
BiLSTM	O
model	O
with	O
(	O
Sci)BERT	O
embeddings	O
outperforms	O
the	O
fine	O
-	O
tuned	O
original	O
(	O
Sci)BERT	O
model	O
.	O
Compared	O
to	O
the	O
other	O
two	O
tasks	O
,	O
this	O
task	O
requires	O
more	O
complex	O
reasoning	O
and	O
has	O
a	O
larger	O
number	O
of	O
possible	O
output	O
classes	O
.	O
We	O
assume	O
that	O
in	O
such	O
a	O
setting	O
,	O
adding	O
more	O
abstraction	O
power	O
to	O
the	O
model	O
(	O
in	O
the	O
form	O
of	O
a	O
BiLSTM	O
)	O
leads	O
to	O
better	O
results	O
.	O
For	O
a	O
more	O
detailed	O
analysis	O
,	O
Table	O
8	O
shows	O
the	O
slot	O
-	O
wise	O
results	O
for	O
the	O
non	O
-	O
neural	O
CRF	O
baseline	O
and	O
the	O
model	O
that	O
performs	O
best	O
on	O
the	O
development	O
set	O
:	O
BiLSTM	O
with	O
SciBERT	O
embeddings	O
.	O
As	O
in	O
the	O
case	O
of	O
entity	O
mention	O
detection	I-TaskName
,	O
the	O
models	O
do	O
well	O
for	O
the	O
categories	O
that	O
consist	O
of	O
numeric	O
mentions	O
plus	O
particular	O
units	O
.	O
In	O
general	O
,	O
model	O
performance	O
is	O
also	O
tied	O
to	O
the	O
frequency	O
of	O
the	O
slot	O
types	O
in	O
the	O
dataset	O
.	O
Recognizing	O
the	O
role	O
a	O
material	O
plays	O
in	O
an	O
experiment	O
(	O
e.g.	O
,	O
AnodeMaterial	B-MethodName
vs.	O
CathodeMaterial	B-MethodName
)	O
remains	O
challenging	O
,	O
possibly	O
requiring	O
background	O
domain	O
knowledge	O
.	O
This	O
type	O
of	O
information	O
is	O
often	O
not	O
stated	O
explicitly	O
in	O
the	O
sentence	O
,	O
but	O
introduced	O
earlier	O
in	O
the	O
discourse	O
and	O
would	O
hence	O
require	O
document	O
-	O
level	O
modeling	O
.	O

Transformer	B-MethodName
-	O
based	O
ED	O
.	O
Several	O
recent	O
studies	O
have	O
proposed	O
ED	O
models	O
based	O
on	O
Transformer	B-MethodName
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
trained	O
with	O
a	O
large	O
entity	O
-	O
annotated	O
corpus	O
obtained	O
from	O
Wikipedia	O
(	O
Broscheit	O
,	O
2019;Ling	O
et	O
al	O
.	O
,	O
2020;Cao	O
et	O
al	O
.	O
,	O
2021;Barba	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
Broscheit	O
(	O
2019	O
)	O
trained	O
an	O
ED	O
model	O
based	O
on	O
BERT	B-MethodName
by	O
classifying	O
each	O
word	O
in	O
the	O
document	O
to	O
the	O
corresponding	O
entity	O
.	O
Similarly	O
,	O
addressed	O
ED	O
using	O
BERT	B-MethodName
by	O
classifying	O
mention	O
spans	O
to	O
the	O
corresponding	O
entities	O
.	O
Ling	O

We	O
propose	O
a	O
global	O
entity	O
disambiguation	O
(	O
ED	O
)	O
model	O
based	O
on	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
To	O
capture	O
global	O
contextual	O
information	O
for	O
ED	O
,	O
our	O
model	O
treats	O
not	O
only	O
words	O
but	O
also	O
entities	O
as	O
input	O
tokens	O
,	O
and	O
solves	O
the	O
task	O
by	O
sequentially	O
resolving	O
mentions	O
to	O
their	O
referent	O
entities	O
and	O
using	O
resolved	O
entities	O
as	O
inputs	O
at	O
each	O
step	O
.	O
We	O
train	O
the	O
model	O
using	O
a	O
large	O
entity	O
-	O
annotated	O
corpus	O
obtained	O
from	O
Wikipedia	O
.	O
We	O
achieve	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
five	O
standard	O
ED	O
datasets	O
:	O
AIDA	B-DatasetName
-	I-DatasetName
CoNLL	I-DatasetName
,	O
MSNBC	B-DatasetName
,	O
AQUAINT	B-DatasetName
,	O
ACE2004	B-DatasetName
,	O
and	O
WNED	B-DatasetName
-	I-DatasetName
WIKI	I-DatasetName
.	O
The	O
source	O
code	O
and	O
model	O
checkpoint	O
are	O
available	O
at	O
https	O
:	O
//github.com	O
/	O
studio	O
-	O
ousia	O
/	O
luke	O
.	O

The	O
results	O
on	O
SUPER	B-MethodName
-	I-MethodName
NATURALINSTRUCTIONS	I-MethodName
are	O
shown	O
in	O
achieves	O
higher	O
overall	O
instruction	O
following	O
performance	O
than	O
the	O
baselines	O
,	O
outperforming	O
a	O
larger	O
model	O
with	O
about	O
4x	O
parameters	O
.	O

t	O
←	O
t	O
+	O
1	O
23	O
:	O
end	O
while	O
the	O
score	O
of	O
recently	O
discovered	O
nodes	O
so	O
the	O
algorithm	O
prefers	O
to	O
continue	O
them	O
.	O
The	O
decay	O
function	O
needs	O
to	O
be	O
monotonic	O
.	O
Hence	O
,	O
we	O
define	O
the	O
decay	O
function	O
as	O
a	O
power	O
function	O
:	O

We	O
propose	O
different	O
ways	O
to	O
integrate	O
visual	O
features	O
in	O
our	O
two	O
monomodal	O
QE	O
approaches	O
(	O
Sections	O
3.1	O
and	O
3.2	O
)	O
.	O
We	O
compare	O
each	O
proposed	O
model	O
with	O
its	O
monomodal	O
QE	O
counterpart	O
as	O
baseline	O
,	O
both	O
using	O
the	O
same	O
hyperparameters	O
.	O

On	O
MuCGEC	B-DatasetName
,	O
we	O
submit	O
the	O
results	O
of	O
our	O
systems	O
to	O
the	O
public	O
evaluation	O
website	O
10	O
.	O
On	O
NLPCC	O
,	O
we	O
implement	O
the	O
tools	O
provided	O
by	O
Zhang	O
et	O
al	O
.	O
(	O
2022	O
)	O
to	O
compute	O
the	O
P	O
(	O
Precision	O
)	O
,	O
R	O
(	O
Recall	O
)	O
,	O
and	O
F	O
0.5	O
of	O
the	O
output	O
on	O
char	O
-	O
level	O
.	O
Also	O
,	O
we	O
report	O
word	O
-	O
level	O
results	O
on	O
NLPCC	O
-	O
test	O
for	O
reference	O
with	O
previous	O
works	O
.	O

In	O
Appendix	O
B	O
,	O
we	O
further	O
show	O
that	O
automatic	O
metrics	O
like	O
ROUGE	B-MethodName
and	O
BERTScore	B-MethodName
(	O
Zhang	O
et	O
al	O
.	O
,	O
2019	O
)	O
that	O
are	O
primarily	O
used	O
for	O
evaluating	O
long	O
document	O
summarization	O
fail	O
to	O
penalize	O
coherence	O
errors	O
in	O
summaries	O
.	O
Better	O
tools	O
for	O
both	O
automatic	O
and	O
human	O
evaluation	O
are	O
needed	O
.	O

Linking	O
dataset	O
entities	O
to	O
geospatial	O
concept	O
is	O
one	O
integral	O
part	O
of	O
our	O
proposed	O
methodology	O
.	O
Ongoing	O
geospatial	O
semantics	O
research	O
mostly	O
focuses	O
on	O
extracting	O
spatial	O
and	O
temporal	O
entities	O
(	O
Kokla	O
and	O
Guilbert	O
,	O
2020	O
;	O
Purves	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
The	O
usual	O
approach	O
is	O
to	O
first	O
extract	O
geo	O
-	O
location	O
concepts	O
(	O
i.e.	O
geotagging	O
)	O
from	O
semi	O
-	O
structured	O
as	O
well	O
as	O
unstructured	O
data	O
and	O
then	O
linking	O
those	O
entities	O
to	O
location	O
based	O
knowledge	O
ontology	O
(	O
i.e.	O
geocoding	O
)	O
.	O
In	O
(	O
Gritta	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
the	O
authors	O
propose	O
a	O
task	O
-	O
metric	O
-	O
evaluation	O
framework	O
to	O
evaluate	O
existing	O
NER	B-TaskName
based	O
geoparsing	O
methods	O
.	O
The	O
primary	O
findings	O
suggest	O
that	O
NER	B-TaskName
based	O
geo	O
-	O
tagger	O
models	O
in	O
general	O
rely	O
on	O
instant	O
word	O
-	O
sense	O
while	O
avoiding	O
contextual	O
information	O
.	O

Environmental	O
sound	O
provides	O
rich	O
perspectives	O
on	O
the	O
physical	O
world	O
.	O
For	O
example	O
,	O
if	O
we	O
hear	O
:	O
joyful	O
laughing	O
,	O
a	O
playful	O
scream	O
,	O
and	O
a	O
splash	O
;	O
we	O
not	O
only	O
can	O
visualize	O
literal	O
objects	O
/	O
actions	O
that	O
might	O
have	O
given	O
rise	O
to	O
the	O
audio	O
scene	O
,	O
but	O
also	O
,	O
we	O
can	O
reason	O
about	O
plausible	O
higher	O
-	O
level	O
facets	O
,	O
e.g.	O
,	O
a	O
child	O
speeding	O
down	O
a	O
water	O
slide	O
at	O
a	O
water	O
park	O
,	O
splashing	O
through	O
the	O
water	O
(	O
see	O
Figure	O
1	O
)	O
.	O
*	O
Work	O
was	O
partially	O
done	O
during	O
an	O
internship	O
at	O
AI2	O
.	O

For	O
future	O
work	O
,	O
it	O
would	O
be	O
interesting	O
to	O
extend	O
FIND	O
to	O
other	O
NLP	O
tasks	O
,	O
e.g.	O
,	O
question	O
answering	O
and	O
natural	O
language	O
inference	O
.	O
This	O
will	O
require	O
some	O
modifications	O
to	O
understand	O
how	O
the	O
features	O
capture	O
relationships	O
between	O
two	O
input	O
texts	O
.	O

Traditional	O
contrastive	O
learning	O
only	O
considers	O
positive	O
and	O
negative	O
samples	O
,	O
and	O
their	O
instances	O
are	O
usually	O
not	O
fine	O
-	O
grained	O
.	O
In	O
our	O
semanticaware	O
contrastive	O
learning	O
,	O
we	O
need	O
to	O
deal	O
with	O
multi	O
-	O
level	O
instances	O
,	O
and	O
use	O
special	O
semanticaware	O
similarities	O
.	O

Modeling	O
cross	O
-	O
lingual	O
divergence	O
There	O
has	O
been	O
many	O
works	O
modeling	O
cross	O
-	O
lingual	O
divergence	O
(	O
e.g.	O
,	O
reordering	O
)	O
in	O
statistical	O
machine	O
translation	O
(	O
Nagata	O
et	O
al	O
.	O
,	O
2006;Durrani	O
et	O
al	O
.	O
,	O
2011Durrani	O
et	O
al	O
.	O
,	O
,	O
2013	O
.	O
However	O
,	O
it	O
is	O
difficult	O
to	O
migrant	O
them	O
to	O
neural	O
machine	O
translation	O
.	O
Kawara	O
et	O
al	O
.	O
(	O
2018	O
)	O
pre	O
-	O
reordered	O
the	O
source	O
sentences	O
with	O
a	O
recursive	O
neural	O
network	O
model	O
.	O
Chen	O
et	O
al	O
.	O
(	O
2019a	O
)	O
learned	O
the	O
reordering	O
embedding	O
by	O
considering	O
the	O
relationship	O
between	O
the	O
position	O
embedding	O
of	O
a	O
word	O
and	O
SANS	O
-	O
calculated	O
sentence	O
representation	O
.	O
showed	O
that	O
SANs	O
in	O
machine	O
translation	O
could	O
learn	O
word	O
order	O
mainly	O
due	O
to	O
the	O
PE	O
,	O
indicating	O
that	O
modeling	O
cross	O
-	O
lingual	O
information	O
at	O
position	O
representation	O
level	O
may	O
be	O
informative	O
.	O
Thus	O
,	O
we	O
propose	O
a	O
novel	O
cross	O
-	O
lingual	O
PE	O
method	O
to	O
improve	O
SANs	O
.	O

Tables	O
1	O
and	O
2	O
report	O
the	O
results	O
of	O
our	O
approach	O
alongside	O
those	O
reported	O
by	O
previous	O
state	O
-	O
of	O
-	O
theart	O
methods	O
on	O
CLINC150	B-DatasetName
,	O
SST	B-MethodName
,	O
ROSTD	B-DatasetName
,	O
and	O
20NewsGroups	B-MethodName
.	O
It	O
can	O
be	O
seen	O
that	O
our	O
proposed	O
method	O
outperforms	O
the	O
prior	O
methods	O
with	O
a	O
large	O
margin	O
in	O
most	O
experiments	O
,	O
achieving	O
an	O
improvement	O
of	O
up	O
to	O
9.13	O
,	O
20.73	O
,	O
38.71	O
points	O
in	O
terms	O
of	O
AUROC	B-DatasetName
,	O
AUPR	O
,	O
and	O
FAR95	B-DatasetName
,	O
respectively	O
,	O
on	O
CLINC150	B-DatasetName
.	O
This	O
well	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
proposed	O
approach	O
.	O

Nevertheless	O
,	O
FIND	B-MethodName
has	O
some	O
limitations	O
.	O
First	O
,	O
the	O
word	O
clouds	O
may	O
reveal	O
sensitive	O
contents	O
in	O
the	O
training	O
data	O
to	O
human	O
debuggers	O
.	O
Second	O
,	O
the	O
more	O
hidden	O
features	O
the	O
model	O
has	O
,	O
the	O
more	O
human	O
effort	O
FIND	B-MethodName
needs	O
for	O
debugging	O
.	O
For	O
instance	O
,	O
BERT	B-MethodName
-	I-MethodName
base	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
has	O
768	O
features	O
(	O
before	O
the	O
final	O
dense	O
layer	O
)	O
which	O
require	O
lots	O
of	O
human	O
effort	O
to	O
perform	O
investigation	O
.	O
In	O
this	O
case	O
,	O
it	O
would	O
be	O
more	O
efficient	O
to	O
use	O
FIND	B-MethodName
to	O
disable	O
attention	O
heads	O
rather	O
than	O
individual	O
features	O
(	O
Voita	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Third	O
,	O
it	O
is	O
possible	O
that	O
one	O
feature	O
detects	O
several	O
patterns	O
(	O
Jacovi	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
it	O
will	O
be	O
difficult	O
to	O
disable	O
the	O
feature	O
if	O
some	O
of	O
the	O
detected	O
patterns	O
are	O
useful	O
while	O
the	O
others	O
are	O
harmful	O
.	O
Hence	O
,	O
FIND	B-MethodName
would	O
be	O
more	O
effective	O
when	O
used	O
together	O
with	O
disentangled	O
text	O
representations	O
(	O
Cheng	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

-DOCSTART-	O
An	O
Exploratory	O
Analysis	O
of	O
Multilingual	O
Word	O
-	O
Level	O
Quality	O
Estimation	O
with	O
Cross	O
-	O
Lingual	O
Transformers	O

The	O
year	O
-	O
to	O
-	O
year	O
nature	O
of	O
financial	O
reports	O
allows	O
us	O
to	O
take	O
advantage	O
of	O
the	O
differences	O
between	O
a	O
company	O
's	O
documents	O
in	O
consecutive	O
years	O
.	O
These	O
differences	O
may	O
reveal	O
complex	O
but	O
insightful	O
relationships	O
within	O
a	O
pair	O
of	O
documents	O
.	O
To	O
better	O
understand	O
these	O
relationships	O
,	O
we	O
investigate	O
them	O
through	O
rationales	O
(	O
represented	O
by	O
the	O
word	O
importance	O
)	O
,	O
which	O
are	O
considered	O
essential	O
signals	O
in	O
financial	O
reports	O
.	O

Entity	O
disambiguation	O
(	O
ED	O
)	O
refers	O
to	O
the	O
task	O
of	O
assigning	O
mentions	O
in	O
a	O
document	O
to	O
corresponding	O
entities	O
in	O
a	O
knowledge	O
base	O
(	O
KB	O
)	O
.	O
This	O
task	O
is	O
challenging	O
because	O
of	O
the	O
ambiguity	O
between	O
mentions	O
(	O
e.g.	O
,	O
"	O
World	O
Cup	O
"	O
)	O
and	O
the	O
entities	O
they	O
refer	O
to	O
(	O
e.g.	O
,	O
FIFA	O
World	O
Cup	O
or	O
Rugby	O
World	O
Cup	O
)	O
.	O
ED	O
models	O
typically	O
rely	O
on	O
local	O
contextual	O
information	O
based	O
on	O
words	O
that	O
co	O
-	O
occur	O
with	O
the	O
mention	O
and	O
global	O
contextual	O
information	O
based	O
on	O
the	O
entity	O
-	O
based	O
coherence	O
of	O
the	O
disambiguation	O
decisions	O
.	O
A	O
key	O
to	O
improve	O
the	O
performance	O
of	O
ED	O
is	O
to	O
effectively	O
combine	O
both	O
local	O
and	O
global	O
contextual	O
information	O
(	O
Ganea	O
and	O
Hofmann	O
,	O
2017;Le	O
and	O
Titov	O
,	O
2018	O
)	O
.	O

•	O
Vote	O
(	O
Mou	O
et	O
al	O
.	O
,	O
2021	O
)	O
proposes	O
to	O
align	O
statements	O
on	O
social	O
networks	O
with	O
voting	O
records	O
.	O

These	O
Figure	O
1	O
illustrates	O
the	O
three	O
instantiations	O
of	O
f	O
.	O
In	O
all	O
cases	O
,	O
attribute	O
-	O
value	O
pairs	O
are	O
ordered	O
in	O
descending	O
order	O
of	O
the	O
frequency	O
with	O
which	O
they	O
appear	O
in	O
the	O
training	O
KB	O
.	O
Finally	O
,	O
since	O
both	O
the	O
candidate	O
generation	O
and	O
candidate	O
re	O
-	O
ranking	O
models	O
we	O
build	O
on	O
use	O
BERT	B-MethodName
,	O
the	O
techniques	O
discussed	O
here	O
can	O
be	O
applied	O
to	O
both	O
stages	O
,	O
but	O
we	O
only	O
focus	O
on	O
re	O
-	O
ranking	O
.	O

D4	O
.	O
Was	O
the	O
data	O
collection	O
protocol	O
approved	O
(	O
or	O
determined	O
exempt	O
)	O
by	O
an	O
ethics	O
review	O
board	O
?	O
No	O
response	O
.	O

We	O
build	O
on	O
this	O
line	O
of	O
research	O
,	O
pioneered	O
by	O
REALM	B-MethodName
and	O
RAG	B-MethodName
,	O
and	O
propose	O
a	O
new	O
approach	O
that	O
we	O
call	O
Re	O
2	O
G	O
(	O
Retrieve	O
,	O
Rerank	O
,	O
Generate	O
)	O
,	O
which	O
combines	O
both	O
neural	O
initial	O
retrieval	O
and	O
reranking	O
into	O
a	O
BART	B-MethodName
-	O
based	O
sequenceto	O
-	O
sequence	I-TaskName
generation	I-TaskName
.	O

To	O
provide	O
more	O
context	O
to	O
the	O
automated	O
evaluation	O
,	O
we	O
also	O
use	O
knowledge	O
graph	O
embeddings	O
.	O
We	O
rely	O
on	O
the	O
KGvec2go	B-MethodName
Web	O
API	O
(	O
Portisch	O
et	O
al	O
.	O
,	O
2020	O
)	O
created	O
from	O
the	O
resources	O
WordNet	O
,	O
Wiktionary	O
,	O
DBpedia	O
,	O
and	O
WebIsALOD	O
.	O
We	O
average	O
the	O
four	O
returned	O
similarity	O
scores	O
based	O
on	O
the	O
different	O
resources	O
,	O
called	O
KB	O
score	O
in	O
the	O
following	O
.	O

The	O
key	O
difference	O
between	O
the	O
vanilla	B-MethodName
Transformer	I-MethodName
decoder	I-MethodName
and	O
ours	O
is	O
the	O
in	O
-	O
parallel	O
cross	O
-	O
attention	O
layer	O
which	O
allows	O
better	O
integration	O
of	O
knowledge	O
encoded	O
in	O
the	O
two	O
sources	O
.	O
Concretely	O
,	O
in	O
-	O
parallel	O
cross	O
attentions	O
are	O
implemented	O
as	O
follows	O
:	O

Evaluation	O
.	O
We	O
evaluate	O
the	O
generated	O
summaries	O
using	O
lexical	O
-	O
overlap	O
metrics	O
,	O
specifically	O
ROUGE-1	O
/	O
2	O
/	O
L	O
(	O
Lin	O
,	O
2004	O
)	O
,	O
and	O
embeddingsimilarity	O
metrics	O
,	O
specifically	O
BERTSCORE	O
(	O
Zhang	O
et	O
al	O
.	O
,	O
2020b	O
)	O
.	O
Besides	O
,	O
we	O
resort	O
to	O
more	O
precise	O
human	O
studies	O
to	O
evaluate	O
the	O
consistency	O
of	O
generated	O
summaries	O
and	O
source	O
documents	O
.	O
See	O
Appendix	O
A	O
for	O
more	O
useful	O
evaluation	O
details	O
.	O

We	O
count	O
psychologically	O
relevant	O
word	O
categories	O
using	O
the	O
Linguistic	O
Inquiry	O
Word	O
Count	O
(	O
Pennebaker	O
et	O
al	O
.	O
,	O
2015	O
,	O
LIWC	O
;)	O
,	O
focusing	O
only	O
on	O
the	O
cognitive	O
processes	O
,	O
positive	O
emotion	O
,	O
negative	O
emotion	O
,	O
and	O
I	O
-	O
word	O
categories	O
,	O
as	O
well	O
as	O
the	O
ANALYTIC	O
and	O
TONE	O
summary	O
variables	O
.	O
5	O
Additionally	O
,	O
we	O
measure	O
the	O
average	O
concreteness	O
level	O
of	O
words	O
in	O
stories	O
using	O
the	O
lexicon	O
by	O
Brysbaert	O
et	O
al	O
.	O
(	O
2014	O
)	O
.	O

B4	O
.	O
Did	O
you	O
discuss	O
the	O
steps	O
taken	O
to	O
check	O
whether	O
the	O
data	O
that	O
was	O
collected	O
/	O
used	O
contains	O
any	O
information	O
that	O
names	O
or	O
uniquely	O
identifies	O
individual	O
people	O
or	O
offensive	O
content	O
,	O
and	O
the	O
steps	O
taken	O
to	O
protect	O
/	O
anonymize	O
it	O
?	O
We	O
did	O
not	O
discuss	O
this	O
as	O
the	O
datasets	O
are	O
commonly	O
used	O
NLP	O
benchmarks	O
that	O
do	O
not	O
contain	O
personal	O
data	O
.	O

For	O
all	O
eight	O
topics	O
,	O
we	O
show	O
the	O
generated	O
argument	O
with	O
the	O
highest	O
and	O
lowest	O
argument	O
quality	O
score	O
in	O
tables	O
11	O
(	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
CC	O
)	O
and	O
12	O
(	O
Arg	O
-	I-MethodName
CTRL	I-MethodName
REDDIT	O
)	O
.	O
Text	O
in	O
bold	O
shows	O
the	O
given	O
control	O
code	O
,	O
text	O
afterwards	O
represents	O
the	O
generated	O
argument	O
.	O
Numbers	O
in	O
brackets	O
after	O
the	O
text	O
show	O
the	O
quality	O
score	O
as	O
predicted	O
by	O
the	O
argument	O
quality	O
model	O
.	O

Our	O
focus	O
is	O
on	O
linking	O
entities	O
to	O
unseen	O
KBs	O
with	O
arbitrary	O
schemas	O
.	O
One	O
solution	O
is	O
to	O
annotate	O
data	O
that	O
can	O
be	O
used	O
to	O
train	O
specialized	O
models	O
for	O
each	O
target	O
KB	O
of	O
interest	O
,	O
but	O
this	O
is	O
not	O
scalable	O
.	O
A	O
more	O
generic	O
solution	O
is	O
to	O
build	O
entity	O
linking	O
models	O
that	O
work	O
with	O
arbitrary	O
KBs	O
.	O
We	O
follow	O
this	O
latter	O
approach	O
and	O
build	O
entity	O
linking	O
models	O
that	O
link	O
to	O
target	O
KBs	O
that	O
have	O
not	O
been	O
observed	O
during	O
training	O
.	O
1	O
Our	O
solution	O
builds	O
on	O
recent	O
models	O
for	O
zero	O
-	O
shot	O
entity	O
linking	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2020;Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
However	O
,	O
these	O
models	O
assume	O
the	O
same	O
,	O
simple	O
KB	O
schema	O
during	O
training	O
and	O
inference	O
.	O
We	O
generalize	O
these	O
models	O
to	O
handle	O
different	O
KBs	O
during	O
training	O
and	O
inference	O
,	O
containing	O
entities	O
represented	O
with	O
an	O
arbitrary	O
set	O
of	O
attribute	O
-	O
value	O
pairs	O
.	O
This	O
generalization	O
relies	O
on	O
two	O
key	O
ideas	O
.	O
First	O
,	O
we	O
convert	O
KB	O
entities	O
into	O
strings	O
that	O
are	O
consumed	O
by	O
the	O
models	O
for	O
zero	O
-	O
shot	O
linking	O
.	O
Central	O
to	O
the	O
string	O
representation	O
are	O
special	O
tokens	O
called	O
attribute	O
separators	O
,	O
which	O
represent	O
frequently	O
occurring	O
attributes	O
in	O
the	O
training	O
KB(s	O
)	O
,	O
and	O
carry	O
over	O
their	O
knowledge	O
to	O
unseen	O
KBs	O
during	O
inference	O
(	O
Section	O
4.1	O
)	O
.	O
Second	O
,	O
we	O
generate	O
more	O
flexible	O
string	O
representations	O
by	O
shuffling	O
entity	O
attributes	O
before	O
converting	O
them	O
to	O
strings	O
,	O

By	O
comparing	O
the	O
translations	O
for	O
headers	O
with	O
special	O
tokenization	O
,	O
we	O
can	O
see	O
that	O
all	O
fine	O
-	O
tuned	O
models	O
,	O
including	O
H2H	O
,	O
H2H+CXT	O
,	O
and	O
CAST	B-MethodName
can	O
accurately	O
translate	O
headers	O
in	O
CamelCase	B-MethodName
or	O
underscore	O
tokenizations	O
,	O
while	O
Base	O
fails	O
to	O
skip	O
the	O
underscore	O
and	O
can	O
not	O
translate	O
"	O
Debt	O
"	O
in	O
the	O
middle	O
of	O
"	O
AccessedDebtService	B-MethodName
"	O
.	O

To	O
further	O
demonstrate	O
the	O
intuition	O
behind	O
our	O
framework	O
,	O
we	O
randomly	O
sample	O
1,000	O
examples	O
from	O
test	O
sets	O
of	O
En→De	O
and	O
En→Es	O
directions	O
and	O
use	O
t	B-MethodName
-	I-MethodName
SNE	I-MethodName
(	O
Van	O
der	O
Maaten	O
and	O
Hinton	O
,	O
2008	O
)	O
to	O
visualize	O
the	O
sentence	O
embedding	O
of	O
translation	O
memories	O
and	O
target	O
sentence	O
encoded	O
by	O
our	O
CMM	B-MethodName
.	O
The	O
result	O
is	O
shown	O
in	O
Figure	O
4	O
and	O
one	O
interesting	O
observation	O
is	O
that	O
although	O
the	O
target	O
side	O
of	O
testset	O
is	O
never	O
exposed	O
to	O
the	O
model	O
,	O
the	O
representation	O
of	O
translation	O
memories	O
are	O
uniformly	O
distributed	O
around	O
the	O
target	O
sentence	O
in	O
the	O
latent	O
semantic	O
space	O
.	O

Does	O
familiarizing	O
the	O
LM	O
with	O
the	O
task	O
format	O
using	O
a	O
few	O
-	O
shot	O
evaluation	O
setting	O
substantially	O
improve	O
performance	O
(	O
§	O
4	O
)	O
?	O
We	O
find	O
that	O
the	O
fewshot	O
evaluation	O
(	O
using	O
up	O
to	O
64	O
examples	O
)	O
does	O
not	O
substantially	O
improve	O
the	O
LMs	O
'	O
performance	O
for	O
most	O
tasks	O
except	O
Social	O
IQa	O
.	O
Moreover	O
,	O
using	O
the	O
few	O
-	O
shot	O
/	O
in	O
-	O
context	O
demonstration	O
setting	O
fails	O
to	O
bridge	O
the	O
gap	O
between	O
the	O
LM	O
and	O
current	O
SOTA	O
.	O

B3	O
.	O
Did	O
you	O
discuss	O
if	O
your	O
use	O
of	O
existing	O
artifact	O
(	O
s	O
)	O
was	O
consistent	O
with	O
their	O
intended	O
use	O
,	O
provided	O
that	O
it	O
was	O
specified	O
?	O
For	O
the	O
artifacts	O
you	O
create	O
,	O
do	O
you	O
specify	O
intended	O
use	O
and	O
whether	O
that	O
is	O
compatible	O
with	O
the	O
original	O
access	O
conditions	O
(	O
in	O
particular	O
,	O
derivatives	O
of	O
data	O
accessed	O
for	O
research	O
purposes	O
should	O
not	O
be	O
used	O
outside	O
of	O
research	O
contexts	O
)	O
?	O
Left	O
blank	O
.	O

Thus	O
,	O
each	O
piece	O
of	O
multi	O
-	O
modal	O
sample	O
is	O
manually	O
annotated	O
with	O
desire	O
category	O
,	O
sentiment	O
category	O
(	O
i.e.	O
,	O
positive	O
,	O
neutral	O
and	O
negative	O
)	O
and	O
emotion	O
category	O
(	O
happiness	O
,	O
sad	O
,	O
neutral	O
,	O
disgust	O
,	O
anger	O
and	O
f	O
ear	O
)	O
.	O
The	O
annotation	O
model	O
is	O
AnnotationModel	O
=	O
(	O
DesireCategory	O
,	O
Sentiment	O
-	O
Category	O
,	O
EmotionCategory	O
,	O
DataSource	O
)	O
.	O

Operationally	O
,	O
NCE	B-MethodName
can	O
be	O
viewed	O
as	O
follows	O
:	O

Assessing	O
Discourse	O
Coherence	O
.	O
Table	O
1	O
shows	O
the	O
experimental	O
results	O
on	O
GCDC	B-DatasetName
dataset	O
2	O
.	O
The	O
first	O
three	O
rows	O
(	O
Li	O
and	O
Jurafsky	O
,	O
2017;Mesgar	O
and	O
Strube	O
,	O
2018;Lai	O
and	O
Tetreault	O
,	O
2018	O
)	O
in	O
the	O
first	O
block	O
show	O
the	O
performance	O
of	O
embeddingbased	O
models	O
,	O
and	O
the	O
last	O
four	O
rows	O
(	O
Mesgar	O
and	O
Strube	O
,	O
2016;Moon	O
et	O
al	O
.	O
,	O
2019;Jeon	O
and	O
Strube	O
,	O
2020a	O
,	O
b	O
)	O
in	O
the	O
same	O
block	O
are	O
the	O
state	O
-	O
of	O
-	O
theart	O
models	O
based	O
on	O
XLNet	O
.	O
With	O
the	O
pre	O
-	O
trained	O
model	O
as	O
the	O
encoder	O
,	O
the	O
latter	O
four	O
models	O
outperform	O
embedding	O
-	O
based	O
methods	O
by	O
a	O
large	O
margin	O
.	O

We	O
here	O
present	O
the	O
results	O
of	O
our	O
inter	O
-	O
annotator	O
agreement	O
study	O
,	O
which	O
we	O
perform	O
in	O
order	O
to	O
estimate	O
the	O
degree	O
of	O
reproducibility	O
of	O
our	O
corpus	O
and	O
to	O
put	O
automatic	O
modeling	O
performance	O
into	O
perspective	O
.	O
Six	O
documents	O
(	O
973	O
sentences	O
)	O
have	O
been	O
annotated	O
independently	O
both	O
by	O
our	O
primary	O
annotator	O
,	O
a	O
graduate	O
student	O
of	O
materials	O
science	O
,	O
and	O
a	O
second	O
annotator	O
,	O
who	O
holds	O
a	O
Ph.D.	O
in	O
physics	O
and	O
is	O
active	O
in	O
the	O
field	O
of	O
materials	O
science	O
.	O
The	O
label	O
distribution	O
in	O
this	O
subset	O
is	O
similar	O
to	O
the	O
one	O
of	O
our	O
overall	O
corpus	O
,	O
with	O
each	O
annotator	O
choosing	O
EXPERIMENT	O
about	O
11.8	O
%	O
of	O
the	O
time	O
.	O
Identification	O
of	O
experiment	O
-	O
describing	O
sentences	O
.	O
Agreement	O
on	O
our	O
first	O
task	O
,	O
judging	O
whether	O
a	O
sentence	O
contains	O
relevant	O
experimental	O
information	O
,	O
is	O
0.75	O
in	O
terms	O
of	O
Cohen	O
's	O
κ	O
(	O
Cohen	O
,	O
1968	O
)	O
,	O
indicating	O
substantial	O
agreement	O
according	O
to	O
Landis	O
and	O
Koch	O
(	O
1977	O
)	O
.	O
The	O
observed	O
agreement	O
,	O
corresponding	O
to	O
accuracy	O
,	O
is	O
94.9	O
%	O
;	O
expected	O
agreement	O
amounts	O
to	O
79.2	O
%	O
.	O
Table	O
2	O
shows	O
precision	O
,	O
recall	O
and	O
F1	O
for	O
the	O
doubly	O
-	O
annotated	O
subset	O
,	O
treating	O
one	O
annotator	O
as	O
the	O
gold	O
standard	O
and	O
the	O
other	O
one	O
's	O
labels	O
as	O
predicted	O
.	O
Our	O
primary	O
annotator	O
identifies	O
119	O
out	O
of	O
973	O
sentences	O
as	O
experiment	O
-	O
describing	O
,	O
our	O
secondary	O
annotator	O
111	O
sentences	O
,	O
with	O
an	O
overlap	O
of	O
90	O
sentences	O
.	O
These	O
statistics	O
are	O
helpful	O
to	O
gain	O
further	O
intuition	O
of	O
how	O
well	O
a	O
human	O
can	O
reproduce	O
another	O
annotator	O
's	O
labels	O
and	O
can	O
also	O
be	O
considered	O
an	O
upper	O
bound	O
for	O
system	O
performance	O
.	O

Complete	O
this	O
story	O
in	O
500	O
words	O
.	O
The	O
narrator	O
,	O
a	O
Yale	O
graduate	O
,	O
moves	O
to	O
New	O
York	O
to	O
learn	O
the	O
bond	O
business	O
.	O
He	O
visits	O
his	O
second	O
cousin	O
,	O
Daisy	O
,	O
and	O
her	O
husband	O
,	O
Tom	O
,	O
for	O
dinner	O
.	O
During	O
the	O
dinner	O
,	O
Daisy	O
mentions	O
she	O
wants	O
to	O
go	O
back	O
to	O
Chicago	O
the	O
next	O
day	O
.	O

We	O
evaluate	O
PAR	O
and	O
competitive	O
baselines	O
on	O
roll	O
call	O
vote	O
prediction	O
and	O
present	O
model	O
performance	O
in	O
Table	O
2	O
.	O
PAR	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
,	O
outperforming	O
existing	O
baselines	O
that	O
model	O
political	O
actors	O
in	O
different	O
ways	O
.	O
As	O
a	O
result	O
,	O
PAR	O
learns	O
high	O
-	O
quality	O
representations	O
of	O
political	O
actors	O
that	O
provide	O
political	O
knowledge	O
and	O
augment	O
the	O
vote	O
prediction	O
process	O
.	O

The	O
input	O
form	O
of	O
BERT	B-MethodName
without	O
context	O
is	O

Predicted	O
Program	O
:	O
fact_1	O
=	O
Verify	O
(	O
"	O
Tritonia	O
is	O
a	O
name	O
for	O
a	O
plant	O
genus	O
.	O
"	O
)	O
fact_2	O
=	O
Verify	O
(	O
"	O
Phyteuma	O
is	O
a	O
name	O
for	O
a	O
plant	O
genus	O
.	O
"	O
)	O
label	O
=	O
Predict	O
(	O
fact_1	O
and	O
fact_2	O
)	O

For	O
the	O
sentence	O
-	O
level	O
QE	O
task	O
,	O
each	O
document	O
of	O
the	O
dataset	O
was	O
split	O
into	O
sentences	O
(	O
lines	O
)	O
,	O
where	O
every	O
sentence	O
has	O
its	O
corresponding	O
MQM	O
score	O
computed	O
in	O
the	O
same	O
way	O
as	O
for	O
the	O
document	O
.	O
We	O
note	O
that	O
this	O
variant	O
is	O
different	O
from	O
the	O
official	O
sentence	O
-	O
level	O
track	O
at	O
WMT	B-DatasetName
since	O
for	O
that	O
task	O
visual	O
information	O
is	O
not	O
available	O
.	O

Diversity	O
:	O
To	O
evaluate	O
the	O
diversity	O
of	O
generated	O
text	O
,	O
we	O
consider	O
Dist	B-MethodName
-	I-MethodName
n	I-MethodName
(	O
Li	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
Self	B-MetricName
-	I-MetricName
BLEU	I-MetricName
(	O
S	B-MetricName
-	I-MetricName
BL	I-MetricName
)	O
(	O
Zhu	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
More	O
metrics	O
details	O
are	O
described	O
in	O
Appendix	O
A.3	O
.	O

Analyzing	O
model	O
learning	O
throughout	O
pretraining	O
requires	O
access	O
to	O
intermediate	O
training	O
check	O
-	O
points	O
,	O
rather	O
than	O
just	O
the	O
final	O
artifact	O
.	O
We	O
replicate	O
the	O
base	O
version	O
of	O
XLM	O
-	I-MethodName
R	I-MethodName
and	O
save	O
a	O
number	O
of	O
checkpoints	O
throughout	O
the	O
training	O
process	O
.	O
Our	O
pretraining	O
setup	O
primarily	O
follows	O
that	O
of	O
the	O
original	O
XLM	O
-	I-MethodName
R	O
,	O
with	O
the	O
exception	O
that	O
we	O
use	O
a	O
smaller	O
batch	O
size	O
(	O
1024	O
examples	O
per	O
batch	O
instead	O
of	O
8192	O
)	O
due	O
to	O
computational	O
constraints	O
.	O
All	O
other	O
hyperparameters	O
remain	O
unchanged	O
.	O

Accuracy	O
results	O
in	O
Table	O
2	O
have	O
a	O
95	O
%	O
Wald	O
confidence	O
interval	O
of	O
±2.8	O
%	O
.	O
The	O
first	O
row	O
of	O
Table	O
2	O
presents	O
the	O
accuracy	O
results	O
of	O
a	O
vanilla	O
UnifiedQA	B-MethodName
large	O
model	O
on	O
SciQ.	O
The	O
second	O
line	O
shows	O
the	O
accuracy	O
when	O
UnifiedQA	B-MethodName
is	O
fine	O
-	O
tuned	O
over	O
the	O
full	O
training	O
corpus	O
.	O
Our	O
objective	O
is	O
thus	O
to	O
get	O
as	O
close	O
as	O
possible	O
to	O
this	O
accuracy	O
score	O
using	O
only	O
un	O
-	O
supervised	O
methods	O
.	O
The	O
results	O
using	O
Wikipedia	O
are	O
the	O
only	O
ones	O
that	O
are	O
unsupervised	O
and	O
therefore	O
are	O
the	O
ones	O
directly	O
comparable	O
to	O
UnifiedQA	B-MethodName
with	O
no	O
fine	O
-	O
tuning	O
or	O
other	O
unsupervised	O
methods	O
.	O
Table	O
2	O
:	O
Accuracy	O
on	O
SciQ	B-MethodName
by	O
UnifiedQA	B-MethodName
fine	O
-	O
tuned	O
on	O
our	O
synthetic	O
datasets	O
.	O
"	O
SciQ	O
data	O
"	O
refers	O
to	O
the	O
questions	O
generated	O
using	O
the	O
support	O
paragraphs	O
in	O
SciQ	B-MethodName
while	O
"	O
Wikipedia	O
data	O
"	O
refers	O
to	O
questions	O
generated	O
using	O
sentences	O
harvested	O
from	O
Wikipedia	O
.	O
All	O
scores	O
are	O
averaged	O
over	O
3	O
independent	O
runs	O
(	O
including	O
the	O
complete	O
question	O
generation	O
process	O
and	O
the	O
final	O
Uni	O
-	O
fiedQA	O
fine	O
-	O
tuning	O
)	O
.	O

In	O
the	O
future	O
,	O
we	O
would	O
like	O
to	O
explore	O
whether	O
such	O
speaker	O
prompting	O
can	O
improve	O
models	O
in	O
other	O
person	O
-	O
centered	O
tasks	O
,	O
e.g.	O
,	O
coreference	O
resolution	I-TaskName
(	O
especially	O
for	O
datasets	O
explicitly	O
testing	O
gender	O
biases	O
)	O
or	O
sentiment	O
analysis	O
.	O
Using	O
techniques	O
such	O
as	O
data	O
augmentation	O
,	O
we	O
can	O
explicitly	O
guide	O
models	O
away	O
from	O
biases	O
learned	O
during	O
training	O
.	O
With	O
ethical	O
considerations	O
in	O
mind	O
,	O
our	O
work	O
advances	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
building	O
more	O
adaptable	O
and	O
person	O
-	O
aware	O
NLP	O
technologies	O
.	O
Yuheng	O
Zhang	O
,	O
Ruoxi	O
Jia	O
,	O
Hengzhi	O
Pei	O
,	O
Wenxiao	O
Wang	O
,	O
Bo	O
Li	O
,	O
and	O
Dawn	O
Song	O
.	O
2020	O

In	O
them	O
,	O
the	O
M	O
LP	O
ap	O
,	O
M	O
LP	O
cl	O
and	O
M	O
LP	O
ac	O
are	O
the	O
MLP	O
applied	O
to	O
predict	O
the	O
probabilities	O
of	O
all	O
appearance	O
,	O
clothing	O
,	O
and	O
action	O
classes	O
(	O
p	O
ap	O
,	O
p	O
cl	O
,	O
and	O
p	O
ac	O
)	O
,	O
respectively	O
.	O
We	O
employ	O
the	O
cross	O
-	O
entropy	O
loss	O
function	O
to	O
train	O
the	O
prediction	O
of	O
commonsense	O
knowledge	O
.	O

Our	O
Twitter	B-MethodName
-	I-MethodName
Para	I-MethodName
is	O
a	O
pre	O
-	O
processed	O
dataset	O
based	O
on	O
(	O
Xu	O
et	O
al	O
.	O
,	O
2014	O
(	O
Xu	O
et	O
al	O
.	O
,	O
,	O
2015	O
.	O
In	O
the	O
original	O
dataset	O
(	O
Xu	O
et	O
al	O
.	O
,	O
2014	O
(	O
Xu	O
et	O
al	O
.	O
,	O
,	O
2015	O
,	O
there	O
are	O
some	O
input	O
sentences	O
that	O
have	O
no	O
corresponding	O
references	O
,	O
so	O
we	O
drop	O
such	O
input	O
-	O
candidate	O
pairs	O
to	O
create	O
Twitter	B-MethodName
-	I-MethodName
Para	I-MethodName
.	O
Specifically	O
,	O
the	O
human	O
-	O
annotated	O
score	O
ranges	O
from	O
0∼1.0	O
,	O
where	O
higher	O
scores	O
mean	O
better	O
quality	O
.	O
The	O
basic	O
statistics	O
of	O
Twitter	B-MethodName
-	I-MethodName
Para	I-MethodName
are	O
listed	O
in	O

The	O
network	O
then	O
splits	O
into	O
two	O
branches	O
.	O
The	O
primary	O
(	O
bottom	O
)	O
branch	O
consists	O
of	O
a	O
neural	O
network	O
model	O
g	O
,	O
with	O
parameters	O
θ	O
3	O
,	O
which	O
produces	O
promotional	O
tone	O
predictionsŷ	O
T	O
1	O
andŷ	O
T	O
2	O
for	O
the	O
two	O
samples	O
:	O

Random	O
effects	O
via	O
regularization	O
.	O
We	O
are	O
now	O
prepared	O
to	O
introduce	O
random	O
effects	O
into	O
the	O
transformer	O
via	O
hierarchical	O
prefix	O
-	O
tuning	O
.	O
Critically	O
,	O
instead	O
of	O
assuming	O
that	O
all	O
values	O
of	O
a	O
particular	O
feature	O
have	O
independent	O
fixed	O
effects	O
(	O
e.g.	O
that	O
the	O
language	O
associated	O
with	O
one	O
genre	O
is	O
independent	O
of	O
other	O
genres	O
)	O
,	O
we	O
would	O
like	O
to	O
assume	O
they	O
are	O
drawn	O
from	O
a	O
common	O
distribution	O
:	O

Multilinguality	O
Multilinguality	O
allows	O
training	O
a	O
single	O
model	O
to	O
perform	O
a	O
task	O
from	O
and/or	O
to	O
multiple	O
languages	O
.	O
Even	O
though	O
this	O
has	O
been	O
applied	O
to	O
many	O
tasks	O
Zampieri	O
,	O
2020	O
,	O
2021	O
)	O
including	O
NMT	B-MethodName
(	O
Nguyen	O
and	O
Chiang	O
,	O
2017;Aharoni	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
multilingual	O
approaches	O
have	O
been	O
rarely	O
used	O
in	O
QE	O
.	O
Shah	O
and	O
Specia	O
(	O
2016	O
)	O
explore	O
QE	O
models	O
for	O
more	O
than	O
one	O
language	O
where	O
they	O
use	O
multitask	O
learning	O
with	O
annotators	O
or	O
languages	O
as	O
multiple	O
tasks	O
.	O
They	O
show	O
that	O
multilingual	O
models	O
led	O
to	O
marginal	O
improvements	O
over	O
bilingual	O
ones	O
with	O
a	O
traditional	O
black	O
-	O
box	O
,	O
feature	O
-	O
based	O
approach	O
.	O
In	O
a	O
recent	O
study	O
,	O
Ranasinghe	O
et	O
al	O
.	O
(	O
2020b	O
)	O
show	O
that	O
multilingual	O
QE	O
models	O
based	O
on	O
transformers	O
trained	O
on	O
high	O
-	O
resource	O
languages	O
can	O
be	O
used	O
for	O
zeroshot	O
,	O
sentence	O
-	O
level	O
QE	O
in	O
low	O
-	O
resource	O
languages	O
.	O

-DOCSTART-	O
Position	I-MethodName
encoding	I-MethodName
(	O
PE	O
)	O
,	O
an	O
essential	O
part	O
of	O
self	O
-	I-MethodName
attention	O
networks	O
(	O
SANs	O
)	O
,	O
is	O
used	O
to	O
preserve	O
the	O
word	O
order	O
information	O
for	O
natural	O
language	O
processing	O
tasks	O
,	O
generating	O
fixed	O
position	O
indices	O
for	O
input	O
sequences	O
.	O
However	O
,	O
in	O
cross	O
-	O
lingual	O
scenarios	O
,	O
e.g.	O
,	O
machine	O
translation	O
,	O
the	O
PEs	O
of	O
source	O
and	O
target	O
sentences	O
are	O
modeled	O
independently	O
.	O
Due	O
to	O
word	O
order	O
divergences	O
in	O
different	O
languages	O
,	O
modeling	O
the	O
cross	O
-	O
lingual	O
positional	O
relationships	O
might	O
help	O
SANs	O
tackle	O
this	O
problem	O
.	O
In	O
this	O
paper	O
,	O
we	O
augment	O
SANs	O
with	O
crosslingual	O
position	O
representations	O
to	O
model	O
the	O
bilingually	O
aware	O
latent	O
structure	O
for	O
the	O
input	O
sentence	O
.	O
Specifically	O
,	O
we	O
utilize	O
bracketing	O
transduction	O
grammar	O
(	O
BTG)-based	B-MethodName
reordering	O
information	O
to	O
encourage	O
SANs	O
to	O
learn	O
bilingual	O
diagonal	O
alignments	O
.	O
Experimental	O
results	O
on	O
WMT'14	B-DatasetName
English⇒German	O
,	O
WAT'17	O
Japanese⇒English	O
,	O
and	O
WMT'17	B-DatasetName
Chinese⇔English	O
translation	O
tasks	O
demonstrate	O
that	O
our	O
approach	O
significantly	O
and	O
consistently	O
improves	O
translation	O
quality	O
over	O
strong	O
baselines	O
.	O
Extensive	O
analyses	O
confirm	O
that	O
the	O
performance	O
gains	O
come	O
from	O
the	O
cross	O
-	O
lingual	O
information	O
.	O

In	O
addition	O
,	O
the	O
API	O
provides	O
the	O
names	O
of	O
the	O
legislators	O
who	O
cosponsored	O
a	O
bill	O
and	O
when	O
this	O
cosponsorship	O
occurred	O
.	O
We	O
automatically	O
match	O
the	O
cosponsors	O
'	O
names	O
to	O
their	O
BioGuide	O
ID	O
.	O
In	O
cases	O
where	O
automated	O
matching	O
was	O
not	O
possible	O
-e.g	O
.	O
,	O
because	O
legislators	O
signed	O
with	O
their	O
nicknames	O
-	O
we	O
resorted	O
to	O
manual	O
matching	O
.	O
As	O
discussed	O
in	O
Section	O
1	O
,	O
we	O
assign	O
cosponsorship	O
their	O
official	O
label	O
.	O
Cospsonsorships	O
recorded	O
at	O
the	O
bill	O
's	O
introduction	O
are	O
active	O
and	O
those	O
recorded	O
after	O
its	O
introduction	O
are	O
passive	O
.	O

5	O
For	O
a	O
fair	O
comparison	O
,	O
we	O
exclude	O
the	O
WNLI	O
following	O
the	O
previous	O
work	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O

The	O
Rules	O
grouping	O
method	O
used	O
in	O
the	O
second	O
stage	O
of	O
the	O
CT	O
-	O
Rules	O
model	O
,	O
relied	O
on	O
categoryspecific	O
statistics	O
in	O
the	O
training	O
portion	O
of	O
SWIPE	B-MethodName
.	O
Categories	O
were	O
split	O
into	O
two	O
sub	O
-	O
groups	O
:	O
contiguous	O
and	O
global	O
.	O
For	O
each	O
category	O
,	O
we	O
analyzed	O
the	O
percentage	O
of	O
annotated	O
of	O
edits	O
of	O
the	O
given	O
category	O
that	O
were	O
contiguous	O
(	O
adjacent	O
)	O
in	O
their	O
operation	O
group	O
.	O
For	O
each	O
edit	O
category	O
,	O
if	O
a	O
majority	O
of	O
annotated	O
cases	O
were	O
contiguous	O
,	O
the	O
edit	O
category	O
was	O
labeled	O
as	O
contiguous	O
,	O
otherwise	O
,	O
it	O
was	O
labeled	O
as	O
global	O
.	O
For	O
categories	O
marked	O
as	O
contiguous	O
,	O
the	O
model	O
generated	O
groups	O
for	O
predicted	O
operation	O
types	O
based	O
on	O
contiguous	O
boundaries	O
(	O
identical	O
to	O
the	O
Adjacent	O
grouping	O
method	O
)	O
,	O
and	O
all	O
operations	O
of	O
a	O
given	O
global	O
category	O
were	O
organized	O
into	O
a	O
single	O
group	O
.	O

Our	O
model	O
is	O
based	O
on	O
BERT	B-MethodName
LARGE	I-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
parameters	O
shared	O
with	O
BERT	B-MethodName
are	O
initialized	O
using	O
BERT	B-MethodName
,	O
and	O
the	O
other	O
parameters	O
are	O
initialized	O
randomly	O
.	O
We	O
treat	O
the	O
hyperlinks	O
in	O
Wikipedia	O
as	O
entity	O
annotations	O
and	O
randomly	O
mask	O
30	O
%	O
of	O
all	O
entities	O
.	O
We	O
train	O
the	O
model	O
by	O
maximizing	O
the	O
log	O
likelihood	O
of	O
entity	O
predictions	O
.	O
Further	O
details	O
are	O
described	O
in	O
Appendix	O
A.	O

ii	O
We	O
explore	O
multilingual	O
,	O
word	O
-	O
level	O
quality	O
estimation	O
with	O
the	O
proposed	O
architecture	O
.	O
We	O
show	O
that	O
multilingual	O
models	O
are	O
competitive	O
with	O
bilingual	O
models	O
.	O

All	O
results	O
are	O
from	O
a	O
single	O
run	O
.	O
The	O
random	O
seed	O
for	O
python	O
,	O
numpy	O
and	O
pytorch	O
was	O
42	O
.	O

We	O
formulate	O
multiple	O
-	O
choice	O
tasks	O
as	O
text	O
-	O
to	O
-	O
text	O
by	O
concatenating	O
the	O
human	O
-	O
authored	O
cartoon	O
descriptions	O
with	O
the	O
choices	O
as	O
input	O
:	O
the	O
target	O
is	O
simply	O
the	O
letter	O
corresponding	O
to	O
the	O
answer	O
,	O
e.g.	O
,	O
E.	O
For	O
explanation	O
,	O
we	O
autoregressively	O
generate	O
the	O
explanations	O
conditioned	O
on	O
the	O
descriptions	O
/	O
captions	O
.	O

Separate	O
scalar	O
mixes	O
.	O
To	O
enable	O
fine	O
-	O
grained	O
analysis	O
of	O
probing	O
results	O
,	O
we	O
train	O
and	O
analyze	O
separate	O
scalar	O
mixes	O
for	O
source	O
and	O
target	O
wordpieces	O
,	O
motivated	O
by	O
the	O
fact	O
that	O
the	O
classifier	O
might	O
utilize	O
different	O
aspects	O
of	O
their	O
representation	O
for	O
prediction	O
1	O
.	O
Indeed	O
,	O
we	O
find	O
that	O
the	O
mixing	O
weights	O
learned	O
for	O
source	O
and	O
target	O
wordpieces	O
might	O
show	O
substantial	O
-and	O
linguistically	O
meaningful	O
-variation	O
.	O
Combined	O
with	O
regressionbased	O
objective	O
,	O
separating	O
the	O
scalar	O
mixes	O
allows	O
us	O
to	O
scrutinize	O
layer	O
utilization	O
patterns	O
for	O
semantic	O
proto	O
-	O
roles	O
.	O

The	O
goal	O
is	O
to	O
identify	O
the	O
emotion	O
label	O
y	O
i	O
for	O
each	O
utterance	O
u	O
i	O
from	O
the	O
pre	O
-	O
defined	O
emotions	O
Y	O
.	O

Language	O
modeling	O
(	O
Dai	O
and	O
Le	O
,	O
2015;Radford	O
et	O
al	O
.	O
,	O
2018;Peters	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
cloze	O
modeling	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019;Baevski	O
et	O
al	O
.	O
,	O
2019	O
;	O
have	O
proven	O
to	O
be	O
effective	O
pre	O
-	O
training	O
tasks	O
for	O
NLP	O
.	O
Unlike	O
Electric	O
,	O
these	O
methods	O
follow	O
the	O
standard	O
recipe	O
of	O
estimating	O
token	O
probabilities	O
with	O
an	O
output	O
softmax	O
and	O
using	O
maximumlikelihood	O
training	O
.	O

When	O
working	O
with	O
clinical	O
data	O
,	O
two	O
key	O
ethical	O
objectives	O
include	O
:	O
(	O
1	O
)	O
the	O
preservation	O
of	O
pa	O
-	O
tient	O
privacy	O
,	O
and	O
(	O
2	O
)	O
the	O
development	O
of	O
language	O
and	O
predictive	O
models	O
that	O
benefit	O
patients	O
and	O
providers	O
to	O
the	O
extent	O
possible	O
,	O
without	O
causing	O
undue	O
harm	O
.	O
With	O
respect	O
to	O
the	O
former	O
,	O
MedNLI	B-MethodName
's	O
premises	O
are	O
sampled	O
from	O
de	O
-	O
identified	O
clinical	O
notes	O
contained	O
in	O
MIMIC	B-DatasetName
-	I-DatasetName
III	I-DatasetName
(	O
Goldberger	O
et	O
al	O
.	O
,	O
2000	O
(	O
June	O
13;Johnson	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
and	O
the	O
hypotheses	O
generated	O
by	O
annotators	O
do	O
not	O
refer	O
to	O
specific	O
patients	O
,	O
providers	O
,	O
or	O
locations	O
by	O
name	O
.	O
MedNLI	B-MethodName
requires	O
users	O
to	O
complete	O
Health	O
Insurance	O
Portability	O
and	O
Accountability	O
Act	O
(	O
HIPAA	B-DatasetName
)	O
training	O
and	O
sign	O
a	O
data	O
use	O
agreement	O
prior	O
to	O
being	O
granted	O
access	O
,	O
which	O
we	O
have	O
complied	O
with	O
.	O

PropBank	B-MethodName
assumes	O
a	O
predicate	O
-	O
independent	O
labeling	O
scheme	O
where	O
predicates	O
are	O
distinguished	O
by	O
their	O
sense	O
(	O
get.01	O
)	O
,	O
and	O
semantic	O
arguments	O
are	O
labeled	O
with	O
generic	O
numbered	O
core	O
(	O
Arg0	O
-	O
5	O
)	O
and	O
modifier	O
(	O
e.g.	O
AM	B-MethodName
-	I-MethodName
TMP	I-MethodName
)	O
roles	O
.	O
Core	O
roles	O
are	O
not	O
tied	O
to	O
specific	O
definitions	O
,	O
but	O
the	O
effort	O
has	O
been	O
made	O
to	O
keep	O
the	O
role	O
assignments	O
consistent	O
for	O
similar	O
verbs	O
;	O
Arg0	O
and	O
Arg1	O
correspond	O
to	O
the	O
Proto	O
-	O
Agent	O
and	O
Proto	O
-	O
Patient	O
roles	O
as	O
per	O
Dowty	O
(	O
1991	O
)	O
.	O
The	O
semantic	O
interpretation	O
of	O
core	O
roles	O
depends	O
on	O
the	O
predicate	O
sense	O
.	O

We	O
use	O
the	O
same	O
line	O
type	O
(	O
dashed	O
or	O
solid	O
)	O
for	O
models	O
trained	O
on	O
the	O
same	O
data	O
.	O
Using	O
the	O
same	O
data	O
,	O
the	O
performance	O
of	O
the	O
two	O
different	O
directions	O
of	O
models	O
can	O
not	O
be	O
compared	O
directly	O
because	O
the	O
target	O
language	O
is	O
different	O
,	O
causing	O
the	O
BLEU	B-MetricName
calculation	O
to	O
be	O
different	O
.	O

We	O
introduce	O
HIPPOCORPUS	O
,	O
1	O
a	O
dataset	O
of	O
6,854	O
diary	O
-	O
like	O
short	O
stories	O
about	O
salient	O
life	O
events	O
,	O
to	O
examine	O
the	O
cognitive	O
processes	O
of	O
remembering	O
and	O
imagining	O
.	O
Using	O
a	O
crowdsourcing	O
pipeline	O
,	O
we	O
collect	O
pairs	O
of	O
recalled	O
and	O
imagined	O
stories	O
written	O
about	O
the	O
same	O
topic	O
.	O
By	O
design	O
,	O
authors	O
of	O
recalled	O
stories	O
rely	O
on	O
their	O
episodic	O
memory	O
to	O
tell	O
their	O
story	O
.	O

Beyond	O
Conventional	O
Entity	O
Linking	O
There	O
have	O
been	O
several	O
attempts	O
to	O
go	O
beyond	O
such	O
conventional	O
settings	O
,	O
e.g.	O
by	O
linking	O
to	O
KBs	O
from	O
diverse	O
domains	O
such	O
as	O
the	O
biomedical	O
sciences	O
(	O
Zheng	O
et	O
al	O
.	O
,	O
2014;D'Souza	O
and	O
Ng	O
,	O
2015	O
)	O
and	O
music	O
(	O
Oramas	O
et	O
al	O
.	O
,	O
2016	O
)	O
or	O
even	O
being	O
completely	O
domain	O
and	O
language	O
independent	O
Onoe	O
and	O
Durrett	O
,	O
2020	O
)	O
.	O
Lin	O
et	O
al	O
.	O
(	O
2017	O
)	O
discuss	O
approaches	O
to	O
link	O
entities	O
to	O
a	O
KB	O
that	O
simply	O
contains	O
a	O
list	O
of	O
names	O
without	O
any	O
other	O
information	O
.	O
Sil	O
et	O
al	O
.	O
(	O
2012	O
)	O
use	O
databaseagnostic	O
features	O
to	O
link	O
against	O
arbitrary	O
databases	O
.	O
However	O
,	O
their	O
approach	O
still	O
requires	O
training	O
data	O
from	O
the	O
target	O
KB	O
.	O
In	O
contrast	O
,	O
this	O
work	O
aims	O
to	O
train	O
entity	O
linking	O
models	O
that	O
do	O
not	O
rely	O
on	O
training	O
data	O
from	O
the	O
target	O
KB	O
,	O
and	O
can	O
be	O
trained	O
on	O
arbitrary	O
KBs	O
,	O
and	O
applied	O
to	O
a	O
different	O
set	O
of	O
KBs	O
.	O
Pan	O
et	O
al	O
.	O
(	O
2015	O
)	O
also	O
do	O
unsupervised	O
entity	O
linking	O
by	O
generating	O
rich	O
context	O
representations	O
for	O
mentions	O
using	O
Abstract	O
Meaning	O
Representations	O
(	O
Banarescu	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
followed	O
by	O
unsupervised	O
graph	O
inference	O
to	O
compare	O
contexts	O
.	O
They	O
assume	O
a	O
rich	O
target	O
KB	O
that	O
can	O
be	O
converted	O
to	O
a	O
connected	O
graph	O
.	O
This	O
works	O
for	O
Wikipedia	O
and	O
adjacent	O
resources	O
but	O
not	O
for	O
arbitrary	O
KBs	O
.	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
introduce	O
a	O
novel	O
zeroshot	O
framework	O
to	O
"	O
develop	O
entity	O
linking	O
systems	O
that	O
can	O
generalize	O
to	O
unseen	O
specialized	O
entities	O
"	O
.	O
Table	O
1	O
summarizes	O
differences	O
between	O
our	O
framework	O
and	O
those	O
from	O
prior	O
work	O
.	O

where	O
the	O
binary	O
label	O
L	O
indicates	O
whether	O
the	O
response	O
is	O
relevant	O
to	O
the	O
personas	O
.	O

The	O
shared	O
limitation	O
of	O
parameter	O
-	O
efficient	O
techniques	O
is	O
that	O
they	O
are	O
not	O
computation	O
-	O
efficient	O
;	O
These	O
methods	O
choose	O
to	O
directly	O
inherit	O
the	O
pretrained	O
weights	O
of	O
the	O
backbone	O
model	O
and	O
add	O
some	O
extra	O
modules	O
,	O
which	O
increases	O
the	O
computational	O
cost	O
of	O
these	O
methods	O
during	O
inference	O
.	O

The	O
noise	O
distribution	O
is	O
trained	O
simultaneously	O
with	O
Electric	O
using	O
standard	O
maximum	O
likelihood	O
estimation	O
over	O
the	O
data	O
.	O
The	O
model	O
producing	O
the	O
noise	O
distribution	O
is	O
much	O
smaller	O
than	O
Electric	O
to	O
reduce	O
the	O
computational	O
overhead	O
.	O

In	O
PATS	O
,	O
we	O
perturb	O
the	O
parameters	O
of	O
all	O
the	O
encoder	O
layers	O
except	O
the	O
Layer	O
Normalization	O
layers	O
.	O

M6Rec	B-MethodName
(	O
Cui	O
et	O
al	O
.	O
,	O
2022	O
)	O
employs	O
prompt	O
tuning	O
of	O
pretrained	O
language	O
models	O
for	O
building	O
a	O
unified	O
framework	O
.	O
M6Rec	B-MethodName
fully	O
utilizes	O
text	O
inputs	O
to	O
generalize	O
to	O
any	O
domains	O
/	O
systems	O
and	O
has	O
the	O
ability	O
to	O
perform	O
zero	O
-	O
shot	O
learning	O
.	O
Since	O
they	O
did	O
not	O
release	O
pretrained	O
M6	B-MethodName
(	O
Lin	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
we	O
used	O
Huggingface	O
RoBERTa	O
to	O
implement	O
it	O
.	O
3	O

FIND	B-MethodName
is	O
suitable	O
for	O
any	O
text	O
classification	O
tasks	O
where	O
a	O
model	O
might	O
learn	O
irrelevant	O
or	O
harmful	O
features	O
during	O
training	O
.	O
It	O
is	O
also	O
convenient	O
to	O
use	O
since	O
only	O
the	O
trained	O
model	O
and	O
the	O
training	O
data	O
are	O
required	O
as	O
input	O
.	O
Moreover	O
,	O
it	O
can	O
address	O
many	O
problems	O
simultaneously	O
such	O
as	O
removing	O
religious	O
and	O
racial	O
bias	O
together	O
with	O
gender	O
bias	O
even	O
if	O
we	O
might	O
not	O
be	O
aware	O
of	O
such	O
problems	O
before	O
using	O
FIND	O
.	O
In	O
general	O
cases	O
,	O
FIND	B-MethodName
is	O
at	O
least	O
useful	O
for	O
model	O
verification	O
.	O

We	O
find	O
that	O
default	O
BPE	B-MethodName
does	O
not	O
perform	O
better	O
than	O
the	O
2	O
-	O
digit	O
baseline	O
,	O
with	O
a	O
SegER	B-MethodName
score	O
of	O
about	O
34	O
%	O
.	O
However	O
,	O
as	O
noted	O
in	O
Section	O
3.1	O
,	O
most	O
cipher	O
elements	O
in	O
historical	O
ciphers	O
are	O
one	O
or	O
two	O
digits	O
long	O
.	O
In	O
our	O
random	O
sample	O
of	O
three	O
historical	O
ciphers	O
,	O
about	O
95	O
%	O
of	O
cipher	O
tokens	O
are	O
one	O
and	O
two	O
-	O
digit	O
(	O
as	O
shown	O
in	O
Table	O
1	O
)	O
.	O
Longer	O
elements	O
appear	O
less	O
often	O
(	O
less	O
than	O
5	O
%	O
of	O
tokens	O
in	O
our	O
test	O
ciphers	O
)	O
.	O
Thus	O
,	O
we	O
limit	O
BPE	O
piece	O
length	O
to	O
a	O
maximum	O
of	O
2	O
digits	O
.	O
This	O
improves	O
the	O
SegER	B-MethodName
score	O
by	O
reducing	O
it	O
to	O
about	O
11	O
%	O
.	O
We	O
call	O
this	O
model	O
"	O
BPE	O
2	O
"	O
in	O
Table	O
2	O
.	O

In	O
the	O
specific	O
implementation	O
,	O
which	O
candidates	O
satisfy	O
the	O
question	O
meanings	O
best	O
are	O
determined	O
by	O
neural	O
models	O
.	O
In	O
the	O
training	O
process	O
,	O
we	O
take	O
relations	O
that	O
appear	O
on	O
shortest	O
paths	O
between	O
mentioned	O
entities	O
and	O
answers	O
as	O
positive	O
samples	O
.	O
In	O
particular	O
,	O
the	O
relation	O
that	O
entails	O
part	O
of	O
or	O
precedes	O
are	O
filtered	O
according	O
to	O
the	O
KG	O
schema	O
in	O
the	O
training	O
process	O
and	O
are	O
predicted	O
by	O
neural	O
models	O
during	O
the	O
test	O
process	O
.	O
Queries	O
for	O
the	O
questions	O
of	O
multiple	O
constraints	O
are	O
the	O
conjunction	O
of	O
the	O
grounding	O
result	O
of	O
each	O
constraint	O
and	O
queries	O
for	O
the	O
questions	O
with	O
no	O
temporal	O
constraints	O
are	O
unrestricted	O
basic	O
query	O
graphs	O
.	O

Models	O
for	O
entity	O
linking	O
typically	O
consist	O
of	O
two	O
stages	O
that	O
balance	O
recall	O
and	O
precision	O
.	O

Figure	O
6	O
:	O
Plot	O
of	O
500	O
runs	O
where	O
we	O
first	O
apply	O
MP	O
and	O
then	O
continue	O
with	O
34	O
iterations	O
of	O
random	O
projections	O
.	O
The	O
shades	O
of	O
red	O
indicate	O
various	O
levels	O
of	O
confidence	O
(	O
10	O
levels	O
)	O
in	O
WEAT	O
scores	O
(	O
y	O
-	O
axis	O
)	O
after	O
a	O
certain	O
number	O
of	O
iterations	O
(	O
x	O
-	O
axis	O
)	O
:	O
darker	O
red	O
shades	O
reflect	O
WEAT	O
scores	O
occurring	O
with	O
a	O
higher	O
probability	O
.	O

In	O
this	O
work	O
,	O
we	O
present	O
the	O
first	O
effort	O
to	O
leverage	O
a	O
hybrid	O
knowledge	O
-	O
transfer	O
approach	O
for	O
the	O
cross	O
-	O
lingual	O
event	O
detection	O
task	O
.	O
We	O
propose	O
a	O
teacher	O
-	O
student	O
framework	O
complemented	O
by	O
a	O
hierarchical	O
training	O
-	O
sample	O
selection	O
scheme	O
that	O
effectively	O
constrains	O
the	O
student	O
-	O
training	O
process	O
to	O
pseudo	O
-	O
labeled	O
target	O
-	O
language	O
samples	O
that	O
are	O
similar	O
to	O
their	O
source	O
-	O
language	O
counterparts	O
.	O
Our	O
HKT	O
-	I-MethodName
CLED	O
model	O
sets	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
most	O
popular	O
benchmarking	O
datasets	O
ACE05	B-MethodName
and	O
ACE05	B-MethodName
-	I-MethodName
ERE	I-MethodName
,	O
and	O
obtains	O
substantial	O
performance	O
improvements	O
on	O
the	O
recentlyreleased	O
,	O
and	O
more	O
diverse	O
,	O
MINION	O
dataset	O
with	O
an	O
average	O
improvement	O
of	O
+7.74	O
F1	O
points	O
across	O
7	O
distinct	O
target	O
languages	O
.	O
We	O
believe	O
these	O
results	O
demonstrate	O
our	O
model	O
's	O
robustness	O
and	O
applicability	O
and	O
validate	O
our	O
claim	O
that	O
combining	O
the	O
benefits	O
of	O
the	O
direct	O
transfer	O
and	O
data	O
transfer	O
approaches	O
is	O
beneficial	O
for	O
cross	O
-	O
lingual	O
learning	O
.	O

•	O
Lastly	O
,	O
we	O
strongly	O
encourage	O
future	O
work	O
to	O
report	O
the	O
variance	O
of	O
the	O
observed	O
results	O
across	O
different	O
design	O
choices	O
.	O
This	O
can	O
provide	O
an	O
indication	O
of	O
the	O
robustness	O
of	O
the	O
language	O
models	O
'	O
performance	O
on	O
commonsense	O
benchmarks	O
.	O

Through	O
what	O
mechanism	O
does	O
a	O
Trojan	O
attack	O
affect	O
an	O
NLP	O
model	O
?	O

We	O
cast	O
each	O
hypothesis	O
string	O
in	O
the	O
MedNLI	B-DatasetName
training	O
dataset	O
to	O
lowercase	O
.	O
We	O
then	O
use	O
a	O
scispaCy	O
model	O
pre	O
-	O
trained	O
on	O
the	O
en_core_sci_lg	O
corpus	O
for	O
tokenization	O
and	O
clinical	O
named	I-TaskName
entity	I-TaskName
recognition	I-TaskName
(	O
CNER	B-DatasetName
)	O
(	O
Neumann	O
et	O
al	O
.	O
,	O
2019a	O
)	O
.	O
One	O
challenge	O
associated	O
with	O
clinical	O
text	O
,	O
and	O
scientific	O
text	O
more	O
generally	O
,	O
is	O
that	O
semantically	O
meaningful	O
entities	O
often	O
consist	O
of	O
spans	O
rather	O
than	O
single	O
tokens	O
.	O
To	O
mitigate	O
this	O
issue	O
during	O
lexical	O
analysis	O
,	O
we	O
map	O
each	O
multi	O
-	O
token	O
entity	O
to	O
a	O
single	O
-	O
token	O
representation	O
,	O
where	O
sub	O
-	O
tokens	O
are	O
separated	O
by	O
underscores	O
.	O

Moreover	O
,	O
with	O
the	O
development	O
of	O
automatic	O
text	O
generation	O
technologies	O
such	O
as	O
InstructGPT	B-MethodName
(	O
Ouyang	O
et	O
al	O
.	O
,	O
2022	O
)	O
and	O
ChatGPT	B-MethodName
3	I-MethodName
,	O
the	O
risk	O
of	O
automatically	O
generated	O
content	O
to	O
society	O
(	O
e.g.	O
,	O
generating	O
fake	O
news	O
or	O
fake	O
reviews	O
of	O
products	O
)	O
is	O
increasing	O
.	O
Therefore	O
,	O
we	O
further	O
adapt	O
our	O
model	O
to	O
distinguish	O
texts	O
generated	O
by	O
AI	O
models	O
and	O
human	O
experts	O
.	O
By	O
conducting	O
experiments	O
on	O
the	O
Human	B-MethodName
ChatGPT	I-MethodName
Comparison	I-MethodName
Corpus	I-MethodName
(	O
HC3	O
)	O
,	O
we	O
observe	O
that	O
our	O
model	O
beats	O
human	O
evaluators	O
and	O
shows	O
excellent	O
capability	O
in	O
the	O
pair	O
-	O
expert	O
task	O
.	O

This	O
loss	O
is	O
minimized	O
whenp	O
θ	O
matches	O
the	O
data	O
distribution	O
p	O
data	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010	O
)	O
.	O
A	O
consequence	O
of	O
this	O
property	O
is	O
that	O
the	O
model	O
learns	O
to	O
be	O
self	O
-	O
normalized	O
such	O
that	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
=	O
1	O
.	O

where	O
e	O
b	O
i1	O
and	O
e	O
b	O
i2	O
are	O
the	O
time	O
embeddings	O
for	O
p	O
b	O
i1	O
and	O
p	O
b	O
i2	O
(	O
same	O
for	O
the	O
target	O
)	O
.	O
We	O
use	O
Time2Vec	O
(	O
Kazemi	O
et	O
al	O
.	O
,	O
2019	O
)	O
for	O
time	O
embeddings	O
,	O
and	O
we	O
jointly	O
learn	O
embeddings	O
for	O
the	O
buyer	O
and	O
the	O
target	O
.	O
Price	O
Encoder	O
.	O
As	O
in	O
Du	O
and	O
Tanaka	O
-	O
Ishii	O
(	O
2020	O
)	O
and	O
Kostkova	O
et	O
al	O
.	O
(	O
2017	O
)	O
,	O
we	O
use	O
a	O
Gated	O
Recurrent	I-MethodName
Unit	O
(	O
Cho	O
et	O
al	O
.	O
,	O
2014	O
,	O
GRU	O
)	O
to	O
encode	O
the	O
price	O
variations	O
over	O
time	O
.	O
We	O
implement	O
two	O
separate	O
GRU	O
b	O
and	O
GRU	O
t	O
for	O
the	O
buyer	O
and	O
the	O
target	O
.	O
At	O
time	O
i	O
,	O
the	O
GRU	O
b	O
's	O
output	O
consists	O
of	O
:	O

SOFC	O
-	O
Exp	O
Corpus	O
.	O
Our	O
corpus	O
consists	O
of	O
45	O

We	O
use	O
1	O
NVIDIA	O
TitanXP	O
GPU	O
with	O
12	O
GB	O
of	O
memory	O
available	O
.	O
Because	O
the	O
maximum	O
input	O
sequence	O
length	O
of	O
the	O
GPT-2	B-MethodName
model	O
we	O
use	O
is	O
1024	O
tokens	O
,	O
we	O
resize	O
all	O
inputs	O
to	O
the	O
last	O
1024	O
tokens	O
before	O
training	O
.	O
We	O
report	O
results	O
for	O
an	O
LM	O
-	O
KT	O
model	O
trained	O
for	O
13k	O
steps	O
with	O
the	O
default	O
batch	O
size	O
of	O
2	O
and	O
learning	O
rate	O
of	O
5e-5	O
,	O
and	O
a	O
Question	O
Generation	O
model	O
trained	O
for	O
25k	O
steps	O
with	O
the	O
same	O
batch	O
size	O
and	O
learning	O
rate	O
.	O
The	O
total	O
compute	O
time	O
to	O
train	O
both	O
models	O
was	O
2.5	O
hours	O
for	O
each	O
language	O
learning	O
task	O
.	O

2	O
.	O
The	O
distribution	O
of	O
the	O
input	O
text	O
,	O
i.e.	O
,	O
the	O
underlying	O
distribution	O
that	O
x	O
1	O
...	O
x	O
k	O
are	O
from	O
.	O

Considerable	O
progress	O
in	O
domain	O
-	O
agnostic	O
NLI	O
has	O
been	O
facilitated	O
by	O
the	O
development	O
of	O
largescale	O
,	O
crowdworker	O
-	O
constructed	O
datasets	O
,	O
including	O
the	O
Stanford	O
Natural	O
Language	O
Inference	I-MethodName
corpus	O
(	O
SNLI	O
)	O
,	O
and	O
the	O
Multi	B-MethodName
-	I-MethodName
Genre	I-MethodName
Natural	I-MethodName
Language	O
Inference	I-MethodName
(	O
MultiNLI	B-MethodName
)	O
corpus	O
(	O
Bowman	O
et	O
al	O
.	O
,	O
2015;Williams	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
MedNLI	O
is	O
a	O
similarlymotivated	O
,	O
healthcare	O
-	O
specific	O
dataset	O
created	O
by	O
a	O
small	O
team	O
of	O
physician	O
-	O
annotators	O
in	O
lieu	O
of	O
crowdworkers	O
,	O
due	O
to	O
the	O
extensive	O
domain	O
expertise	O
required	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018	O
)	O
.	O
Poliak	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
Gururangan	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
Tsuchiya	O
(	O
2018	O
)	O
,	O
andMcCoy	O
et	O
al	O
.	O
(	O
2019	O
)	O
empirically	O
demonstrate	O
that	O
SNLI	B-DatasetName
and	O
MultiNLI	B-MethodName
contain	O
lexical	O
and	O
syntactic	O
annotation	O
artifacts	O
that	O
are	O
disproportionately	O
associated	O
with	O
specific	O
classes	O
,	O
allowing	O
a	O
hypothesis	O
-	O
only	O
classifier	O
to	O
significantly	O
outperform	O
a	O
majority	O
-	O
class	O
baseline	O
model	O
.	O
The	O
presence	O
of	O
such	O
artifacts	O
is	O
hypothesized	O
to	O
be	O
partially	O
attributable	O
to	O
the	O
priming	O
effect	O
of	O
the	O
example	O
hypotheses	O
provided	O
to	O
crowdworkers	O
at	O
annotation	O
-	O
time	O
.	O
Romanov	O
and	O
Shivade	O
(	O
2018	O
)	O
note	O
that	O
a	O
hypothesis	O
-	O
only	O
baseline	O
is	O
able	O
to	O
outperform	O
a	O
majority	O
class	O
baseline	O
in	O
MedNLI	O
,	O
but	O
they	O
do	O
not	O
identify	O
specific	O
artifacts	O
.	O

Teacher	O
's	O
auxiliary	O
loss	O
Inspired	O
by	O
(	O
Pham	O
et	O
al	O
.	O
,	O
2021	O
)	O
,	O
in	O
order	O
to	O
balance	O
the	O
trade	O
-	O
off	O
between	O
self	O
-	O
evolution	O
and	O
transferability	O
of	O
the	O
teacher	O
We	O
observe	O
that	O
for	O
LGTM	B-MethodName
,	O
student	O
model	O
does	O
not	O
suffer	O
from	O
overfitting	O
(	O
thanks	O
to	O
distillation	O
influence	O
)	O
,	O
and	O
the	O
teacher	O
can	O
balance	O
its	O
own	O
evolution	O
and	O
effective	O
knowledge	O
transfer	O
(	O
thanks	O
to	O
auxiliary	O
loss	O
)	O
.	O

The	O
statistics	O
of	O
the	O
ED	O
datasets	O
used	O
in	O
our	O
experiments	O
are	O
provided	O
in	O
Table	O
6	O
.	O

•	O
We	O
conduct	O
three	O
human	O
experiments	O
that	O
demonstrate	O
the	O
effectiveness	O
of	O
FIND	B-MethodName
in	O
different	O
scenarios	O
.	O
The	O
results	O
not	O
only	O
highlight	O
the	O
usefulness	O
of	O
our	O
approach	O
but	O
also	O
reveal	O
interesting	O
behaviors	O
of	O
CNNs	B-MethodName
for	O
text	O
classification	O
.	O

'	O
picked	O
up	O
a	O
nasty	O
h	O
pylori	O
'	O
from	O
an	O
casual	O
doctor	O
date	O
,	O
i	O
know	O
i	O
should	O
have	O
gotten	O
to	O
know	O
the	O
person	O
better	O
.	O
took	O
a	O
while	O
until	O
they	O
showed	O
up	O
.	O
had	O
severe	O
upset	O
stomach	O
,	O
occasional	O
diarrhea	O
,	O
nausea	O
and	O
slow	O
but	O
steady	O
weight	O
loss	O
.	O
took	O
a	O
long	O
time	O
and	O
several	O
doctors	O
to	O
diagnose	O
my	O
steadily	O
worsening	O
condition	O
.	O
tried	O
prevpak	O
first	O
,	O
seemed	O
to	O
work	O
at	O
first	O
butmy	O
infection	O
came	O
back	O
.	O
the	O
new	O
gi	O
then	O
prescribed	O
pylera	O
after	O
my	O
3rd	O
endoscopy	O
.	O
pylera	O
has	O
worked	O
,	O
it	O
's	O
been	O
a	O
year	O
and	O
i	O
am	O
still	O
h	O
pylera	O
negative	O
.	O
but	O
it	O
's	O
been	O
brutal	O
and	O
F	O
(	O
s	O
adv	O
,	O
l	O
=	O
"	O
6.0	O
"	O
)	O
=	O
0.97	O
Cos	O
.	O
=	O
-0.19	O

In	O
this	O
section	O
,	O
we	O
first	O
describe	O
our	O
experiment	O
setup	O
including	O
datasets	O
and	O
baselines	O
in	O
Sec	O
.	O
5.1	O
.	O
Then	O
we	O
compare	O
our	O
proposed	O
LGTM	B-TaskName
to	O
meta	O
distillation	O
to	O
gain	O
some	O
basic	O
understanding	O
of	O
how	O
to	O
incorporate	O
the	O
student	O
's	O
feedback	O
in	O
Sec	O
.	O
5.2	O
.	O
To	O
further	O
verify	O
the	O
effectiveness	O
of	O
our	O
method	O
,	O
in	O
Sec	O
.	O
5.3	O
we	O
compare	O
to	O
10	O
widely	O
adopted	O
knowledge	O
distillation	O
baselines	O
and	O
show	O
consistently	O
better	O
results	O
.	O
Then	O
we	O
demonstrate	O
how	O
distillation	O
influence	O
works	O
in	O
Sec	O
.	O
5.4	O
,	O
followed	O
by	O
ablation	O
studies	O
of	O
LGTM	B-TaskName
in	O
Sec	O
.	O
5.5	O
.	O

To	O
verify	O
this	O
,	O
we	O
further	O
conduct	O
experiments	O
on	O
PubMed	O
(	O
Cohan	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
a	O
long	O
-	O
document	O

The	O
untrained	O
mBERT	B-MethodName
baseline	O
expectedly	O
underperforms	O
;	O
however	O
,	O
we	O
note	O
good	O
baseline	O
results	O
on	O
surface	O
-	O
level	O
tasks	O
for	O
English	O
,	O
which	O
we	O
attribute	O
to	O
memorizing	O
token	O
identity	O
and	O
position	O
:	O
although	O
the	O
weights	O
are	O
set	O
randomly	O
,	O
the	O
frozen	O
encoder	O
still	O
associates	O
each	O
wordpiece	O
input	O
with	O
a	O
fixed	O
random	O
vector	O
.	O
We	O
have	O
confirmed	O
this	O
assumption	O
by	O
scalar	O
mix	O
analysis	O
of	O
the	O
untrained	O
mBERT	B-MethodName
baseline	O
:	O
in	O
our	O
experiments	O
the	O
baseline	O
probes	O
for	O
both	O
English	O
and	O
German	O
attended	O
almost	O
exclusively	O
to	O
the	O
first	O
few	O
layers	O
of	O
the	O
encoder	O
,	O
independent	O
of	O
the	O
task	O
.	O
For	O
brevity	O
,	O
here	O
and	O
further	O
we	O
do	O
not	O
examine	O
baseline	O
mixing	O
weights	O
and	O
only	O
report	O
the	O
scores	O
.	O

Further	O
Analysis	O
Note	O
that	O
a	O
direct	O
attribution	O
of	O
the	O
gain	O
in	O
translation	O
quality	O
to	O
better	O
translation	O
of	O
idioms	O
specifically	O
is	O
challenging	O
.	O
Further	O
,	O
similarity	O
-	O
based	O
quality	O
metrics	O
such	O
as	O
COMET	B-MethodName
-	I-MethodName
QE	I-MethodName
themselves	O
might	O
be	O
penalizing	O
non	O
-	O
literalness	O
,	O
even	O
though	O
they	O
are	O
less	O
likely	O
to	O
do	O
this	O
than	O
surface	O
-	O
level	O
metrics	O
such	O
as	O
BLEU	B-MetricName
or	O
ChrF	B-MetricName
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002b	O
;	O
Popović	O
,	O
2015	O
)	O
.	O
Therefore	O
,	O
while	O
a	O
natural	O
monolingual	O
dataset	O
presents	O
a	O
useful	O
testbed	O
for	O
investigating	O
figurative	O
compositionality	O
abilities	O
,	O
an	O
explicit	O
comparison	O
of	O
figurative	O
compositionality	O
between	O
the	O
systems	O
is	O
very	O
difficult	O
.	O
Therefore	O
,	O
we	O
also	O
conduct	O
experiments	O
on	O
synthetic	O
data	O
,	O
where	O
we	O
explicitly	O
control	O
the	O
finegrained	O
attributes	O
of	O
the	O
input	O
sentences	O
.	O
We	O
do	O
this	O
by	O
allocating	O
most	O
of	O
the	O
variation	O
among	O
the	O
input	O
sentences	O
to	O
certain	O
constituent	O
expressions	O
in	O
synthetic	O
data	O
generation	O
.	O

Our	O
probing	O
framework	O
is	O
implemented	O
using	O
AllenNLP	B-MethodName
.	O
2	O
We	O
train	O
the	O
probes	O
for	O
20	O
epochs	O
using	O
the	O
Adam	O
optimizer	O
with	O
default	O
parameters	O
and	O
a	O
batch	O
size	O
of	O
32	B-HyperparameterValue
.	O
Due	O
to	O
the	O
frozen	O
encoder	O
and	O
flat	O
model	O
architecture	O
,	O
the	O
total	O
runtime	O
of	O
the	O
main	O
experiments	O
is	O
under	O
8	O
hours	O
on	O
a	O
single	O
Tesla	O
V100	O
GPU	O
.	O
In	O
addition	O
to	O
pre	O
-	O
trained	O
mBERT	B-MethodName
we	O
report	O
baseline	O
performance	O
using	O
a	O
frozen	O
untrained	O
mBERT	B-MethodName
model	O
obtained	O
by	O
randomizing	O
the	O
encoder	O
weights	O
post	O
-	O
initialization	O
as	O
in	O
Jawahar	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

To	O
improve	O
the	O
quality	O
of	O
the	O
constructed	O
data	O
,	O
we	O
derive	O
an	O
approach	O
to	O
filter	O
out	O
instances	O
that	O
are	O
less	O
informative	O
to	O
ICL	B-MethodName
.	O
We	O
consider	O
the	O
following	O
score	O
to	O
measure	O
the	O
informativeness	O
of	O
an	O
instance	O
based	O
on	O
the	O
perplexity	O
difference	O
of	O
the	O
paragraphs	O
in	O
the	O
instance	O
before	O
and	O
after	O
they	O
are	O
concatenated	O
as	O
a	O
sequence	O
:	O

2	O
.	O
Candidate	O
Reranking	O
:	O
This	O
stage	O
ranks	O
the	O
candidates	O
in	O
E	O
by	O
how	O
likely	O
they	O
are	O
to	O
be	O
the	O
correct	O
entity	O
.	O
Unlike	O
candidate	O
generation	O
,	O
models	O
for	O
re	O
-	O
ranking	O
are	O
typically	O
more	O
complex	O
and	O
oriented	O
towards	O
generating	O
a	O
high	O
-	O
precision	O
ranked	O
list	O
since	O
the	O
objective	O
of	O
this	O
stage	O
is	O
to	O
identify	O
the	O
most	O
likely	O
entity	O
for	O
each	O
mention	O
.	O
This	O
stage	O
is	O
evaluated	O
using	O
precision@1	O
(	O
or	O
accuracy	O
)	O
i.e.	O
whether	O
the	O
highest	O
ranked	O
entity	O
is	O
the	O
correct	O
entity	O
.	O

In	O
this	O
section	O
,	O
we	O
present	O
the	O
algorithm	O
to	O
train	O
our	O
model	O
,	O
METRO	B-MethodName
-	I-MethodName
T0	I-MethodName
.	O

We	O
employ	O
three	O
datasets	O
for	O
text	O
classification	O
and	O
three	O
datasets	O
for	O
natural	O
language	O
inference	O
as	O
described	O
below	O
.	O
In	O
our	O
experiments	O
,	O
we	O
randomly	O
sample	O
1000	O
instances	O
.	O

Comparing	O
our	O
model	O
without	O
word	O
-	O
level	O
alignment	O
,	O
i.e.	O
,	O
-TLM	O
,	O
to	O
the	O
baseline	O
mBERT	B-MethodName
in	O
Table	O
2	O
,	O
we	O
get	O
2	O
-	O
4	O
%	O
improvement	O
in	O
the	O
zero	O
-	O
shot	O
setting	O
and	O
1	O
-	O
2	O
%	O
improvement	O
in	O
translate	O
-	O
train	O
as	O
the	O
amount	O
of	O
parallel	O
data	O
is	O
increased	O
.	O
These	O
are	O
relatively	O
large	O
improvements	O
considering	O
the	O
fact	O
that	O
only	O
sentence	O
-	O
level	O
alignment	O
is	O
used	O
.	O
This	O
also	O
conforms	O
to	O
our	O
intuition	O
that	O
sentence	O
-	O
level	O
alignment	O
is	O
a	O
good	O
fit	O
here	O
since	O
XNLI	O
is	O
a	O
sentencelevel	O
task	O
.	O

Next	O
,	O
we	O
introduce	O
an	O
information	O
fusion	O
module	O
to	O
enable	O
the	O
interaction	O
between	O
textual	O
(	O
z	O
T	O
)	O
and	O
graph	O
(	O
z	O
G	O
)	O
hidden	O
states	O
,	O
in	O
order	O
to	O
obtain	O
the	O
fused	O
representation	O
,	O
z	O
′	O
.	O
We	O
implement	O
two	O
information	O
fusion	O
operations	O
:	O
(	O
1	O
)	O
addition	O
,	O
i.e.	O
,	O
z	O
′	O
=	O
z	O
T	O
+	O
z	O
G	O
,	O
and	O
(	O
2	O
)	O
gating	O
mechanism	O
between	O
z	O
T	O
and	O
z	O
G	O
as	O
in	O
Zhao	O
et	O
al	O
.	O
(	O
2018	O
)	O
except	O
that	O
we	O
use	O
GELU	O
(	O
•	O
)	O
as	O
the	O
activation	O
function	O
.	O
The	O
operation	O
selection	O
is	O
determined	O
by	O
downstream	O
tasks	O
.	O

To	O
train	O
both	O
our	O
LM	O
-	O
KT	O
knowledge	O
tracing	O
model	O
and	O
our	O
question	O
generation	O
model	O
,	O
we	O
use	O
the	O
pre	O
-	O
trained	O
OpenAI	O
GPT-2	O
model	O
from	O
the	O
HuggingFace	O
Transformers	O
library	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
For	O
question	O
generation	O
,	O
we	O
modify	O
the	O
library	O
to	O
add	O
a	O
linear	O
layer	O
and	O
the	O
modified	O
loss	O
function	O
for	O
question	O
generation	O
from	O
Section	O
3	O
.	O

The	O
influence	O
of	O
group	O
size	O
.	O
In	O
WhitenedCSE	B-MethodName
,	O
we	O
divide	O
the	O
representation	O
into	O
k	O
groups	O
.	O
However	O
,	O
we	O
know	O
the	O
size	O
of	O
group	O
controls	O
the	O
degree	O
of	O
whitening	O
,	O
and	O
has	O
a	O
great	O
effect	O
on	O
the	O
effectiveness	O
of	O
WhitenedCSE	B-MethodName
,	O
so	O
we	O
carry	O
out	O
an	O
experiment	O
with	O
k	O
varying	O
from	O
32	O
to	O
384	O
.	O
As	O
shown	O
in	O
Tab	O
.	O
4	O
,	O
we	O
can	O
see	O
that	O
the	O
best	O
performance	O
is	O
achieved	O
when	O
k	O
=	O
384	O
,	O
and	O
the	O
second	O
best	O
performance	O
is	O
achieved	O
when	O
k	O
=	O
128	O
.	O
When	O
k	O
takes	O
other	O
values	O
,	O
the	O
performance	O
will	O
drop	O
slightly	O
.	O

Question	O
Generation	O
We	O
frame	O
question	O
generation	O
as	O
finetuning	O
a	O
new	O
autoregressive	O
LM	O
.	O
Given	O
random	O
samples	O
of	O
students	O
and	O
questions	O
from	O
a	O
held	O
-	O
out	O
set	O
not	O
used	O
to	O
train	O
LM	O
-	O
KT	O
,	O
we	O
can	O
construct	O
a	O
new	O
dataset	O
D	O
consisting	O
of	O
s	O
i	O
d	O
i	O
<	O
G	O
>	O
q	O
i	O
sequences	O
,	O
where	O
<	O
G	O
>	O
is	O
a	O
special	O
generation	O
token	O
and	O
d	O
i	O
=	O
p	O
θ	O
KT	O
(	O
<	O
Y>|s	O
i	O
,	O
q	O
i	O
)	O
is	O
the	O
continuous	O
difficulty	O
value	O
assigned	O
by	O
LM	O
-	O
KT	O
.	O
We	O
learn	O
a	O
linear	O
layer	O
to	O
map	O
the	O
continuous	O
input	O
difficulty	O
into	O
a	O
difficulty	O
control	O
vector	O
c	O
d	O
of	O
dimension	O
matching	O
the	O
LM	O
word	O
-	O
embeddings	O
,	O
which	O
we	O
append	O
to	O
the	O
token	O
embeddings	O
.	O
Unlike	O
LM	O
-	O
KT	O
,	O
we	O
train	O
our	O
question	O
generation	O
model	O
p	O
θ	O
QG	O
to	O
minimize	O
the	O
loss	O
only	O
on	O
the	O
question	O
text	O
,	O
which	O
only	O
appears	O
after	O
the	O
<	O
G	O
>	O
token	O
.	O
If	O
t	O
g	O
is	O
the	O
token	O
index	O
of	O
<	O
G	O
>	O
,	O
then	O
our	O
modified	O
loss	O
is	O
:	O

We	O
obtain	O
393,423	O
biographies	O
from	O
Ravfogel	O
et	O
al	O
.	O
(	O
2020	O
)	O
which	O
is	O
a	O
subset	O
of	O
the	O
original	O
corpus	O
of	O
describing	O
people	O
with	O
28	O
different	O
occupations	O
.	O
9	O
We	O
split	O
the	O
data	O
in	O
the	O
same	O
65	O
%	O
training	O
,	O
10	O
%	O
development	O
and	O
25	O
%	O
test	O
splits	O
as	O
used	O
by	O
and	O
Ravfogel	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
Like	O
Ravfogel	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
we	O
use	O
logistic	O
classifiers	O
that	O
take	O
one	O
of	O
three	O
representations	O
of	O
the	O
biographies	O
as	O
input	O
:	O
(	O
1	O
)	O
one	O
-	O
hot	O
BOW	O
,	O
(	O
2	O
)	O
averaged	O
FastText	O
embeddings	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
(	O
3	O
)	O
the	O
last	O
hidden	O
state	O
of	O
BERT	B-MethodName
over	O
the	O
[	O
CLS	O
]	O
token	O
.	O

We	O
performed	O
basic	O
pre	O
-	O
processing	O
of	O
transcripts	O
in	O
each	O
dataset	O
by	O
which	O
we	O
removed	O
speech	O
artifact	O
descriptions	O
and	O
converted	O
non	O
-	O
ASCII	O
characters	O
to	O
plain	O
text	O
.	O
We	O
also	O
excluded	O
portions	O
of	O
transcripts	O
that	O
represented	O
speech	O
that	O
did	O
not	O
belong	O
to	O
the	O
participant	O
.	O

Inspired	O
by	O
recent	O
work	O
on	O
discourse	O
modeling	O
(	O
Kang	O
et	O
al	O
.	O
,	O
2019;Nadeem	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
we	O
use	O
language	O
models	O
to	O
assess	O
the	O
narrative	O
linearity	O
of	O
a	O
story	O
by	O
measuring	O
how	O
sentences	O
relate	O
to	O
their	O
context	O
in	O
the	O
story	O
.	O
We	O
compare	O
the	O
likelihoods	O
of	O
sentences	O
under	O
two	O
generative	O
models	O
(	O
Figure	O
2	O
)	O
.	O
The	O
bag	O
model	O
makes	O
the	O
assumption	O
that	O
every	O
sentence	O
is	O
drawn	O
independently	O
from	O
the	O
main	O
theme	O
of	O
the	O
story	O
(	O
represented	O
by	O
E	O
)	O
.	O
On	O
the	O
other	O
hand	O
,	O
the	O
chain	O
model	O
assumes	O
that	O
a	O
story	O
begins	O
with	O
a	O
theme	O
,	O
and	O
sentences	O
linearly	O
follow	O
each	O
other	O
.	O
3	O
.	O
∆	O
l	O
is	O
computed	O
as	O
the	O
difference	O
in	O
negative	O
loglikelihoods	O
between	O
the	O
bag	O
and	O
chain	O
models	O
:	O

In	O
§	O
4.5	O
,	O
we	O
will	O
demonstrate	O
our	O
comparative	O
studies	O
between	O
the	O
aforementioned	O
methods	O
and	O
GlobEnc	O
.	O

Finally	O
,	O
we	O
create	O
a	O
held	O
-	O
out	O
set	O
of	O
Duolingo	O
questions	O
for	O
both	O
French	O
and	O
Spanish	O
learners	O
to	O
create	O
the	O
training	O
data	O
for	O
our	O
question	O
generation	O
model	O
.	O
From	O
a	O
set	O
of	O
random	O
student	O
states	O
,	O
we	O
select	O
questions	O
from	O
this	O
set	O
and	O
use	O
a	O
trained	O
LM	O
-	O
KT	O
model	O
to	O
assign	O
the	O
difficulty	O
score	O
.	O
In	O
practice	O
,	O
this	O
held	O
-	O
out	O
set	O
can	O
come	O
from	O
any	O
source	O
,	O
not	O
just	O
Duolingo	O
data	O
.	O

We	O
conduct	O
an	O
ablation	O
study	O
on	O
the	O
IMDb	B-DatasetName
dataset	O
.	O
As	O
shown	O
in	O
Table	O
3	O
,	O
we	O
can	O
find	O
:	O
1	O
)	O
variational	O
learning	O
further	O
enhances	O
control	O
accuracy	O
and	O
diversity	O
with	O
slight	O
PPL	O
loss	O
,	O
which	O
is	O
worthwhile	O
since	O
the	O
generated	O
text	O
is	O
already	O
fluent	O
enough	O
(	O
close	O
to	O
ground	O
truth	O
PPL	O
)	O
.	O
2	O
)	O
pseudo	O
labels	O
lead	O
to	O
a	O
significant	O
improvement	O
.	O
3	O
)	O
soft	O
pseudo	O
text	O
outperforms	O
the	O
hard	O
one	O
on	O
controllability	O
and	O
diversity	O
but	O
with	O
marginal	O
fluency	O
loss	O
.	O
Solely	O
hard	O
pseudo	O
text	O
in	O
ST	O
limits	O
model	O
coverage	O
,	O
while	O
the	O
soft	O
one	O
brings	O
a	O
smoother	O
noise	O
and	O
helps	O
push	O
the	O
learned	O
boundary	O
.	O

When	O
computing	O
token	O
-	O
class	O
pointwise	O
mutual	O
information	O
(	O
PMI	O
)	O
,	O
we	O
exclude	O
tokens	O
that	O
appear	O
less	O
than	O
five	O
times	O
in	O
the	O
overall	O
training	O
dataset	O
's	O
hypotheses	O
.	O
Then	O
,	O
following	O
Gururangan	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
who	O
apply	O
add-100	O
smoothing	O
to	O
raw	O
counts	O
to	O
highlight	O
particularly	O
discriminative	O
token	O
-	O
class	O
co	O
-	O
occurrence	O
patterns	O
,	O
we	O
apply	O
add-50	O
smoothing	O
to	O
raw	O
counts	O
.	O
Our	O
approach	O
is	O
similarly	O
motivated	O
;	O
our	O
choice	O
of	O
50	O
reflects	O
the	O
smaller	O
state	O
space	O
associated	O
with	O
a	O
focus	O
on	O
the	O
clinical	O
domain	O
.	O

SANs	O
can	O
be	O
implemented	O
with	O
multi	O
-	O
head	O
attention	O
mechanism	O
,	O
which	O
requires	O
extra	O
splitting	O
and	O
concatenation	O
operations	O
.	O
Specifically	O
,	O
W	O
Q	O
,	O
W	O
K	O
,	O
W	O
V	O
and	O
Q	O
,	O
K	O
,	O
V	O
in	O
Eq	O
.	O
(	O
3	O
)	O
is	O
split	O
into	O
H	O
sub	O
-	O
matrices	O
,	O
yielding	O
H	O
heads	O
.	O
For	O
the	O
h	O
-	O
th	O
head	O
,	O
the	O
output	O
is	O
computed	O
by	O
:	O

•	O
sentence	O
:	O
The	O
argument	O
.	O

Here	O
we	O
provide	O
some	O
additional	O
details	O
of	O
all	O
the	O
datasets	O
used	O
in	O
this	O
work	O
.	O
Complexity	O
of	O
Styles	O
in	O
Datasets	O
:	O
As	O
discussed	O
in	O
Section	O
5.2	O
,	O
we	O
consider	O
three	O
tasks	O
-	O
sentiment	O
,	O
discourse	O
and	O
fine	O
-	O
grained	O
text	O
style	O
transfer	O
.	O
As	O
prepossessing	O
,	O
we	O
remove	O
non	O
-	O
essential	O
special	O
characters	O
and	O
lowercase	O
all	O
sentences	O
.	O
Except	O
for	O
the	O
Yelp	O
dataset	O
,	O
no	O
pruning	O
is	O
done	O
based	O
on	O
sentence	O
length	O
.	O
The	O
vocab	O
size	O
during	O
training	O
was	O
limited	O
at	O
25k	O
unless	O
mentioned	O
otherwise	O
.	O

(	O
2	O
)	O
A	O
number	O
of	O
firms	O
have	O
taken	O
steps	O
to	O
make	O
their	O
online	O
business	O
more	O
efficient	O
and	O
more	O
efficient	O
.	O
New	O
York	O
-	O
based	O
Gartner	O
says	O
that	O
new	O
companies	O
such	O
as	O
AT	O
&	O
T	O
,	O
Bell	O
,	O
IBM	O
...	O

Our	O
main	O
theoretical	O
result	O
,	O
and	O
the	O
foundation	O
of	O
our	O
modeling	O
approach	O
,	O
can	O
be	O
stated	O
as	O
follows	O
:	O
in	O
any	O
language	O
understanding	O
task	O
that	O
can	O
be	O
modeled	O
compositionally	O
,	O
data	O
for	O
the	O
task	O
exhibits	O
symmetries	O
in	O
the	O
sense	O
of	O
Definition	O
1	O
.	O
We	O
explain	O
,	O
formalize	O
,	O
and	O
prove	O
this	O
statement	O
below	O
.	O

MedNLI	O
Is	O
Not	O
Immune	O
:	O
Natural	O
Language	O
Inference	O
Artifacts	O
in	O
the	O
Clinical	O
Domain	O

Entity	O
linking	O
consists	O
of	O
disambiguating	O
entity	O
mentions	O
M	O
from	O
one	O
or	O
more	O
documents	O
to	O
a	O
target	O
knowledge	O
base	O
,	O
KB	O
,	O
containing	O
unique	O
entities	O
.	O
We	O
assume	O
that	O
each	O
entity	O
e	O
∈	O
KB	O
is	O
represented	O
using	O
a	O
set	O
of	O
attribute	O
-	O
value	O
pairs	O

The	O
average	O
compression	O
ratio	O
from	O
EW	O
to	O
SEW	O
page	O
in	O
SWIPE	B-DatasetName
document	O
pairs	O
is	O
0.87	O
,	O
suggesting	O
that	O
SEW	O
pages	O
are	O
not	O
significantly	O
shorter	O
than	O
their	O
EW	O
matches	O
.	O
In	O
fact	O
,	O
26	O
%	O
of	O
document	O
pairs	O
have	O
a	O
compression	O
ratio	O
larger	O
than	O
1	O
,	O
indicating	O
that	O
is	O
not	O
infrequent	O
for	O
the	O
simplification	O
of	O
a	O
document	O
to	O
be	O
longer	O
than	O
the	O
original	O
document	O
.	O

As	O
we	O
can	O
see	O
,	O
QuEst+Vis-2	O
model	O
outperforms	O
the	O
baseline	O
with	O
p	O
-	O
value	O
=	O
0.002	O
.	O
Thus	O
,	O
visual	O
features	O
significantly	O
improve	O
the	O
performance	O
of	O
featurebased	O
QE	O
systems	O
compared	O
to	O
the	O
monomodal	O
QE	O
counterparts	O
.	O

Algorithm	O
2	O
Efficient	O
NCE	B-MethodName
loss	O
estimation	O

Step	O
2b	O
:	O
Training	O
the	O
ranker	O
We	O
use	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
MT	B-MethodName
-	I-MethodName
DNN	I-MethodName
2	I-MethodName
(	O
base	O
and	O
large	O
)	O
to	O
train	O
a	O
ranker	O
.	O
For	O
training	O
,	O
we	O
create	O
five	O
splits	O
:	O
(	O
1	O
)	O
one	O
in	O
-	O
topic	O
split	O
using	O
a	O
random	O
subset	O
from	O
all	O
four	O
topics	O
and	O
(	O
2	O
)	O
four	O

3	O
.	O
Everything	O
Is	O
Fine	O
Heuristic	O
:	O
a	O
premisehypothesis	O
pair	O
satisfies	O
this	O
heuristic	O
if	O
the	O
hypothesis	O
contains	O
one	O
or	O
more	O
of	O
the	O
same	O
MeSH	B-TaskName
entities	O
as	O
the	O
premise	O
(	O
excluding	O
the	O
patient	O
entity	O
,	O
which	O
appears	O
in	O
almost	O
all	O
notes	O
)	O
and	O
also	O
contains	O
:	O
(	O
1	O
)	O
a	O
negation	O
word	O
or	O
phrase	O
(	O
e.g.	O
,	O
does	O
not	O
have	O
,	O
no	O
finding	O
,	O
no	O
,	O
denies	O
)	O
;	O
or	O
(	O
2	O
)	O
a	O
word	O
or	O
phrase	O
that	O
affirms	O
the	O
patient	O
's	O
health	O
(	O
e.g.	O
,	O
normal	O
,	O
healthy	O
,	O
discharged	O
)	O
.	O

6	O
https	O
:	O
/	O
/	O
github.com	O
/	O
google-research	O
/	O
google-r	O
esearch	O
/	O
tree	O
/	O
master	O
/	O
rouge	O
7	O
https	O
:	O
/	O
/	O
github.com	O
/	O
Tiiiger	O
/	O
bert_score	O
8	O
https	O
:	O
/	O
/	O
github.com	O
/	O
abisee	O
/	O
pointer-generator	O
9	O
https	O
:	O
/	O
/	O
github.com	O
/	O
artmatsak	O
/	O
cnn-dailymail	O
10	O
https	O
:	O
/	O
/	O
github.com	O
/	O
EdinburghNLP	O
/	O
XSum	O

•	O
We	O
propose	O
a	O
technique	O
to	O
disable	O
the	O
learned	O
features	O
which	O
are	O
irrelevant	O
or	O
harmful	O
to	O
the	O
classification	O
task	O
so	O
as	O
to	O
improve	O
the	O
classifier	O
.	O
This	O
technique	O
and	O
the	O
word	O
clouds	O
form	O
the	O
human	O
-	O
debugging	O
framework	O
-FIND	O
.	O

Due	O
to	O
the	O
similarities	O
between	O
different	O
languages	O
,	O
such	O
as	O
words	O
,	O
grammar	O
,	O
and	O
semantics	O
,	O
multilingual	O
models	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
;	O
Conneau	O
and	O
Lample	O
,	O
2019	O
;	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
;	O
Chi	O
et	O
al	O
.	O
,	O
2022	O
)	O
have	O
been	O
shown	O
to	O
generalize	O
to	O
unseen	O
languages	O
in	O
a	O
wide	O
range	O
of	O
tasks	O
.	O
In	O
machine	O
translation	O
,	O
multilingual	O
models	O
exhibit	O
the	O
ability	O
to	O
perform	O
zero	O
-	O
shot	O
transfer	O
in	O
that	O
they	O
can	O
translate	O
on	O
unseen	O
language	O
pairs	O
(	O
Zoph	O
et	O
al	O
.	O
,	O
2016	O
;	O
Johnson	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
With	O
the	O
help	O
of	O
self	O
-	O
supervised	O
learning	O
,	O
model	O
can	O
better	O
acquire	O
language	O
-	O
invariant	O
representation	O
,	O
thus	O
improving	O
zero	O
-	O
shot	O
machine	O
translation	O
.	O

where	O
W	O
g	O
is	O
a	O
trainable	O
parameter	O
.	O
During	O
training	O
process	O
,	O
we	O
set	O
γ	O
t	O
to	O
the	O
ground	O
-	O
truth	O
labelγ	O
t	O
.	O

Figure	O
1	O
:	O
An	O
illustrative	O
example	O
of	O
schema	O
translation	O
from	O
English	O
to	O
Chinese	O
.	O
1	O
-4	O
denotes	O
headers	O
with	O
abbreviation	O
,	O
polysemy	O
,	O
verb	O
-	O
object	O
phrase	O
and	O
special	O
symbol	O
,	O
respectively	O
.	O

The	O
comparison	O
of	O
FULL	B-MethodName
,	O
DENSE	B-MethodName
,	O
and	O
DENSE10	B-MethodName
illustrates	O
how	O
well	O
our	O
data	O
approximates	O
the	O
real	O
distribution	O
of	O
annotations	O
for	O
each	O
tangram	O
,	O
and	O
the	O
advantage	O
of	O
DENSE	B-MethodName
.	O
Figure	O
4	O
shows	O
the	O
complete	O
distribution	O
of	O
values	O
.	O
Comparing	O
DENSE10	B-MethodName
and	O
DENSE	B-MethodName
,	O
the	O
rankings	O
of	O
the	O
tangrams	O
are	O
largely	O
the	O
same	O
with	O
the	O
additional	O
annotations	O
:	O
for	O
SND	O
,	O
Spearman	O
's	O
rank	O
correlation	O
coefficient	O
is	O
r	O
(	O
72	O
)	O
=	O
.78	O
,	O
p	O
≪	O
.001	O
;	O
for	O
PND	O
,	O
r	O
(	O
72	O
)	O
=	O
.87	O
,	O
p	O
≪	O
.001	O
;	O
for	O
PSA	O
,	O
r	O
(	O
72	O
)	O
=	O
.76	O
,	O
p	O
≪	O
.001	O
.	O
The	O
tangrams	O
sampled	O
for	O
DENSE	B-MethodName
represent	O
well	O
the	O
distribution	O
of	O
tangrams	O
along	O
the	O
different	O
measures	O
,	O
as	O
illustrated	O
by	O
the	O
red	O
highlights	O
in	O
Figure	O
4	O
.	O

Because	O
the	O
original	O
dataset	O
was	O
intended	O
for	O
per	O
-	O
token	O
error	O
prediction	O
,	O
each	O
question	O
has	O
per	O
-	O
token	O
information	O
that	O
includes	O
whether	O
the	O
student	O
translated	O
the	O
token	O
correctly	O
,	O
as	O
well	O
as	O
Universal	O
Dependencies	O
tags	O
such	O
as	O
part	O
of	O
speech	O
and	O
morphology	O
labels	O
.	O
We	O
use	O
the	O
full	O
question	O
text	O
,	O
rather	O
than	O
individual	O
tokens	O
,	O
for	O
our	O
task	O
,	O
and	O
combine	O
the	O
labels	O
such	O
that	O
if	O
a	O
Duolingo	O
user	O
incorrectly	O
translated	O
one	O
or	O
more	O
tokens	O
in	O
a	O
question	O
,	O
the	O
entire	O
question	O
is	O
marked	O
incorrect	O
.	O
We	O
do	O
not	O
use	O
any	O
additional	O
features	O
.	O

For	O
each	O
heuristic	O
,	O
we	O
subset	O
the	O
complete	O
dataset	O
to	O
find	O
pattern	O
-	O
satisfying	O
premise	O
-	O
heuristic	O
pairs	O
.	O
We	O
use	O
this	O
subset	O
when	O
performing	O
the	O
χ	O
2	O
tests	O
.	O

Although	O
a	O
model	O
's	O
scale	O
is	O
important	O
for	O
its	O
performance	O
,	O
it	O
comes	O
with	O
additional	O
efficiency	O
and	O
computational	O
costs	O
,	O
among	O
other	O
considerations	O
(	O
Bommasani	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Fine	O
-	O
tuning	O
large	O
pre	O
-	O
trained	O
language	O
models	O
is	O
usually	O
timeconsuming	O
and	O
expensive	O
,	O
and	O
it	O
also	O
requires	O
a	O
large	O
number	O
of	O
manually	O
annotated	O
examples	O
.	O
A	O
possible	O
direction	O
that	O
alleviates	O
these	O
requirements	O
is	O
to	O
use	O
adapter	O
-	O
based	O
models	O
(	O
Rebuffi	O
et	O
al	O
.	O
,	O
2017	O
;	O
Pfeiffer	O
et	O
al	O
.	O
,	O
2021	O
)	O
and	O
other	O
techniques	O
for	O
efficient	O
training	O
(	O
Lester	O
et	O
al	O
.	O
,	O
2021	O
;	O
Ben	O
Zaken	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O

For	O
neural	O
prediction	O
functions	O
,	O
the	O
simplest	O
-	O
toimplement	O
confidence	O
function	O
is	O
likely	O
MAX	B-MethodName
-	I-MethodName
PROB	I-MethodName
,	O
shown	O
here	O
applied	O
to	O
a	O
three	O
-	O
way	O
sentiment	O
analysis	O
task	O
:	O

To	O
investigate	O
the	O
use	O
of	O
NLP	O
tools	O
for	O
studying	O
the	O
cognitive	O
traces	O
of	O
recollection	O
versus	O
imagination	O
in	O
stories	O
,	O
we	O
collect	O
and	O
release	O
HIP	O
-	O
POCORPUS	O
,	O
a	O
dataset	O
of	O
imagined	O
and	O
recalled	O
stories	O
.	O
We	O
introduce	O
measures	O
to	O
characterize	O
narrative	O
flow	O
and	O
influence	O
of	O
semantic	O
vs.	O
episodic	O
knowledge	O
in	O
stories	O
.	O
We	O
show	O
that	O
imagined	O
stories	O
have	O
a	O
more	O
linear	O
flow	O
and	O
contain	O
more	O
commonsense	O
knowledge	O
,	O
whereas	O
recalled	O
stories	O
are	O
less	O
connected	O
and	O
contain	O
more	O
specific	O
concrete	O
events	O
.	O
Additionally	O
,	O
we	O
show	O
that	O
our	O
measures	O
can	O
uncover	O
the	O
effect	O
in	O
language	O
of	O
narrativization	O
of	O
memories	O
over	O
time	O
.	O
We	O
hope	O
these	O
findings	O
bring	O
attention	O
to	O
the	O
feasibility	O
of	O
employing	O
statistical	O
natural	O
language	O
processing	O
machinery	O
as	O
tools	O
for	O
exploring	O
human	O
cognition	O
.	O
Figure	O
4	O
:	O
We	O
extract	O
phrases	O
from	O
the	O
main	O
themes	O
of	O
recalled	O
(	O
left	O
)	O
and	O
imagined	O
(	O
right	O
)	O
stories	O
,	O
using	O
RAKE	O
(	O
Rose	O
et	O
al	O
.	O
,	O
2010	O
)	O
;	O
size	O
of	O
words	O
corresponds	O
to	O
frequency	O
in	O
corpus	O
,	O
and	O
color	O
is	O
only	O
for	O
readability	O
.	O

We	O
conceptualize	O
dataset	O
artifacts	O
at	O
the	O
lexical	O
level	O
as	O
emergent	O
correlations	O
between	O
tokens	O
and	O
labels	O
in	O
input	O
data	O
,	O
consistently	O
to	O
lexical	O
annotation	O
artifacts	O
in	O
NLI	O
(	O
Gururangan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
As	O
such	O
,	O
given	O
a	O
target	O
class	O
c	O
,	O
we	O
formally	O
define	O
lexical	O
artifacts	O
L	O
c	O
as	O
the	O
set	O
of	O
highly	O
-	O
discriminating	O
2	O
tokens	O
for	O
c	O
,	O
which	O
comprise	O
authentic	O
artifacts	O
A	O
c	O
-items	O
that	O
potentially	O
carry	O
useful	O
information	O
for	O
the	O
class	O
at	O
hand	O
-and	O
spurious	O
artifacts	O
S	O
c	O
-items	O
that	O
are	O
spuriously	O
(	O
or	O
undesirably	O
)	O
associated	O
to	O
the	O
target	O
class	O
-such	O
that	O
L	O
c	O
=	O
A	O
c	O
∪	O
S	O
c	O
.	O
In	O
the	O
context	O
of	O
hate	O
speech	O
detection	O
,	O
we	O
consider	O
the	O
hateful	O
class	O
as	O
c	O
unless	O
otherwise	O
specified	O
and	O
simplify	O
the	O
notation	O
(	O
i.e.	O
,	O
from	O
"	O
•	O
c	O
"	O
to	O
"	O
•	O
"	O
)	O
.	O

We	O
compare	O
two	O
traditional	O
baselines	O
:	O
Majority	O
and	O
Random	O
;	O
and	O
five	O
traditional	O
methods	O
for	O
ob	O
-	O
taining	O
text	O
representations	O
:	O
Topic	O
Modeling	O
using	O
BERT	B-MethodName
topic	O
(	O
Grootendorst	O
,	O
2022	O
)	O
,	O
TF	B-MethodName
-	I-MethodName
IDF	I-MethodName
(	O
Sammut	O
and	O
Webb	O
,	O
2010	O
)	O
,	O
W	O
ord2vec	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
Glove	O
(	O
Pennington	O
et	O
al	O
.	O
,	O
2014	O
)	O
,	O
and	O
BERT	B-MethodName
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
5	O
.	O
For	O
Topic	O
Modeling	O
,	O
we	O
select	O
five	O
topics	O
and	O
match	O
them	O
with	O
our	O
computing	O
careers	O
.	O
Additionally	O
,	O
we	O
fine	O
-	O
tuned	O
BERT	B-MethodName
embeddings	O
with	O
our	O
training	O
data	O
in	O
two	O
ways	O
:	O

In	O
this	O
work	O
,	O
we	O
proposed	O
a	O
multiple	O
-	O
choice	O
question	O
generation	O
method	O
that	O
can	O
be	O
used	O
to	O
fine	O
-	O
tune	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
UnifiedQA	B-MethodName
model	O
and	O
improve	O
its	O
performance	O
on	O
an	O
unseen	O
and	O
out	O
of	O
domain	O
dataset	O
.	O
Our	O
contributions	O
are	O
:	O

On	O
the	O
other	O
hand	O
,	O
neural	O
models	O
(	O
Transformerbased	B-MethodName
and	O
BiLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
)	O
performed	O
better	O
.	O
All	O
of	O
them	O
performed	O
better	O
on	O
the	O
test	O
set	O
than	O
on	O
the	O
development	O
set	O
,	O
which	O
shows	O
good	O
generalization	O
ability	O
.	O
The	O
BiLSTM	B-MethodName
-	I-MethodName
CRF	I-MethodName
model	O
fed	O
with	O
different	O
combinations	O
of	O
Transformer	B-MethodName
-	O
based	O
word	O
embeddings	O
and	O
subword	O
embeddings	O
outperformed	O
multilingual	O
BERT	B-MethodName
and	O
Spanish	O
monolingual	O
BETO	O
.	O
The	O
model	O
fed	O
with	O
codeswitch	O
,	O
BPE	O
,	O
and	O
character	O
embeddings	O
ranked	O
first	O
and	O
was	O
significantly	O
better	O
than	O
the	O
result	O
obtained	O
by	O
the	O
model	O
fed	O
with	O
BETO+BERT	B-MethodName
,	O
BPE	B-MethodName
,	O
and	O
character	O
embeddings	O
.	O

XNLI	O
is	O
an	O
evaluation	O
dataset	O
for	O
cross	O
-	O
lingual	O
NLI	O
that	O
covers	O
15	O
languages	O
.	O
The	O
dataset	O
is	O
human	O
-	O
translated	O
from	O
the	O
development	O
and	O
test	O
sets	O
of	O
the	O
English	O
MultiNLI	O
dataset	O
.	O
Given	O
a	O
sentence	O
pair	O
of	O
premise	O
and	O
hypothesis	O
,	O
the	O
task	O
is	O
to	O
classify	O
their	O
relationship	O
as	O
entailment	O
,	O
contradiction	O
,	O
and	O
neutral	O
.	O
For	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
transfer	O
,	O
we	O
train	O
on	O
the	O
English	O
MultiNLI	O
training	O
set	O
,	O
and	O
apply	O
the	O
model	O
to	O
the	O
test	O
sets	O
of	O
the	O
other	O
languages	O
.	O
For	O
translatetrain	O
,	O
we	O
train	O
on	O
translation	O
data	O
that	O
come	O
with	O
the	O
dataset	O
4	O
.	O

.	O
We	O
therefore	O
hypothesise	O
here	O
that	O
the	O
highly	O
dimensional	O
and	O
contextualised	O
word	O
-	O
level	O
representations	O
from	O
BERT	B-MethodName
are	O
already	O
enough	O
and	O
do	O
not	O
benefit	O
from	O
the	O
extra	O
information	O
provided	O
by	O
the	O
visual	O
features	O
.	O

For	O
all	O
neural	O
-	O
based	O
models	O
,	O
we	O
experiment	O
with	O
the	O
all	O
three	O
integration	O
strategies	O
(	O
'	O
embed	O
'	O
,	O
'	O
annot	O
'	O
and	O
'	O
last	O
'	O
)	O
and	O
all	O
three	O
fusion	O
strategies	O
(	O
'	O
conc	O
'	O
,	O
'	O
mult	O
'	O
and	O
'	O
mult2	O
'	O
)	O
presented	O
in	O
Section	O
3.2	O
.	O
This	O
leads	O
to	O
6	O
multimodal	O
models	O
for	O
each	O
BiRNN	B-MethodName
and	O
BERT	B-MethodName
-	I-MethodName
BiRNN	I-MethodName
.	O
In	O
Tables	O
2	O
and	O
4	O
,	O
as	O
well	O
as	O
in	O
Figures	O
2	O
and	O
3	O
,	O
we	O
report	O
the	O
top	O
three	O
performing	O
models	O
.	O
We	O
refer	O
the	O
reader	O
to	O
the	O
Appendix	O
for	O
the	O
full	O
set	O
of	O
results	O
.	O

In	O
a	O
similar	O
architecture	O
,	O
but	O
with	O
multi	O
-	O
task	O
learning	O
,	O
report	O
that	O
multilingual	O
QE	O
models	O
outperform	O
bilingual	O
models	O
,	O
particularly	O
in	O
less	O
balanced	O
quality	O
label	O
distributions	O
and	O
lowresource	O
settings	O
.	O
However	O
,	O
these	O
two	O
papers	O
are	O
focused	O
on	O
sentence	O
-	O
level	O
QE	O
and	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
no	O
prior	O
work	O
has	O
been	O
done	O
on	O
multilingual	O
,	O
word	O
-	O
level	O
QE	O
models	O
.	O

Note	O
that	O
since	O
COMET	B-MethodName
-	I-MethodName
QE	I-MethodName
is	O
the	O
state	O
-	O
of	O
-	O
theart	O
quality	O
estimator	O
,	O
it	O
is	O
a	O
very	O
strong	O
baseline	O
for	O
the	O
reranking	O
stage	O
where	O
the	O
goal	O
is	O
to	O
find	O
a	O
better	O
translation	O
.	O
The	O
fact	O
that	O
we	O
can	O
match	O
its	O
hallucinatory	O
rate	O
reduction	O
by	O
analyzing	O
model	O
inner	O
workings	O
has	O
value	O
from	O
different	O
perspectives	O
.	O

Since	O
SciQ	O
is	O
a	O
multiple	O
-	O
choice	O
dataset	O
,	O
we	O
must	O
add	O
distractors	O
to	O
each	O
question	O
we	O
generate	O
,	O
to	O
match	O
the	O
format	O
of	O
SciQ.	O
A	O
simple	O
solution	O
to	O
this	O
problem	O
is	O
to	O
select	O
random	O
distractors	O
among	O
answers	O
to	O
other	O
similar	O
questions	O
generated	O
from	O
the	O
dataset	O
of	O
sentences	O
we	O
gathered	O
.	O
Obviously	O
,	O
selecting	O
random	O
distractors	O
may	O
lead	O
to	O
a	O
fine	O
-	O
tuning	O
dataset	O
that	O
is	O
too	O
easy	O
to	O
solve	O
.	O
Therefore	O
,	O
we	O
propose	O
another	O
strategy	O
that	O
selects	O
hard	O
distractors	O
for	O
each	O
question	O
.	O
To	O
do	O
so	O
,	O
starting	O
from	O
our	O
synthetic	O
dataset	O
with	O
random	O
distractors	O
,	O
we	O
finetune	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
using	O
the	O
standard	O
method	O
of	O
training	O
for	O
multiple	O
choices	O
question	O
answering	O
.	O
Each	O
pair	O
question	O
/	O
choice	O
is	O
fed	O
to	O
RoBERTa	O
and	O
the	O
embedding	O
corresponding	O
to	O
the	O
first	O
token	O
(	O
"	O
[	O
CLS	O
]	O
"	O
)	O
is	O
given	O
to	O
a	O
linear	O
layer	O
to	O
produce	O
a	O
single	O
scalar	O
score	O
for	O
each	O
choice	O
.	O
The	O
scores	O
corresponding	O
to	O
every	O
choice	O
for	O
a	O
given	O
question	O
are	O
then	O
compared	O
to	O
each	O
other	O
by	O
a	O
softmax	O
and	O
a	O
cross	O
-	O
entropy	O
loss	O
.	O
With	O
this	O
method	O
,	O
RoBERTa	O
is	O
trained	O
to	O
score	O
a	O
possible	O
answer	O
for	O
a	O
given	O
question	O
,	O
based	O
on	O
whether	O
or	O
not	O
it	O
is	O
a	O
credible	O
answer	O
to	O
that	O
question	O
.	O
For	O
each	O
question	O
,	O
we	O
then	O
randomly	O
select	O
a	O
number	O
of	O
candidate	O
distractors	O
from	O
the	O
answers	O
to	O
other	O
questions	O
and	O
we	O
use	O
our	O
trained	O
RoBERTa	O
to	O
score	O
each	O
of	O
these	O
candidates	O
.	O
The	O
3	O
candidates	O
with	O
the	O
highest	O
scores	O
(	O
and	O
thus	O
the	O
most	O
credible	O
answers	O
)	O
are	O
selected	O
.	O
The	O
idea	O
is	O
that	O
during	O
this	O
first	O
training	O
,	O
RoBERTa	O
will	O
learn	O
a	O
large	O
amount	O
of	O
simplistic	O
logic	O
.	O
For	O
example	O
,	O
because	O
of	O
the	O
initial	O
random	O
selection	O
of	O
distractors	O
,	O
it	O
is	O
highly	O
unlikely	O
that	O
even	O
one	O
of	O
the	O
distractors	O
will	O
be	O
close	O
enough	O
to	O
the	O
question	O
's	O
semantic	O
field	O
.	O
Furthermore	O
,	O
a	O
lot	O
distractors	O
have	O
an	O
incorrect	O
grammar	O
(	O
eg	O
:	O
a	O
distractor	O
might	O
be	O
plural	O
when	O
the	O
question	O
expects	O
a	O
singular	O
)	O
.	O
Therefore	O
,	O
in	O
this	O
initial	O
training	O
,	O
RoBERTa	O
might	O
learn	O
to	O
isolate	O
the	O
answer	O
with	O
a	O
corresponding	O
semantic	O
field	O
or	O
the	O
one	O
with	O
correct	O
grammar	O
.	O
The	O
re	O
-	O
selection	O
then	O
minimizes	O
the	O
amount	O
of	O
trivial	O
distractors	O
and	O
models	O
trained	O
on	O
this	O
new	O
refined	O
dataset	O
will	O
have	O
to	O
focus	O
on	O
deeper	O
and	O
more	O
meaningful	O
relations	O
between	O
the	O
questions	O
and	O
the	O
answers	O
.	O
The	O
process	O
is	O
better	O
shown	O
in	O
Figure	O
4	O
,	O
and	O
an	O
example	O
of	O
refined	O
distractors	O
can	O
be	O
found	O
in	O
Figure	O
3	O
.	O

We	O
train	O
a	O
realis	O
event	O
tagger	O
(	O
using	O
BERT	B-MethodName
-	O
base	O
;	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
on	O
the	O
annotated	O
literary	O
events	O
corpus	O
by	O
Sims	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
slightly	O
outperforms	O
the	O
original	O
author	O
's	O
models	O
.	O
We	O
provide	O
further	O
training	O
details	O
in	O
Appendix	O
B.1	O
.	O

In	O
this	O
section	O
,	O
we	O
focus	O
on	O
the	O
last	O
step	O
in	O
a	O
parsingas	O
-	O
tagging	O
pipeline	O
,	O
which	O
is	O
to	O
decode	O
a	O
tag	O
sequence	O
into	O
a	O
tree	O
.	O
The	O
goal	O
of	O
the	O
decoding	O
step	O
is	O
to	O
find	O
a	O
valid	O
sequence	O
of	O
tags	O
t	O
*	O
that	O
are	O
assigned	O
the	O
highest	O
probability	O
under	O
the	O
model	O
for	O
a	O
given	O
sentence	O
,	O
i.e.	O
,	O

We	O
mainly	O
evaluate	O
our	O
approach	O
in	O
Machine	O
Translation	O
(	O
MT	O
)	O
.	O
We	O
select	O
the	O
most	O
popular	O
MT	O
benchmark	O
-WMT14	O
English	O
-	O
German	O
(	O
En	O
-	O
De	O
)	O
translation	O
task	O
,	O
which	O
is	O
also	O
a	O
touchstone	O
for	O
seq2seq	O
evaluation	O
,	O
as	O
our	O
main	O
test	O
bed	O
.	O
To	O
compare	O
with	O
previous	O
work	O
,	O
we	O
also	O
evaluate	O
WMT14	B-DatasetName
English	O
-	O
French	O
(	O
En	O
-	O
Fr	O
)	O
translation	O
.	O
We	O
follow	O
the	O
standard	O
way	O
to	O
train	O
and	O
evaluate	O
evaluate	O
WMT14	B-DatasetName
En	O
-	O
De	O
and	O
En	O
-	O
Fr	O
.	O
As	O
Ott	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
we	O
use	O
a	O
joint	O
source	O
-	O
target	O
dictionary	O
of	O
32	O
K	O
Byte	I-MethodName
Pair	I-MethodName
Encoding	I-MethodName
(	O
BPE	O
)	O
for	O
En	O
-	O
De	O
,	O
and	O
40	O
K	O
BPE	O
for	O
En	O
-	O
Fr	O
.	O
We	O
mainly	O
use	O
sacreBLEU	B-DatasetName
(	O
Post	O
,	O
2018	O
)	O
for	O
evaluation	O
.	O

The	O
structure	O
of	O
the	O
final	O
dataset	O
is	O
described	O
in	O
Section	O
F.	O
For	O
reproducibility	O
of	O
results	O
,	O
we	O
create	O
fixed	O
splits	O
for	O
in	O
-	O
and	O
cross	O
-	O
topic	O
experiments	O
.	O
9	O
,	O
we	O
show	O
the	O
synonyms	O
used	O
for	O
filtering	O
prior	O
to	O
the	O
argument	O
and	O
stance	O
classification	O
step	O
.	O
We	O
filtered	O
out	O
all	O
sentences	O
that	O
did	O
not	O
contain	O
tokens	O
from	O
the	O
topic	O
they	O
belong	O
to	O
or	O
any	O
synonyms	O
defined	O
for	O
this	O
topic	O
.	O

subjective	O
experience	O
of	O
their	O
own	O
gender	O
,	O
which	O
encompasses	O
a	O
diverse	O
range	O
of	O
experiences	O
and	O
expressions	O
(	O
WHO	O
,	O
2021	O
;	O
NIH	O
;	O
Prince	O
,	O
2005	O
)	O
,	O
eg	O
.	O
cisgender	O
,	O
transgender	O
,	O
non	O
-	O
binary	O
etc	O
.	O
Historically	O
,	O
there	O
are	O
several	O
cultures	O
where	O
gender	O
is	O
understood	O
as	O
a	O
spectrum	O
,	O
for	O
example	O
,	O
the	O
Bugis	O
people	O
of	O
Indonesia	O
recognize	O
five	O
genders	O
(	O
Davies	O
,	O
2007	O
)	O
.	O
While	O
there	O
are	O
nations	O
that	O
legally	O
acknowledge	O
gender	O
exclusively	O
as	O
a	O
binary	O
(	O
female	O
or	O
male	O
)	O
(	O
EqualDex	O
,	O
2022	O
)	O
,	O
an	O
increasing	O
number	O
of	O
jurisdictions	O
recognize	O
gender	O
as	O
a	O
broader	O
concept	O
,	O
including	O
the	O
USA	O
(	O
U.S.	O
Dept	O
of	O
State	O
,	O
2022	O
;	O
EqualDex	O
,	O
2022	O
)	O
.	O

For	O
the	O
first	O
task	O
,	O
on	O
average	O
,	O
14.33	O
out	O
of	O
30	O
features	O
were	O
disabled	O
and	O
the	O
macro	O
F1	O
scores	O
of	O
the	O
20Newsgroups	B-DatasetName
before	O
and	O
after	O
debugging	O
are	O
0.853	O
and	O
0.828	O
,	O
respectively	O
.	O
The	O
same	O
metrics	O
of	O
the	O
Religion	O
dataset	O
are	O
0.731	O
and	O
0.799	O
.	O
This	O
shows	O
that	O
disabling	O
irrelevant	O
features	O
mildly	O
undermined	O
the	O
predictive	O
performance	O
on	O
the	O
indistribution	O
dataset	O
,	O
but	O
clearly	O
enhanced	O
the	O
performance	O
on	O
the	O
out	O
-	O
of	O
-	O
distribution	O
dataset	O
(	O
see	O
Figure	O
8	O
,	O
left	O
)	O
.	O
This	O
is	O
especially	O
evident	O
for	O
the	O
Atheism	O
class	O
for	O
which	O
the	O
F1	O
score	O
increased	O
around	O
15	O
%	O
absolute	O
.	O
We	O
noticed	O
from	O
the	O
word	O
clouds	O
that	O
many	O
prominent	O
words	O
for	O
the	O
Atheism	O
class	O
learned	O
by	O
the	O
models	O
are	O
person	O
names	O
(	O
e.g.	O
,	O
Keith	O
,	O
Gregg	O
,	O
Schneider	O
)	O
and	O
these	O
are	O
not	O
applicable	O
to	O
the	O
Religion	O
dataset	O
.	O
Forcing	O
the	O
models	O
to	O
use	O
only	O
relevant	O
features	O
(	O
detecting	O
terms	O
like	O
'	O
atheists	O
'	O
and	O
'	O
science	O
'	O
)	O
,	O
therefore	O
,	O
increased	O
the	O
macro	O
F1	O
on	O
the	O
Religion	O
dataset	O
.	O

Intelligent	O
and	O
adaptive	O
online	O
education	O
systems	O
aim	O
to	O
make	O
high	O
-	O
quality	O
education	O
available	O
for	O
a	O
diverse	O
range	O
of	O
students	O
.	O
However	O
,	O
existing	O
systems	O
usually	O
depend	O
on	O
a	O
pool	O
of	O
hand	O
-	O
made	O
questions	O
,	O
limiting	O
how	O
finegrained	O
and	O
open	O
-	O
ended	O
they	O
can	O
be	O
in	O
adapting	O
to	O
individual	O
students	O
.	O
We	O
explore	O
targeted	O
question	O
generation	O
as	O
a	O
controllable	O
sequence	B-TaskName
generation	I-TaskName
task	O
.	O
We	O
first	O
show	O
how	O
to	O
fine	O
-	O
tune	O
pre	O
-	O
trained	O
language	O
models	O
for	O
deep	O
knowledge	I-TaskName
tracing	O
(	O
LM	O
-	O
KT	O
)	O
.	O
This	O
model	O
accurately	O
predicts	O
the	O
probability	O
of	O
a	O
student	O
answering	O
a	O
question	O
correctly	O
,	O
and	O
generalizes	O
to	O
questions	O
not	O
seen	O
in	O
training	O
.	O
We	O
then	O
use	O
LM	O
-	O
KT	O
to	O
specify	O
the	O
objective	O
and	O
data	O
for	O
training	O
a	O
model	O
to	O
generate	O
questions	O
conditioned	O
on	O
the	O
student	O
and	O
target	O
difficulty	O
.	O
Our	O
results	O
show	O
we	O
succeed	O
at	O
generating	O
novel	O
,	O
wellcalibrated	O
language	O
translation	O
questions	O
for	O
second	O
language	O
learners	O
from	O
a	O
real	O
online	O
education	O
platform	O
.	O

(	O
1.00	O
)	O
death	O
penalty	O
CON	O
god	O
.	O
And	O
yet	O
,	O
while	O
the	O
Church	O
exhorts	O
civil	O
authorities	O
.	O
(	O
0.41	O
)	O
school	O
uniforms	O
CON	O
resources	O
.	O
The	O
lack	O
of	O
a	O
uniform	O
system	O
for	O
the	O
collection	O
and	O
use	O
of	O
data	O
,	O
as	O
well	O
as	O
insufficient	O
funding	O
to	O
collect	O
it	O
,	O
are	O
major	O
barriers	O
that	O
limit	O
access	O
to	O
information	O
on	O
student	O
achievement	O
in	O
schools	O
with	O
high	O
concentrations	O
of	O
students	O
from	O
low	O
-	O
income	O
families	O
.	O
(	O
0.92	O
)	O
school	O
uniforms	O
PRO	O
fun	O
:	O
The	O
kids	O
are	O
having	O
a	O
lot	O
of	O
fun	O
.	O
(	O
0.38	O
)	O
gun	O
control	O
PRO	O
homicides	O
.	O
In	O
addition	O
to	O
being	O
an	O
effective	O
crime	O
deterrent	O
and	O
reducing	O
suicides	O
,	O
research	O
has	O
shown	O
that	O
defensive	O
firearm	O
use	O
prevents	O
more	O
than	O
80	O
percent	O
of	O
all	O
gun	O
-	O
related	O
violent	O
crimes	O
including	O
homicides	O
,	O
robberies	O
,	O
assaults	O
,	O
rapes	O
,	O
and	O
aggravated	O
assaults	O
[	O
1	O
]	O
.	O
(	O
0.96	O
)	O
gun	O
control	O
PRO	O
prevent	O
;	O
You	O
liberals	O
need	O
to	O
wake	O
up	O
and	O
smell	O
the	O
coffee	O
.	O
(	O
0.43	O
)	O
marijuana	O
legalization	O
PRO	O
safer	O
:	O
Legalizing	O
cannabis	O
will	O
help	O
reduce	O
crime	O
rates	O
(	O
especially	O
violent	O
crimes	O
)	O
and	O
make	O
society	O
safer	O
overall	O
.	O
(	O
0.96	O
)	O
marijuana	O
legalization	O
PRO	O
benefits	O
.	O
Decrease	O
amount	O
of	O
police	O
officers	O
needed	O
6	O
.	O
(	O
0.37	O
)	O
minimum	O
wage	O
PRO	O
poor	O
:	O
Raising	O
the	O
minimum	O
wage	O
will	O
not	O
only	O
benefit	O
those	O
working	O
full	O
time	O
but	O
also	O
reduce	O
government	O
expenditures	O
on	O
social	O
services	O
such	O
as	O
food	O
stamps	O
and	O
Medicaid	O
which	O
disproportionately	O
affect	O
the	O
poor	O
.	O
(	O
0.97	O
)	O
minimum	O
wage	O
CON	O
cost	O
:	O
If	O
you	O
raise	O
the	O
price	O
of	O
a	O
Big	O
Mac	O
to	O
$	O
10	O
and	O
then	O
pay	O
an	O
extra	O
dime	O
or	O
two	O
per	O
burger	O
so	O
that	O
it	O
's	O
still	O
only	O
$	O
9	O
...	O
well	O
,	O
maybe	O
your	O
business	O
is	O
n't	O
worth	O
saving	O
at	O
all	O
because	O
there	O
just	O
wo	O
n't	O
be	O
anyone	O
willing	O
to	O
eat	O
out	O
after	O
they	O
'	O
ve	O
had	O
their	O
fill	O
(	O
unless	O
perhaps	O
they	O
're	O
on	O
welfare	O
)	O
and	O
now	O
have	O
no	O
job	O
and	O
ca	O
n't	O
afford	O
health	O
care	O
eitherbut	O
I	O
doubt	O
very	O
seriously	O
that	O
most	O
people	O
making	O
those	O
kinds	O
of	O
wages	O
/	O
salaries	O
would	O
suddenly	O
decide	O
not	O
to	O
work	O
if	O
forced	O
to	O
shoulder	O
the	O
added	O
cost	O
.	O
(	O
0.44	O
)	O
12	O
:	O
Generated	O
arguments	O
with	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
.	O
Text	O
in	O
bold	O
shows	O
the	O
given	O
control	O
code	O
,	O
text	O
afterwards	O
represents	O
the	O
generated	O
argument	O
.	O
Numbers	O
in	O
brackets	O
after	O
the	O
text	O
show	O
the	O
quality	O
score	O
as	O
predicted	O
by	O
the	O
argument	O
quality	O
model	O
.	O

The	O
article	O
discusses	O
how	O
Rod	O
Blagojevich	O
,	O
a	O
former	O
Illinois	O
governor	O
,	O
has	O
let	O
his	O
hair	O
go	O
while	O
serving	O
his	O
prison	O
sentence	O
.	O
The	O
photos	O
show	O
the	O
former	O
governor	O
with	O
white	O
hair	O
,	O
rather	O
than	O
the	O
black	O
hair	O
that	O
was	O
his	O
trademark	O
as	O
a	O
politician	O
.	O

In	O
faithfulness	O
evaluation	O
,	O
erasure	O
-	O
based	O
methods	O
examine	O
the	O
drop	O
in	O
prediction	O
scores	O
by	O
removing	O
the	O
important	O
tokens	O
from	O
the	O
input	O
(	O
Section	O
2.1.1	O
)	O
.	O
However	O
,	O
the	O
drop	O
in	O
the	O
prediction	O
scores	O
may	O
be	O
the	O
result	O
of	O
the	O
altered	O
,	O
out	O
-	O
of	O
-	O
distribution	O
inputs	O
(	O
Bastings	O
and	O
Filippova	O
,	O
2020	O
)	O
.	O
To	O
overcome	O
this	O
problem	O
,	O
we	O
design	O
a	O
new	O
strategy	O
to	O
evaluate	O
faithfulness	O
by	O
relying	O
on	O
cross	O
-	O
lingual	O
models	O
and	O
datasets	O
.	O
Before	O
diving	O
into	O
details	O
,	O
let	O
us	O
recall	O
Corrolary	O
2	O
from	O
Jacovi	O
and	O
Goldberg	O
(	O
2020	O
)	O
.	O

We	O
also	O
compare	O
with	O
Mesgar	O
and	O
Strube	O
(	O
2016	O
)	O
,	O
which	O
feeds	O
subgraphs	O
as	O
input	O
features	O
.	O
For	O
a	O
fair	O
comparison	O
,	O
we	O
input	O
document	O
representations	O
from	O
XLNet	O
to	O
this	O
model	O
,	O
equip	O
it	O
with	O
a	O
two	O
-	O
layer	O
DNN	O
and	O
softmax	O
layer	O
for	O
feature	O
extraction	O
and	O
classification	O
.	O
Furthermore	O
,	O
we	O
compare	O
our	O
method	O
against	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
each	O
task	O
to	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O

We	O
base	O
our	O
new	O
aspect	O
detection	I-TaskName
dataset	O
on	O
the	O
UKP	O
Sentential	I-MethodName
Argument	I-MethodName
Mining	O
Corpus	O
(	O
UKP	O
-	O
Corpus	O
)	O
by	O
Stab	O
et	O
al	O
.	O
(	O
2018b	O
)	O
,	O
as	O
it	O
already	O
contains	O
sentence	O
-	O
level	O
arguments	O
and	O
two	O
of	O
the	O
control	O
codes	O
we	O
aim	O
to	O
use	O
:	O
topics	O
and	O
stance	O
labels	O
.	O
More	O
precisely	O
,	O
it	O
contains	O
25,474	O
manually	O
labelled	O
sentences	O
for	O
eight	O
controversial	O
topics	O
in	O
English	O
.	O
Each	O
sample	O
consists	O
of	O
a	O
topic	O
and	O
a	O
sentence	O
,	O
labelled	O
as	O
either	O
being	O
supporting	O
,	O
attacking	O
,	O
or	O
no	O
argument	O
towards	O
the	O
given	O
topic	O
.	O
As	O
we	O
are	O
only	O
interested	O
in	O
arguments	O
,	O
we	O
do	O
not	O
consider	O
the	O
non	O
-	O
argumentative	O
sentences	O
.	O

In	O
this	O
section	O
,	O
we	O
explain	O
how	O
we	O
achieve	O
over	O
23fps	O
real	O
-	O
time	O
inference	O
,	O
by	O
using	O
MediaPipe	B-MethodName
Holistic	O
for	O
generating	O
poses	O
(	O
as	O
an	O
ISLR	B-TaskName
encoder	O
)	O
and	O
our	O
pose	O
-	O
based	O
models	O
(	O
as	O
decoder	O
)	O
that	O
recognizes	O
the	O
sign	O
at	O
any	O
given	O
window	O
.	O

BERT	B-MethodName
and	O
related	O
pre	O
-	O
training	O
methods	O
(	O
Baevski	O
et	O
al	O
.	O
,	O
2019;Lan	O
et	O
al	O
.	O
,	O
2020	O
)	O
train	O
a	O
large	O
neural	O
network	O
to	O
perform	O
the	O
cloze	O
task	O
.	O
These	O
models	O
learn	O
the	O
probability	O
p	O
data	O
(	O
x	O
t	O
|x	O
\t	O
)	O
of	O
a	O
token	O
x	O
t	O
occurring	O
in	O
the	O
surrounding	O
context	O

a	O
CRF	O
model	O
using	O
the	O
token	O
,	O
its	O
lemma	O
,	O
part	O
-	O
ofspeech	O
tag	O
and	O
mat2vec	O
embedding	O
as	O
features	O
.	O
7	O

(	O
2	O
)	O
the	O
category	O
of	O
each	O
action	O
in	O
the	O
action	O
chain	O
A.	O
The	O
δ	O
(	O
.	O
)	O
outputs	O
the	O
prediction	O
,	O
and	O
the	O
Θ	O
is	O
the	O
learnable	O
parameter	O
.	O

Quality	O
Estimation	I-MethodName
(	O
QE	O
)	O
for	O
Machine	O
Translation	O
(	O
MT	O
)	O
(	O
Blatz	O
et	O
al	O
.	O
,	O
2004;Specia	O
et	O
al	O
.	O
,	O
2009	O
)	O
aims	O
to	O
predict	O
the	O
quality	O
of	O
a	O
machine	O
-	O
translated	O
text	O
without	O
using	O
reference	O
translations	O
.	O
It	O
estimates	O
a	O
label	O
(	O
a	O
category	O
,	O
such	O
as	O
'	O
good	O
'	O
or	O
'	O
bad	O
'	O
,	O
or	O
a	O
numerical	O
score	O
)	O
for	O
a	O
translation	O
,	O
given	O
text	O
in	O
a	O
source	O
language	O
and	O
its	O
machine	O
translation	O
in	O
a	O
target	O
language	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
QE	O
can	O
operate	O
at	O
different	O
linguistic	O
levels	O
,	O
including	O
sentence	O
and	O
document	O
levels	O
.	O
Sentence	O
-	O
level	O
QE	O
estimates	O
the	O
translation	O
quality	O
of	O
a	O
whole	O
sentence	O
,	O
while	O
document	O
-	O
level	O
QE	O
predicts	O
the	O
translation	O
quality	O
of	O
an	O
entire	O
document	O
,	O
even	O
though	O
in	O
practice	O
in	O
literature	O
the	O
documents	O
have	O
been	O
limited	O
to	O
a	O
small	O
set	O
of	O
3	O
-	O
5	O
sentences	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O

..	O
q	O
j	O
m	O
a	O
j	O
m	O
,	O
a	O
i	O
∈	O
{	O
<	O
Y>,<N	O
>	O
}	O
LM	O
-	O
KT	O
Given	O
the	O
sequential	O
nature	O
of	O
student	O
learning	O
over	O
time	O
,	O
we	O
can	O
easily	O
frame	O
knowledge	O
tracing	O
as	O
an	O
autoregressive	O
language	O
modeling	O
task	O
.	O
Given	O
a	O
dataset	O
D	O
of	O
students	O
s	O
1	O
,	O
s	O
2	O
,	O
...	O
,	O
s	O
|D|	O
,	O
we	O
employ	O
the	O
standard	O
training	O
objective	O
of	O
finding	O
the	O
parameters	O
θ	O
KT	O
that	O
minimizes	O

We	O
introduce	O
Electric	O
,	O
an	O
energy	O
-	O
based	O
cloze	O
model	O
for	O
representation	O
learning	O
over	O
text	O
.	O
Like	O
BERT	B-MethodName
,	O
it	O
is	O
a	O
conditional	O
generative	O
model	O
of	O
tokens	O
given	O
their	O
contexts	O
.	O
However	O
,	O
Electric	O
does	O
not	O
use	O
masking	O
or	O
output	O
a	O
full	O
distribution	O
over	O
tokens	O
that	O
could	O
occur	O
in	O
a	O
context	O
.	O
Instead	O
,	O
it	O
assigns	O
a	O
scalar	O
energy	O
score	O
to	O
each	O
input	O
token	O
indicating	O
how	O
likely	O
it	O
is	O
given	O
its	O
context	O
.	O
We	O
train	O
Electric	O
using	O
an	O
algorithm	O
based	O
on	O
noise	O
-	O
contrastive	O
estimation	O
and	O
elucidate	O
how	O
this	O
learning	O
objective	O
is	O
closely	O
related	O
to	O
the	O
recently	O
proposed	O
ELECTRA	O
pre	O
-	O
training	O
method	O
.	O
Electric	O
performs	O
well	O
when	O
transferred	O
to	O
downstream	O
tasks	O
and	O
is	O
particularly	O
effective	O
at	O
producing	O
likelihood	O
scores	O
for	O
text	O
:	O
it	O
reranks	O
speech	O
recognition	O
n	O
-	O
best	O
lists	O
better	O
than	O
language	O
models	O
and	O
much	O
faster	O
than	O
masked	O
language	O
models	O
.	O
Furthermore	O
,	O
it	O
offers	O
a	O
clearer	O
and	O
more	O
principled	O
view	O
of	O
what	O
ELECTRA	O
learns	O
during	O
pre	O
-	O
training	O
.	O

While	O
covering	O
similar	O
domains	O
,	O
Wikidata	O
and	O
the	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
Reference	O
KB	O
have	O
different	O
schemas	O
.	O
Wikidata	O
is	O
more	O
structured	O
and	O
entities	O
are	O
associated	O
with	O
statements	O
represented	O
using	O
attribute	O
-	O
value	O
pairs	O
,	O
which	O
are	O
short	O
snippets	O
rather	O
than	O
full	O
sentences	O
.	O
The	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
Reference	O
KB	O
contains	O
both	O
short	O
snippets	O
like	O
these	O
,	O
along	O
with	O
the	O
text	O
of	O
the	O
Wikipedia	O
article	O
of	O
the	O
entity	O
.	O
The	O
two	O
KBs	O
also	O
differ	O
in	O
size	O
,	O
with	O
Wikidata	O
containing	O
almost	O
seven	O
times	O
the	O
number	O
of	O
entities	O
in	O
TAC	B-MethodName
KBP	I-MethodName
.	O

We	O
summarize	O
the	O
paper	O
's	O
main	O
claims	O
in	O
the	O
last	O
two	O
paragraphs	O
of	O
the	O
introduction	O
A4	O
.	O
Have	O
you	O
used	O
AI	O
writing	O
assistants	O
when	O
working	O
on	O
this	O
paper	O
?	O

We	O
thank	O
the	O
four	O
anonymous	O
reviewers	O
whose	O
feedback	O
and	O
suggestions	O
helped	O
improve	O
this	O
manuscript	O
.	O
The	O
first	O
author	O
was	O
supported	O
by	O
the	O
National	O
Institute	O
of	O
Standards	O
and	O
Technology	O
's	O
(	O
NIST	O
)	O
Professional	O
Research	O
Experience	O
Program	O
(	O
PREP	O
)	O
.	O
This	O
research	O
was	O
also	O
supported	O
by	O
the	O
DARPA	B-DatasetName
KAIROS	O
program	O
.	O
The	O
views	O
and	O
conclusions	O
contained	O
in	O
this	O
publication	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
representing	O
official	O
policies	O
or	O
endorsements	O
of	O
NIST	B-DatasetName
,	O
DARPA	B-DatasetName
,	O
or	O
the	O
U.S.	O
Government	O
.	O

For	O
fair	O
comparison	O
,	O
we	O
keep	O
the	O
Transformer	B-MethodName
decoder	O
unchanged	O
and	O
validate	O
different	O
position	O
representation	O
strategies	O
on	O
the	O
encoder	O
.	O
We	O
conduct	O
all	O
experiments	O
on	O
the	O
TRANSFORMER	B-MethodName
-	I-MethodName
BIG	I-MethodName
with	O
four	O
V100	O
GPUs	O
.	O

One	O
classical	O
way	O
to	O
compress	O
the	O
training	O
dataset	O
is	O
data	O
selection	O
.	O
Data	O
selection	O
methods	O
choose	O
a	O
subset	O
of	O
effective	O
training	O
samples	O
on	O
the	O
basis	O
of	O
a	O
number	O
of	O
heuristic	O
measures	O
,	O
for	O
example	O
,	O
cluster	O
centers	O
(	O
Sener	O
and	O
Savarese	O
,	O
2018	O
)	O
,	O
diversity	O
(	O
Aljundi	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
likelihood	O
of	O
models	O
(	O
Moore	O
and	O
Lewis	O
,	O
2010	O
)	O
.	O
Although	O
the	O
data	O
selection	O
methods	O
effectively	O
work	O
for	O
efficient	O
model	O
training	O
and	O
several	O
applications	O
,	O
such	O
as	O
active	O
learning	O
(	O
Sener	O
and	O
Savarese	O
,	O
2018	O
)	O
and	O
continual	O
learning	O
(	O
Aljundi	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
their	O
performance	O
is	O
clearly	O
restricted	O
because	O
they	O
rely	O
on	O
the	O
existence	O
of	O
representative	O
samples	O
that	O
are	O
effective	O
for	O
model	O
training	O
in	O
the	O
original	O
dataset	O
.	O

We	O
evaluate	O
Electric	O
on	O
GLUE	B-DatasetName
and	O
SQuAD	B-DatasetName
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
where	O
Electric	O
substantially	O
outperforms	O
BERT	B-MethodName
but	O
slightly	O
under	O
-	O
performs	O
ELECTRA	B-MethodName
.	O
However	O
,	O
Electric	O
is	O
particularly	O
useful	O
in	O
its	O
ability	O
to	O
efficiently	O
produce	O
pseudo	O
-	O
likelihood	O
scores	O
(	O
Salazar	O
et	O
al	O
.	O
,	O
2020	O
)	O
for	O
text	O
:	O
Electric	O
is	O
better	O
at	O
re	O
-	O
ranking	O
the	O
outputs	O
of	O
a	O
speech	O
recognition	O
system	O
than	O
GPT-2	B-MethodName
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
is	O
much	O
faster	O
at	O
re	O
-	O
ranking	O
than	O
BERT	B-MethodName
because	O
it	O
scores	O
all	O
input	O
tokens	O
simultaneously	O
rather	O
than	O
having	O
to	O
be	O
run	O
multiple	O
times	O
with	O
different	O
tokens	O
masked	O
out	O
.	O
In	O
total	O
,	O
investigating	O
Electric	O
leads	O
to	O
a	O
more	O
principled	O
understanding	O
of	O
ELECTRA	B-MethodName
and	O
our	O
results	O
suggest	O
that	O
EBMs	O
are	O
a	O
promising	O
alternative	O
to	O
the	O
standard	O
generative	O
models	O
currently	O
used	O
for	O
language	O
representation	O
learning	O
.	O

We	O
compare	O
our	O
proposed	O
method	O
with	O
the	O
following	O
strong	O
baselines	O
.	O

where	O
sequence	O
x	O
(	O
j	O
)	O
contains	O
the	O
full	O
s	O
j	O
d	O
j	O
<	O
G	O
>	O
q	O
j	O
sequence	O
.	O
At	O
test	O
time	O
,	O
we	O
generate	O
tokens	O
w	O
1	O
...	O
w	O
n	O
conditioned	O
on	O
the	O
s	O
j	O
d	O
j	O
<	O
G	O
>	O
prefix	O
.	O

Figure	O
1	O
:	O
Example	O
input	O
and	O
outputs	O
for	O
our	O
LM	O
-	O
based	O
knowledge	O
tracing	O
model	O
(	O
middle	O
)	O
and	O
question	O
generation	O
model	O
(	O
bottom	O
)	O
for	O
an	O
online	O
reverse	O
language	O
translation	O
task	O
(	O
top	O
)	O
.	O
A	O
question	O
in	O
this	O
task	O
consists	O
of	O
a	O
target	O
phrase	O
for	O
the	O
student	O
,	O
in	O
this	O
case	O
a	O
Spanish	O
learner	O
,	O
to	O
translate	O
(	O
e.g.	O
"	O
the	O
woman	O
"	O
)	O
.	O

We	O
share	O
the	O
parameters	O
in	O
the	O
two	O
-	O
stream	O
mechanism	O
to	O
retain	O
more	O
information	O
about	O
the	O
translation	O
decoding	O
procedure	O
for	O
reconstruction	O
.	O
Computationally	O
,	O
we	O
denote	O
the	O
representation	O
of	O
t	O
-	O
th	O
layer	O
in	O
Translation	O
and	O
Reconstruction	O
streams	O
as	O
h	O
and	O
g	O
,	O
respectively	O
.	O
The	O
first	O
layer	O
representations	O
of	O
the	O
two	O
streams	O
are	O
both	O
set	O
as	O
the	O
precedent	O
word	O
embedding	O
,	O
i.e.	O
h	O
0	O
t	O
=	O
g	O
0	O
t	O
=	O
e	O
(	O
y	O
t	O
)	O
.	O
For	O
each	O
layer	O
n	O
=	O
1	O
,	O
2	O
,	O
...	O
,	O
N	O
,	O
the	O
representations	O
of	O
two	O
streams	O
are	O
calculated	O
as	O
follows	O
:	O
3	O

Inspired	O
by	O
Shaw	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
we	O
model	O
the	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
labeled	O
directed	O
graph	O
and	O
use	O
the	O
same	O
formulation	O
of	O
relationaware	O
self	O
-	O
attention	O
as	O
Shaw	O
et	O
al	O
.	O
(	O
2018	O
)	O
.	O
Here	O

Our	O
proposed	O
XL	O
PE	O
intuitively	O
encourages	O
SANs	O
to	O
learn	O
bilingual	O
diagonal	O
alignment	O
,	O
so	O
has	O
the	O
2	O
Replace	O
PEXL	O
in	O
Eq	O
.	O
(	O
9	O
)	O
with	O
PEIN	B-MethodName
-	I-MethodName
XL	I-MethodName
in	O
Eq	O
.	O
(	O
8)	O
.	O
potential	O
to	O
induce	O
better	O
attention	O
matrices	O
.	O
We	O
explore	O
this	O
hypothesis	O
on	O
the	O
widely	O
used	O
Gold	O
Alignment	O
dataset	O
3	O
and	O
follow	O
Tang	O
et	O
al	O
.	O
(	O
2019	O
)	O
to	O
perform	O
the	O
alignment	O
.	O
The	O
only	O
difference	O
being	O
that	O
we	O
average	O
the	O
attention	O
matrices	O
across	O
all	O
heads	O
from	O
the	O
penultimate	O
layer	O
(	O
Garg	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
alignment	O
error	O
rate	O
(	O
AER	B-MethodName
,	O
Och	O
and	O
Ney	O
2003	O
)	O
,	O
precision	O
(	O
P	O
)	O
and	O
recall	O
(	O
R	O
)	O
are	O
reported	O
as	O
the	O
evaluation	O
metrics	O
.	O
Tab	O
.	O
3	O
summarizes	O
the	O
results	O
.	O
We	O
can	O
see	O
:	O
1	O
)	O
XL	O
PE	O
allows	O
SANs	O
to	O
learn	O
better	O
attention	O
matrices	O
,	O
thereby	O
improving	O
alignment	O
performance	O
(	O
27.4	O
/	O
26.9	O
vs.	O
29.7	O
)	O
;	O
and	O
2	O
)	O
combining	O
the	O
two	O
strategies	O
delivers	O
consistent	O
improvements	O
(	O
24.7	O
vs.	O
29.7	O
)	O
.	O

In	O
this	O
work	O
,	O
we	O
focus	O
on	O
self	O
-	O
supervised	O
,	O
alignment	O
-	O
oriented	O
training	O
tasks	O
using	O
minimum	O
parallel	O
data	O
to	O
improve	O
mBERT	B-MethodName
's	O
cross	O
-	O
lingual	O
transferability	O
.	O
We	O
propose	O
a	O
Post	O
-	I-MethodName
Pretraining	I-MethodName
Alignment	I-MethodName
(	O
PPA	O
)	O
method	O
consisting	O
of	O
both	O
wordlevel	O
and	O
sentence	O
-	O
level	O
alignment	O
,	O
as	O
well	O
as	O
a	O
finetuning	O
technique	O
on	O
downstream	O
tasks	O
that	O
take	O
pairs	O
of	O
text	O
as	O
input	O
,	O
such	O
as	O
NLI	O
and	O
Question	O
Answering	O
(	O
QA	O
)	O
.	O
Specifically	O
,	O
we	O
use	O
a	O
slightly	O
different	O
version	O
of	O
TLM	B-MethodName
as	O
our	O
word	O
-	O
level	O
alignment	O
task	O
and	O
contrastive	O
learning	O
(	O
Hadsell	O
et	O
al	O
.	O
,	O
2006	O
)	O
on	O
mBERT	B-MethodName
's	O
[	O
CLS	O
]	O
tokens	O
to	O
align	O
sentence	O
-	O
level	O
representations	O
.	O
Both	O
tasks	O
are	O
self	O
-	O
supervised	O
and	O
do	O
not	O
require	O
pre	O
-	O
alignment	O
tools	O
such	O
as	O
FastAlign	O
.	O
Our	O
sentence	O
-	O
level	O
alignment	O
is	O
implemented	O
using	O
MoCo	O
(	O
He	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
an	O
instance	O
discrimination	O
-	O
based	O
method	O
of	O
contrastive	O
learn-	O
ing	O
that	O
was	O
recently	O
proposed	O
for	O
self	O
-	O
supervised	O
representation	O
learning	O
in	O
computer	O
vision	O
.	O
Lastly	O
,	O
when	O
finetuning	O
on	O
NLI	O
and	O
QA	O
tasks	O
for	O
non	O
-	O
English	O
languages	O
,	O
we	O
perform	O
sentence	O
-	O
level	O
codeswitching	O
with	O
English	O
as	O
a	O
form	O
of	O
both	O
alignment	O
and	O
data	O
augmentation	O
.	O
We	O
conduct	O
controlled	O
experiments	O
on	O
XNLI	B-MethodName
and	O
MLQA	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
leveraging	O
varying	O
amounts	O
of	O
parallel	O
data	O
during	O
alignment	O
.	O
We	O
then	O
conduct	O
an	O
ablation	O
study	O
that	O
shows	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
On	O
XNLI	O
,	O
our	O
aligned	O
mBERT	B-MethodName
improves	O
over	O
the	O
original	O
mBERT	B-MethodName
by	O
4.7	O
%	O
for	O
zero	O
-	O
shot	O
transfer	O
,	O
and	O
outperforms	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
while	O
using	O
the	O
same	O
amount	O
of	O
parallel	O
data	O
from	O
the	O
same	O
source	O
.	O
For	O
translate	O
-	O
train	O
,	O
where	O
translation	O
of	O
English	O
training	O
data	O
is	O
available	O
in	O
the	O
target	O
language	O
,	O
our	O
model	O
achieves	O
comparable	O
performance	O
to	O
XLM	O
while	O
using	O
far	O
fewer	O
resources	O
.	O
On	O
MLQA	O
,	O
we	O
get	O
2.3	O
%	O
improvement	O
over	O
mBERT	O
and	O
outperform	O
XLM	O
-	O
R	O
Base	O
for	O
zero	O
-	O
shot	O
transfer	O
.	O

COMET	O
leverages	O
contextual	O
word	O
embeddings	O
of	O
the	O
source	O
sentence	O
,	O
MT	O
hypothesis	O
,	O
and	O
reference	O
(	O
or	O
human	O
post	O
-	O
edition	O
)	O
extracted	O
from	O
pretrained	O
cross	O
-	O
lingual	O
models	O
.	O
The	O
embeddings	O
are	O
combined	O
and	O
fed	O
into	O
a	O
feed	O
-	O
forward	O
network	O
.	O
It	O
's	O
a	O
quality	O
estimation	O
system	O
and	O
is	O
trained	O
with	O
human	O
assessments	O
(	O
DA	O
,	O
HTER	O
,	O
MQM	O
)	O
.	O

The	O
values	O
displayed	O
diagonally	O
across	O
section	O
I	O
of	O
Table	O
2	O
show	O
the	O
results	O
for	O
supervised	O
,	O
bilingual	O
,	O
word	O
-	O
level	O
QE	O
models	O
where	O
the	O
model	O
was	O
trained	O
on	O
the	O
training	O
set	O
of	O
a	O
particular	O
language	O
pair	O
and	O
tested	O
on	O
the	O
test	O
set	O
of	O
the	O
same	O
language	O
pair	O
.	O
As	O
can	O
be	O
seen	O
in	O
section	O
V	O
,	O
the	O
architecture	O
outperforms	O
the	O
baselines	O
in	O
all	O
the	O
language	O
pairs	O
and	O
also	O
outperforms	O
the	O
majority	O
of	O
the	O
best	O
systems	O
from	O
previous	O
competitions	O
.	O
In	O
addition	O
to	O
the	O
target	O
word	O
F1	O
-	O
score	O
,	O
our	O
architecture	O
outperforms	O
the	O
baselines	O
and	O
best	O
systems	O
in	O
target	O
gaps	O
F1	O
-	O
score	O
and	O
source	O
words	O
F1	O
-	O
score	O
too	O
as	O
shown	O
in	O
Tables	O
5	O
and	O
6	O
.	O
In	O
the	O
following	O
sections	O
we	O
explore	O
its	O
behaviour	O
in	O
different	O
multilingual	O
settings	O
.	O

We	O
construct	O
the	O
dataset	O
in	O
two	O
steps	O
:	O
collecting	O
3,158	O
English	O
tables	O
and	O
then	O
manually	O
translating	O
the	O
schema	O
of	O
English	O
tables	O
to	O
other	O
languages	O
.	O
(	O
Pasupat	O
and	O
Liang	O
,	O
2015	O
)	O
,	O
in	O
which	O
they	O
randomly	O
select	O
2,108	O
multidomain	O
data	O
tables	O
in	O
English	O
from	O
Wikipedia	O
with	O
at	O
least	O
eight	O
rows	O
and	O
five	O
columns	O
.	O
Secondly	O
,	O
we	O
manually	O
collect	O
176	O
English	O
tables	O
from	O
the	O
search	O
engine	O
covering	O
multiple	O
domains	O
like	O
retail	O
,	O
education	O
,	O
and	O
government	O
.	O
At	O
last	O
,	O
we	O
select	O
all	O
the	O
tables	O
that	O
appear	O
in	O
the	O
training	O
set	O
and	O
development	O
set	O
from	O
the	O
Spider	O
dataset	O
(	O
Yu	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
which	O
contains	O
200	O
databases	O
covering	O
138	O
different	O
domains	O
.	O
Finally	O
,	O
we	O
obtained	O
3,158	O
tables	O
with	O
11,979	O
headers	O
in	O
total	O
.	O

Hypothesis	O
:	O
The	O
air	O
tasted	O
through	O
boiling	O
armor	O
-the	O
taste	O
of	O
betrayal	O
.	O

In	O
the	O
zero	O
-	O
shot	O
setting	O
,	O
removing	O
MoCo	B-MethodName
(	O
-MoCo	O
)	O
performs	O
similarly	O
to	O
-TLM	O
,	O
where	O
we	O
observe	O
an	O
accuracy	O
drop	O
of	O
about	O
1	O
%	O
compared	O
to	O
our	O
full	O
system	O
.	O
In	O
translate	O
-	O
train	O
,	O
-MoCo	O
outperforms	O
-TLM	O
and	O
even	O
matches	O
the	O
full	O
system	O
performance	O
for	O
250k	O
.	O

All	O
our	O
experiments	O
were	O
carried	O
out	O
on	O
a	O
single	O
server	O
with	O
one	O
NVIDIA	O
Quadro	O
GP100	O
GPU	O
.	O
The	O
total	O
computation	O
time	O
for	O
generating	O
and	O
scoring	O
translations	O
was	O
less	O
than	O
24	O
hours	O
.	O

As	O
the	O
GLUE	O
benchmark	O
results	O
indicate	O
(	O
Table	O
6	O
)	O
,	O
MABEL	O
preserves	O
semantic	O
knowledge	O
across	O
downstream	O
tasks	O
.	O
On	O
average	O
,	O
MABEL	B-MethodName
performs	O
marginally	O
better	O
than	O
BERT	B-MethodName
(	O
82.0	O
%	I-MetricValue
vs.	O
81.8	O
%	O
)	O
,	O
but	O
not	O
as	O
well	O
as	O
BERT	B-MethodName
fine	O
-	O
tuned	O
beforehand	O
on	O
the	O
NLI	O
task	O
with	O
MNLI	O
and	O
SNLI	O
data	O
(	O
BERT	B-MethodName
-	O
NLI	O
)	O
,	O
at	O
82.0	O
%	O
vs.	O
82.1	O
%	O
.	O
Other	O
bias	O
mitigation	O
baselines	O
lag	O
behind	O
BERT	B-MethodName
,	O
but	O
the	O
overall	O
semantic	O
deterioration	O
remains	O
minimal	O
.	O

Local	O
ED	O
Model	O
.	O
Our	O
local	O
ED	O
model	O
takes	O
words	O
and	O
N	O
[	O
MASK	O
]	O
tokens	O
corresponding	O
to	O
the	O
mentions	O
in	O
the	O
document	O
.	O
The	O
model	O
then	O
computes	O
the	O
embedding	O
m	O
′	O
e	O
∈	O
R	O
H	O
for	O
each	O
[	O
MASK	O
]	O
token	O
using	O
Eq.(2	O
)	O
and	O
predicts	O
the	O
entity	O
using	O
softmax	O
over	O
the	O
K	O
entity	O
candidates	O
:	O

Our	O
held	O
-	O
out	O
test	O
bed	O
is	O
the	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
2010	O
data	O
(	O
LDC2018T16	B-DatasetName
)	O
which	O
consists	O
of	O
documents	O
from	O
English	O
newswire	O
,	O
discussion	O
forum	O
and	O
web	O
data	O
(	O
Ji	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
4	O
The	O
target	O
KB	O
(	O
KB	O
test	O
)	O
is	O
the	O
TAC	B-MethodName
-	I-MethodName
KBP	I-MethodName
Reference	O
KB	O
and	O
is	O
built	O
from	O
English	O
Wikipedia	O
articles	O
and	O
their	O
associated	O
infoboxes	O
(	O
LDC2014T16	B-DatasetName
)	O
.	O
5	O
Our	O
primary	O
training	O
and	O
validation	O
data	O
is	O
the	O
CoNLL	B-DatasetName
-	I-DatasetName
YAGO	I-DatasetName
dataset	O
(	O
Hoffart	O
et	O
al	O
.	O
,	O
2011	O
)	O
Table	O
2	O
describes	O
the	O
sizes	O
of	O
these	O
various	O
datasets	O
along	O
with	O
the	O
number	O
of	O
entities	O
in	O
their	O
respective	O
KBs	O
.	O

We	O
split	O
our	O
gold	O
standard	O
data	O
set	O
into	O
roughly	O
70	O
%	O
for	O
training	O
,	O
15	O
%	O
for	O
development	O
and	O
15	O
%	O
for	O
testing	O
.	O
We	O
also	O
made	O
sure	O
that	O
the	O
objects	O
in	O
the	O
test	O
set	O
do	O
not	O
appear	O
in	O
the	O
training	O
set	O
.	O
Our	O
fine	O
-	O
tuning	O
framework	O
is	O
based	O
on	O
the	O
RoBERTabase	O
model	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
For	O
the	O
hyperparameters	O
,	O
we	O
used	O
a	O
max	O
sequence	O
length	O
of	O
192	O
,	O
a	O
batch	O
size	O
of	O
8	O
,	O
learning	O
rate	O
initialized	O
as	O
2e-5	O
,	O
and	O
train	O
for	O
15	O
epochs	O
.	O
Each	O
result	O
is	O
averaged	O
over	O
three	O
runs	O
with	O
different	O
random	O
seeds	O
.	O
We	O
report	O
overall	O
accuracy	O
as	O
well	O
as	O
precision	O
,	O
recall	O
and	O
F1	O
scores	O
macro	O
-	O
averaged	O
over	O
the	O
3	O
classes	O
.	O

We	O
report	O
the	O
macro	O
-	O
averaged	O
recall	O
(	O
R	O
)	O
,	O
mean	O
reciprocal	O
rank	O
(	O
MRR	O
)	O
,	O
and	O
mean	O
average	O
precision	O
(	O
MAP	O
)	O
,	O
which	O
are	O
the	O
average	O
values	O
of	O
the	O
corresponding	O
metrics	O
over	O
a	O
set	O
of	O
n	O
queries	O
.	O
Note	O
that	O
as	O
those	O
metrics	O
are	O
computed	O
for	O
a	O
filter	O
set	O
of	O
size	O
k	O
=	O
|F	O
q	O
|	O
≪	O
|C|	O
(	O
and	O
not	O
on	O
the	O
entire	O
list	O
of	O
articles	O
in	O
C	O
)	O
,	O
we	O
report	O
them	O
with	O
the	O
suffix	O
"	O
@	O
k	O
"	O
.	O

•	O
MNLI	O
:	O
Multi	O
-	O
genre	O
Natural	O
Language	O
Inference	O
(	O
Williams	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Given	O
a	O
premise	O
sentence	O
and	O
a	O
hypothesis	O
sentence	O
,	O
the	O
task	O
is	O
to	O
predict	O
whether	O
the	O
premise	O
entails	O
the	O
hypothesis	O
,	O
contradicts	O
the	O
hypothesis	O
,	O
or	O
neither	O
.	O
The	O
dataset	O
contains	O
393k	O
train	O
examples	O
drawn	O
from	O
ten	O
different	O
sources	O
.	O
using	O
dev	O
-	O
set	O
model	O
selection	O
to	O
choose	O
the	O
test	O
set	O
submission	O
may	O
alleviate	O
the	O
high	O
variance	O
of	O
fine	O
-	O
tuning	O
to	O
some	O
extent	O
,	O
such	O
model	O
selection	O
is	O
still	O
not	O
sufficient	O
for	O
reliable	O
comparisons	O
between	O
methods	O
(	O
Reimers	O
and	O
Gurevych	O
,	O
2018	O
)	O
.	O

we	O
can	O
only	O
use	O
the	O
ability	O
to	O
use	O
electronic	O
products	O
without	O
game	O
function	O
.	O

Caption	O
:	O
Son	O
,	O
we	O
finally	O
attracted	O
the	O
fifty	O
-	O
foot	O
-	O
and	O
-	O
over	O
demographic	O
!	O
Both	O
bad	O
:	O
The	O
humanauthored	O
explanation	O
misses	O
the	O
direct	O
reference	O
to	O
the	O
movie	O
"	O
Attack	O
of	O
the	O
50	O
-	O
Foot	O
-	O
Woman	O
"	O
(	O
1958	O
)	O
,	O
and	O
the	O
machine	O
focuses	O
on	O
non	O
-	O
sequiturs	O
like	O
age	O
18	O
/	O
viewers	O
/	O
etc	O
.	O

The	O
similarity	O
metrics	O
used	O
in	O
our	O
experiments	O
are	O
L	O
2	O
and	O
cos	O
.	O
For	O
the	O
sake	O
of	O
convenience	O
,	O
in	O
the	O
following	O
text	O
,	O
we	O
abbreviate	O
cos	O
and	O
L	O
2	O
square	O
similarity	O
invariance	O
as	O
similarity	O
invariance	O
.	O

A	O
substitution	O
cipher	O
is	O
a	O
cipher	O
that	O
is	O
created	O
by	O
substituting	O
each	O
plaintext	O
character	O
with	O
another	O
character	O
according	O
to	O
a	O
substitution	O
table	O
called	O
the	O
key	O
.	O
We	O
define	O
major	O
terms	O
in	O
the	O
following	O
subsections	O
.	O

Furthermore	O
,	O
the	O
most	O
robust	O
setting	O
agrees	O
with	O
the	O
form	O
of	O
MLS	O
since	O
they	O
both	O
allocate	O
zero	O
probability	O
to	O
the	O
source	O
category	O
's	O
tokens	O
,	O
which	O
further	O
proves	O
the	O
robustness	O
of	O
MLS	O
.	O
in	O
each	O
bin	O
.	O

Training	O
Document	O
Generation	I-TaskName
We	O
create	O
the	O
final	O
training	O
documents	O
for	O
the	O
argument	O
generation	O
model	O
by	O
concatenating	O
all	O
arguments	O
that	O
have	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
(	O
i.e.	O
the	O
same	O
control	O
code	O
)	O
.	O
Further	O
,	O
we	O
aggregate	O
all	O
arguments	O
that	O
include	O
an	O
aspect	O
with	O
the	O
same	O
stem	O
into	O
the	O
same	O
document	O
(	O
e.g.	O
arguments	O
with	O
cost	O
and	O
costs	O
as	O
aspect	O
)	O
.	O
To	O
cope	O
with	O
limited	O
hardware	O
resources	O
,	O
we	O
restrict	O
the	O
total	O
number	O
of	O
arguments	O
for	O
each	O
topic	O
and	O
stance	O
to	O
100,000	O
(	O
i.e.	O
1.6	O
M	O
over	O
all	O
eight	O
topics	O
)	O
.	O
Also	O
,	O
as	O
some	O
aspects	O
dominate	O
by	O
means	O
of	O
quantity	O
of	O
related	O
arguments	O
and	O
others	O
appear	O
only	O
rarely	O
,	O
we	O
empirically	O
determine	O
an	O
upper	O
and	O
lower	O
bound	O
of	O
1,500	O
and	O
15	O
arguments	O
for	O
each	O
document	O
,	O
which	O
still	O
allows	O
us	O
to	O
retrieve	O
the	O
above	O
defined	O
amount	O
of	O
training	O
arguments	O
.	O

We	O
introduce	O
the	O
XM3600	B-DatasetName
dataset	O
as	O
a	O
benchmark	O
for	O
evaluating	O
the	O
performance	O
of	O
multilingual	O
image	O
captioning	O
models	O
.	O
The	O
images	O
in	O
the	O
dataset	O
are	O
geographically	O
diverse	O
,	O
covering	O
all	O
inhabited	O
continents	O
and	O
a	O
large	O
fraction	O
of	O
the	O
world	O
population	O
.	O
We	O
believe	O
this	O
benchmark	O
has	O
the	O
potential	O
to	O
positively	O
impact	O
both	O
the	O
research	O
and	O
the	O
applications	O
of	O
this	O
technology	O
,	O
and	O
enable	O
(	O
among	O
other	O
things	O
)	O
better	O
accessibility	O
for	O
visually	O
-	O
impaired	O
users	O
across	O
the	O
world	O
,	O
including	O
speakers	O
of	O
lowresource	O
languages	O
.	O

1	O
.	O
The	O
input	O
-	O
label	O
mapping	O
,	O
i.e.	O
,	O
whether	O
each	O
input	O
x	O
i	O
is	O
paired	O
with	O
a	O
correct	O
label	O
y	O
i	O
.	O

•	O
MULTIVERS	O
(	O
Wadden	O
et	O
al	O
.	O
,	O
2022b	O
)	O
,	O
formerly	O
known	O
as	O
LongChecker	B-MethodName
,	O
uses	O
the	O
Long	O
-	O
Former	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2020	O
)	O
for	O
claim	O
verification	O
to	O
address	O
the	O
long	O
input	O
evidence	O
problem	O
.	O
We	O
use	O
a	O
model	O
checkpoint	O
finetuned	O
on	O
FEVER	O
.	O
6	O

In	O
OR	O
-	I-MethodName
QuAC	I-MethodName
,	O
we	O
compare	O
our	O
models	O
with	O
previously	O
proposed	O
dense	O
retrieval	O
approaches	O
in	O
conversational	O
search	O
,	O
CQE	B-MethodName
(	O
Lin	O
et	O
al	O
.	O
,	O
2021b	O
)	O
and	O
ConvDR	B-MethodName
(	O
Yu	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Both	O
of	O
them	O
utilize	O
the	O
standalone	O
question	O
q	O
′	O
t	O
to	O
mine	O
hard	O
negatives	O
and	O
knowledge	O
distillation	O
from	O
off	O
-	O
the	O
-	O
shelf	O
retrievers	O
trained	O
on	O
ODQA	O
,	O
regarding	O
it	O
as	O
a	O
teacher	O
model	O
.	O
Although	O
they	O
were	O
not	O
tested	O
on	O
QReCC	B-MethodName
,	O
we	O
can	O
indirectly	O
compare	O
them	O
with	O
others	O
using	O
DPR	O
with	O
CQR	O
Negs	O
instead	O
.	O

Our	O
architecture	O
relies	O
on	O
the	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
transformer	O
model	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
to	O
derive	O
the	O
representations	O
of	O
the	O
input	O
sentences	O
.	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
has	O
been	O
trained	O
on	O
a	O
large	O
-	O
scale	O
multilingual	O
dataset	O
in	O
104	O
languages	O
,	O
totalling	O
2.5	O
TB	O
,	O
extracted	O
from	O
the	O
CommonCrawl	O
datasets	O
.	O
It	O
is	O
trained	O
using	O
only	O
RoBERTa	O
's	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
masked	O
language	O
modelling	O
(	O
MLM	O
)	O
objective	O
.	O
XML	O
-	O
R	O
was	O
used	O
by	O
the	O
winning	O
systems	O
in	O
the	O
recent	O
WMT	B-DatasetName
2020	O
shared	O
task	O
on	O
sentence	O
-	O
level	O
QE	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020a;Lee	O
,	O
2020	O
;	O
.	O
This	O
motivated	O
us	O
to	O
use	O
a	O
similar	O
approach	O
for	O
wordlevel	O
QE	O
.	O

Machine	O
translation	O
evaluation	O
has	O
conventionally	O
relied	O
on	O
reference	O
,	O
where	O
outputs	O
are	O
compared	O
against	O
translations	O
written	O
by	O
humans	O
.	O
This	O
is	O
in	O
contrast	O
to	O
the	O
reference	O
-	O
free	O
manner	O
in	O
which	O
translation	O
quality	O
is	O
directly	O
assessed	O
with	O
the	O
source	O
text	O
.	O
Reference	O
-	O
free	O
evaluation	O
(	O
Napoles	O
et	O
al	O
.	O
,	O
2016;Thompson	O
and	O
Post	O
,	O
2020;Agrawal	O
et	O
al	O
.	O
,	O
2021	O
)	O
has	O
the	O
potential	O
to	O
free	O
the	O
evaluation	O
model	O
from	O
the	O
constraints	O
of	O
labor	O
-	O
intensive	O
annotations	O
,	O
allowing	O
it	O
to	O
pivot	O
easily	O
to	O
new	O
domains	O
.	O
In	O
this	O
way	O
,	O
reference	O
-	O
free	O
evaluation	O
metrics	O
are	O
substantially	O
more	O
scalable	O
and	O
have	O
lately	O
been	O
in	O
the	O
spotlight	O
.	O

Then	O
,	O
we	O
define	O
three	O
sorts	O
of	O
entity	O
types	O
to	O
distinguish	O
the	O
target	O
header	O
from	O
its	O
context	O
.	O
Specifically	O
,	O
for	O
a	O
token	O
in	O
the	O
target	O
header	O
,	O
we	O
assign	O
a	O
special	O
edge	O
Target	O
point	O
to	O
itself	O
,	O
denoting	O
the	O
entity	O
type	O
.	O
For	O
tokens	O
in	O
S	O
and	O
V	O
,	O
we	O
assign	O
them	O
different	O
edges	O
point	O
to	O
themselves	O
,	O
e.g.	O
,	O
Header	O
,	O
and	O
Value	O
respectively	O
.	O
Figure	O
2	O
illustrates	O
an	O
example	O
graph	O
(	O
with	O
actual	O
edges	O
and	O
labels	O
)	O
and	O
its	O
induced	O
relational	O
matrix	O
R.	O
Initial	O
Token	O
Embedding	O
.	O
We	O
obtain	O
the	O
initial	O
token	O
embedding	O
by	O
a	O
pre	O
-	O
trained	O
transformer	O
encoder	O
before	O
feeding	O
it	O
to	O
the	O
ration	O
-	O
aware	O
transformer	O
.	O
To	O
obtain	O
the	O
input	O
sequence	O
,	O
each	O
element	O
in	O
S	O
and	O
V	O
are	O
firstly	O
concatenated	O
with	O
a	O
vertical	O
bar	O
"	O
|	O
"	O
.	O
Then	O
,	O
the	O
target	O
header	O
H	O
,	O
the	O
rest	O
of	O
the	O
headers	O
S	O
,	O
and	O
the	O
selected	O
cell	O
values	O
V	O
are	O
concatenated	O
by	O
a	O
separator	O
symbol	O
"	O
[	O
sep	O
]	O
"	O
.	O
At	O
last	O
,	O
following	O
,	O
an	O
additional	O
source	O
language	O
token	O
"	O
hsrci	O
"	O
is	O
added	O
at	O
the	O
front	O
to	O
help	O
the	O
pretrained	O
model	O
identify	O
the	O
source	O
language	O
.	O
The	O
encoder	O
then	O
transforms	O
the	O
final	O
input	O
sequence	O
into	O
a	O
sequence	O
of	O
embedding	O

Drafting	O
counter	O
-	O
arguments	O
is	O
an	O
important	O
skill	O
for	O
debating	O
,	O
to	O
provide	O
constructive	O
feedback	O
,	O
and	O
to	O
foster	O
critical	O
thinking	O
.	O
We	O
lean	O
onto	O
the	O
work	O
of	O
Wachsmuth	O
et	O
al	O
.	O
(	O
2018	O
)	O
who	O
describe	O
a	O
counterargument	O
as	O
discussing	O
the	O
same	O
aspect	O
as	O
an	O
initial	O
argument	O
,	O
but	O
with	O
a	O
switched	O
stance	O
.	O
Hence	O
,	O
given	O
our	O
defined	O
control	O
codes	O
,	O
our	O
model	O
is	O
especially	O
fit	O
for	O
counter	O
-	O
argument	O
generation	O
.	O
Unlike	O
current	O
models	O
for	O
this	O
task	O
,	O
we	O
do	O
not	O
require	O
a	O
specific	O
dataset	O
with	O
argument	O
and	O
counterargument	O
pairs	O
(	O
Hidey	O
and	O
McKeown	O
,	O
2019	O
;	O
.	O
Also	O
,	O
in	O
contrast	O
to	O
the	O
model	O
by	O
that	O
implicitly	O
integrates	O
inputrelated	O
"	O
Keyphrases	O
"	O
into	O
the	O
process	O
of	O
counterargument	O
generation	O
,	O
our	O
model	O
is	O
able	O
to	O
concentrate	O
on	O
every	O
aspect	O
of	O
the	O
input	O
explicitly	O
and	O
with	O
a	O
separate	O
argument	O
,	O
allowing	O
for	O
more	O
transparency	O
and	O
interpretability	O
over	O
the	O
process	O
of	O
counter	O
-	O
argument	O
generation	O
.	O
We	O
exemplary	O
show	O
how	O
the	O
combination	O
of	O
aspect	O
detection	O
and	O
controlled	O
argument	O
generation	O
can	O
be	O
successfully	O
leveraged	O
to	O
tackle	O
this	O
task	O
.	O
For	O
that	O
,	O
we	O
manually	O
compose	O
initial	O
arguments	O
for	O
the	O
topics	O
nuclear	O
energy	O
and	O
school	O
uniforms	O
.	O
Then	O
,	O
we	O
automatically	O
detect	O
their	O
aspects	O
and	O
generate	O
a	O
counterargument	O
for	O
each	O
aspect	O
by	O
passing	O
the	O
topic	O
,	O
opposite	O
stance	O
of	O
the	O
original	O
argument	O
,	O
and	O
one	O
of	O
the	O
aspects	O
into	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
CC	I-MethodName
.	O
For	O
both	O
topics	O
,	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
CC	I-MethodName
produces	O
meaningful	O
counterarguments	O
based	O
on	O
the	O
detected	O
aspects	O
(	O
see	O
Table	O
7	O
)	O
.	O

where	O
y	O
j	O
denotes	O
the	O
jth	O
token	O
of	O
the	O
generated	O
output	O
y	O
and	O
T	O
is	O
the	O
length	O
of	O
the	O
final	O
output	O
.	O
The	O
generator	O
is	O
based	O
on	O
the	O
T5	B-MethodName
architecture	O
and	O
uses	O
cross	O
attentions	O
to	O
model	O
the	O
interactions	O
between	O
retrieved	O
passages	O
.	O

Finally	O
,	O
we	O
also	O
conduct	O
human	O
studies	O
to	O
compare	O
summaries	O
of	O
GPT-3	B-MethodName
w	O
/	O
o	O
and	O
w	O
/	O
SumCoT.	B-MethodName
Results	O
(	O
as	O
shown	O
in	O
Table	O
6	O
)	O
indicate	O
that	O
the	O
Sum	O
-	O
CoT	O
technique	O
further	O
improves	O
the	O
performance	O
of	O
the	O
standard	O
zero	O
-	O
shot	O
paradigm	O
in	O
all	O
dimensions	O
,	O
particularly	O
coherence	O
and	O
relevance	O
.	O

We	O
conducted	O
experiments	O
on	O
Quora	B-MethodName
1	O
,	O
Twitter	O
(	O
Lan	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
MSCOCO	B-DatasetName
(	O
Lin	O
et	O
al	O
.	O
,	O
2014	O
)	O
benchmark	O
datasets	O
,	O
and	O
followed	O
the	O
same	O
setting	O
in	O
previous	O
works	O
(	O
Lin	O
et	O
al	O
.	O
,	O
2014	O
;	O
Liu	O
et	O
al	O
.	O
,	O
2020	O
;	O
Ding	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
For	O
meta	O
-	O
learning	O
,	O
we	O
choose	O
a	O
different	O
source	O
task	O
's	O
labeld	O
train	O
-	O
set	O
from	O
the	O
target	O
task	O
to	O
randomly	O
construct	O
meta	O
tasks	O
.	O
Appendix	O
Table	O
4	O
describes	O
more	O
details	O
.	O

For	O
each	O
of	O
these	O
466	O
target	O
words	O
,	O
we	O
also	O
obtain	O
a	O
list	O
of	O
words	O
from	O
WordNet	O
,	O
which	O
are	O
1	O
Levenshtein	O
distance	O
away	O
.	O
We	O
treat	O
this	O
word	O
list	O
as	O
the	O
pseudo	O
-	O
match	O
list	O
.	O
We	O
also	O
consider	O
the	O
number	O
of	O
tokenizations	O
for	O
each	O
target	O
word	O
,	O
excluding	O
their	O
pseudo	O
-	O
match	O
list	O
as	O
well	O
as	O
by	O
excluding	O
all	O
those	O
which	O
are	O
equally	O
close	O
to	O
or	O
closer	O
to	O
a	O
word	O
in	O
the	O
pseudo	O
-	O
match	O
list	O
than	O
they	O
are	O
to	O
the	O
target	O
word	O
.	O
We	O
also	O
compute	O
the	O
statistics	O
of	O
those	O
with	O
exact	O
matches	O
.	O

A	O
simple	O
yet	O
effective	O
stateless	O
scoring	O
function	O
as	O
an	O
alternative	O
to	O
more	O
complicated	O
length	O
-	O
adjusted	O
counterparts	O
is	O
devised	O
,	O
and	O
we	O
show	O
that	O
it	O
works	O
well	O
and	O
helps	O
further	O
in	O
finding	O
diverse	O
texts	O
.	O

We	O
thank	O
Tilman	O
Beck	O
and	O
Nandan	O
Thakur	O
for	O
their	O
support	O
in	O
the	O
human	O
evaluation	O
(	O
Section	O
7.1	O
)	O
.	O
This	O
work	O
has	O
been	O
supported	O
by	O
the	O
German	O
Research	O
Foundation	O
within	O
the	O
project	O
"	O
Open	O
Argument	O
Mining	O
"	O
(	O
GU	O
798/25	O
-	O
1	O
)	O
,	O
associated	O
with	O
the	O
Priority	O
Program	O
"	O
Robust	O
Argumentation	O
Machines	O
(	O
RATIO	O
)	O
"	O
(	O
SPP-1999	O
)	O
.	O

•	O
SST	O
:	O
Stanford	O
Sentiment	O
Treebank	O
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
.	O
The	O
tasks	O
is	O
to	O
determine	O
if	O
the	O
sentence	O
is	O
positive	O
or	O
negative	O
in	O
sentiment	O
.	O

Given	O
the	O
source	O
src	O
and	O
target	O
tgt	O
wordpieces	O
encoded	O
as	O
e	O
src	O
and	O
e	O
tgt	O
,	O
our	O
goal	O
is	O
to	O
predict	O
the	O
label	O
y.	O

1	O
.	O
Candidate	O
generation	O
:	O
The	O
objective	O
of	O
this	O
stage	O
is	O
to	O
select	O
K	O
candidate	O
entities	O
E	O
⊂	O
KB	O
for	O
each	O
mention	O
m	O
∈	O
M	O
,	O
where	O
K	O
is	O
a	O
hyperparameter	O
and	O
K	O
<	O
<	O
|KB|	O
.	O

To	O
test	O
whether	O
a	O
QE	O
model	O
trained	O
on	O
a	O
particular	O
language	O
pair	O
can	O
be	O
generalised	O
to	O
other	O
language	O
pairs	O
,	O
different	O
domains	O
and	O
MT	O
types	O
,	O
we	O
performed	O
zero	O
-	O
shot	O
quality	O
estimation	O
.	O
We	O
used	O
the	O
QE	O
model	O
trained	O
on	O
a	O
particular	O
language	O
pair	O
and	O
evaluated	O
it	O
on	O
the	O
test	O
sets	O
of	O
the	O
other	O
language	O
pairs	O
.	O
Non	O
-	O
diagonal	O
values	O
of	O
section	O
I	O
in	O
Table	O
2	O
show	O
how	O
each	O
QE	O
model	O
performed	O
on	O
other	O
language	O
pairs	O
.	O
For	O
better	O
visualisation	O
,	O
the	O
nondiagonal	O
values	O
of	O
section	O
I	O
of	O
Table	O
2	O
show	O
by	O
how	O
much	O
the	O
score	O
changes	O
when	O
the	O
zero	O
-	O
shot	O
QE	O
model	O
is	O
used	O
instead	O
of	O
the	O
bilingual	O
QE	O
model	O
.	O
As	O
can	O
be	O
seen	O
,	O
the	O
scores	O
decrease	O
,	O
but	O
this	O
decrease	O
is	O
negligible	O
and	O
is	O
to	O
be	O
expected	O
.	O
For	O
most	O
pairs	O
,	O
the	O
QE	O
model	O
that	O
did	O
not	O
see	O
any	O
training	O
instances	O
of	O
that	O
particular	O
language	O
pair	O
outperforms	O
the	O
baselines	O
that	O
were	O
trained	O
extensively	O
on	O
that	O
particular	O
language	O
pair	O
.	O
Further	O
analysing	O
the	O
results	O
,	O
we	O
can	O
see	O
that	O
zero	O
-	O
shot	O
QE	O
performs	O
better	O
when	O
the	O
language	O
pair	O
shares	O
some	O
properties	O
such	O
as	O
domain	O
,	O
MT	O
type	O
or	O
language	O
direction	O
.	O
For	O
example	O
,	O
En	O
-	O
De	O
SMT	O
⇒	O
En	O
-	O
Cs	O
SMT	O
is	O
better	O
than	O
En	O
-	O
De	O
NMT	O
⇒	O
En	O
-	O
Cs	O
SMT	O
and	O
En	O
-	O
De	O
SMT	O
⇒	O
En	O
-	O
De	O
NMT	O
is	O
better	O
than	O
En	O
-	O
Cs	O
SMT	O
⇒	O
En	O
-	O
De	O
NMT	O
.	O

Although	O
compression	O
has	O
the	O
ability	O
to	O
identify	O
bias	O
in	O
most	O
cases	O
,	O
some	O
metrics	O
still	O
show	O
little	O
or	O
no	O
correlation	O
with	O
compression	O
rate	O
.	O
These	O
results	O
suggest	O
that	O
gender	O
information	O
comprises	O
only	O
one	O
facet	O
of	O
embedded	O
bias	O
in	O
the	O
representations	O
.	O
Other	O
factors	O
that	O
may	O
influence	O
these	O
metrics	O
are	O
not	O
considered	O
or	O
measured	O
,	O
such	O
as	O
the	O
connection	O
between	O
a	O
name	O
and	O
a	O
profession	O
.	O

We	O
estimate	O
the	O
importance	O
of	O
each	O
sentence	O
for	O
a	O
specific	O
entity	O
pair	O
.	O
Low	O
-	O
scored	O
sentences	O
will	O
be	O
treated	O
as	O
non	O
-	O
evidence	O
,	O
and	O
in	O
principle	O
,	O
can	O
be	O
removed	O
without	O
changing	O
DocRE	B-MethodName
predictions	O
.	O

The	O
two	O
other	O
selection	O
methods	O
extract	O
sentences	O
from	O
SciQ	O
itself	O
and	O
therefore	O
are	O
not	O
entirely	O
unsupervised	O
but	O
rather	O
simulate	O
a	O
situation	O
where	O
we	O
have	O
access	O
to	O
unannotated	O
texts	O
that	O
precisely	O
describe	O
the	O
domains	O
of	O
interest	O
such	O
as	O
a	O
school	O
book	O
for	O
example	O
.	O
The	O
SciQ	O
dataset	O
includes	O
a	O
support	O
paragraph	O
for	O
each	O
question	O
(	O
see	O
Figure	O
1	O
)	O
.	O
Pooled	O
together	O
,	O
these	O
support	O
paragraphs	O
provide	O
us	O
with	O
a	O
large	O
dataset	O
of	O
texts	O
about	O
the	O
domains	O
of	O
interest	O
.	O
We	O
gather	O
the	O
paragraphs	O
corresponding	O
to	O
all	O
questions	O
and	O
split	O
them	O
into	O
sentences	O
to	O
produce	O
a	O
large	O
set	O
of	O
sentences	O
that	O
are	O
no	O
longer	O
associated	O
with	O
any	O
particular	O
question	O
but	O
cover	O
all	O
the	O
topics	O
found	O
in	O
the	O
questions	O
.	O
We	O
compare	O
two	O
different	O
setups	O
.	O
In	O
the	O
first	O
one	O
,	O
we	O
include	O
all	O
the	O
sentences	O
extracted	O
from	O
the	O
train	O
,	O
validation	O
and	O
test	O
sets	O
thus	O
simulating	O
a	O
perfect	O
selection	O
of	O
sentences	O
that	O
cover	O
all	O
the	O
knowledge	O
expressed	O
in	O
the	O
questions	O
.	O
Still	O
,	O
we	O
only	O
use	O
the	O
support	O
paragraphs	O
and	O
not	O
the	O
annotated	O
questions	O
themselves	O
.	O
As	O
compared	O
to	O
the	O
classical	O
supervised	O
paradigm	O
,	O
this	O
setting	O
removes	O
all	O
annotation	O
costs	O
for	O
the	O
application	O
developer	O
,	O
but	O
it	O
still	O
requires	O
to	O
gather	O
sentences	O
that	O
are	O
deemed	O
useful	O
for	O
the	O
test	O
set	O
of	O
interest	O
.	O
We	O
then	O
compare	O
this	O
setup	O
with	O
another	O
one	O
,	O
where	O
only	O
the	O
sentences	O
from	O
the	O
train	O
set	O
are	O
included	O
.	O
This	O
scenario	O
arguably	O
meets	O
more	O
practical	O
needs	O
since	O
it	O
would	O
suffice	O
to	O
gather	O
sentences	O
close	O
to	O
the	O
domain	O
of	O
interest	O
.	O
The	O
number	O
of	O
sentences	O
for	O
each	O
dataset	O
is	O
presented	O
in	O
Table	O
1	O
.	O

In	O
addition	O
to	O
token	O
-	O
level	O
decoding	O
attention	O
,	O
we	O
propose	O
a	O
graph	O
-	O
selection	O
attention	O
mechanism	O
(	O
GSA	O
)	O
to	O
inform	O
the	O
decoder	O
with	O
learned	O
hierarchical	O
information	O
,	O
while	O
realizing	O
the	O
sentencelevel	O
content	O
selection	O
.	O
In	O
each	O
decoding	O
step	O
t	O
,	O
our	O
decoder	O
first	O
obtains	O
a	O
graph	O
context	O
vector	O
,	O
c	O
t	O
G	O
,	O
which	O
entails	O
the	O
global	O
information	O
of	O
the	O
latent	O
hierarchical	O
graph	O
.	O
We	O
first	O
compute	O
the	O
graph	O
-	O
level	O
attention	O
distribution	O
a	O
t	O
G	O
by	O
,	O

son	O
's	O
r	O
of	O
0.602	O
.	O
This	O
shows	O
that	O
even	O
when	O
using	O
better	O
word	O
presentations	O
,	O
the	O
visual	O
features	O
help	O
to	O
get	O
further	O
(	O
albeit	O
modest	O
)	O
improvements	O
.	O
Table	O
3	O
shows	O
an	O
example	O
of	O
predicted	O
scores	O
at	O
the	O
sentence	O
-	O
level	O
for	O
the	O
baseline	O
model	O
(	O
BiRNN	B-MethodName
)	O
and	O
for	O
the	O
best	O
multimodal	O
BiRNN	B-MethodName
model	O
(	O
BiRNN+Vis	B-MethodName
-	O
embed	O
-	O
mult2	O
)	O
.	O
The	O
multimodal	O
model	O
has	O
predicted	O
a	O
closer	O
score	O
(	O
-0.002	O
)	O
to	O
the	O
gold	O
MQM	O
score	O
(	O
0.167	O
)	O
than	O
the	O
baseline	O
model	O
(	O
-0.248	O
)	O
.	O
The	O
French	O
translation	O
is	O
poor	O
(	O
cumulative	O
-	O
split	O
is	O
,	O
for	O
instance	O
,	O
not	O
translated	O
)	O
as	O
the	O
low	O
gold	O
MQM	O
score	O
shows	O
.	O
However	O
,	O
the	O
(	O
main	O
)	O
word	O
stopwatch	O
is	O
correctly	O
translated	O
as	O
chronomètre	O
in	O
French	O
.	O
Since	O
the	O
associated	O
picture	O
indeed	O
represents	O
a	O
stopwatch	O
,	O
one	O
explanation	O
for	O
this	O
improvement	O
could	O
be	O
that	O
the	O
multimodal	O
model	O
may	O
have	O
rewarded	O
this	O
correct	O
and	O
important	O
part	O
of	O
the	O
translation	O
.	O

In	O
summary	O
,	O
our	O
work	O
contributes	O
to	O
the	O
research	O
on	O
Automated	O
Text	O
Scoring	O
with	O
the	O
following	O
main	O
findings	O
:	O
(	O
i	O
)	O
text	O
spans	O
contained	O
in	O
an	O
answer	O
that	O
increase	O
the	O
answer	O
quality	O
,	O
compared	O
to	O
those	O
decreasing	O
answer	O
quality	O
,	O
are	O
more	O
likely	O
to	O
be	O
identified	O
by	O
human	O
graders	O
;	O
(	O
ii	O
)	O
there	O
exists	O
a	O
certain	O
level	O
of	O
alignment	O
between	O
DL	O
-	O
based	O
graders	O
and	O
human	O
graders	O
regarding	O
the	O
words	O
they	O
think	O
are	O
important	O
in	O
assessing	O
answer	O
quality	O
no	O
matter	O
whether	O
they	O
agree	O
on	O
the	O
quality	O
score	O
of	O
an	O
answer	O
;	O
and	O
(	O
iii	O
)	O
the	O
important	O
words	O
detected	O
by	O
DL	O
-	O
based	O
graders	O
can	O
be	O
potentially	O
used	O
to	O
facilitate	O
human	O
grading	O
,	O
though	O
more	O
research	O
efforts	O
are	O
required	O
to	O
understand	O
how	O
these	O
words	O
are	O
to	O
be	O
utilized	O
by	O
human	O
graders	O
.	O

To	O
ensure	O
the	O
annotation	O
quality	O
,	O
we	O
aggregate	O
annotated	O
results	O
from	O
three	O
students	O
for	O
every	O
dataset	O
using	O
majority	O
vote	O
.	O
If	O
all	O
three	O
students	O
annotate	O
differently	O
from	O
each	O
other	O
for	O
an	O
instance	O
,	O
we	O
introduce	O
a	O
fourth	O
student	O
to	O
arbitrate	O
.	O

Further	O
research	O
on	O
the	O
effect	O
of	O
preprinting	O
on	O
peer	O
review	O
.	O
We	O
find	O
that	O
the	O
preprinted	O
papers	O
have	O
consistently	O
higher	O
ratings	O
(	O
for	O
both	O
Soundness	O
,	O
Excitement	O
,	O
and	O
reviewer	O
confidence	O
)	O
,	O
get	O
more	O
recommendations	O
for	O
awards	O
,	O
and	O
a	O
higher	O
acceptance	O
rate	O
.	O
There	O
are	O
several	O
possible	O
underlying	O
causes	O
(	O
from	O
reviewer	O
biases	O
to	O
higher	O
initial	O
paper	O
quality	O
and	O
benefits	O
of	O
community	O
feedback	O
)	O
,	O
which	O
likely	O
all	O
contribute	O
to	O
this	O
effect	O
.	O
Since	O
these	O
factors	O
necessitate	O
different	O
actions	O
if	O
they	O
were	O
the	O
major	O
contributor	O
to	O
the	O
observed	O
effect	O
,	O
for	O
informed	O
policy	O
decisions	O
it	O
is	O
necessary	O
to	O
establish	O
how	O
they	O
intermix	O
.	O
We	O
observe	O
however	O
that	O
although	O
the	O
present	O
1	O
-	O
month	O
embargo	O
policy	O
does	O
not	O
solve	O
this	O
problem	O
,	O
it	O
is	O
effective	O
at	O
mitigating	O
it	O
,	O
since	O
we	O
only	O
had	O
13.8	O
%	O
such	O
papers	O
.	O

Finally	O
,	O
we	O
perform	O
cross	O
-	O
entropy	O
loss	O
on	O
all	O
query	O
samples	O
.	O
Note	O
that	O
in	O
the	O
multi	O
-	O
label	O
setting	O
,	O
as	O
an	O
utterance	O
may	O
have	O
multiple	O
labels	O
,	O
we	O
need	O
to	O
consider	O
|C|	O
labels	O
for	O
each	O
query	O
sentence	O
.	O
The	O
classification	O
loss	O
is	O
calculated	O
as	O
:	O

Per	O
MedNLI	O
's	O
data	O
use	O
agreement	O
requirements	O
,	O
we	O
do	O
not	O
attempt	O
to	O
identify	O
any	O
patient	O
,	O
provider	O
,	O
or	O
institution	O
mentioned	O
in	O
the	O
de	O
-	O
identified	O
corpus	O
.	O
Additionally	O
,	O
while	O
we	O
provide	O
AFLite	O
easy	O
and	O
difficult	O
partition	O
information	O
for	O
community	O
use	O
in	O
the	O
form	O
of	O
split	O
-	O
example	O
ids	O
and	O
a	O
checksum	O
,	O
we	O
do	O
not	O
share	O
the	O
premise	O
or	O
hypothesis	O
text	O
associated	O
with	O
any	O
example	O
.	O
Interested	O
readers	O
are	O
encouraged	O
to	O
complete	O
the	O
necessary	O
training	O
and	O
obtain	O
credentials	O
so	O
that	O
they	O
can	O
access	O
the	O
complete	O
dataset	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018;Goldberger	O
et	O
al	O
.	O
,	O
2000	O
(	O
June	O
13	O
)	O
.	O

[	O
SPEAKER	O
]	O
's	O
question	O
:	O
[	O
QUESTION	O
]	O
Respond	O
"	O
yes	O
"	O
if	O
answered	O
,	O
"	O
no	O
"	O
otherwise	O
.	O

The	O
record	O
producer	O
that	O
produced	O
the	O
bluegrass	O
album	O
was	O
born	O
on	O
22	O
June	O
,	O
1944	O
.	O
This	O
album	O
inspired	O
a	O
Tony	O
award	O
winning	O
musical	O
.	O
This	O
musical	O
had	O
a	O
character	O
that	O
was	O
originated	O
by	O
Carmen	O
Cusack	O
.	O

Similarly	O
,	O
we	O
use	O
Eq	O
.	O
(	O
3)∼	O
(	O
5	O
)	O
to	O
calculate	O
multiple	O
heads	O
of	O
SANs	O
.	O

The	O
court	O
held	O
that	O
the	O
defendant	O
A	O
made	O
up	O
facts	O
,	O
concealed	O
the	O
truth	O
and	O
defrauded	O
others	O
'	O
property	O
for	O
the	O
purpose	O
of	O
illegal	O
possession	O
.	O
The	O
amount	O
was	O
large	O
,	O
and	O
his	O
behavior	O
constituted	O
the	O
crime	O
of	O
fraud	O
.	O

NLI	O
(	O
Falke	O
et	O
al	O
.	O
,	O
2019	O
)	O
is	O
an	O
entailment	O
-	O
based	O
method	O
which	O
takes	O
the	O
maximal	O
entailment	O
probability	O
between	O
summary	O
and	O
document	O
sentence	O
as	O
the	O
factual	O
consistency	O
score	O
.	O
As	O
no	O
dialogue	O
-	O
based	O
entailment	O
model	O
is	O
available	O
,	O
we	O
compute	O
the	O
entailment	O
probability	O
between	O
reference	O
and	O
generated	O
summaries	O
with	O
a	O
BERT	B-MethodName
-	O
based	O
entailment	O
model	O
trained	O
on	O
SNLI	O
and	O
MultiNLI	O
datasets	O
.	O

Results	O
on	O
PubMed	O
and	O
arXiv	O
datasets	O
are	O
shown	O
in	O
Table	O
2	O
.	O
Our	O
models	O
strongly	O
outperform	O
both	O
extractive	O
and	O
abstractive	O
baselines	O
,	O
suggesting	O
the	O
effectiveness	O
of	O
unifying	O
section	O
segmentation	O
with	O
summarization	O
.	O
The	O
LEAD	O
baseline	O
,	O
however	O
,	O
does	O
not	O
perform	O
as	O
well	O
on	O
long	O
documents	O
as	O
it	O
does	O
on	O
news	O
articles	O
.	O
It	O
is	O
interesting	O
to	O
note	O
that	O
our	O
models	O
are	O
trained	O
with	O
indirect	O
signals	O
,	O
i.e.	O
,	O
binary	O
sentence	O
labels	O
derived	O
from	O
reference	O
summaries	O
,	O
and	O
they	O
remain	O
quite	O
effective	O
at	O
capturing	O
salient	O
content	O
on	O
long	O
documents	O
.	O

The	O
results	O
of	O
multi	O
-	O
lingual	O
STS	O
benchmark	O
are	O
shown	O
in	O
Table	O
3	O
.	O
For	O
unsupervised	O
XLM	B-MethodName
-	I-MethodName
R	I-MethodName
and	O
mBERT	B-MethodName
without	O
finetuning	O
,	O
we	O
try	O
several	O
pooling	O
methods	O
and	O
find	O
that	O
averaging	O
over	O
the	O
first	O
and	O
the	O
last	O
layers	O
yields	O
the	O
best	O
results	O
on	O
STS	O
.	O
The	O
poor	O
results	O
of	O
pre	O
-	O
trained	O
language	O
models	O
mean	O
that	O
the	O
sentence	O
embeddings	O
of	O
pre	O
-	O
trained	O
language	O
models	O
do	O
not	O
capture	O
the	O
semantics	O
in	O
the	O
cosine	O
similarity	O
space	O
well	O
.	O
With	O
unsupervised	O
mSimCSE	O
pre	O
-	O
training	O
,	O
it	O
enhances	O
the	O
semantics	O
of	O
monolingual	O
STS	O
tasks	O
,	O
i.e.	O
"	O
ar	O
-	O
ar	O
"	O
and	O
"	O
es	O
-	O
es	O
"	O
.	O

Perturbed	O
Layer	O
We	O
further	O
study	O
how	O
perturbing	O
representations	O
from	O
different	O
layers	O
affect	O
generation	O
performance	O
.	O
We	O
conduct	O
experiments	O
on	O
AdvGrad	B-MethodName
by	O
gradually	O
moving	O
δ	O
x	O
or	O
δ	O
y	O
from	O
word	O
embeddings	O
to	O
high	O
-	O
layer	O
representations	O
of	O
the	O
encoder	O
or	O
decoder	O
,	O
separately	O
.	O
In	O
this	O
procedure	O
,	O
the	O
other	O
side	O
perturbation	O
remains	O
fixed	O
on	O
the	O
word	O
embedding	O
.	O
The	O
results	O
are	O
illustrated	O
in	O
Figure	O
2	O
,	O
where	O
the	O
horizontal	O
axis	O
(	O
Layer	O
i	O
d	O
)	O
indicates	O
the	O
perturbed	O
layer	O
and	O
the	O
longitudinal	O
axis	O
reports	O
the	O
corresponding	O
ROUGE	O
-	O
L	O
score	O
.	O
2	O
Because	O
both	O
BART	B-MethodName
encoder	O
and	O
decoder	O
are	O
composed	O
of	O
12	O
transformer	O
layers	O
,	O
we	O
denote	O
layer	O
0	O
as	O
the	O
word	O
embeddings	O
and	O
layer	O
12	O
as	O
the	O
output	O
representations	O
of	O
the	O
encoder	O
or	O
decoder	O
.	O

1,1	O
,	O
...	O
,	O
x	O
m	O
k	O
i	O
,	O
t	O
}	O
are	O
input	O
modality	O
sequences	O
and	O
m	O
1	O
,	O
m	O
2	O
denote	O
the	O
two	O
modality	O
types	O
,	O
some	O
modality	O
inputs	O
are	O
missing	O
with	O
probability	O
p	O
′	O
.	O
Following	O
Ma	O
et	O
al	O
.	O
(	O
2021	O
)	O
,	O
we	O
assume	O
that	O
modality	O
m	O
1	O
is	O
complete	O
and	O
the	O
random	O
missing	O
only	O
happens	O
on	O
modality	O
m	O
2	O
,	O
which	O
we	O
call	O
the	O
victim	O
modality	O
.	O
Consequently	O
,	O
we	O
can	O
divide	O
the	O
training	O
set	O
into	O
the	O
complete	O
and	O
missing	O
splits	O
,	O
denoted	O
as	O

We	O
use	O
the	O
rank	O
-	O
based	O
measures	O
to	O
evaluate	O
the	O
quality	O
of	O
the	O
prediction	O
including	O
Mean	O
Reciprocal	I-MethodName
Rank	O
(	O
MRR	O
)	O
and	O
Hits@N.	O
Their	O
detailed	O
definitions	O
are	O
introduced	O
below	O
:	O

Finally	O
,	O
we	O
show	O
ablation	O
result	O
for	O
our	O
codeswitching	O
in	O
translate	O
-	O
train	O
.	O
On	O
average	O
,	O
codeswitching	O
provides	O
an	O
additional	O
gain	O
of	O
1	O
%	O
.	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
74.9	O
54.8	O
62.2	O
68.0	O
48.8	O
61.1	O
61.6	O
XLM	O
-	O
R	O
Base	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
77.1	O
54.9	O
60.9	O
67.4	O
59.4	O
61.8	O
63.6	O
Translate	O
-	O
train	O
mBERT	O
from	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
77.7	O
51.8	O
62	O
Training	O
mBERT	O
with	O
Word	O
Alignments	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
post	O
-	O
align	O
mBERT	O
embeddings	O
by	O
first	O
generating	O
word	O
alignments	O
on	O
parallel	O
sentences	O
that	O
involve	O
English	O
.	O
For	O
each	O
aligned	O
word	O
pair	O
,	O
the	O
L	O
2	O
distance	O
between	O
their	O
embeddings	O
is	O
minimized	O
to	O
train	O
the	O
model	O
.	O
In	O
order	O
to	O
maintain	O
original	O
transferability	O
to	O
downstream	O
tasks	O
,	O
a	O
regularization	O
term	O
is	O
added	O
to	O
prevent	O
the	O
target	O
language	O
embeddings	O
from	O
deviating	O
too	O
much	O
from	O
their	O
mBERT	O
initialization	O
.	O
Our	O
approach	O
post	O
-	O
aligns	O
mBERT	O
with	O
two	O
self	O
-	O
supervised	O
signals	O
from	O
parallel	O
data	O
without	O
using	O
pre	O
-	O
alignment	O
tools	O
.	O
Wang	O
et	O
al	O
.	O
(	O
2019	O
)	O
also	O
align	O
mBERT	O
em-	O
Table	O
5	O
:	O
Ablation	O
Study	O
on	O
XNLI	O
.	O
250k	O
,	O
600k	O
,	O
2	O
M	O
refer	O
to	O
the	O
maximum	O
number	O
of	O
parallel	O
sentence	O
pairs	O
per	O
language	O
used	O
in	O
PPA	O
.	O
MoCo	O
refers	O
to	O
our	O
sentence	O
-	O
level	O
alignment	O
task	O
using	O
contrastive	O
learning	O
.	O
TLM	O
refers	O
to	O
our	O
word	O
-	O
level	O
alignment	O
task	O
with	O
translation	O
language	O
modeling	O
.	O
CS	O
stands	O
for	O
code	O
-	O
switching	O
.	O
We	O
conduct	O
an	O
additional	O
study	O
repl	O
TLM	O
w/	O
MLM	O
,	O
which	O
means	O
instead	O
of	O
TLM	O
training	O
,	O
we	O
augment	O
our	O
sentence	O
-	O
level	O
alignment	O
with	O
regular	O
MLM	O
on	O
monolingual	O
text	O
.	O
This	O
ablation	O
confirms	O
that	O
the	O
TLM	O
objective	O
helps	O
because	O
of	O
its	O
word	O
alignment	O
capability	O
,	O
not	O
because	O
we	O
train	O
the	O
encoders	O
with	O
more	O
data	O
and	O
iterations	O
.	O

linguistic	O
knowledge	O
(	O
Reif	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Indeed	O
,	O
even	O
an	O
informal	O
inspection	O
of	O
layer	O
-	O
wise	O
intrasentence	O
similarities	O
(	O
Fig	O
.	O
1	O
)	O
suggests	O
that	O
these	O
models	O
capture	O
elements	O
of	O
linguistic	O
structure	O
,	O
and	O
those	O
differ	O
depending	O
on	O
the	O
layer	O
of	O
the	O
model	O
.	O
A	O
grounded	O
investigation	O
of	O
these	O
regularities	O
allows	O
to	O
interpret	O
the	O
model	O
's	O
behaviour	O
,	O
design	O
better	O
pre	O
-	O
trained	O
encoders	O
and	O
inform	O
the	O
downstream	O
model	O
development	O
.	O
Such	O
investigation	O
is	O
the	O
main	O
subject	O
of	O
probing	O
,	O
and	O
recent	O
studies	O
confirm	O
that	O
BERT	B-MethodName
implicitly	O
captures	O
many	O
aspects	O
of	O
language	O
use	O
,	O
lexical	O
semantics	O
and	O
grammar	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

We	O
combined	O
instances	O
from	O
all	O
the	O
language	O
pairs	O
and	O
built	O
a	O
single	O
word	O
-	O
level	O
QE	O
model	O
.	O
Our	O
results	O
,	O
displayed	O
in	O
section	O
II	O
(	O
"	O
All	O
"	O
)	O
of	O
Table	O
2	O
,	O
show	O
that	O
multilingual	O
models	O
perform	O
on	O
par	O
with	O
bilingual	O
models	O
or	O
even	O
better	O
for	O
some	O
language	O
pairs	O
.	O
We	O
also	O
investigate	O
whether	O
combining	O
language	O
pairs	O
that	O
share	O
either	O
the	O
same	O
domain	O
or	O
MT	O
type	O
can	O
be	O
more	O
beneficial	O
,	O
since	O
it	O
is	O
possible	O
that	O
the	O
learning	O
process	O
is	O
better	O
when	O
language	O
pairs	O
share	O
certain	O
characteristics	O
.	O
However	O
as	O
shown	O
in	O
sections	O
III	O
and	O
IV	O
of	O
Table	O
2	O
,	O
for	O
the	O
majority	O
of	O
the	O
language	O
pairs	O
,	O
specialised	O
multilingual	O
models	O
built	O
on	O
certain	O
domains	O
or	O
MT	O
types	O
do	O
not	O
perform	O
better	O
than	O
multilingual	O
models	O
which	O
contain	O
all	O
the	O
data	O
.	O
Section	O
IV	O
shows	O
the	O
results	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
and	O
the	O
best	O
system	O
submitted	O
for	O
the	O
language	O
pair	O
in	O
that	O
competition	O
.	O
NR	O
implies	O
that	O
a	O
particular	O
result	O
was	O
not	O
reported	O
by	O
the	O
organisers	O
.	O
Zero	O
-	O
shot	O
results	O
are	O
coloured	O
in	O
grey	O
and	O
the	O
value	O
shows	O
the	O
difference	O
between	O
the	O
best	O
result	O
in	O
that	O
section	O
for	O
that	O
language	O
pair	O
and	O
itself	O
.	O

Besides	O
an	O
accurate	O
solution	O
to	O
the	O
J(A	O
,	O
B	O
)	O
,	O
whether	O
TFWSVD	B-MethodName
can	O
obtain	O
a	O
performance	O
gain	O
is	O
also	O
decided	O
by	O
the	O
properties	O
of	O
the	O
target	O
matrix	O
W	O
itself	O
.	O
TFWSVD	B-MethodName
is	O
to	O
capture	O
the	O
different	O
importance	O
of	O
parameters	O
.	O
However	O
,	O
if	O
the	O
parameters	O
in	O
W	O
equally	O
contributed	O
to	O
the	O
model	O
performance	O
,	O
then	O
the	O
standard	O
SVD	O
should	O
be	O
good	O
enough	O
.	O
Driven	O
by	O
these	O
factors	O
,	O
we	O
are	O
interested	O
in	O
this	O
question	O
:	O
Is	O
there	O
a	O
method	O
that	O
can	O
"	O
foresee	O
"	O
when	O
SVD	O
will	O
fail	O
,	O
and	O
TFWSVD	B-MethodName
can	O
help	O
retain	O
performance	O
?	O

Finally	O
,	O
we	O
measure	O
the	O
calibration	O
of	O
our	O
LM	O
-	O
KT	O
models	O
for	O
both	O
Spanish	O
and	O
French	O
(	O
from	O
En	O
-	O
glish	O
)	O
learners	O
,	O
which	O
is	O
the	O
crucial	O
property	O
for	O
our	O
downstream	O
generation	O
task	O
.	O
We	O
bin	O
our	O
test	O
data	O
by	O
predicted	O
question	O
difficulty	O
,	O
and	O
plot	O
the	O
fraction	O
of	O
true	O
correct	O
answers	O
in	O
each	O
bin	O
.	O
Figure	O
2	O
shows	O
that	O
LM	O
-	O
KT	O
is	O
well	O
-	O
calibrated	O
,	O
for	O
both	O
Spanish	O
and	O
French	O
,	O
meaning	O
the	O
predicted	O
difficulty	O
matches	O
the	O
empirically	O
observed	O
proportion	O
of	O
correct	O
answers	O
.	O

Crowdworker	O
-	O
constructed	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
datasets	O
have	O
been	O
found	O
to	O
contain	O
statistical	O
artifacts	O
associated	O
with	O
the	O
annotation	O
process	O
that	O
allow	O
hypothesis	O
-	O
only	O
classifiers	O
to	O
achieve	O
better	O
-	O
than	O
-	O
random	O
performance	O
(	O
Poliak	O
et	O
al	O
.	O
,	O
2018;Gururangan	O
et	O
al	O
.	O
,	O
2018;Tsuchiya	O
,	O
2018	O
)	O
.	O
We	O
investigate	O
whether	O
MedNLI	O
,	O
a	O
physician	O
-	O
annotated	O
dataset	O
with	O
premises	O
extracted	O
from	O
clinical	O
notes	O
,	O
contains	O
such	O
artifacts	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018	O
)	O
.	O
We	O
find	O
that	O
entailed	O
hypotheses	O
contain	O
generic	O
versions	O
of	O
specific	O
concepts	O
in	O
the	O
premise	O
,	O
as	O
well	O
as	O
modifiers	O
related	O
to	O
responsiveness	O
,	O
duration	O
,	O
and	O
probability	O
.	O
Neutral	O
hypotheses	O
feature	O
conditions	O
and	O
behaviors	O
that	O
co	O
-	O
occur	O
with	O
,	O
or	O
cause	O
,	O
the	O
condition(s	O
)	O
in	O
the	O
premise	O
.	O
Contradiction	O
hypotheses	O
feature	O
explicit	O
negation	O
of	O
the	O
premise	O
and	O
implicit	O
negation	O
via	O
assertion	O
of	O
good	O
health	O
.	O
Adversarial	O
filtering	O
demonstrates	O
that	O
performance	O
degrades	O
when	O
evaluated	O
on	O
the	O
difficult	O
subset	O
.	O
We	O
provide	O
partition	O
information	O
and	O
recommendations	O
for	O
alternative	O
dataset	O
construction	O
strategies	O
for	O
knowledge	O
-	O
intensive	O
domains	O
.	O

All	O
datasets	O
and	O
their	O
splits	O
used	O
in	O
the	O
experiments	O
are	O
listed	O
in	O
Table	O
1	O
.	O
We	O
will	O
explain	O
each	O
of	O
them	O
in	O
the	O
following	O
sections	O
.	O
For	O
each	O
classification	O
task	O
,	O
we	O
ran	O
and	O
improved	O
three	O
models	O
,	O
using	O
different	O
random	O
seeds	O
,	O
independently	O
of	O
one	O
another	O
,	O
and	O
the	O
reported	O
results	O
are	O
the	O
average	O
of	O
the	O
three	O
runs	O
.	O
Regarding	O
the	O
models	O
,	O
we	O
used	O
1D	O
CNNs	B-MethodName
with	O
the	O
same	O
structures	O
for	O
all	O
the	O
tasks	O
and	O
datasets	O
.	O
The	O
convolution	O
layer	O
had	O
three	O
filter	O
sizes	O
[	O
2	O
,	O
3	O
,	O
4	O
]	O
with	O
10	O
filters	O
for	O
each	O
size	O
(	O
i.e.	O
,	O
d	O
=	O
10	O
×	O
3	O
=	O
30	O
)	O
.	O
All	O
the	O
activation	O
functions	O
were	O
ReLU	O
except	O
the	O
softmax	O
at	O
the	O
output	O
layer	O
.	O
The	O
input	O
documents	O
were	O
padded	O
or	O
trimmed	O
to	O
have	O
150	O
words	O
(	O
L	O
=	O
150	O
)	O
.	O
We	O
used	O
pre	O
-	O
trained	O
300	O
-	O
dim	O
GloVe	O
vectors	O
(	O
Pennington	O
et	O
al	O
.	O
,	O
2014	O
)	O
as	O
non	O
-	O
trainable	O
weights	O
in	O
the	O
embedding	O
layers	O
.	O
All	O
the	O
models	O
were	O
implemented	O
using	O
Keras	O
and	O
trained	O
with	O
Adam	O
optimizer	O
.	O
We	O
used	O
iNNvestigate	O
(	O
Alber	O
et	O
al	O
.	O
,	O
2018	O
)	O
to	O
run	O
LRP	O
on	O
CNN	O
features	O
.	O
In	O
particular	O
,	O
we	O
used	O
the	O
LRP	O
-	O
propagation	O
rule	O
to	O
stabilize	O
the	O
relevance	O
scores	O
(	O
=	O
10	O
−7	O
)	O
.	O
Finally	O
,	O
we	O
used	O
Amazon	B-MethodName
Mechanical	I-MethodName
Turk	I-MethodName
(	O
MTurk	B-MethodName
)	O
to	O
collect	O
crowdsourced	O
responses	O
for	O
selecting	O
features	O
to	O
disable	O
.	O
Each	O
question	O
was	O
answered	O
by	O
ten	O
workers	O
and	O
the	O
answers	O
were	O
aggregated	O
using	O
majority	O
votes	O
or	O
average	O
scores	O
depending	O
on	O
the	O
question	O
type	O
(	O
as	O
explained	O
next	O
)	O
.	O

Entity	O
mention	O
detection	O
and	O
type	O
assignment	O
.	O

The	O
distant	O
supervision	O
process	O
relies	O
on	O
matching	O
entities	O
in	O
a	O
sentence	O
with	O
facts	O
from	O
the	O
knowledge	O
graph	O
.	O
To	O
detect	O
and	O
identify	O
the	O
named	O
entities	O
in	O
the	O
articles	O
,	O
we	O
use	O
the	O
DBpedia	B-MethodName
Spotlight	O
(	O
Mendes	O
et	O
al	O
.	O
,	O
2011	O
)	O
entity	O
linker	O
.	O
For	O
the	O
extraction	O
of	O
temporal	O
and	O
numerical	O
entities	O
,	O
we	O
use	O
the	O
spaCy	O
1	O
tool	O
.	O

•	O
We	O
truncate	O
longer	O
input	O
sequences	O
token	O
by	O
token	O
,	O
if	O
the	O
input	O
is	O
formed	O
from	O
multiple	O
sequences	O
(	O
see	O
Section	O
B	O
)	O
,	O
i.e.	O
,	O
pairs	O
,	O
we	O
start	O
from	O
the	O
longest	O
one	O
.	O

•	O
We	O
have	O
shown	O
that	O
simple	O
unsupervised	O
methods	O
could	O
be	O
used	O
to	O
finetune	O
existing	O
multipurpose	O
question	O
answering	O
models	O
(	O
in	O
our	O
case	O
UnifiedQA	O
)	O
to	O
new	O
datasets	O
or	O
domains	O
.	O

(	O
t	O
)	O
i	O
is	O
the	O
i	O
th	O
row	O
of	O
W	O
(	O
t	O
)	O
,	O
representing	O
the	O
label	O
word	O
embedding	O
of	O
class	O
C	O
i	O
.	O
To	O
make	O
the	O
adaptation	O
more	O
robust	O
,	O
we	O
add	O
an	O
instance	O
-	O
level	O
attention	O
mechanism	O
via	O
coefficient	O
α	O
j	O
i	O
.	O
Such	O
attention	O
score	O
is	O
to	O
measure	O
the	O
informative	O
degree	O
of	O
each	O
support	O
instance	O
.	O
According	O
to	O
previous	O
works	O
(	O
Gao	O
et	O
al	O
.	O
,	O
2019a	O
;	O
Dong	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
instances	O
are	O
not	O
equally	O
informative	O
,	O
and	O
we	O
should	O
make	O
those	O
informative	O
(	O
resp	O
.	O
noisy	O
instances	O
)	O
contribute	O
more	O
(	O
resp	O
.	O
less	O
)	O
during	O
fast	O
-	O
tuning	O
to	O
improve	O
the	O
robustness	O
.	O
We	O
calculate	O
α	O
j	O
i	O
as	O
shown	O
below	O
:	O

Figure	O
2	O
shows	O
the	O
annotation	O
guidelines	O
for	O
the	O
Amazon	O
Mechanical	O
Turk	O
study	O
.	O
Figure	O
3	O
shows	O
one	O
example	O
of	O
a	O
HIT	O
with	O
two	O
aspects	O
selected	O
.	O
Selected	O
aspects	O
are	O
highlighted	O
in	O
the	O
sentence	O
.	O
We	O
did	O
not	O
allow	O
to	O
choose	O
overlapping	O
aspects	O
.	O
If	O
the	O
aspect	O
was	O
not	O
found	O
in	O
the	O
first	O
list	O
provided	O
by	O
the	O
learned	O
ranker	O
,	O
crowdworkers	O
could	O
choose	O
from	O
as	O
second	O
list	O
with	O
the	O
remaining	O
1	O
-	O
4	O
-	O
grams	O
of	O
the	O
sentence	O
(	O
aspect	O
candidates	O
starting	O
or	O
ending	O
with	O
stopwords	O
,	O
as	O
well	O
as	O
candidates	O
with	O
punctuation	O
and	O
numbers	O
,	O
were	O
removed	O
from	O
the	O
list	O
)	O
.	O
Additional	O
checkboxes	O
were	O
added	O
to	O
choose	O
from	O
if	O
the	O
sentence	O
contained	O
no	O
aspect	O
or	O
the	O
aspect	O
was	O
not	O
explicitly	O
mentioned	O
.	O
Figure	O
4	O
shows	O
a	O
ranked	O
list	O
of	O
aspect	O
candidates	O
for	O
an	O
example	O
.	O

Among	O
these	O
methods	O
,	O
SimCSE	B-MethodName
may	O
be	O
viewed	O
as	O
our	O
direct	O
baseline	O
,	O
because	O
WhitenedCSE	B-MethodName
may	O
be	O
viewed	O
as	O
being	O
transformed	O
from	O
SimCSE	B-MethodName
by	O
adding	O
the	O
SGW	B-MethodName
and	O
replacing	O
the	O
dual	O
-	O
positive	O
contrastive	O
loss	O
with	O
multi	O
-	O
positive	O
contrastive	O
loss	O
.	O

Given	O
a	O
source	O
sentence	O
S	O
,	O
all	O
the	O
edits	O
suggested	O
by	O
single	O
models	O
constitute	O
a	O
candidate	O
set	O
A	O
,	O
and	O
the	O
number	O
of	O
edit	O
spans	O
is	O
denoted	O
as	O
m.	O
An	O
edit	O
span	O
means	O
the	O
start	O
-	O
end	O
pair	O
of	O
an	O
edit	O
's	O
position	O
in	O
the	O
sentence	O
.	O
The	O
set	O
of	O
all	O
the	O
edits	O
(	O
from	O
different	O
single	O
models	O
)	O
on	O
the	O
i	O
-	O
th	O
edit	O
span	O
(	O
including	O
"	O
noop	O
"	O
)	O
is	O
denoted	O
as	O
A	O
i	O
.	O
Thus	O
,	O
we	O
can	O
divide	O
A	O
=	O
m	O
i=1	O
A	O
i	O
,	O
where	O
A	O
i	O
=	O
{	O
e	O
i	O
j	O
|	O
j	O
=	O
1	O
,	O
2	O
,	O
...	O
,	O
|A	O
i	O
|	O
}	O
,	O
and	O
e	O
i	O
j	O
means	O
the	O
j	O
-	O
th	O
edit	O
on	O
the	O
i	O
-	O
th	O
edit	O
span	O
.	O

Based	O
on	O
the	O
same	O
experiment	O
setup	O
,	O
we	O
train	O
the	O
models	O
with	O
other	O
simple	O
schedules	O
(	O
shown	O
in	O
Figure	O
6	O
)	O
for	O
200k	O
steps	O
using	O
the	O
linear	O
learning	O
rate	O
decay	O
and	O
finetune	O
them	O
on	O
the	O
SQuAD	B-DatasetName
v1.1	O
.	O
The	O
results	O
on	O
SQuAD	B-DatasetName
v1.1	O
dev	O
set	O
are	O
presented	O
in	O
Table	O
4	O
.	O
We	O
find	O
that	O
cosine	O
is	O
the	O
best	O
compared	O
with	O
those	O
alternatives	O
.	O
Step	O
Masking	O
ratio	O

Online	O
education	O
platforms	O
can	O
increase	O
the	O
accessibility	O
of	O
educational	O
resources	O
around	O
the	O
world	O
.	O
However	O
,	O
achieving	O
equitable	O
outcomes	O
across	O
diverse	O
learning	O
needs	O
benefits	O
from	O
systems	O
that	O
are	O
adaptive	O
and	O
individualized	O
to	O
each	O
student	O
(	O
Doroudi	O
and	O
Brunskill	O
,	O
2019	O
)	O
.	O
Traditionally	O
,	O
adaptive	O
education	O
methods	O
involve	O
planning	O
over	O
a	O
pool	O
of	O
pre	O
-	O
made	O
questions	O
(	O
Atkinson	O
,	O
1972;Hunziker	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
These	O
are	O
naturally	O
limited	O
by	O
the	O
diversity	O
and	O
coverage	O
of	O
the	O
pool	O
,	O
as	O
well	O
as	O
the	O
scaling	O
capacity	O
of	O
curriculum	O
planning	O
algorithms	O
.	O
Recent	O
approaches	O
,	O
such	O
as	O
procedural	O
generation	O
for	O
personalized	O
programming	O
games	O
(	O
Valls	O
-	O
Vargas	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
are	O
limited	O
to	O
well	O
-	O
specified	O
small	O
domains	O
.	O
We	O
address	O
these	O
limitations	O
by	O
leveraging	O
recent	O
success	O
in	O
deep	O
generative	O
models	O
,	O
in	O
particular	O
language	O
models	O
(	O
LMs	O
)	O
.	O

We	O
therefore	O
collect	O
the	O
dataset	O
through	O
two	O
phases	O
:	O
(	O
1	O
)	O
simulating	O
multimodal	O
dialog	O
flows	O
with	O
templated	O
utterances	O
-thereby	O
programmatically	O
generating	O
fine	O
-	O
grained	O
-	O
scene	O
-	O
grounded	O
annotations	O
and	O
systematically	O
ensuring	O
the	O
diversity	O
of	O
the	O
conversations	O
,	O
and	O
(	O
2	O
)	O
manual	O
paraphrasing	O
,	O
which	O
ensures	O
the	O
naturalness	O
of	O
utterances	O
with	O
a	O
significantly	O
less	O
annotation	O
overhead	O
(	O
Rastogi	O
et	O
al	O
.	O
,	O
2020	O
;	O
Shah	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

The	O
performance	O
of	O
HAN	B-MethodName
is	O
also	O
in	O
general	O
better	O
than	O
non	O
-	O
meta	O
-	O
path	O
-	O
based	O
approaches	O
,	O
especially	O
on	O
macro	O
-	O
F1	O
,	O
again	O
demonstrating	O
the	O
effectiveness	O
of	O
meta	O
-	O
paths	O
on	O
HIN	B-MethodName
embedding	O
.	O
The	O
superior	O
performance	O
of	O
MetaFill	B-MethodName
on	O
both	O
link	O
prediction	O
and	O
node	O
classification	O
collectively	O
proves	O
the	O
effectiveness	O
of	O
using	O
text	O
filling	O
to	O
generate	O
meta	O
-	O
paths	O
.	O

The	O
KILT	B-MethodName
benchmark	O
has	O
been	O
recently	O
introduced	O
to	O
evaluate	O
the	O
capabilities	O
of	O
pre	O
-	O
trained	O
language	O
models	O
to	O
address	O
NLP	O
tasks	O
that	O
require	O
access	O
to	O
external	O
knowledge	O
.	O
We	O
evaluate	O
on	O
four	O
diverse	O
tasks	O
from	O
KILT	B-MethodName
:	O
slot	O
filling	O
,	O
question	O
answering	O
,	O
fact	O
checking	O
and	O
dialog	O
.	O
Figure	O
1	O
shows	O
examples	O
of	O
these	O
tasks	O
.	O
Re	O
2	O
G	O
makes	O
significant	O
gains	O
on	O
all	O
four	O
tasks	O
,	O
reaching	O
the	O
top	O
of	O
the	O
KILT	B-MethodName
leaderboards	O
and	O
establishing	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O

Classification	O
.	O
Both	O
methods	O
aim	O
to	O
remove	O
linearly	O
encoded	O
information	O
.	O
Ravfogel	O
et	O
al	O
.	O
(	O
2020	O
)	O
test	O
to	O
what	O
extent	O
the	O
non	O
-	O
linear	O
encoding	O
of	O
gender	O
remains	O
intact	O
by	O
running	O
a	O
1	O
-	O
hidden	O
-	O
layered	O
MLP	O
with	O
ReLU	O
activation	O
and	O
report	O
85.0	O
%	O
after	O
35	O
iterations	O
with	O
INLP	O
.	O
After	O
a	O
single	O
MP	O
projection	O
,	O
accuracy	O
of	O
the	O
MLP	O
drops	O
to	O
81.6	O
%	O
.	O

To	O
obtain	O
control	O
codes	O
from	O
training	O
data	O
,	O
we	O
pre	O
-	O
define	O
a	O
set	O
of	O
topics	O
to	O
retrieve	O
documents	O
for	O
and	O
rely	O
on	O
an	O
existing	O
stance	O
detection	O
model	O
to	O
classify	O
whether	O
a	O
sentence	O
argues	O
in	O
favor	O
(	O
pro	O
)	O
or	O
against	O
(	O
con	O
)	O
the	O
given	O
topic	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018a	O
)	O
.	O
Regarding	O
argument	O
aspect	O
detection	O
,	O
however	O
,	O
past	O
work	O
has	O
two	O
drawbacks	O
:	O
it	O
either	O
uses	O
simple	O
rule	O
-	O
based	O
extraction	O
of	O
verb	O
-	O
and	O
noun	O
-	O
phrases	O
(	O
Fujii	O
and	O
Ishikawa	O
,	O
2006	O
)	O
or	O
the	O
definition	O
of	O
aspects	O
is	O
based	O
on	O
target	O
-	O
concepts	O
located	O
within	O
the	O
same	O
sentence	O
(	O
Gemechu	O
and	O
Reed	O
,	O
2019	O
)	O
.	O
Aspects	O
as	O
we	O
require	O
and	O
define	O
them	O
are	O
not	O
bound	O
to	O
any	O
part	O
-	O
of	O
-	O
speech	O
tag	O
and	O
(	O
1	O
)	O
hold	O
the	O
core	O
reason	O
upon	O
which	O
the	O
conclusion	O
/	O
evidence	O
is	O
built	O
and	O
(	O
2	O
)	O
encode	O
the	O
stance	O
towards	O
a	O
general	O
but	O
not	O
necessarily	O
explicitly	O
mentioned	O
topic	O
the	O
argument	O
discusses	O
.	O
For	O
instance	O
:	O

Errors	O
in	O
the	O
last	O
category	O
occur	O
when	O
the	O
model	O
predicts	O
an	O
entity	O
whose	O
name	O
has	O
no	O
string	O
overlap	O
with	O
that	O
of	O
the	O
gold	O
entity	O
or	O
the	O
mention	O
.	O
This	O
likely	O
happens	O
when	O
the	O
signals	O
from	O
the	O
context	O
override	O
the	O
signals	O
from	O
the	O
mention	O
itself	O
.	O

Many	O
educational	O
activities	O
involve	O
sequential	O
data	O
,	O
such	O
as	O
language	O
translation	O
,	O
reading	O
compre-	O

Q5	O
:	O
Do	O
supervised	O
explanations	O
help	O
,	O
even	O
with	O
GPT-4	B-MethodName
?	O
Test	O
:	O
5	O
-	O
shot	O
GPT-4	B-MethodName
vs.	O
Zero	O
-	I-MethodName
shot	I-MethodName
GPT-4	B-MethodName
.	O
Answer	O
:	O
Yes	O
.	O
The	O
zero	O
-	O
shot	O
version	O
of	O
GPT-4	B-MethodName
is	O
missing	O
access	O
not	O
only	O
to	O
the	O
supervision	O
of	O
paired	O
(	O
caption	O
,	O
explanation	O
)	O
data	O
,	O
but	O
also	O
,	O
explanations	O
in	O
the	O
detailed	O
style	O
of	O
our	O
released	O
corpus	O
.	O
Perhaps	O
as	O
a	O
result	O
,	O
5	B-MethodName
-	O
shot	O
GPT-4	B-MethodName
(	O
which	O
also	O
achieves	O
significantly	O
higher	O
BLEU-4	B-MetricName
/	O
Rouge	B-MetricName
-	I-MetricName
L	I-MetricName
)	O
is	O
preferred	O
in	O
64	O
%	O
of	O
cases	O
.	O

Now	O
that	O
we	O
have	O
a	O
candidate	O
reference	O
responsẽ	O
s	O
t+1	O
,	O
we	O
can	O
guide	O
the	O
language	O
model	O
towards	O
generating	O
a	O
similar	O
response	O
.	O
To	O
do	O
this	O
,	O
we	O
modify	O
the	O
logits	O
from	O
the	O
language	O
model	O
to	O
encourage	O
generation	O
of	O
the	O
control	O
words	O
or	O
similar	O
words	O
.	O
We	O
start	O
with	O
the	O
first	O
word	O
w	O
0	O
ins	O
t+1	O
and	O
upweight	O
logits	O
in	O
a	O
way	O
similar	O
to	O
DBS	O
(	O
Pascual	O
et	O
al	O
.	O
,	O
2020	O
)	O
using	O
similarity	O
of	O
GloVe	O
vector	O
embeddings	O
:	O

The	O
ICoref	B-MethodName
-	I-MethodName
inc	O
model	O
from	O
Xia	O
et	O
al	O
.	O
(	O
2020	O
)	O
is	O
an	O
important	O
comparison	O
point	O
as	O
the	O
only	O
baseline	O
in	O
the	O
sentence	O
-	O
incremental	O
setting	O
.	O
While	O
ICorefinc	B-MethodName
does	O
not	O
rely	O
on	O
speaker	O
embeddings	O
,	O
our	O
own	O
models	O
(	O
both	O
Part	O
-	O
Inc	O
and	O
Sent	O
-	O
Inc	O
)	O
do	O
.	O
Given	O
the	O
important	O
role	O
of	O
speaker	O
identity	O
in	O
a	O
dialogue	O
setting	O
,	O
it	O
is	O
useful	O
to	O
know	O
the	O
effect	O
of	O
removing	O
these	O
embeddings	O
in	O
our	O
models	O
.	O

beddings	O
using	O
parallel	O
data	O
.	O
They	O
learn	O
a	O
linear	O
transformation	O
that	O
maps	O
a	O
word	O
embedding	O
in	O
a	O
target	O
language	O
to	O
the	O
embedding	O
of	O
the	O
aligned	O
word	O
in	O
the	O
source	O
language	O
.	O
They	O
show	O
that	O
their	O
transformed	O
embeddings	O
are	O
more	O
effective	O
on	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
dependency	O
parsing	O
.	O

Previous	O
work	O
on	O
related	O
tasks	O
(	O
Taniguchi	O
et	O
al	O
.	O
,	O
2019	O
;	O
Kim	O
and	O
Choi	O
,	O
2020	O
)	O
and	O
on	O
in	O
-	O
domain	O
versions	O
of	O
our	O
task	O
(	O
Ishigaki	O
et	O
al	O
.	O
,	O
2021	O
)	O
have	O
traditionally	O
divided	O
the	O
efforts	O
into	O
simpler	O
sub	O
-	O
tasks	O
that	O
can	O
be	O
combined	O
into	O
a	O
pipeline	O
approach	O
.	O
We	O
follow	O
a	O
similar	O
approach	O
,	O
also	O
presenting	O
two	O
subtasks	O
.	O

We	O
train	O
these	O
three	O
models	O
on	O
COCO-35L.	B-DatasetName
In	O
addition	O
,	O
we	O
consider	O
a	O
fourth	O
model	O
based	O
on	O
mT5base	O
+	O
ViT	O
-	I-MethodName
B	I-MethodName
/	O
16	O
and	O
trained	O
on	O
CC3M-35L.	B-DatasetName
The	O
models	O
are	O
trained	O
on	O
a	O
4x4x4	O
TPU	O
-	O
v4	O
architecture	O
using	O
an	O
Adafactor	O
(	O
Shazeer	O
and	O
Stern	O
,	O
2018	O
)	O
optimizer	O
with	O
a	O
constant	O
learning	O
rate	O
period	O
between	O
{	O
1k	O
,	O
10k	O
}	O
steps	O
,	O
followed	O
by	O
a	O
reversed	O
square	O
-	O
root	O
decay	O
with	O
the	O
number	O
of	O
steps	O
.	O
The	O
batch	O
size	O
is	O
2048	O
in	O
all	O
the	O
experiments	O
.	O
The	O
initial	O
learning	O
rate	O
is	O
between	O
{	O
1e-4	O
,	O
3e-4	O
}	O
.	O
We	O
use	O
the	O
same	O
vocabulary	O
(	O
size	O
250k	O
)	O
as	O
mT5	O
(	O
Xue	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
The	O
model	O
trained	O
with	O
CC3M-35L	B-DatasetName
is	O
subsequently	O
finetuned	O
on	O
COCO-35L	B-DatasetName
with	O
constant	O
learning	O
rate	O
3e-5	O
for	O
1	O
epoch	O
.	O

We	O
use	O
the	O
pretrained	O
mBERT	B-MethodName
model	O
to	O
initialize	O
both	O
the	O
query	O
and	O
momentum	O
encoders	O
.	O
mBERT	B-MethodName
is	O
made	O
of	O
12	O
Transformer	B-MethodName
blocks	O
,	O
12	O
attention	O
heads	O
,	O
and	O
hidden	O
size	O
d	O
h	O
=	O
768	O
.	O
For	O
input	O
,	O
instead	O
of	O
feeding	O
the	O
query	O
encoder	O
with	O
English	O
examples	O
and	O
the	O
momentum	O
encoder	O
with	O
translation	O
examples	O
or	O
vice	O
versa	O
,	O
we	O
propose	O
a	O
random	O
input	O
shuffling	O
approach	O
.	O
Specifically	O
,	O
we	O
randomly	O
shuffle	O
the	O
order	O
of	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
when	O
feeding	O
the	O
two	O
encoders	O
,	O
so	O
that	O
the	O
query	O
encoder	O
sees	O
both	O
English	O
and	O
translation	O
examples	O
.	O
We	O
observe	O
that	O
this	O
is	O
a	O
crucial	O
step	O
towards	O
learning	O
good	O
multilingual	O
representations	O
using	O
our	O
method	O
.	O
The	O
final	O
hidden	O
state	O
h	O
∈	O
R	O
1×d	O
h	O
of	O
the	O
[	O
CLS	O
]	O
token	O
,	O
normalized	O
with	O
L	O
2	O
norm	O
,	O
is	O
treated	O
as	O
the	O
sentence	O
representation	O
1	O
.	O
Following	O
Chen	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
we	O
add	O
a	O
non	O
-	O
linear	O
projection	O
layer	O
on	O
top	O
of	O
h	O
:	O

Instruction	O
-	O
tuning	O
enables	O
stronger	O
generalization	O
to	O
unseen	O
tasks	O
.	O
Generally	O
instruction	O
-	O
tuned	O
models	O
perform	O
better	O
compared	O
to	O
their	O
untuned	O
LM	O
counterparts	O
(	O
Tk	B-MethodName
-	O
INSTRUCT	O
vs.	O
T5	B-MethodName
-	O
LM	O
,	O
In	B-MethodName
-	O
structGPT	O
vs.	O
GPT-3	B-MethodName
)	O
and	O
heuristic	O
baselines	O
.	O
This	O
indicates	O
models	O
do	O
learn	O
to	O
follow	O
instructions	O
by	O
finetuning	O
on	O
instruction	O
data	O
,	O
and	O
this	O
can	O
generalize	O
to	O
new	O
instructions	O
for	O
unseen	O
tasks	O
.	O
T0	B-MethodName
is	O
an	O
exception	O
,	O
which	O
is	O
only	O
slightly	O
better	O
than	O
T5	B-MethodName
-	O
LM	O
.	O
We	O
suspect	O
this	O
is	O
because	O
the	O
style	O
of	O
prompting	O
in	O
T0	B-MethodName
's	O
training	O
data	O
is	O
very	O
different	O
from	O
our	O
style	O
of	O
instructions	O
.	O

The	O
first	O
part	O
of	O
Table	O
2	O
presents	O
the	O
results	O
for	O
sentence	O
-	O
level	O
multimodal	O
QE	O
with	O
BiRNN	B-MethodName
.	O
The	O
best	O
model	O
is	O
BiRNN+Vis	B-MethodName
-	O
embed	O
-	O
mult2	O
,	O
achieving	O
a	O
Pearson	O
's	O
r	O
of	O
0.535	O
,	O
significantly	O
outperforming	O
the	O
baseline	O
(	O
p	O
-	O
value<0.01	O
)	O
.	O
Visual	O
features	O
can	O
,	O
therefore	O
,	O
help	O
to	O
improve	O
the	O
performance	O
of	O
sentence	O
-	O
level	O
neural	O
-	O
based	O
QE	O
systems	O
significantly	O
.	O

In	O
Table	O
1	O
,	O
the	O
settings	O
for	O
Adapter-108	B-MethodName
and	O
Prefix	B-MethodName
-	I-MethodName
tuning-108	I-MethodName
are	O
clear	O
,	O
as	O
the	O
only	O
arguments	O
are	O
the	O
bottleneck	O
size	O
/	O
prefix	O
length	O
;	O
for	O
LoRA-54	B-MethodName
,	O
we	O
apply	O
rank-54	O
updates	O
for	O
both	O
W	O
q	O
and	O
W	O
v	O
,	O
as	O
suggested	O
by	O
Hu	O
et	O
al	O
.	O
(	O
2021	O
)	O
;	O
for	O
MAM	O
adapter	O
,	O
we	O
mimic	O
the	O
parameter	O
assignment	O
scheme	O
(	O
bottleneck	O
size	O
512	O
for	O
FFN	O
and	O
prefix	O
length	O
30	O
)	O
by	O
He	O
et	O
al	O
.	O
(	O
2021a	O
)	O
,	O
and	O
use	O
the	O
ratio	O
102	O
:	O
6	O
to	O
implement	O
MAM	O
adapters	O
with	O
1.61	O
%	O
tunable	O
parameters	O
.	O

We	O
create	O
a	O
cross	O
-	O
topic	O
split	O
with	O
the	O
data	O
of	O
two	O
topics	O
as	O
test	O
set	O
(	O
gun	O
control	O
,	O
school	O
uniforms	O
)	O
,	O
one	O
topic	O
as	O
dev	O
set	O
(	O
death	O
penalty	O
)	O
,	O
and	O
the	O
remaining	O
topics	O
as	O
train	O
set	O
and	O
evaluate	O
two	O
models	O
with	O
it	O
.	O
First	O
,	O
we	O
use	O
the	O
ranking	O
approach	O
described	O
in	O
Step	O
2a-2b	O
to	O
fine	O
-	O
tune	O
MT	O
-	O
DNN	O
BASE	O
on	O
the	O
newly	O
generated	O
data	O
(	O
"	O
Ranker	O
"	O
)	O
.	O
At	O
inference	O
,	O
we	O
choose	O
the	O
top	O
T	O
aspects	O
for	O
each	O
argument	O
as	O
candidates	O
.	O
We	O
tune	O
T	O
on	O
the	O
dev	O
set	O
and	O
find	O
T	O
=	O
2	O
to	O
be	O
the	O
best	O
choice	O
.	O
Second	O
,	O
we	O
use	O
BERT	B-MethodName
for	O
sequence	O
tagging	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
label	O
all	O
tokens	O
of	O
the	O
samples	O
with	O
BIO	O
tags	O
.	O
As	O
previously	O
done	O
with	O
the	O
ranker	O
,	O
we	O
experiment	O
with	O
BERT	B-MethodName
and	O
MT	B-MethodName
-	I-MethodName
DNN	I-MethodName
weights	O
and	O
find	O
BERT	B-MethodName
LARGE	O
to	O
be	O
the	O
best	O
choice	O
(	O
trained	O
for	O
5	O
epochs	O
,	O
with	O
a	O
learning	O
rate	O
of	O
1	O
×	O
10	O
−5	O
and	O
a	O
batch	O
size	O
of	O
32	O
)	O
.	O
We	O
flatten	O
the	O
predictions	O
for	O
all	O
test	O
samples	O
and	O
calculate	O
the	O
F	B-MetricName
1	I-MetricName
,	O
Precision	O
,	O
and	O
Recall	O
macro	O
scores	O
.	O
All	O
models	O
are	O
trained	O
over	O
five	O
seeds	O
and	O
the	O
averaged	O
results	O
are	O
reported	O
in	O
Table	O
3	O
.	O

Treating	O
entities	O
as	O
inputs	O
of	O
Transformer	B-MethodName
.	O
Recent	O
studies	O
Yamada	O
et	O
al	O
.	O
,	O
2020;Sun	O
et	O
al	O
.	O
,	O
2020	O
)	O
have	O
proposed	O
Transformerbased	B-MethodName
models	O
that	O
treat	O
entities	O
as	O
input	O
tokens	O
to	O
enrich	O
their	O
expressiveness	O
using	O
additional	O
information	O
contained	O
in	O
the	O
entity	O
embeddings	O
.	O
However	O
,	O
these	O
models	O
were	O
designed	O
to	O
solve	O
general	O
NLP	O
tasks	O
and	O
not	O
tested	O
on	O
ED	O
.	O
We	O
treat	O
entities	O
as	O
input	O
tokens	O
to	O
capture	O
the	O
global	O
context	O
that	O
is	O
shown	O
to	O
be	O
highly	O
effective	O
for	O
ED	O
.	O

-DOCSTART-	O
Multimodal	O
Quality	O
Estimation	O
for	O
Machine	O
Translation	I-TaskName

It	O
is	O
made	O
up	O
of	O
a	O
set	O
of	O
selected	O
cell	O
values	O
V	O
i	O
=	O
{	O
v	O
1	O
,	O
.	O
.	O
.	O
,	O
v	O
t	O
}	O
of	O
H	O
i	O
and	O
the	O
rest	O
of	O
headers	O

We	O
follow	O
the	O
experiment	O
setup	O
in	O
(	O
Gururangan	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
7	O
is	O
used	O
as	O
the	O
LM	O
.	O
In	O
each	O
experiment	O
,	O
we	O
first	O
DA	O
-	O
train	O
the	O
LM	O
and	O
then	O
fine	O
-	O
tune	O
it	O
on	O
the	O
end	O
-	O
task	O
.	O
The	O
final	O
evaluation	O
is	O
based	O
on	O
the	O
end	O
-	O
task	O
results	O
.	O

Further	O
,	O
we	O
point	O
out	O
some	O
limitations	O
of	O
the	O
Arg	B-MethodName
-	I-MethodName
CTRL	I-MethodName
that	O
mitigate	O
the	O
risks	O
discussed	O
before	O
.	O
One	O
of	O
these	O
limitations	O
is	O
that	O
it	O
can	O
not	O
be	O
used	O
to	O
generate	O
arguments	O
for	O
unseen	O
topics	O
,	O
which	O
makes	O
a	O
widespread	O
application	O
(	O
e.g.	O
to	O
produce	O
fake	O
news	O
)	O
rather	O
unlikely	O
(	O
using	O
an	O
unseen	O
topic	O
as	O
control	O
code	O
results	O
in	O
nonsensical	O
repetitions	O
of	O
the	O
input	O
)	O
.	O
The	O
analysis	O
in	O
Section	O
6	O
of	O
the	O
paper	O
shows	O
that	O
the	O
model	O
fails	O
to	O
produce	O
aspectspecific	O
sentences	O
in	O
92	O
%	O
of	O
the	O
cases	O
if	O
it	O
was	O
not	O
explicitly	O
conditioned	O
on	O
them	O
at	O
training	O
time	O
.	O
Even	O
in	O
case	O
of	O
success	O
,	O
the	O
aspect	O
has	O
to	O
exist	O
in	O
the	O
training	O
data	O
.	O
Also	O
,	O
the	O
model	O
is	O
trained	O
with	O
balanced	O
classes	O
,	O
i.e.	O
both	O
supporting	O
and	O
opposing	O
arguments	O
for	O
each	O
topic	O
are	O
seen	O
with	O
equal	O
frequency	O
to	O
prevent	O
possible	O
bias	O
into	O
one	O
or	O
the	O
other	O
direction	O
.	O

Flat	O
model	O
.	O
To	O
decrease	O
the	O
models	O
'	O
own	O
expressive	O
power	O
(	O
Hewitt	O
and	O
Liang	O
,	O
2019	O
)	O
,	O
we	O
keep	O
the	O
number	O
of	O
parameters	O
in	O
our	O
probing	O
model	O
as	O
low	O
as	O
possible	O
.	O
While	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
utilize	O
pooled	O
self	O
-	O
attentional	O
span	O
representations	O
and	O
a	O
projection	O
layer	O
to	O
enable	O
cross	O
-	O
model	O
comparison	O
,	O
we	O
directly	O
feed	O
the	O
wordpiece	O
encoding	O
into	O
the	O
classifier	O
,	O
using	O
the	O
first	O
wordpiece	O
of	O
a	O
word	O
.	O
To	O
further	O
increase	O
the	O
selectivity	O
of	O
the	O
model	O
,	O
we	O
directly	O
project	O
the	O
source	O
and	O
target	O
wordpiece	O
representations	O
into	O
the	O
label	O
space	O
,	O
opposed	O
to	O
the	O
two	O
-	O
layer	O
MLP	O
classifier	O
used	O
in	O
the	O
original	O
setup	O
.	O

one	O
pass	O
through	O
the	O
transformer	O
for	O
k	O
noise	O
samples	O
and	O
n	O
−	O
k	O
data	O
samples	O
.	O
However	O
,	O
this	O
procedure	O
only	O
truly	O
minimizes	O
L	O
ifp	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
=	O
p	O
θ	O
(	O
x	O
t	O
|x	O
noised	O
\t	O
)	O
.	O
To	O
apply	O
this	O
efficiency	O
trick	O
we	O
are	O
making	O
the	O
assumption	O
they	O
are	O
approximately	O
equal	O
,	O
which	O
we	O
argue	O
is	O
reasonable	O
because	O
(	O
1	O
)	O
we	O
choose	O
a	O
small	O
k	O
of	O
0.15n	O
and	O
(	O
2	O
)	O
q	O
is	O
trained	O
to	O
be	O
close	O
to	O
the	O
data	O
distribution	O
(	O
see	O
below	O
)	O
.	O
This	O
efficiency	O
trick	O
is	O
analogous	O
to	O
BERT	B-MethodName
masking	O
out	O
multiple	O
tokens	O
per	O
input	O
sequence	O
.	O

To	O
exploit	O
the	O
value	O
of	O
TKGs	B-MethodName
,	O
recent	O
research	O
effort	O
has	O
been	O
devoted	O
to	O
process	O
natural	O
language	O
questions	O
over	O
TKG	B-MethodName
,	O
i.e.	O
,	O
question	O
answering	O
over	O
TKG	B-MethodName
(	O
TKGQA	B-MethodName
in	O
short	O
)	O
(	O
Saxena	O
et	O
al	O
.	O
,	O
2021	O
)	O
.	O
Given	O
a	O
question	O
and	O
a	O
background	O
TKG	B-MethodName
,	O
it	O
retrieves	O
from	O
the	O
TKG	O
an	O
answer	O
to	O
the	O
question	O
.	O
To	O
foster	O
research	O
on	O
TKGQA	B-MethodName
,	O
several	O
datasets	O
have	O
been	O
introduced	O
,	O
among	O
which	O
CRONQUES	O
-	O
TIONS	I-MethodName
(	O
Saxena	O
et	O
al	O
.	O
,	O
2021	O
)	O
is	O
by	O
far	O
the	O
largest	O
.	O
We	O
explain	O
the	O
task	O
with	O
a	O
sample	O
question	O
in	O
CRON	O
-	O
QUESTIONS	O
.	O

To	O
measure	O
the	O
prevalence	O
of	O
semantic	O
memory	O
in	O
a	O
story	O
,	O
we	O
count	O
the	O
number	O
of	O
sentences	O
that	O
matched	O
ATOMIC	O
knowledge	O
tuples	O
in	O
their	O
surrounding	O
context	O
.	O
We	O
use	O
a	O
context	O
window	O
of	O
size	O
n	O
c	O
=	O
n	O
e	O
=	O
2	O
to	O
match	O
inferences	O
,	O
and	O
use	O
the	O
spaCy	O
pipeline	O
(	O
Honnibal	O
and	O
Montani	O
,	O
2017	O
)	O
to	O
extract	O
noun	O
and	O
verb	O
phrases	O
.	O

•	O
The	O
effect	O
of	O
debiasing	O
on	O
internal	O
representations	O
is	O
reflected	O
in	O
gender	O
extractability	O
,	O
while	O
not	O
always	O
in	O
CEAT	O
.	O
Thus	O
,	O
gender	O
extractability	O
is	O
a	O
more	O
reliable	O
indicator	O
of	O
gender	O
bias	O
in	O
NLP	O
models	O
.	O

Regression	O
tasks	O
.	O
The	O
original	O
edge	O
probing	O
setup	O
only	O
considers	O
classification	O
tasks	O
.	O
Many	O
language	O
phenomena	O
-including	O
positional	O
information	O
and	O
semantic	O
proto	O
-	O
roles	O
,	O
are	O
naturally	O
modeled	O
as	O
regression	O
.	O
We	O
extend	O
the	O
architecture	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
and	O
support	O
both	O
classification	O
and	O
regression	O
:	O
the	O
former	O
achieved	O
via	O
softmax	O
,	O
the	O
latter	O
via	O
direct	O
linear	O
regression	O
to	O
the	O
target	O
value	O
.	O

In	O
this	O
section	O
,	O
we	O
start	O
by	O
presenting	O
our	O
proposed	O
lightweight	O
framework	O
PTO	O
(	O
Section	O
3.1	O
)	O
,	O
then	O
introducing	O
two	O
extensions	O
of	O
PTO	O
to	O
leverage	O
optional	O
training	O
data	O
(	O
Sections	O
3.2	O
to	O
3.4	O
)	O
.	O
Finally	O
,	O
we	O
make	O
a	O
summary	O
in	O
Section	O
3.5	O
.	O

Context	O
Difference	O
.	O
Compared	O
with	O
plain	O
text	O
,	O
which	O
is	O
a	O
sequence	O
of	O
words	O
,	O
tables	O
have	O
welldefined	O
structures	O
,	O
and	O
understanding	O
a	O
table	O
's	O
structure	O
is	O
crucial	O
for	O
schema	O
translation	O
.	O
Specifically	O
,	O
a	O
table	O
consists	O
of	O
an	O
ordered	O
arrangement	O
of	O
rows	O
and	O
columns	O
.	O
Each	O
column	O
header	O
describes	O
the	O
concept	O
of	O
that	O
column	O
.	O
The	O
intersection	O
of	O
a	O
row	O
and	O
a	O
column	O
is	O
called	O
a	O
cell	O
.	O
Each	O
cell	O
contains	O
entities	O
of	O
the	O
column	O
header	O
it	O
belongs	O
to	O
.	O
This	O
structure	O
plays	O
an	O
important	O
role	O
in	O
schema	O
translation	O
,	O
especially	O
for	O
polysemy	O
words	O
and	O
abbreviation	O
words	O
.	O
For	O
example	O
,	O
in	O
Figure	O
1	O
,	O
the	O
header	O
"	O
Match	O
"	O
could	O
be	O
translated	O
to	O
"	O
kÙ	O
(	O
Matchstick	O
)	O
"	O
,	O
"	O
9	O
M	O
(	O
Mapping	O
)	O
"	O
,	O
and	O
"	O
'	O
[	O
(	O
Competition	O
)	O
"	O
,	O
but	O
its	O
sibling	O
column	O
header	O
"	O
Hosted_by	O
"	O
provides	O
important	O
clues	O
that	O
the	O
table	O
might	O
belong	O
to	O
the	O
domain	O
of	O
sport	O
.	O
Thus	O
,	O
translating	O
"	O
Match	O
"	O
to	O
"	O
'	O
[	O
(	O
Competition	O
)	O
"	O
is	O
more	O
appropriate	O
in	O
the	O
context	O
.	O
Moreover	O
,	O
a	O
column	O
header	O
's	O
cell	O
values	O
could	O
also	O
provide	O
hints	O
to	O
infer	O
the	O
meaning	O
of	O
the	O
header	O
.	O
For	O
example	O
,	O
successive	O
numerical	O
cell	O
values	O
indicate	O
that	O
"	O
No	O
.	O
"	O
might	O
be	O
an	O
identity	O
column	O
in	O
Figure	O
1	O
.	O
NMT	O
models	O
trained	O
with	O
plain	O
text	O
have	O
never	O
seen	O
the	O
structure	O
of	O
tables	O
,	O
and	O
consequently	O
,	O
they	O
perform	O
poorly	O
in	O
schema	O
translation	O
.	O

We	O
proposed	O
FPT	O
,	O
a	O
prefix	O
tuning	O
-	O
based	O
method	O
,	O
to	O
mitigate	O
the	O
effect	O
of	O
attribute	O
transfer	O
.	O
FPT	B-MethodName
could	O
encode	O
implicit	O
attributes	O
in	O
a	O
dataset	O
by	O
a	O
general	O
prefix	O
and	O
use	O
it	O
to	O
suppress	O
the	O
attribute	O
transfer	O
via	O
inference	O
-	O
time	O
logits	O
manipulation	O
.	O
Results	O
in	O
the	O
single	O
-	O
attribute	O
control	O
experiments	O
showed	O
that	O
,	O
with	O
FPT	O
,	O
the	O
generated	O
texts	O
can	O
be	O
more	O
effectively	O
controlled	O
under	O
the	O
desired	O
attribute	O
with	O
higher	O
text	O
fluency	O
.	O
Experimental	O
results	O
in	O
the	O
multi	O
-	O
attribute	O
control	O
suggested	O
that	O
FPT	O
can	O
achieve	O
comparable	O
performance	O
to	O
the	O
state	O
-	O
ofthe	O
-	O
art	O
approach	O
while	O
keeping	O
the	O
flexibility	O
of	O
adding	O
new	O
prefixes	O
without	O
retraining	O
.	O

Word	O
-	O
level	O
QE	O
is	O
generally	O
framed	O
as	O
a	O
supervised	O
ML	O
problem	O
(	O
Kepler	O
et	O
al	O
.	O
,	O
2019;Lee	O
,	O
2020	O
)	O
trained	O
on	O
data	O
in	O
which	O
the	O
correctness	O
of	O
translation	O
is	O
labelled	O
at	O
word	O
-	O
level	O
(	O
i.e.	O
good	O
,	O
bad	O
,	O
gap	O
)	O
.	O

Although	O
GPT3	B-MethodName
can	O
generalize	O
to	O
80	O
digits	O
on	O
copying	O
random	O
numbers	O
(	O
Figure	O
2	O
)	O
,	O
it	O
does	O
not	O
generalize	O
well	O
beyond	O
20	O
items	O
on	O
reversing	O
,	O
which	O
suggests	O
that	O
reversing	O
might	O
require	O
stronger	O
locating	O
capability	O
than	O
copying	O
.	O
This	O
problem	O
also	O
occurs	O
on	O
DeBERTa	B-MethodName
and	O
T5	B-MethodName
.	O
When	O
tested	O
on	O
the	O
OOD	O
data	O
,	O
the	O
models	O
tends	O
to	O
generate	O
only	O
a	O
sublist	O
of	O
the	O
input	O
.	O
Using	O
fine	O
-	O
grained	O
steps	O
(	O
Figure	O
9(b	O
)	O
)	O
or	O
positional	O
markers	O
,	O
whether	O
implicit	O
or	O
explicit	O
(	O
Figure	O
9(c	O
)	O
)	O
,	O
does	O
not	O
significantly	O
improve	O
the	O
generalization	O
of	O
the	O
experimented	O
models	O
.	O
The	O
reason	O
might	O
be	O
the	O
increasing	O
distance	O
between	O
the	O
source	O
item	O
and	O
the	O
replicated	O
item	O
as	O
stated	O
above	O
.	O
Again	O
,	O
LMs	O
+	O
tutor	O
maintains	O
100	O
%	O
accuracy	O
throughout	O
the	O
experiments	O
.	O
We	O
put	O
more	O
discussion	O
about	O
the	O
results	O
in	O
appendix	O
A.5	O
due	O
to	O
the	O
page	O
limit	O
.	O

Baseline	O
.	O
We	O
use	O
a	O
method	O
that	O
relies	O
on	O
crosslingual	O
language	O
model	O
pretraining	O
,	O
namely	O
XLM	B-MethodName
(	O
Lample	O
and	O
Conneau	O
,	O
2019	O
)	O
.	O
This	O
approach	O
trains	O
a	O
bilingual	O
MLM	O
separately	O
for	O
En	O
-	O
Mk	O
and	O
En	O
-	O
Sq	O
,	O
which	O
is	O
used	O
to	O
initialize	O
the	O
encoder	O
-	O
decoder	O
of	O
the	O
corresponding	O
NMT	B-TaskName
system	O
.	O
Each	O
system	O
is	O
then	O
trained	O
in	O
an	O
unsupervised	O
way	O
.	O

Redundancy	O
is	O
an	O
essential	O
problem	O
in	O
LDQA	O
since	O
in	O
the	O
answer	O
generation	I-TaskName
phase	O
,	O
repetitious	O
paragraphs	O
could	O
make	O
the	O
QA	O
model	O
confused	O
(	O
Appendix	O
D	O
)	O
.	O
Therefore	O
,	O
it	O
's	O
crucial	O
to	O
select	O
important	O
and	O
diverse	O
evidence	O
pieces	O
for	O
the	O
QA	O
model	O
.	O
To	O
this	O
end	O
,	O
we	O
explore	O
the	O
effects	O
of	O
the	O
evidence	O
history	O
module	O
on	O
redundancy	O
reduction	O
.	O

We	O
begin	O
by	O
identifying	O
the	O
host	O
speaker	O
and	O
focusing	O
on	O
their	O
questions	O
.	O
Next	O
,	O
we	O
predict	O
which	O
speaker	O
(	O
s	O
)	O
would	O
answer	O
the	O
question	O
by	O
identifying	O
speaker	O
entities	O
mentioned	O
in	O
utterances	O
or	O
from	O
previous	O
dialogue	O
turns	O
.	O
Finally	O
,	O
we	O
search	O
utterances	O
from	O
the	O
identified	O
speakers	O
until	O
a	O
stopping	O
criterion	O
is	O
met	O
and	O
label	O
it	O
as	O
the	O
answer	O
.	O
Due	O
to	O
the	O
assumptions	O
made	O
in	O
the	O
above	O
process	O
,	O
models	O
trained	O
directly	O
on	O
this	O
data	O
could	O
overfit	O
on	O
spurious	O
correlations	O
(	O
Jia	O
and	O
Liang	O
,	O
2017	O
;	O
Wang	O
and	O
Bansal	O
,	O
2018	O
)	O
.	O
Thus	O
,	O
we	O
apply	O
various	O
perturbations	O
to	O
the	O
context	O
such	O
as	O
separating	O
the	O
question	O
and	O
answer	O
utterances	O
,	O
converting	O
to	O
unanswerable	O
questions	O
by	O
removing	O
relevant	O
sentences	O
,	O
creating	O
more	O
speaker	O
transitions	O
,	O
and	O
masking	O
speaker	O
names	O
.	O
Refer	O
to	O
Appendix	O
F	O
for	O
additional	O
details	O
.	O

1	O
.	O
You	O
can	O
see	O
the	O
data	O
in	O
"	O
sample_200.txt	O
"	O
,	O
which	O
contains	O
results	O
of	O
200	O
sentences	O
.	O

SPR	B-MethodName
follows	O
the	O
work	O
of	O
Dowty	O
(	O
1991	O
)	O
and	O
discards	O
the	O
notion	O
of	O
categorical	O
semantic	O
roles	O
in	O
favor	O
of	O
feature	O
bundles	O
.	O

To	O
better	O
understand	O
the	O
relationship	O
between	O
intrinsic	O
and	O
extrinsic	O
fairness	O
metrics	O
,	O
we	O
conduct	O
extensive	O
experiments	O
on	O
19	O
pre	O
-	O
trained	O
language	O
models	O
(	O
BERT	B-MethodName
,	O
etc	O
.	O
)	O
.	O
We	O
delve	O
into	O
three	O
kinds	O
of	O
biases	O
,	O
toxicity	O
,	O
sentiment	O
,	O
and	O
stereotype	O
,	O
with	O
six	O
fairness	O
metrics	O
across	O
intrinsic	O
and	O
extrinsic	O
metrics	O
,	O
in	O
text	O
classification	O
and	O
generation	O
downstream	O
settings	O
.	O
The	O
protected	O
group	O
domains	O
we	O
focus	O
on	O
are	O
gender	O
,	O
race	O
,	O
and	O
religion	O
.	O

-DOCSTART-	O
We	O
harness	O
neural	O
language	O
and	O
commonsense	O
models	O
to	O
study	O
how	O
cognitive	O
processes	O
of	O
recollection	O
and	O
imagination	O
are	O
engaged	O
in	O
storytelling	O
.	O
We	O
rely	O
on	O
two	O
key	O
aspects	O
of	O
stories	O
:	O
narrative	O
flow	O
(	O
how	O
the	O
story	O
reads	O
)	O
and	O
semantic	O
vs.	O
episodic	O
knowledge	O
(	O
the	O
types	O
of	O
events	O
in	O
the	O
story	O
)	O
.	O
We	O
propose	O
as	O
a	O
measure	O
of	O
narrative	O
flow	O
the	O
likelihood	O
of	O
sentences	O
under	O
generative	O
language	O
models	O
conditioned	O
on	O
varying	O
amounts	O
of	O
history	O
.	O
Then	O
,	O
we	O
quantify	O
semantic	O
knowledge	O
by	O
measuring	O
the	O
frequency	O
of	O
commonsense	O
events	O
(	O
from	O
the	O
ATOMIC	O
knowledge	O
graph	O
;	O
Sap	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
episodic	O
knowledge	O
by	O
counting	O
realis	O
events	O
(	O
Sims	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
both	O
shown	O
in	O
Figure	O
1	O
.	O

To	O
refine	O
distractors	O
,	O
we	O
use	O
the	O
"	O
Large	O
"	O
version	O
of	O
RoBERTa	O
and	O
all	O
models	O
are	O
trained	O
for	O
4	O
epochs	O
and	O
a	O
learning	O
rate	O
of	O
1	B-HyperparameterValue
×	O
10	I-MetricValue
−5	I-MetricValue
.	O
These	O
hyperparameters	O
are	O
chosen	O
based	O
on	O
previous	O
experiments	O
with	O
RoBERTa	O
on	O
other	O
multiple	O
-	O
choice	O
datasets	O
.	O
The	O
final	O
UnifiedQA	O
fine	O
-	O
tuning	O
is	O
done	O
using	O
the	O
same	O
multiple	O
choices	O
question	O
answering	O
setup	O
as	O
the	O
one	O
used	O
in	O
the	O
original	O
UnifiedQA	O
paper	O
(	O
Khashabi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
use	O
the	O
"	O
Large	O
"	O
version	O
of	O
UnifiedQA	B-MethodName
and	O
all	O
the	O
models	O
are	O
trained	O
for	O
4	O
epochs	O
using	O
Adafactor	O
and	O
a	O
learning	O
rate	O
of	O
1	O
×	O
10	I-MetricValue
−5	I-MetricValue
.	O
The	O
learning	O
rate	O
is	O
loosely	O
tuned	O
to	O
get	O
the	O
best	O
performance	O
on	O
the	O
validation	O
set	O
during	O
the	O
supervised	O
training	O
of	O
UnifiedQA	B-MethodName
.	O
We	O
use	O
the	O
Hugging	O
Face	O
pytorch	O
-	O
transformers	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
library	O
for	O
model	O
implementation	O
.	O
Experiments	O
presented	O
in	O
this	O
paper	O
were	O
carried	O
out	O
using	O
the	O
Grid'5000	O
testbed	O
(	O
Balouek	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
supported	O
by	O
a	O
scientific	O
interest	O
group	O
hosted	O
by	O
Inria	O
and	O
including	O
CNRS	O
,	O
RENATER	O
and	O
several	O
Universities	O
as	O
well	O
as	O
other	O
organizations	O
(	O
see	O
https://www.grid5000.fr	O
)	O
.	O

In	O
order	O
to	O
create	O
questions	O
from	O
a	O
single	O
constituency	O
structure	O
,	O
jsRealB	O
uses	O
the	O
classical	O
grammar	O
transformations	O
:	O
for	O
a	O
who	O
question	O
,	O
it	O
removes	O
the	O
subject	O
(	O
i.e.	O
the	O
first	O
noun	O
phrase	O
before	O
the	O
verb	O
phrase	O
)	O
,	O
for	O
a	O
what	O
question	O
,	O
it	O
removes	O
the	O
subject	O
or	O
the	O
direct	O
object	O
(	O
i.e.	O
the	O
first	O
noun	O
phrase	O
within	O
the	O
verb	O
phrase	O
)	O
;	O
for	O
other	O
types	O
of	O
questions	O
(	O
when	O
,	O
where	O
)	O
it	O
removes	O
the	O
first	O
prepositional	O
phrase	O
within	O
the	O
verb	O
phrase	O
.	O
Depending	O
on	O
the	O
preposition	O
,	O
the	O
question	O
will	O
be	O
a	O
when	O
or	O
a	O
where	O
.	O
Note	O
that	O
the	O
removed	O
part	O
becomes	O
the	O
answer	O
to	O
the	O
question	O
.	O

Task	O
definitions	O
.	O
Our	O
rich	O
graph	O
-	O
based	O
annotation	O
scheme	O
allows	O
for	O
a	O
number	O
of	O
information	O
extraction	O
tasks	O
.	O
In	O
the	O
scope	O
of	O
this	O
paper	O
,	O
we	O
address	O
the	O
following	O
steps	O
of	O
(	O
1	O
)	O
identifying	O
sentences	O
that	O
describe	O
SOFC	O
-	O
related	O
experiments	O
,	O
(	O
2	O
)	O
recognizing	O
and	O
typing	O
relevant	O
named	O
entities	O
,	O
and	O

n	O
t=1	O
−	O
log	O
n•p	O
θ	O
(	O
xt|x	O
\t	O
)	O
n•p	O
θ	O
(	O
xt|x	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
.	O
2	O
.	O
Sample	O
k	O
negative	O
samples	O
according	O
to	O
t	O
∼	O
unif{1	O
,	O
n},x	O
t	O
∼	O
q(x	O
t	O
|x	O
\t	O
)	O
.	O
3	O
.	O
For	O
each	O
negative	O
sample	O
,	O
add	O
to	O
the	O
loss	O
−	O
log	O
k•q(xt|x	O
\t	O
)	O
n•p	O
θ	O
(	O
xt|x	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
.	O

One	O
limitation	O
of	O
our	O
model	O
is	O
that	O
,	O
similar	O
to	O
existing	O
ED	O
models	O
,	O
our	O
model	O
can	O
not	O
handle	O
entities	O
that	O
are	O
not	O
included	O
in	O
the	O
vocabulary	O
.	O
In	O
our	O
future	O
work	O
,	O
we	O
will	O
investigate	O
the	O
method	O
to	O
compute	O
the	O
embeddings	O
of	O
such	O
entities	O
using	O
a	O
post	O
-	O
hoc	O
training	O
with	O
an	O
extended	O
vocabulary	O
(	O
Tai	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

In	O
this	O
paper	O
,	O
we	O
build	O
the	O
optimal	O
translation	O
policy	O
under	O
all	O
latency	O
by	O
simply	O
setting	O
the	O
search	O
interval	O
,	O
achieving	O
high	O
performance	O
.	O
However	O
,	O
we	O
think	O
that	O
the	O
performance	O
of	O
our	O
method	O
can	O
be	O
further	O
improved	O
by	O
exploring	O
more	O
interval	O
settings	O
.	O
Additionally	O
,	O
although	O
we	O
train	O
the	O
agent	O
using	O
a	O
simple	O
architecture	O
and	O
achieve	O
good	O
performance	O
,	O
there	O
exists	O
a	O
performance	O
gap	O
between	O
the	O
learned	O
policy	O
and	O
the	O
searched	O
optimal	O
policy	O
under	O
low	O
latency	O
.	O
Exploring	O
more	O
powerful	O
models	O
of	O
the	O
agent	O
may	O
help	O
improve	O
the	O
performance	O
and	O
we	O
leave	O
it	O
for	O
future	O
work	O
.	O

Step	O
1	O
:	O
Preliminary	O
annotations	O
To	O
ensure	O
the	O
feasibility	O
of	O
creating	O
a	O
dataset	O
for	O
this	O
task	O
,	O
two	O
experts	O
(	O
a	O
post	O
-	O
doctoral	O
researcher	O
and	O
an	O
undergraduate	O
student	O
with	O
NLP	O
background	O
)	O
independently	O
annotate	O
800	O
random	O
samples	O
(	O
from	O
four	O
topics	O
,	O
200	O
per	O
topic	O
)	O
taken	O
from	O
the	O
UKP	O
-	O
Corpus	O
.	O
The	O
annotations	O
are	O
binary	O
and	O
on	O
token	O
-	O
level	O
,	O
where	O
multiple	O
spans	O
of	O
tokens	O
could	O
be	O
selected	O
as	O
aspects	O
.	O
The	O
resulting	O
inter	O
-	O
annotator	O
agreement	O
of	O
this	O
study	O
is	O
Krippendorff	O
's	O
α	O
u	O
=	O
.38	O
.	O
While	O
this	O
shows	O
that	O
the	O
task	O
is	O
generally	O
feasible	O
,	O
the	O
agreement	O
on	O
exact	O
token	O
spans	O
is	O
rather	O
low	O
.	O
Hence	O
,	O
in	O
the	O
following	O
steps	O
,	O
we	O
reduce	O
the	O
complexity	O
of	O
the	O
annotation	O
task	O
.	O

where	O
E	O
=	O
E	O
L	O
∩	O
E	O
C	O
.	O
As	O
a	O
result	O
,	O
the	O
loss	O
function	O
L	O
2	O
enables	O
PAR	O
to	O
ensure	O
ideological	O
stance	O
consistency	O
among	O
political	O
actors	O
.	O

With	O
respect	O
to	O
benefiting	O
patients	O
,	O
the	O
discussion	O
of	O
natural	O
language	O
artifacts	O
we	O
have	O
presented	O
is	O
intended	O
to	O
encourage	O
clinical	O
researchers	O
who	O
rely	O
on	O
(	O
or	O
construct	O
)	O
expert	O
-	O
annotated	O
clinical	O
corpora	O
to	O
train	O
domain	O
-	O
specific	O
language	O
models	O
,	O
or	O
consume	O
such	O
models	O
to	O
perform	O
downstream	O
tasks	O
,	O
to	O
be	O
aware	O
of	O
the	O
presence	O
of	O
annotation	O
artifacts	O
,	O
and	O
adjust	O
their	O
assessments	O
of	O
model	O
performance	O
accordingly	O
.	O
It	O
is	O
our	O
hope	O
that	O
these	O
findings	O
can	O
be	O
used	O
to	O
inform	O
error	O
analysis	O
and	O
improve	O
predictive	O
models	O
that	O
inform	O
patient	O
care	O
.	O

For	O
any	O
given	O
example	O
,	O
the	O
higher	O
the	O
cross	O
-	O
entropy	O
is	O
,	O
the	O
poorer	O
the	O
quality	O
of	O
the	O
corresponding	O
translation	O
,	O
which	O
reflects	O
the	O
inability	O
in	O
this	O
case	O
.	O

Morphophonology	O
refers	O
to	O
the	O
bidirectional	O
interaction	O
between	O
phonology	O
and	O
morphology	O
and	O
is	O
crucial	O
for	O
understanding	O
how	O
morphologically	O
related	O
words	O
may	O
nevertheless	O
surface	O
with	O
different	O
forms	O
.	O
Arabic	O
exhibits	O
pervasive	O
morphophonological	O
processes	O
governed	O
by	O
phonological	O
constraints	O
on	O
syllable	O
structure	O
which	O
interact	O
both	O
with	O
concatenative	O
and	O
templatic	O
morphology	O
.	O
2	O
To	O
make	O
matters	O
more	O
complex	O
,	O
Arabic	O
varieties	O
exhibit	O
distinct	O
morphophonological	O
processes	O
,	O
so	O
words	O
with	O
identical	O
morphological	O
analyses	O
may	O
have	O
different	O
forms	O
.	O
Table	O
1	O
demonstrates	O
dialectal	O
variation	O
in	O
surface	O
realizations	O
for	O
the	O
same	O
morphological	O
analysis	O
.	O

We	O
conduct	O
experiments	O
on	O
word	O
order	O
-	O
diverse	O
language	O
pairs	O
:	O
WMT'14	B-DatasetName
English⇒German	O
(	O
En	O
-	O
De	O
)	O
,	O
WAT'17	O
Japanese⇒English	O
(	O
Ja	O
-	O
En	O
)	O
,	O
and	O
WMT'17	B-DatasetName
Chinese⇔English	O
(	O
Zh	O
-	O
En	O
&	O
En	O
-	O
Zh	O
)	O
.	O

•	O
20Newsgroups	O
:	O
We	O
downloaded	O
the	O
standard	O
splits	O
of	O
the	O
dataset	O
using	O
scikit	O
-	O
learn	O
11	O
.	O
The	O
header	O
and	O
the	O
footer	O
of	O
each	O
text	O
were	O
removed	O
.	O

In	O
this	O
section	O
,	O
We	O
evaluate	O
our	O
method	O
on	O
seven	O
Semantic	B-MethodName
Textual	O
Similarity	I-TaskName
(	O
STS	O
)	O
tasks	O
and	O
seven	O
transfer	O
tasks	O
.	O
We	O
use	O
the	O
SentEval	B-MethodName
(	O
Conneau	O
and	O
Kiela	O
,	O
2018	O
)	O
toolkit	O
for	O
all	O
of	O
tasks	O
.	O

Then	O
we	O
start	O
investigating	O
the	O
impact	O
of	O
the	O
additional	O
bilingual	O
dataset	O
on	O
the	O
model	O
performance	O
.	O

Perplexity	O
is	O
one	O
of	O
the	O
most	O
common	O
metrics	O
for	O
evaluating	O
language	O
models	O
,	O
and	O
is	O
defined	O
as	O
the	O
exponential	O
average	O
negative	O
log	O
-	O
likelihood	O
of	O
a	O
sequence	O
:	O

Contributions	O
.	O
This	O
work	O
studies	O
the	O
effect	O
of	O
the	O
linguistic	O
formalism	O
on	O
probing	O
results	O
.	O
We	O
conduct	O
cross	O
-	O
formalism	O
experiments	O
on	O
PropBank	B-MethodName
,	O
VerbNet	B-MethodName
and	O
FrameNet	B-MethodName
role	I-TaskName
prediction	I-TaskName
in	O
English	O
and	O
German	O
,	O
and	O
show	O
that	O
the	O
formalism	O
can	O
affect	O
probing	O
results	O
in	O
a	O
linguistically	O
meaningful	O
way	O
;	O
in	O
addition	O
,	O
we	O
demonstrate	O
that	O
layer	O
probing	O
can	O
detect	O
subtle	O
differences	O
between	O
implementations	O
of	O
the	O
same	O
formalism	O
in	O
different	O
languages	O
.	O
On	O
the	O
technical	O
side	O
,	O
we	O
advance	O
the	O
recently	O
introduced	O
edge	O
and	O
layer	O
probing	O
framework	O
(	O
Tenney	O
et	O
al	O
.	O
,	O
2019b	O
)	O
;	O
in	O
particular	O
,	O
we	O
introduce	O
anchor	O
tasks	O
-an	O
analytical	O
tool	O
inspired	O
by	O
feature	O
-	O
based	O
systems	O
that	O
allows	O
deeper	O
qualitative	O
insights	O
into	O
the	O
pre	O
-	O
trained	O
models	O
'	O
behaviour	O
.	O
Finally	O
,	O
advancing	O
the	O
current	O
knowledge	O
about	O
the	O
encoding	O
of	O
predicate	O
semantics	O
in	O
BERT	B-MethodName
,	O
we	O
perform	O
a	O
fine	O
-	O
grained	O
semantic	O
proto	O
-	O
role	O
probing	O
study	O
and	O
demonstrate	O
that	O
semantic	O
proto	O
-	O
role	O
properties	O
can	O
be	O
extracted	O
from	O
pre	O
-	O
trained	O
BERT	B-MethodName
,	O
contrary	O
to	O
the	O
existing	O
reports	O
.	O
Our	O
results	O
suggest	O
that	O
along	O
with	O
task	O
and	O
language	O
,	O
linguistic	O
formalism	O
is	O
an	O
important	O
dimension	O
to	O
be	O
accounted	O
for	O
in	O
probing	O
research	O
.	O

Table	O
6	O
shows	O
more	O
cases	O
when	O
deleting	O
all	O
instances	O
containing	O
specific	O
words	O
,	O
including	O
"	O
be	O
-	O
come	O
"	O
(	O
verb	O
)	O
,	O
"	O
fresh	O
"	O
(	O
adjective	O
)	O
,	O
and	O
"	O
energy	O
"	O
(	O
noun	O
)	O
.	O
We	O
can	O
find	O
that	O
unlearned	O
models	O
(	O
i.e.	O
,	O
RE	B-MethodName
-	I-MethodName
TRAIN	I-MethodName
and	O
KGA	B-MethodName
)	O
tend	O
to	O
generate	O
alternatives	O
with	O
similar	O
meanings	O
regardless	O
of	O
the	O
part	O
of	O
speech	O
.	O

While	O
ELECTRA	B-MethodName
learns	O
whether	O
a	O
token	O
is	O
more	O
likely	O
to	O
come	O
from	O
the	O
data	O
distribution	O
p	O
data	O
or	O
noise	O
distribution	O
q	O
,	O
Electric	O
only	O
learns	O
p	O
data	O
because	O
q	O
is	O
passed	O
into	O
the	O
model	O
directly	O
.	O
This	O
difference	O
is	O
analogous	O
to	O
using	O
negative	O
sampling	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
vs.	O
noise	O
-	O
contrastive	O
estimation	O
(	O
Mnih	O
and	O
Kavukcuoglu	O
,	O
2013	O
)	O
for	O
learning	O
word	O
embeddings	O
.	O
A	O
disadvantage	O
of	O
Electric	O
compared	O
to	O
ELEC	B-MethodName
-	I-MethodName
TRA	I-MethodName
is	O
that	O
it	O
is	O
less	O
flexible	O
in	O
the	O
choice	O
of	O
noise	O
distribution	O
.	O
Since	O
ELECTRA	O
's	O
binary	O
classifier	O
does	O
not	O
need	O
to	O
access	O
q	O
,	O
its	O
q	O
only	O
needs	O
to	O
be	O
defined	O
for	O
negative	O
sample	O
positions	O
in	O
the	O
input	O
sequence	O
.	O
Therefore	O
ELECTRA	B-MethodName
can	O
use	O
a	O
masked	O
language	O
model	O
rather	O
than	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
for	O
q.	O
An	O
advantage	O
of	O
Electric	O
is	O
that	O
it	O
directly	O
provides	O
(	O
un	O
-	O
normalized	O
)	O
probabilitieŝ	O
p	O
θ	O
for	O
tokens	O
,	O
making	O
it	O
useful	O
for	O
applications	O
such	O
as	O
re	O
-	O
ranking	O
the	O
outputs	O
of	O
text	O
generation	O
systems	O
.	O
The	O
differences	O
between	O
ELECTRA	O
and	O
Electric	O
are	O
summarized	O
below	O
:	O

We	O
can	O
improve	O
on	O
this	O
by	O
adding	O
some	O
structure	O
to	O
this	O
representation	O
by	O
teaching	O
our	O
model	O
that	O
the	O
v	O
i	O
belong	O
to	O
different	O
segments	O
.	O
As	O
in	O
the	O
baseline	O
candidate	O
re	O
-	O
ranking	O
model	O
,	O
we	O
do	O
this	O
by	O
separating	O
them	O
with	O
[	O
SEP	O
]	O
tokens	O
.	O
We	O
call	O
this	O
[	O
SEP]-separation	O
.	O
This	O
approach	O
is	O
also	O
used	O
by	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
andMulang	O
'	O
et	O
al	O
.	O
(	O
2020	O
)	O
"	O
name	O
"	O
:	O
"	O
Douglas	O
Adams	O
"	O
"	O
place	O
of	O
birth	O
"	O
:	O
"	O
Cambridge	O
"	O
"	O
occupation	O
"	O
:	O
"	O
novelist	O
"	O
"	O
employer	O
"	O
:	O
"	O
BBC	O
"	O
to	O
separate	O
the	O
entity	O
attributes	O
in	O
their	O
respective	O
KBs	O
.	O

1	O
.	O
An	O
attention	O
check	O
in	O
the	O
recruitment	O
qualification	O
task	O
(	O
"	O
How	O
many	O
letters	O
are	O
in	O
the	O
word	O
'	O
banana	O
'	O
?	O
"	O
)	O
;	O
we	O
only	O
recruited	O
participants	O
who	O
passed	O
this	O
initial	O
attention	O
check	O
.	O

The	O
last	O
inequality	O
is	O
an	O
empirical	O
conclusion	O
,	O
since	O
in	O
our	O
experiments	O
l	O
≈	O
10	O
while	O
d	O
=	O
32	O
in	O
most	O
situations	O
.	O

We	O
considered	O
two	O
tasks	O
in	O
this	O
experiment	O
.	O
The	O
first	O
task	O
aims	O
to	O
classify	O
"	O
Christianity	O
"	O
vs	O
"	O
Atheism	O
"	O
documents	O
from	O
the	O
20	B-DatasetName
Newsgroups	I-DatasetName
dataset	O
5	O
.	O
This	O
dataset	O
is	O
special	O
because	O
it	O
contains	O
a	O
lot	O
of	O
artifacts	O
-tokens	O
(	O
e.g.	O
,	O
person	O
names	O
,	O
punctuation	O
marks	O
)	O
which	O
are	O
not	O
relevant	O
,	O
but	O
strongly	O
co	O
-	O
occur	O
with	O
one	O
of	O
the	O
classes	O
.	O
For	O
evaluation	O
,	O
we	O
used	O
the	O
Religion	O
dataset	O
by	O
Ribeiro	O
et	O
al	O
.	O
(	O
2016	O
)	O
,	O
containing	O
"	O
Christianity	O
"	O
and	O
"	O
Atheism	O
"	O
web	O
pages	O
,	O
as	O
a	O
target	O
dataset	O
.	O
The	O
second	O
task	O
is	O
sentiment	O
analysis	O
.	O
We	O
used	O
,	O
as	O
a	O
training	O
dataset	O
,	O
Amazon	O
Clothes	O
,	O
with	O
reviews	O
of	O
clothing	O
,	O
shoes	O
,	O
and	O
jewelry	O
products	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
,	O
and	O
as	O
test	O
sets	O
three	O
out	O
-	O
of	O
-	O
distribution	O
datasets	O
-Amazon	O
Music	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
,	O
Amazon	O
Mixed	O
,	O
and	O
the	O
Yelp	O
dataset	O
(	O
which	O
was	O
used	O
in	O
Experiment	O
1	O
)	O
.	O
Amazon	O
Music	O
contains	O
only	O
reviews	O
from	O
the	O
"	O
Digital	O
Music	O
"	O
product	O
category	O
which	O
was	O
found	O
to	O
have	O
an	O
extreme	O
distribution	O
shift	O
from	O
the	O
clothes	O
category	O
(	O
Hendrycks	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Amazon	O
Mixed	O
compiles	O
the	O
reviews	O
from	O
various	O
kinds	O
of	O
products	O
,	O
while	O
Yelp	O
focuses	O
on	O
restaurant	O
reviews	O
.	O

Most	O
previous	O
work	O
seeking	O
the	O
numerical	O
solution	O
for	O
low	O
-	O
rank	O
approximation	O
is	O
designed	O
for	O
unweighted	O
cases	O
,	O
with	O
applications	O
such	O
as	O
predicting	O
the	O
missing	O
values	O
recommendation	O
system	O
(	O
Yu	O
et	O
al	O
.	O
,	O
2014	O
;	O
Zhou	O
et	O
al	O
.	O
,	O
2008	O
)	O
.	O
Also	O
,	O
a	O
few	O
attempts	O
have	O
been	O
made	O
to	O
solve	O
the	O
weighted	O
lowrank	O
approximation	O
problem	O
through	O
EM	O
-	O
based	O
algorithm	O
(	O
Srebro	O
and	O
Jaakkola	O
,	O
2003	O
)	O
,	O
or	O
alternating	O
least	O
squares	O
(	O
He	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O

Effect	O
of	O
τ	O
in	O
HeadXL	B-MethodName
SANs	O

We	O
introduce	O
an	O
LM	O
-	O
based	O
knowledge	O
tracing	O
model	O
(	O
LM	O
-	O
KT	O
)	O
to	O
predict	O
students	O
'	O
difficulty	O
on	O
novel	O
questions	O
(	O
e.g.	O
target	O
phrases	O
to	O
translate	O
)	O
.	O
We	O
show	O
that	O
LM	O
-	O
KT	O
is	O
well	O
-	O
calibrated	O
,	O
allowing	O
us	O
to	O
pose	O
the	O
learning	O
problem	O
for	O
the	O
question	O
generator	O
:	O
given	O
a	O
student	O
state	O
,	O
generate	O
a	O
question	O
that	O
will	O
achieve	O
a	O
target	O
difficulty	O
,	O
according	O
to	O
LM	O
-	O
KT	O
.	O
We	O
evaluate	O
both	O
LM	O
-	O
KT	O
and	O
question	O
generation	O
models	O
on	O
real	O
users	O
and	O
responses	O
from	O
Duolingo	O
1	O
,	O
a	O
popular	O
online	O
second	O
-	O
language	O
learning	O
platform	O
.	O

We	O
also	O
experimented	O
with	O
zero	O
-	O
shot	O
QE	O
with	O
multilingual	O
QE	O
models	O
.	O
We	O
trained	O
the	O
QE	O
model	O
in	O
all	O
the	O
pairs	O
except	O
one	O
and	O
performed	O
predic	O
-	O
tion	O
on	O
the	O
test	O
set	O
of	O
the	O
language	O
pair	O
left	O
out	O
.	O
In	O
section	O
II	O
(	O
"	O
All-1	O
"	O
)	O
,	O
we	O
show	O
its	O
difference	O
to	O
the	O
multilingual	O
QE	O
model	O
.	O
This	O
also	O
provides	O
competitive	O
results	O
for	O
the	O
majority	O
of	O
the	O
languages	O
,	O
proving	O
it	O
is	O
possible	O
to	O
train	O
a	O
single	O
multilingual	O
QE	O
model	O
and	O
extend	O
it	O
to	O
a	O
multitude	O
of	O
languages	O
and	O
domains	O
.	O
This	O
approach	O
provides	O
better	O
results	O
than	O
performing	O
transfer	O
learning	O
from	O
a	O
bilingual	O
model	O
.	O

To	O
enable	O
applying	O
BC	O
for	O
text	O
-	O
based	O
reasoning	O
,	O
we	O
introduce	O
four	O
LM	O
-	O
based	O
modules	O
:	O
Fact	O
Check	O
,	O
Rule	O
Selection	O
,	O
Goal	O
Decomposition	O
,	O
and	O
Sign	O
Agreement	O
,	O
each	O
implemented	O
by	O
showing	O
relevant	O
in	O
-	O
context	O
demonstrations	O
to	O
a	O
pretrained	O
LM	O
(	O
see	O
Appendix	O
D.3	O
for	O
details	O
)	O
.	O
We	O
describe	O
these	O
modules	O
and	O
then	O
proceed	O
to	O
the	O
full	O
algorithm	O
.	O

Probing	O
.	O
We	O
probe	O
the	O
representation	O
of	O
a	O
profession	O
word	O
as	O
extracted	O
from	O
Winobias	O
sentences	O
,	O

The	O
noise	O
distribution	O
q	O
comes	O
from	O
a	O
neural	O
network	O
trained	O
to	O
match	O
p	O
data	O
.	O
NCE	B-MethodName
commonly	O
employs	O
this	O
idea	O
to	O
ensure	O
the	O
classification	O
task	O
is	O
sufficiently	O
challenging	O
for	O
the	O
model	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010;Wang	O
and	O
Ou	O
,	O
2018	O
)	O
.	O
In	O
particular	O
,	O
we	O
use	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
as	O
proposed	O
by	O
Baevski	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
is	O
more	O
accurate	O
than	O
a	O
language	O
model	O
because	O
it	O
uses	O
context	O
to	O
both	O
sides	O
of	O
each	O
token	O
.	O
The	O
model	O
runs	O
two	O
transformers	O
T	B-MethodName
LTR	O
and	O
T	B-MethodName
RTL	O
over	O
the	O
input	O
sequence	O
.	O
These	O
transformers	O
apply	O
causal	O
masking	O
so	O
one	O
processes	O
the	O
sequence	O
left	O
-	O
to	O
-	O
right	O
and	O
the	O
other	O
operates	O
right	O
-	O
to	O
-	O
left	O
.	O
The	O
model	O
's	O
predictions	O
come	O
from	O
a	O
softmax	O
layer	O
applied	O
to	O
the	O
concatenated	O
states	O
of	O
the	O
two	O
transformers	O
:	O

D1	O
.	O
Did	O
you	O
report	O
the	O
full	O
text	O
of	O
instructions	O
given	O
to	O
participants	O
,	O
including	O
e.g.	O
,	O
screenshots	O
,	O
disclaimers	O
of	O
any	O
risks	O
to	O
participants	O
or	O
annotators	O
,	O
etc	O
.	O
?	O
Appendix	O
B	O
D2	O
.	O
Did	O
you	O
report	O
information	O
about	O
how	O
you	O
recruited	O
(	O
e.g.	O
,	O
crowdsourcing	O
platform	O
,	O
students	O
)	O
and	O
paid	O
participants	O
,	O
and	O
discuss	O
if	O
such	O
payment	O
is	O
adequate	O
given	O
the	O
participants	O
'	O
demographic	O
(	O
e.g.	O
,	O
country	O
of	O
residence	O
)	O
?	O
Appendix	O
B	O
D3	O
.	O
Did	O
you	O
discuss	O
whether	O
and	O
how	O
consent	O
was	O
obtained	O
from	O
people	O
whose	O
data	O
you	O
're	O
using	O
/	O
curating	O
?	O
For	O
example	O
,	O
if	O
you	O
collected	O
data	O
via	O
crowdsourcing	O
,	O
did	O
your	O
instructions	O
to	O
crowdworkers	O
explain	O
how	O
the	O
data	O
would	O
be	O
used	O
?	O
Not	O
applicable	O
.	O
Left	O
blank	O
.	O

•	O
We	O
introduce	O
a	O
new	O
task	O
named	O
Grounded	O
Multimodal	I-MethodName
Named	I-MethodName
Entity	I-MethodName
Recognition	I-MethodName
(	O
GMNER	B-MethodName
)	O
,	O
which	O
aims	O
to	O
extract	O
all	O
the	O
entity	O
-	O
type	O
-	O
region	O
triples	O
from	O
a	O
text	O
-	O
image	O
pair	O
.	O
Moreover	O
,	O
we	O
construct	O
a	O
Twitter	O
dataset	O
for	O
the	O
task	O
based	O
on	O
two	O
existing	O
MNER	O
datasets	O
.	O
•	O
We	O
extend	O
four	O
well	O
-	O
known	O
MNER	O
methods	O
to	O
benchmark	O
the	O
GMNER	O
task	O
and	O
further	O
propose	O
a	O
Hierarchical	O
Index	O
generation	O
framework	O
named	O
H	O
-	O
Index	O
,	O
which	O
generates	O
the	O
entity	O
-	O
typeregion	O
triples	O
in	O
a	O
hierarchical	O
manner	O
.	O
•	O
Experimental	O
results	O
on	O
our	O
annotated	O
dataset	O
show	O
that	O
the	O
proposed	O
H	O
-	O
Index	O
framework	O
performs	O
significantly	O
better	O
than	O
a	O
number	O
of	O
unimodal	O
and	O
multimodal	O
baseline	O
systems	O
on	O
the	O
GMNER	O
task	O
,	O
and	O
outperforms	O
the	O
second	O
best	O
system	O
by	O
3.96	O
%	O
absolute	O
percentage	O
points	O
on	O
F1	B-MetricName
score	O
.	O

Comparing	O
VA	B-MethodName
-	I-MethodName
Rand	I-MethodName
to	O
vip	O
-	O
AnT	O
,	O
we	O
see	O
accuracy	O
increases	O
in	O
all	O
classification	O
and	O
retrieval	O
setups	O
.	O
For	O
example	O
,	O
on	O
AudioCaps	B-MethodName
,	O
vip	O
-	O
AnT	O
outperforms	O
VA	B-MethodName
-	I-MethodName
Rand	I-MethodName
by	O
4.5	O
%	I-MetricValue
R	O
@	O
1	O
and	O
13.6	O
%	I-MetricValue
R	O
@	O
10	I-MetricValue
.	O
This	O
confirms	O
that	O
the	O
findings	O
of	O
carry	O
-	O
over	O
to	O
unsupervised	O
audio	O
pre	O
-	O
training	O
.	O

Table	O
18	O
shows	O
some	O
examples	O
of	O
variation	O
in	O
tokenization	O
.	O

Objective	O
AT	O
Supervision	O
VT	O
Alignment	O
Zero	O
-	O
shot	O
AT	O
Retrieval	O
MMV	O
(	O
Alayrac	O
et	O
al	O
.	O
,	O
2020	O
)	O
Random	O
L	O
bi	O
-	O
bi	O
None	O
Trainable	O
VATT	O
(	O
Akbari	O
et	O
al	O
.	O
,	O
2021	O
)	O
Random	O
L	O
bi	O
-	O
bi	O
None	O
Trainable	O
AudioCLIP	O
(	O
Guzhov	O
et	O
al	O
.	O
,	O
2021a	O
)	O
ImageNet	O
L	O
tri	O
2	O
M	O
Audio	O
Tags	O
Trainable	O
Wav2CLIP	B-DatasetName
(	O
Wu	O
et	O
al	O
.	O
,	O
2021	O
)	O
Random	O

We	O
used	O
this	O
propagation	O
rule	O
,	O
so	O
called	O
LRP-	B-MethodName
,	O
in	O
the	O
experiments	O
of	O
this	O
paper	O
.	O
For	O
more	O
details	O
about	O
LRP	B-MethodName
propagation	O
rules	O
,	O
please	O
see	O
Montavon	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

