-DOCSTART- -X- O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2022 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
1 -X- _ O
- -X- _ O
11 -X- _ O
July -X- _ O
10 -X- _ O
- -X- _ O
15 -X- _ O
, -X- _ O
2022 -X- _ O
© -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Social -X- _ O
Norms -X- _ O
Guide -X- _ O
Reference -X- _ O
Resolution -X- _ O
Mitchell -X- _ O
Abrams -X- _ O
andMatthias -X- _ O
Scheutz -X- _ O
Human -X- _ O
- -X- _ O
Robot -X- _ O
Interaction -X- _ O
Laboratory -X- _ O
, -X- _ O
Tufts -X- _ O
University -X- _ O
, -X- _ O
Medford -X- _ O
, -X- _ O
MA -X- _ O
02155 -X- _ O
{ -X- _ O
mitchell.abrams -X- _ O
, -X- _ O
matthias.scheutz -X- _ O
} -X- _ O
@ -X- _ O
tufts.edu -X- _ O
Abstract -X- _ O
Humans -X- _ O
use -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
vision -X- _ O
, -X- _ O
and -X- _ O
context -X- _ O
to -X- _ O
resolve -X- _ O
referents -X- _ O
in -X- _ O
their -X- _ O
environment -X- _ O
. -X- _ O

While -X- _ O
some -X- _ O
situated -X- _ O
reference -X- _ O
resolution -X- _ O
is -X- _ O
trivial -X- _ O
, -X- _ O
ambiguous -X- _ O
cases -X- _ O
arise -X- _ O
when -X- _ O
the -X- _ O
language -X- _ O
is -X- _ O
underspecified -X- _ O
or -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
candidate -X- _ O
referents -X- _ O
. -X- _ O

This -X- _ O
study -X- _ O
investigates -X- _ O
how -X- _ O
pragmatic -X- _ O
modulators -X- _ O
external -X- _ O
to -X- _ O
the -X- _ O
linguistic -X- _ O
content -X- _ O
are -X- _ O
critical -X- _ O
for -X- _ O
the -X- _ O
correct -X- _ O
interpretation -X- _ B-TaskName
of -X- _ I-TaskName
referents -X- _ I-TaskName
in -X- _ O
these -X- _ O
scenarios -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
in -X- _ O
a -X- _ O
human -X- _ O
subjects -X- _ O
experiment -X- _ O
how -X- _ O
the -X- _ O
social -X- _ O
norms -X- _ O
applicable -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
context -X- _ O
influence -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
referring -X- _ O
expressions -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
how -X- _ O
current -X- _ O
coreference -X- _ O
tools -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
fail -X- _ O
to -X- _ O
handle -X- _ O
these -X- _ O
ambiguous -X- _ O
cases -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
briefly -X- _ O
discuss -X- _ O
the -X- _ O
implications -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
for -X- _ O
assistive -X- _ O
robots -X- _ O
which -X- _ O
will -X- _ O
routinely -X- _ O
need -X- _ O
to -X- _ O
resolve -X- _ O
referents -X- _ O
in -X- _ O
their -X- _ O
environment -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Humans -X- _ O
interacting -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
need -X- _ O
to -X- _ O
resolve -X- _ O
referential -X- _ O
expressions -X- _ O
often -X- _ O
referring -X- _ O
to -X- _ O
referents -X- _ O
in -X- _ O
their -X- _ O
environment -X- _ O
; -X- _ O
utterances -X- _ O
like -X- _ O
pick -X- _ O
up -X- _ O
the -X- _ O
green -X- _ O
box -X- _ O
orpick -X- _ O
it -X- _ O
up -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
highlight -X- _ O
some -X- _ O
referring -X- _ O
expressions -X- _ O
that -X- _ O
point -X- _ O
to -X- _ O
a -X- _ O
referent -X- _ O
. -X- _ O

These -X- _ O
expressions -X- _ O
appear -X- _ O
in -X- _ O
various -X- _ O
forms -X- _ O
, -X- _ O
from -X- _ O
clear -X- _ O
and -X- _ O
specific -X- _ O
— -X- _ O
the -X- _ O
green -X- _ O
box -X- _ O
— -X- _ O
to -X- _ O
underspecified -X- _ O
and -X- _ O
ambiguous -X- _ O
— -X- _ O
it -X- _ O
. -X- _ O

But -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
, -X- _ O
especially -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
, -X- _ O
also -X- _ O
requires -X- _ O
vision -X- _ O
and -X- _ O
pragmatic -X- _ O
context -X- _ O
to -X- _ O
disambiguate -X- _ O
references -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
linguistically -X- _ O
underspecifed -X- _ O
example -X- _ O
of -X- _ O
pick -X- _ O
it -X- _ O
up -X- _ O
, -X- _ O
a -X- _ O
listener -X- _ O
may -X- _ O
have -X- _ O
to -X- _ O
look -X- _ O
for -X- _ O
the -X- _ O
candidate -X- _ O
objects -X- _ O
in -X- _ O
the -X- _ O
environment -X- _ O
to -X- _ O
figure -X- _ O
out -X- _ O
what -X- _ O
itrefers -X- _ O
to -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
the -X- _ O
social -X- _ O
setting -X- _ O
can -X- _ O
modulate -X- _ O
what -X- _ O
referent -X- _ O
is -X- _ O
intended -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
same -X- _ O
referring -X- _ O
expression -X- _ O
and -X- _ O
objects -X- _ O
in -X- _ O
the -X- _ O
environment -X- _ O
; -X- _ O
in -X- _ O
a -X- _ O
dining -X- _ O
room -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
a -X- _ O
spoon -X- _ O
on -X- _ O
the -X- _ O
ground -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
more -X- _ O
likely -X- _ O
candidate -X- _ O
than -X- _ O
a -X- _ O
pencil -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
pragmatic -X- _ O
modulators -X- _ O
like -X- _ O
this -X- _ O
in -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
. -X- _ O

The -X- _ O
psycholinguistics -X- _ O
literature -X- _ O
has -X- _ O
leveraged -X- _ O
eye -X- _ O
tracking -X- _ O
to -X- _ O
infer -X- _ O
what -X- _ O
referents -X- _ O
humans -X- _ O
resolve -X- _ O
in -X- _ O
various -X- _ O
contexts -X- _ O
( -X- _ O
Tanenhaus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1995 -X- _ O
; -X- _ O
Spivey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2001 -X- _ O
) -X- _ O
. -X- _ O

Pragmatic -X- _ O
modulators -X- _ O
outside -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
content -X- _ O
can -X- _ O
further -X- _ O
constrain -X- _ O
the -X- _ O
referential -X- _ O
domain -X- _ O
and -X- _ O
affect -X- _ O
referent -X- _ O
interpretation -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
task -X- _ O
- -X- _ O
relevant -X- _ O
constraints -X- _ O
( -X- _ O
Hanna -X- _ O
and -X- _ O
Tanenhaus -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
gap -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
in -X- _ O
understanding -X- _ O
how -X- _ O
other -X- _ O
pragmatic -X- _ O
modulators -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
affect -X- _ O
the -X- _ O
interpretation -X- _ B-TaskName
of -X- _ I-TaskName
referents -X- _ I-TaskName
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
while -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
work -X- _ O
on -X- _ O
modeling -X- _ O
what -X- _ O
social -X- _ O
norms -X- _ O
are -X- _ O
activated -X- _ O
in -X- _ O
various -X- _ O
contexts -X- _ O
and -X- _ O
settings -X- _ O
( -X- _ O
Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
how -X- _ O
norms -X- _ O
guide -X- _ O
humans -X- _ O
to -X- _ O
interpret -X- _ O
referring -X- _ O
expressions -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
conventions -X- _ O
such -X- _ O
as -X- _ O
standing -X- _ O
on -X- _ O
the -X- _ O
right -X- _ O
side -X- _ O
of -X- _ O
an -X- _ O
escalator -X- _ O
while -X- _ O
walking -X- _ O
on -X- _ O
the -X- _ O
left -X- _ O
, -X- _ O
or -X- _ O
sitting -X- _ O
in -X- _ O
the -X- _ O
back -X- _ O
of -X- _ O
cab -X- _ O
, -X- _ O
can -X- _ O
have -X- _ O
modulatory -X- _ O
influence -X- _ O
on -X- _ O
reference -X- _ O
resolution -X- _ O
and -X- _ O
object -X- _ O
selection -X- _ O
. -X- _ O

The -X- _ O
aim -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
pragmatic -X- _ O
modulators -X- _ O
, -X- _ O
especially -X- _ O
social -X- _ O
norms -X- _ O
, -X- _ O
in -X- _ O
guiding -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
. -X- _ O

First -X- _ O
we -X- _ O
provide -X- _ O
background -X- _ O
on -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
and -X- _ O
context -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
focus -X- _ O
on -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
in -X- _ O
particular -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
referents -X- _ O
are -X- _ O
guided -X- _ O
by -X- _ O
social -X- _ O
norms -X- _ O
in -X- _ O
certain -X- _ O
contexts -X- _ O
through -X- _ O
a -X- _ O
human -X- _ O
- -X- _ O
subjects -X- _ O
experiment -X- _ O
. -X- _ O

We -X- _ O
proceed -X- _ O
to -X- _ O
compare -X- _ O
results -X- _ O
from -X- _ O
this -X- _ O
experiment -X- _ O
— -X- _ O
the -X- _ O
referents -X- _ O
selected -X- _ O
given -X- _ O
the -X- _ O
situational -X- _ O
context -X- _ O
and -X- _ O
referring -X- _ O
expressions -X- _ O
— -X- _ O
against -X- _ O
several -X- _ O
coreference -X- _ O
tools -X- _ O
that -X- _ O
attempt -X- _ O
to -X- _ O
resolve -X- _ O
these -X- _ O
referents -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
eye -X- _ O
towards -X- _ O
assistive -X- _ O
robots -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
by -X- _ O
outlining -X- _ O
an -X- _ O
approach -X- _ O
for -X- _ O
teaching -X- _ O
robots -X- _ O
to -X- _ O
leverage -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
context -X- _ O
for -X- _ O
object -X- _ O
selection -X- _ O
. -X- _ O

2 -X- _ O
Background -X- _ O
2.1 -X- _ O
Reference -X- _ B-TaskName
Resolution -X- _ I-TaskName
in -X- _ O
NLP -X- _ O
Reference -X- _ O
resolution -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
task -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
approaches -X- _ O
in -X- _ O
NLP -X- _ O
— -X- _ O
through -X- _ O
significant -X- _ O
strides -X- _ O
in -X- _ O
deep -X- _ O
learning—1 -X- _ O

perform -X- _ O
well -X- _ O
on -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
reference -X- _ O
resolution -X- _ O
by -X- _ O
learning -X- _ O
important -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
. -X- _ O

Indeed -X- _ O
, -X- _ O
coreference -X- _ O
phenomenon -X- _ O
are -X- _ O
naturally -X- _ O
guided -X- _ O
by -X- _ O
several -X- _ O
linguistic -X- _ O
phenomena -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
( -X- _ O
Jurafsky -X- _ O
and -X- _ O
Martin -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O

Among -X- _ O
them -X- _ O
are -X- _ O
gender -X- _ O
agreement -X- _ O
, -X- _ O
number -X- _ O
agreement -X- _ O
, -X- _ O
person -X- _ O
agreement -X- _ O
, -X- _ O
recency -X- _ O
, -X- _ O
binding -X- _ O
constraints -X- _ O
, -X- _ O
verb -X- _ O
semantics -X- _ O
, -X- _ O
and -X- _ O
selectional -X- _ O
restrictions -X- _ O
— -X- _ O
features -X- _ O
often -X- _ O
useful -X- _ O
for -X- _ O
coreference -X- _ O
models -X- _ O
in -X- _ O
NLP -X- _ O
such -X- _ O
as -X- _ O
CoreNLP -X- _ B-MethodName
( -X- _ O
Finkel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
more -X- _ O
recent -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
neural -X- _ O
model -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
AllenNLP -X- _ B-MethodName
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
moves -X- _ O
away -X- _ O
from -X- _ O
traditional -X- _ O
engineered -X- _ O
features -X- _ O
and -X- _ O
syntactic -X- _ O
information -X- _ O
and -X- _ O
instead -X- _ O
relies -X- _ O
on -X- _ O
word -X- _ O
embeddings -X- _ O
within -X- _ O
and -X- _ O
around -X- _ O
potential -X- _ O
coreferent -X- _ O
mention -X- _ O
spans -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
spans -X- _ O
, -X- _ O
among -X- _ O
other -X- _ O
approaches -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
while -X- _ O
powerful -X- _ O
models -X- _ O
encode -X- _ O
important -X- _ O
linguistic -X- _ O
cues -X- _ O
for -X- _ O
reference -X- _ B-TaskName
interpretation -X- _ I-TaskName
, -X- _ O
and -X- _ O
use -X- _ O
word -X- _ O
embeddings -X- _ O
to -X- _ O
capture -X- _ O
word -X- _ O
similarity -X- _ O
, -X- _ O
they -X- _ O
fail -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
contextual -X- _ O
knowledge -X- _ O
( -X- _ O
Emami -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
renders -X- _ O
current -X- _ O
NLP -X- _ O
tools -X- _ O
insufficient -X- _ O
for -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
. -X- _ O

Recently -X- _ O
, -X- _ O
coreference -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Winograd -X- _ B-TaskName
Schema -X- _ I-TaskName
Challenge -X- _ I-TaskName
( -X- _ O
WSC -X- _ B-TaskName
) -X- _ O
, -X- _ O
proposed -X- _ O
by -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
challenge -X- _ O
coreference -X- _ O
models -X- _ O
to -X- _ O
handle -X- _ O
world -X- _ O
knowledge -X- _ O
and -X- _ O
common -X- _ O
sense -X- _ O
reasoning -X- _ O
. -X- _ O

The -X- _ O
KnowRef -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Emami -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
coreference -X- _ O
corpus -X- _ O
of -X- _ O
natural -X- _ O
texts -X- _ O
, -X- _ O
provides -X- _ O
a -X- _ O
new -X- _ O
benchmark -X- _ O
for -X- _ O
coreference -X- _ B-TaskName
resolution -X- _ I-TaskName
that -X- _ O
requires -X- _ O
systems -X- _ O
to -X- _ O
reason -X- _ O
about -X- _ O
context -X- _ O
. -X- _ O

The -X- _ O
coreference -X- _ O
task -X- _ O
created -X- _ O
sentences -X- _ O
stripped -X- _ O
of -X- _ O
linguistic -X- _ O
cues -X- _ O
from -X- _ O
syntax -X- _ O
, -X- _ O
gender -X- _ O
agreement -X- _ O
, -X- _ O
and -X- _ O
number -X- _ O
agreement -X- _ O
, -X- _ O
forcing -X- _ O
systems -X- _ O
to -X- _ O
rely -X- _ O
on -X- _ O
context -X- _ O
and -X- _ O
world -X- _ O
knowledge -X- _ O
. -X- _ O

Emami -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
KnowRef -X- _ B-DatasetName
dataset -X- _ O
to -X- _ O
improve -X- _ O
its -X- _ O
accuracy -X- _ O
over -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
systems -X- _ O
can -X- _ O
encode -X- _ O
world -X- _ O
knowledge -X- _ O
and -X- _ O
common -X- _ O
sense -X- _ O
reasoning -X- _ O
to -X- _ O
an -X- _ O
extent -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
these -X- _ O
Winograd -X- _ O
Schema -X- _ O
type -X- _ O
datastets -X- _ O
. -X- _ O

Yet -X- _ O
these -X- _ O
powerful -X- _ O
models -X- _ O
remain -X- _ O
opaque -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
explicitly -X- _ O
model -X- _ O
the -X- _ O
pragmatic -X- _ O
constraints -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
. -X- _ O

3 -X- _ O
Pragmatic -X- _ O
Constraints -X- _ O
and -X- _ O
Social -X- _ O
Norms -X- _ O
Work -X- _ O
on -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
gets -X- _ O
closer -X- _ O
to -X- _ O
modeling -X- _ O
pragmatic -X- _ O
constraints -X- _ O
, -X- _ O
mainly -X- _ O
by -X- _ O
moving -X- _ O
beyond -X- _ O
text -X- _ O
and -X- _ O
considering -X- _ O
gesture -X- _ O
and -X- _ O
context -X- _ O
to -X- _ O
help -X- _ O
disambiguate -X- _ O
referring -X- _ O
expres -X- _ O
- -X- _ O
sions -X- _ O
( -X- _ O
Matuszek -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Whitney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
tion -X- _ O
to -X- _ O
speech -X- _ O
and -X- _ O
gesture -X- _ O
, -X- _ O
incorporates -X- _ O
contextual -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
their -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
where -X- _ O
people -X- _ O
refer -X- _ O
to -X- _ O
objects -X- _ O
on -X- _ O
a -X- _ O
table -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
exploits -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
kitchen -X- _ O
domain -X- _ O
and -X- _ O
uses -X- _ O
recipes -X- _ O
as -X- _ O
a -X- _ O
knowledge -X- _ O
base -X- _ O
to -X- _ O
understand -X- _ O
tools -X- _ O
and -X- _ O
ingredients -X- _ O
that -X- _ O
typically -X- _ O
belong -X- _ O
together -X- _ O
. -X- _ O

Chai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2004 -X- _ O
) -X- _ O
also -X- _ O
uses -X- _ O
domain -X- _ O
knowledge -X- _ O
in -X- _ O
a -X- _ O
graph -X- _ O
- -X- _ O
matching -X- _ O
algorithm -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
referring -X- _ O
expressions -X- _ O
with -X- _ O
a -X- _ O
map -X- _ O
showing -X- _ O
houses -X- _ O
and -X- _ O
prices -X- _ O
. -X- _ O

The -X- _ O
guiding -X- _ O
context -X- _ O
, -X- _ O
here -X- _ O
, -X- _ O
is -X- _ O
conversational -X- _ O
history -X- _ O
and -X- _ O
domain -X- _ O
knowledge -X- _ O
about -X- _ O
house -X- _ O
pricing -X- _ O
. -X- _ O

Within -X- _ O
the -X- _ O
psycholinguistics -X- _ O
literature -X- _ O
, -X- _ O
Hanna -X- _ O
and -X- _ O
Tanenhaus -X- _ O
( -X- _ O
2004 -X- _ O
) -X- _ O
use -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
in -X- _ O
a -X- _ O
cooking -X- _ O
simulation -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
pragmatic -X- _ O
constraints -X- _ O
have -X- _ O
modulatory -X- _ O
influence -X- _ O
on -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
referring -X- _ O
expressions -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
participants -X- _ O
followed -X- _ O
a -X- _ O
confederate -X- _ O
cook -X- _ O
’s -X- _ O
instructions -X- _ O
for -X- _ O
a -X- _ O
recipe -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
cook -X- _ O
used -X- _ O
the -X- _ O
the -X- _ O
definite -X- _ O
noun -X- _ O
phrase -X- _ O
the -X- _ O
cake -X- _ O
mix -X- _ O
to -X- _ O
signal -X- _ O
potential -X- _ O
referents -X- _ O
in -X- _ O
the -X- _ O
cooking -X- _ O
space -X- _ O
. -X- _ O

The -X- _ O
addressee -X- _ O
’s -X- _ O
domain -X- _ O
of -X- _ O
interpretation -X- _ O
changed -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
based -X- _ O
constraints -X- _ O
— -X- _ O
cued -X- _ O
perceptually -X- _ O
with -X- _ O
the -X- _ O
cook -X- _ O
’s -X- _ O
hands -X- _ O
being -X- _ O
empty -X- _ O
or -X- _ O
full -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
addressees -X- _ O
monitor -X- _ O
the -X- _ O
speaker -X- _ O
, -X- _ O
they -X- _ O
tend -X- _ O
to -X- _ O
interpret -X- _ O
the -X- _ O
referent -X- _ O
in -X- _ O
the -X- _ O
cook -X- _ O
’s -X- _ O
area -X- _ O
when -X- _ O
the -X- _ O
cook -X- _ O
’s -X- _ O
hands -X- _ O
were -X- _ O
full -X- _ O
and -X- _ O
the -X- _ O
referent -X- _ O
in -X- _ O
their -X- _ O
own -X- _ O
area -X- _ O
when -X- _ O
the -X- _ O
cook -X- _ O
’s -X- _ O
hands -X- _ O
were -X- _ O
empty -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
support -X- _ O
constraint -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
speaker -X- _ O
constraints -X- _ O
are -X- _ O
taken -X- _ O
into -X- _ O
account -X- _ O
for -X- _ O
interpretation -X- _ O
alongside -X- _ O
linguistic -X- _ O
ones -X- _ O
; -X- _ O
indeed -X- _ O
, -X- _ O
this -X- _ O
study -X- _ O
highlights -X- _ O
how -X- _ O
a -X- _ O
definite -X- _ O
referring -X- _ O
expression -X- _ O
can -X- _ O
point -X- _ O
to -X- _ O
a -X- _ O
few -X- _ O
possible -X- _ O
candidate -X- _ O
objects -X- _ O
in -X- _ O
a -X- _ O
restricted -X- _ O
domain -X- _ O
, -X- _ O
just -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
linguistic -X- _ O
form -X- _ O
, -X- _ O
yet -X- _ O
people -X- _ O
can -X- _ O
disambiguate -X- _ O
which -X- _ O
referent -X- _ O
is -X- _ O
being -X- _ O
referred -X- _ O
to -X- _ O
from -X- _ O
the -X- _ O
pragmatic -X- _ O
context -X- _ O
. -X- _ O

While -X- _ O
this -X- _ O
study -X- _ O
focuses -X- _ O
on -X- _ O
speaker -X- _ O
- -X- _ O
based -X- _ O
constraints -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
knowledge -X- _ O
about -X- _ O
the -X- _ O
modualtory -X- _ O
influence -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
in -X- _ O
interpreting -X- _ O
referring -X- _ O
expressions -X- _ O
. -X- _ O

A -X- _ O
promising -X- _ O
step -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
are -X- _ O
attempts -X- _ O
to -X- _ O
computationally -X- _ O
model -X- _ O
social -X- _ O
norms -X- _ O
with -X- _ O
the -X- _ O
ultimate -X- _ O
aim -X- _ O
of -X- _ O
creating -X- _ O
norm -X- _ O
competent -X- _ O
artificial -X- _ O
agents -X- _ O
( -X- _ O
Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
experimentally -X- _ O
collected -X- _ O
responses -X- _ O
from -X- _ O
humans -X- _ O
to -X- _ O
generate -X- _ O
social -X- _ O
norms -X- _ O
for -X- _ O
eight -X- _ O
contexts -X- _ O
, -X- _ O
including -X- _ O
a -X- _ O
library -X- _ O
, -X- _ O
boardroom -X- _ O
, -X- _ O
bathroom -X- _ O
, -X- _ O
and -X- _ O
restaurant -X- _ O
, -X- _ O
among -X- _ O
others -X- _ O
. -X- _ O

While -X- _ O
social -X- _ O
norms -X- _ O
can -X- _ O
be -X- _ O
elusive -X- _ O
and -X- _ O
challenging -X- _ O
to -X- _ O
define -X- _ O
, -X- _ O
since -X- _ O
they -X- _ O
vary -X- _ O
by -X- _ O
cul-2 -X- _ O

ture -X- _ O
and -X- _ O
appear -X- _ O
on -X- _ O
various -X- _ O
levels -X- _ O
of -X- _ O
demand -X- _ O
, -X- _ O
Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2020 -X- _ O
) -X- _ O
follows -X- _ O
Janoff -X- _ O
- -X- _ O
Bulman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2009 -X- _ O
) -X- _ O
in -X- _ O
viewing -X- _ O
social -X- _ O
norms -X- _ O
as -X- _ O
prescriptions -X- _ O
and -X- _ O
prohibitions -X- _ O
and -X- _ O
giving -X- _ O
attention -X- _ O
the -X- _ O
gradability -X- _ O
of -X- _ O
these -X- _ O
norms -X- _ O
by -X- _ O
mapping -X- _ O
the -X- _ O
deontic -X- _ O
force -X- _ O
— -X- _ O
how -X- _ O
strong -X- _ O
or -X- _ O
weak -X- _ O
these -X- _ O
norms -X- _ O
are -X- _ O
to -X- _ O
be -X- _ O
followed -X- _ O
— -X- _ O
to -X- _ O
the -X- _ O
collected -X- _ O
prescriptions -X- _ O
andprohibitions -X- _ O
. -X- _ O

Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
define -X- _ O
norms -X- _ O
more -X- _ O
formally -X- _ O
as -X- _ O
such -X- _ O
: -X- _ O
A -X- _ O
norm -X- _ O
is -X- _ O
an -X- _ O
instruction -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
community -X- _ O
, -X- _ O
to -X- _ O
( -X- _ O
not -X- _ O
) -X- _ O
perform -X- _ O
an -X- _ O
action -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
context -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
a -X- _ O
sufficient -X- _ O
number -X- _ O
of -X- _ O
individuals -X- _ O
in -X- _ O
the -X- _ O
community -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
demand -X- _ O
, -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
degree -X- _ O
, -X- _ O
of -X- _ O
each -X- _ O
other -X- _ O
to -X- _ O
follow -X- _ O
the -X- _ O
instruction -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
do -X- _ O
in -X- _ O
fact -X- _ O
follow -X- _ O
it -X- _ O
. -X- _ O

We -X- _ O
will -X- _ O
adopt -X- _ O
this -X- _ O
definition -X- _ O
for -X- _ O
social -X- _ O
norms -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
which -X- _ O
formalizes -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
prescriptions -X- _ O
andprohibitions -X- _ O
being -X- _ O
followed -X- _ O
by -X- _ O
many -X- _ O
people -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
broaden -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
to -X- _ O
include -X- _ O
descriptive -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
, -X- _ O
although -X- _ O
Bicchieri -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
makes -X- _ O
a -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
distinction -X- _ O
between -X- _ O
social -X- _ O
norms -X- _ O
, -X- _ O
conventions -X- _ O
, -X- _ O
and -X- _ O
descriptive -X- _ O
norms -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
moral -X- _ O
norms -X- _ O
or -X- _ O
legal -X- _ O
obligations -X- _ O
in -X- _ O
the -X- _ O
present -X- _ O
paper -X- _ O
. -X- _ O

Equally -X- _ O
important -X- _ O
, -X- _ O
this -X- _ O
study -X- _ O
offers -X- _ O
an -X- _ O
approach -X- _ O
for -X- _ O
teaching -X- _ O
norms -X- _ O
to -X- _ O
robots -X- _ O
for -X- _ O
guiding -X- _ O
actions -X- _ O
and -X- _ O
balancing -X- _ O
norms -X- _ O
with -X- _ O
goals -X- _ O
. -X- _ O

They -X- _ O
outline -X- _ O
an -X- _ O
enriched -X- _ O
Markvov -X- _ B-MethodName
Decision -X- _ I-MethodName
Process -X- _ I-MethodName
( -X- _ O
MDP -X- _ B-MethodName
) -X- _ O
approach -X- _ O
that -X- _ O
uses -X- _ O
a -X- _ O
starting -X- _ O
norm -X- _ O
base -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
predefined -X- _ O
norms -X- _ O
collected -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
and -X- _ O
refines -X- _ O
it -X- _ O
through -X- _ O
human -X- _ O
interaction -X- _ O
and -X- _ O
feedback -X- _ O
. -X- _ O

We -X- _ O
look -X- _ O
at -X- _ O
this -X- _ O
proposal -X- _ O
optimistically -X- _ O
for -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
vein -X- _ O
, -X- _ O
teaching -X- _ O
embodied -X- _ O
agents -X- _ O
the -X- _ O
specific -X- _ O
behavior -X- _ O
of -X- _ O
performing -X- _ O
situated -X- _ O
reference -X- _ O
resolution -X- _ O
. -X- _ O

A -X- _ O
referring -X- _ O
expression -X- _ O
can -X- _ O
appear -X- _ O
in -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
linguistic -X- _ O
forms -X- _ O
, -X- _ O
but -X- _ O
pragmatics -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
form -X- _ O
, -X- _ O
has -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
modulate -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
referent -X- _ O
entirely -X- _ O
. -X- _ O

This -X- _ O
will -X- _ O
be -X- _ O
true -X- _ O
for -X- _ O
humans -X- _ O
that -X- _ O
use -X- _ O
natural -X- _ O
language -X- _ O
with -X- _ O
robots -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Imagine -X- _ O
a -X- _ O
situation -X- _ O
where -X- _ O
someone -X- _ O
commands -X- _ O
an -X- _ O
assistive -X- _ O
robot -X- _ O
in -X- _ O
a -X- _ O
home -X- _ O
: -X- _ O
take -X- _ O
it -X- _ O
away -X- _ O
. -X- _ O

The -X- _ O
robot -X- _ O
can -X- _ O
use -X- _ O
the -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
vision -X- _ O
input -X- _ O
to -X- _ O
scan -X- _ O
the -X- _ O
area -X- _ O
for -X- _ O
potential -X- _ O
referents -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O

If -X- _ O
a -X- _ O
shoe -X- _ O
and -X- _ O
a -X- _ O
spoon -X- _ O
are -X- _ O
salient -X- _ O
objects -X- _ O
on -X- _ O
a -X- _ O
dining -X- _ O
room -X- _ O
table -X- _ O
, -X- _ O
the -X- _ O
convention -X- _ O
of -X- _ O
a -X- _ O
shoe -X- _ O
not -X- _ O
belonging -X- _ O
on -X- _ O
a -X- _ O
table -X- _ O
would -X- _ O
make -X- _ O
the -X- _ O
shoe -X- _ O
the -X- _ O
more -X- _ O
likely -X- _ O
candidate -X- _ O
. -X- _ O

Alternatively -X- _ O
if -X- _ O
a -X- _ O
shoe -X- _ O
and -X- _ O
a -X- _ O
spoon -X- _ O
are -X- _ O
salient -X- _ O
objects -X- _ O
on -X- _ O
the -X- _ O
floor -X- _ O
of -X- _ O
a -X- _ O
bedroom -X- _ O
, -X- _ O
the -X- _ O
spoon -X- _ O
would -X- _ O
likely -X- _ O
be -X- _ O
the -X- _ O
referent -X- _ O
. -X- _ O

Marrying -X- _ O
the -X- _ O
work -X- _ O
on -X- _ O
pragmatic -X- _ O
constraints -X- _ O
onreference -X- _ O
resolution -X- _ O
and -X- _ O
social -X- _ O
norms -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
where -X- _ O
humans -X- _ O
are -X- _ O
tasked -X- _ O
with -X- _ O
identifying -X- _ O
the -X- _ O
referent -X- _ O
of -X- _ O
an -X- _ O
ambiguous -X- _ O
referring -X- _ O
expression -X- _ O
across -X- _ O
various -X- _ O
contexts -X- _ O
and -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
various -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
. -X- _ O

This -X- _ O
experiment -X- _ O
relates -X- _ O
to -X- _ O
previous -X- _ O
work -X- _ O
that -X- _ O
leverages -X- _ O
crowd -X- _ O
sourcing -X- _ O
for -X- _ O
collecting -X- _ O
anaphora -X- _ O
annotations -X- _ O
and -X- _ O
judgments -X- _ O
( -X- _ O
Poesio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Chamberlain -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Kicikoglu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Although -X- _ O
this -X- _ O
body -X- _ O
of -X- _ O
work -X- _ O
focuses -X- _ O
on -X- _ O
a -X- _ O
game -X- _ O
- -X- _ O
with -X- _ O
- -X- _ O
a -X- _ O
- -X- _ O
purpose -X- _ O
( -X- _ O
GWAP -X- _ O
) -X- _ O
approach -X- _ O
to -X- _ O
crowd -X- _ O
sourcing -X- _ O
( -X- _ O
V -X- _ O
on -X- _ O
Ahn -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
study -X- _ O
does -X- _ O
not -X- _ O
gamify -X- _ O
our -X- _ O
annotation -X- _ O
task -X- _ O
but -X- _ O
it -X- _ O
does -X- _ O
avoid -X- _ O
using -X- _ O
linguistic -X- _ O
and -X- _ O
annotation -X- _ O
terminology -X- _ O
for -X- _ O
participants -X- _ O
. -X- _ O

Poesio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
specifically -X- _ O
, -X- _ O
collects -X- _ O
several -X- _ O
judgements -X- _ O
and -X- _ O
disagreements -X- _ O
over -X- _ O
ambiguous -X- _ O
cases -X- _ O
of -X- _ O
anaphora -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
our -X- _ O
study -X- _ O
captures -X- _ O
the -X- _ O
reasons -X- _ O
and -X- _ O
explanations -X- _ O
people -X- _ O
make -X- _ O
when -X- _ O
resolving -X- _ O
a -X- _ O
referent -X- _ O
, -X- _ O
although -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
adjudication -X- _ O
process -X- _ O
. -X- _ O

Through -X- _ O
overall -X- _ O
decisions -X- _ O
and -X- _ O
explanations -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
then -X- _ O
able -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
agreement -X- _ O
and -X- _ O
interpretations -X- _ O
over -X- _ O
our -X- _ O
ambiguous -X- _ O
scenarios -X- _ O
. -X- _ O

4 -X- _ O
Experiment -X- _ O
and -X- _ O
Results -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
an -X- _ O
online -X- _ O
vignettebased -X- _ O
human -X- _ O
- -X- _ O
subjects -X- _ O
experiment -X- _ O
designed -X- _ O
to -X- _ O
explicate -X- _ O
the -X- _ O
potential -X- _ O
role -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
in -X- _ O
resolving -X- _ O
references -X- _ O
in -X- _ O
context -X- _ O
. -X- _ O

We -X- _ O
recruited -X- _ O
50 -X- _ O
participants -X- _ O
on -X- _ O
Prolific -X- _ O
( -X- _ O
see -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
prolific -X- _ O
. -X- _ O
co -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
online -X- _ O
participant -X- _ O
recruitment -X- _ O
site -X- _ O
which -X- _ O
is -X- _ O
known -X- _ O
to -X- _ O
provide -X- _ O
better -X- _ O
results -X- _ O
on -X- _ O
tasks -X- _ O
like -X- _ O
ours -X- _ O
. -X- _ O

Participants -X- _ O
were -X- _ O
free -X- _ O
to -X- _ O
leave -X- _ O
the -X- _ O
study -X- _ O
at -X- _ O
any -X- _ O
point -X- _ O
, -X- _ O
their -X- _ O
data -X- _ O
was -X- _ O
anonymized -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
received -X- _ O
adequate -X- _ O
payment -X- _ O
for -X- _ O
the -X- _ O
study -X- _ O
. -X- _ O

A -X- _ O
consent -X- _ O
form -X- _ O
was -X- _ O
presented -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
each -X- _ O
study -X- _ O
with -X- _ O
information -X- _ O
on -X- _ O
how -X- _ O
their -X- _ O
data -X- _ O
would -X- _ O
be -X- _ O
used -X- _ O
. -X- _ O

We -X- _ O
restricted -X- _ O
our -X- _ O
recruitment -X- _ O
to -X- _ O
people -X- _ O
living -X- _ O
in -X- _ O
the -X- _ O
United -X- _ O
States -X- _ O
and -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
the -X- _ O
study -X- _ O
and -X- _ O
native -X- _ O
speakers -X- _ O
of -X- _ O
English -X- _ O
. -X- _ O

Each -X- _ O
participant -X- _ O
was -X- _ O
presented -X- _ O
with -X- _ O
eight -X- _ O
text -X- _ O
vignettes -X- _ O
where -X- _ O
each -X- _ O
vignette -X- _ O
described -X- _ O
a -X- _ O
scene -X- _ O
within -X- _ O
a -X- _ O
daily -X- _ O
- -X- _ O
life -X- _ O
context -X- _ O
. -X- _ O

Each -X- _ O
scene -X- _ O
contains -X- _ O
four -X- _ O
pieces -X- _ O
of -X- _ O
information -X- _ O
: -X- _ O
an -X- _ O
explicit -X- _ O
mention -X- _ O
of -X- _ O
the -X- _ O
setting -X- _ O
( -X- _ O
The -X- _ O
scene -X- _ O
takes -X- _ O
place -X- _ O
in -X- _ O
a -X- _ O
library -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
background -X- _ O
— -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
objects -X- _ O
and -X- _ O
people -X- _ O
in -X- _ O
the -X- _ O
scene -X- _ O
— -X- _ O
an -X- _ O
underspecified -X- _ O
referring -X- _ O
expression -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
remove -X- _ O
it -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
actor -X- _ O
in -X- _ O
the -X- _ O
scene -X- _ O
acting -X- _ O
on -X- _ O
an -X- _ O
object -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
always -X- _ O
two -X- _ O
salient -X- _ O
referents -X- _ O
that -X- _ O
are -X- _ O
potential -X- _ O
candidates -X- _ O
for -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
. -X- _ O

Participants -X- _ O
must -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
referent -X- _ O
chosen -X- _ O
by -X- _ O
the -X- _ O
actor -X- _ O
in3 -X- _ O

Contexts -X- _ O
Items -X- _ O
Hypothesized -X- _ O
Norms -X- _ O
Library -X- _ O
head -X- _ O
seat -X- _ O
, -X- _ O
side -X- _ O
seat -X- _ O
do -X- _ O
not -X- _ O
interrupt -X- _ O
someone -X- _ O
at -X- _ O
the -X- _ O
library -X- _ O
; -X- _ O
give -X- _ O
space -X- _ O
to -X- _ O
others -X- _ O
Boardroom -X- _ O
head -X- _ O
seat -X- _ O
, -X- _ O
side -X- _ O
seat -X- _ O
do -X- _ O
not -X- _ O
sit -X- _ O
at -X- _ O
the -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
Taxicab -X- _ O
front -X- _ O
seat -X- _ O
, -X- _ O
back -X- _ O
seat -X- _ O
you -X- _ O
should -X- _ O
sit -X- _ O
in -X- _ O
the -X- _ O
front -X- _ O
seat -X- _ O
Friend -X- _ O
’s -X- _ O
Car -X- _ O
front -X- _ O
seat -X- _ O
, -X- _ O
back -X- _ O
seat -X- _ O
you -X- _ O
should -X- _ O
sit -X- _ O
in -X- _ O
the -X- _ O
back -X- _ O
seat -X- _ O
Dining -X- _ O
Room -X- _ O
shoe -X- _ O
, -X- _ O
spoon -X- _ O
a -X- _ O
shoe -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
a -X- _ O
dining -X- _ O
table -X- _ O
Leather -X- _ O
Shop -X- _ O
shoe -X- _ O
, -X- _ O
spoon -X- _ O
a -X- _ O
spoon -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
a -X- _ O
non -X- _ O
dining -X- _ O
table -X- _ O
Bookstore -X- _ O
magazine -X- _ O
, -X- _ O
toothbrush -X- _ O
a -X- _ O
toothbrush -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
the -X- _ O
floor -X- _ O
of -X- _ O
a -X- _ O
bathroom -X- _ O
Bathroom -X- _ O
magazine -X- _ O
, -X- _ O
toothbrush -X- _ O
a -X- _ O
magazine -X- _ O
for -X- _ O
display -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
the -X- _ O
ground -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Overview -X- _ O
of -X- _ O
contexts -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
the -X- _ O
items -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
hypothesized -X- _ O
norms -X- _ O
activated -X- _ O
in -X- _ O
each -X- _ O
context -X- _ O
. -X- _ O

the -X- _ O
scene -X- _ O
was -X- _ O
the -X- _ O
correct -X- _ O
one -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
information -X- _ O
still -X- _ O
in -X- _ O
view -X- _ O
, -X- _ O
participants -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
explanation -X- _ O
for -X- _ O
their -X- _ O
answer -X- _ O
and -X- _ O
are -X- _ O
provided -X- _ O
a -X- _ O
multiple -X- _ O
choice -X- _ O
listing -X- _ O
of -X- _ O
five -X- _ O
potential -X- _ O
explanations -X- _ O
and -X- _ O
one -X- _ O
open -X- _ O
text -X- _ O
response -X- _ O
option -X- _ O
labeled -X- _ O
other -X- _ O
. -X- _ O

These -X- _ O
reasons -X- _ O
include -X- _ O
: -X- _ O
typical -X- _ O
for -X- _ O
the -X- _ O
setting -X- _ O
, -X- _ O
object -X- _ O
is -X- _ O
mentioned -X- _ O
first -X- _ O
, -X- _ O
object -X- _ O
is -X- _ O
mentioned -X- _ O
more -X- _ O
recently -X- _ O
, -X- _ O
time -X- _ O
sensitive -X- _ O
option -X- _ O
, -X- _ O
more -X- _ O
convenient -X- _ O
option -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
. -X- _ O

We -X- _ O
included -X- _ O
reasons -X- _ O
that -X- _ O
could -X- _ O
explain -X- _ O
that -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
was -X- _ O
the -X- _ O
one -X- _ O
that -X- _ O
was -X- _ O
intended -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
subjective -X- _ O
options -X- _ O
that -X- _ O
potentially -X- _ O
frame -X- _ O
the -X- _ O
question -X- _ O
as -X- _ O
a -X- _ O
personal -X- _ O
preference -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
offered -X- _ O
a -X- _ O
text -X- _ O
response -X- _ O
if -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
options -X- _ O
fit.1We -X- _ O
summarize -X- _ O
the -X- _ O
contexts -X- _ O
, -X- _ O
candidate -X- _ O
objects -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
hypothesized -X- _ O
norm -X- _ O
associated -X- _ O
with -X- _ O
each -X- _ O
context -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

Each -X- _ O
context -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
inspired -X- _ O
by -X- _ O
Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
assumed -X- _ O
to -X- _ O
activate -X- _ O
their -X- _ O
own -X- _ O
inventory -X- _ O
of -X- _ O
norms -X- _ O
to -X- _ O
help -X- _ O
disambiguate -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
. -X- _ O

Our -X- _ O
hypothesized -X- _ O
norms -X- _ O
are -X- _ O
partly -X- _ O
based -X- _ O
on -X- _ O
intuition -X- _ O
but -X- _ O
also -X- _ O
inspired -X- _ O
by -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
norms -X- _ O
and -X- _ O
behavior -X- _ O
. -X- _ O

Aarts -X- _ O
and -X- _ O
Dijksterhuis -X- _ O
( -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
conducted -X- _ O
a -X- _ O
survey -X- _ O
with -X- _ O
undergraduates -X- _ O
to -X- _ O
confirm -X- _ O
the -X- _ O
normative -X- _ O
behavior -X- _ O
of -X- _ O
acting -X- _ O
silently -X- _ O
in -X- _ O
a -X- _ O
library -X- _ O
setting -X- _ O
. -X- _ O

This -X- _ O
norm -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
our -X- _ O
study -X- _ O
in -X- _ O
a -X- _ O
library -X- _ O
scene -X- _ O
: -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
open -X- _ O
seat -X- _ O
at -X- _ O
a -X- _ O
table -X- _ O
right -X- _ O
next -X- _ O
to -X- _ O
someone -X- _ O
and -X- _ O
a -X- _ O
seat -X- _ O
further -X- _ O
away -X- _ O
from -X- _ O
someone -X- _ O
. -X- _ O

Although -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
mention -X- _ O
to -X- _ O
noise -X- _ O
, -X- _ O
seating -X- _ O
right -X- _ O
next -X- _ O
to -X- _ O
someone -X- _ O
else -X- _ O
— -X- _ O
a -X- _ O
stranger -X- _ O
— -X- _ O
is -X- _ O
potentially -X- _ O
noisy -X- _ O
and -X- _ O
interruptive -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
not -X- _ O
littering -X- _ O
( -X- _ O
Cialdini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1991 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
focused -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
referent -X- _ O
was -X- _ O
“ -X- _ O
correct -X- _ O
” -X- _ O
was -X- _ O
chosen -X- _ O
after -X- _ O
initial -X- _ O
pilot -X- _ O
experiments -X- _ O
showed -X- _ O
that -X- _ O
asking -X- _ O
subjects -X- _ O
for -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
rather -X- _ O
than -X- _ O
providing -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
the -X- _ O
actor -X- _ O
in -X- _ O
the -X- _ O
scene -X- _ O
led -X- _ O
to -X- _ O
a -X- _ O
confound -X- _ O
: -X- _ O
subjects -X- _ O
often -X- _ O
choose -X- _ O
the -X- _ O
referent -X- _ O
they -X- _ O
would -X- _ O
have -X- _ O
chosen -X- _ O
instead -X- _ O
of -X- _ O
hypothesizing -X- _ O
the -X- _ O
referent -X- _ O
the -X- _ O
actor -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
context -X- _ O
would -X- _ O
have -X- _ O
selected.prohibitions -X- _ O
of -X- _ O
objects -X- _ O
not -X- _ O
belonging -X- _ O
in -X- _ O
certain -X- _ O
contexts -X- _ O
; -X- _ O
a -X- _ O
shoe -X- _ O
is -X- _ O
not -X- _ O
supposed -X- _ O
to -X- _ O
be -X- _ O
on -X- _ O
a -X- _ O
clean -X- _ O
dining -X- _ O
room -X- _ O
table -X- _ O
and -X- _ O
a -X- _ O
toothbrush -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
the -X- _ O
bathroom -X- _ O
floor -X- _ O
. -X- _ O

We -X- _ O
posit -X- _ O
other -X- _ O
norms -X- _ O
that -X- _ O
tend -X- _ O
to -X- _ O
influence -X- _ O
frequent -X- _ O
behavior -X- _ O
such -X- _ O
as -X- _ O
sitting -X- _ O
with -X- _ O
your -X- _ O
friend -X- _ O
in -X- _ O
their -X- _ O
car -X- _ O
, -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
the -X- _ O
backseat -X- _ O
, -X- _ O
and -X- _ O
sitting -X- _ O
in -X- _ O
the -X- _ O
back -X- _ O
of -X- _ O
a -X- _ O
taxicab -X- _ O
. -X- _ O

Similar -X- _ O
to -X- _ O
Winograd -X- _ O
schema -X- _ O
datasets -X- _ O
, -X- _ O
each -X- _ O
referring -X- _ O
expression -X- _ O
is -X- _ O
stripped -X- _ O
of -X- _ O
linguistic -X- _ O
surface -X- _ O
cues -X- _ O
such -X- _ O
as -X- _ O
gender -X- _ O
, -X- _ O
number -X- _ O
, -X- _ O
and -X- _ O
person -X- _ O
that -X- _ O
would -X- _ O
give -X- _ O
away -X- _ O
the -X- _ O
referent -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
these -X- _ O
scenes -X- _ O
are -X- _ O
set -X- _ O
up -X- _ O
so -X- _ O
that -X- _ O
subjects -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
have -X- _ O
to -X- _ O
rely -X- _ O
on -X- _ O
information -X- _ O
outside -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
help -X- _ O
them -X- _ O
make -X- _ O
a -X- _ O
decision -X- _ O
. -X- _ O

The -X- _ O
only -X- _ O
linguistic -X- _ O
cue -X- _ O
we -X- _ O
maintain -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
is -X- _ O
recency -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
ordering -X- _ O
of -X- _ O
the -X- _ O
referents -X- _ O
. -X- _ O

These -X- _ O
scenes -X- _ O
include -X- _ O
: -X- _ O
library -X- _ O
, -X- _ O
boardroom -X- _ O
, -X- _ O
taxicab -X- _ O
, -X- _ O
friend -X- _ O
’s -X- _ O
car -X- _ O
, -X- _ O
dining -X- _ O
room -X- _ O
, -X- _ O
leather -X- _ O
shop -X- _ O
, -X- _ O
bookstore -X- _ O
, -X- _ O
home -X- _ O
bathroom -X- _ O
. -X- _ O

Each -X- _ O
scene -X- _ O
has -X- _ O
a -X- _ O
complementary -X- _ O
scene -X- _ O
that -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
referents -X- _ O
; -X- _ O
the -X- _ O
library -X- _ O
and -X- _ O
boardroom -X- _ O
share -X- _ O
two -X- _ O
seats -X- _ O
, -X- _ O
the -X- _ O
taxicab -X- _ O
and -X- _ O
friend -X- _ O
’s -X- _ O
car -X- _ O
share -X- _ O
two -X- _ O
seats -X- _ O
, -X- _ O
the -X- _ O
dining -X- _ O
room -X- _ O
and -X- _ O
leather -X- _ O
shop -X- _ O
share -X- _ O
a -X- _ O
shoe -X- _ O
and -X- _ O
a -X- _ O
spoon -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
bookstore -X- _ O
and -X- _ O
home -X- _ O
bathroom -X- _ O
share -X- _ O
a -X- _ O
toothbrush -X- _ O
and -X- _ O
a -X- _ O
magazine -X- _ O
. -X- _ O

The -X- _ O
purpose -X- _ O
of -X- _ O
creating -X- _ O
complementary -X- _ O
scenes -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
referent -X- _ O
was -X- _ O
to -X- _ O
demonstrate -X- _ O
how -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
is -X- _ O
constant -X- _ O
, -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
associated -X- _ O
with -X- _ O
it -X- _ O
, -X- _ O
modulate -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
the -X- _ O
referent -X- _ O
. -X- _ O

We -X- _ O
posit -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
that -X- _ O
people -X- _ O
will -X- _ O
select -X- _ O
the -X- _ O
seat -X- _ O
in -X- _ O
the -X- _ O
back -X- _ O
of -X- _ O
the -X- _ O
cab -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
the -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
cab -X- _ O
. -X- _ O

This -X- _ O
would -X- _ O
be -X- _ O
guided -X- _ O
by -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
sitting -X- _ O
in -X- _ O
the -X- _ O
back -X- _ O
of -X- _ O
a -X- _ O
cab -X- _ O
. -X- _ O

Alternatively -X- _ O
, -X- _ O
people -X- _ O
would -X- _ O
most -X- _ O
likely -X- _ O
choose -X- _ O
to -X- _ O
sit -X- _ O
in -X- _ O
the -X- _ O
front -X- _ O
seat -X- _ O
in -X- _ O
a -X- _ O
friend -X- _ O
’s -X- _ O
car -X- _ O
and -X- _ O
not -X- _ O
the -X- _ O
back -X- _ O
seat -X- _ O
, -X- _ O
also -X- _ O
for -X- _ O
conventional -X- _ O
reasons -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
excerpts -X- _ O
show -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
scenes -X- _ O
participants -X- _ O
read -X- _ O
during -X- _ O
the -X- _ O
experiment -X- _ O
. -X- _ O

The4 -X- _ O

one -X- _ O
below -X- _ O
is -X- _ O
for -X- _ O
the -X- _ O
dining -X- _ O
room -X- _ O
context -X- _ O
: -X- _ O
The -X- _ O
scene -X- _ O
takes -X- _ O
place -X- _ O
in -X- _ O
a -X- _ O
dining -X- _ O
room -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
shoe -X- _ O
and -X- _ O
a -X- _ O
spoon -X- _ O
sitting -X- _ O
on -X- _ O
a -X- _ O
dining -X- _ O
room -X- _ O
table -X- _ O
. -X- _ O

Dinner -X- _ O
is -X- _ O
about -X- _ O
to -X- _ O
be -X- _ O
served -X- _ O
. -X- _ O

Someone -X- _ O
says -X- _ O
, -X- _ O
“ -X- _ O
remove -X- _ O
it -X- _ O
. -X- _ O
” -X- _ O

Someone -X- _ O
else -X- _ O
removes -X- _ O
the -X- _ O
shoe -X- _ O
from -X- _ O
the -X- _ O
table -X- _ O
. -X- _ O

This -X- _ O
next -X- _ O
example -X- _ O
, -X- _ O
describing -X- _ O
a -X- _ O
leather -X- _ O
shop -X- _ O
, -X- _ O
shows -X- _ O
a -X- _ O
complementary -X- _ O
scene -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
candidate -X- _ O
objects -X- _ O
of -X- _ O
the -X- _ O
shoe -X- _ O
and -X- _ O
spoon -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
definite -X- _ O
referring -X- _ O
expression -X- _ O
, -X- _ O
remove -X- _ O
it -X- _ O
. -X- _ O

The -X- _ O
scene -X- _ O
takes -X- _ O
place -X- _ O
in -X- _ O
a -X- _ O
leather -X- _ O
shop -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
spoon -X- _ O
and -X- _ O
a -X- _ O
shoe -X- _ O
sitting -X- _ O
on -X- _ O
a -X- _ O
worktable -X- _ O
. -X- _ O

Nothing -X- _ O
else -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
table -X- _ O
. -X- _ O

A -X- _ O
customer -X- _ O
is -X- _ O
coming -X- _ O
into -X- _ O
the -X- _ O
store -X- _ O
. -X- _ O

Pointing -X- _ O
to -X- _ O
the -X- _ O
worktable -X- _ O
, -X- _ O
someone -X- _ O
in -X- _ O
the -X- _ O
room -X- _ O
says -X- _ O
, -X- _ O
“ -X- _ O
remove -X- _ O
it -X- _ O
. -X- _ O
” -X- _ O

The -X- _ O
employee -X- _ O
removes -X- _ O
the -X- _ O
spoon -X- _ O
. -X- _ O

While -X- _ O
each -X- _ O
participant -X- _ O
sees -X- _ O
all -X- _ O
eight -X- _ O
scenes -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
conditions -X- _ O
where -X- _ O
the -X- _ O
ordering -X- _ O
of -X- _ O
the -X- _ O
referents -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
are -X- _ O
flipped -X- _ O
. -X- _ O

Condition -X- _ O
A -X- _ O
lists -X- _ O
the -X- _ O
intended -X- _ O
( -X- _ O
correct -X- _ O
) -X- _ O
referent -X- _ O
last -X- _ O
and -X- _ O
condition -X- _ O
B -X- _ O
lists -X- _ O
the -X- _ O
intended -X- _ O
referent -X- _ O
first -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
dining -X- _ O
room -X- _ O
scene -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
condition -X- _ O
A -X- _ O
lists -X- _ O
the -X- _ O
spoon -X- _ O
first -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
shoe -X- _ O
and -X- _ O
condition -X- _ O
B -X- _ O
lists -X- _ O
the -X- _ O
shoe -X- _ O
first -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
spoon -X- _ O
. -X- _ O

We -X- _ O
create -X- _ O
these -X- _ O
conditions -X- _ O
to -X- _ O
test -X- _ O
whether -X- _ O
people -X- _ O
are -X- _ O
biased -X- _ O
by -X- _ O
the -X- _ O
recency -X- _ O
of -X- _ O
referents -X- _ O
and -X- _ O
to -X- _ O
also -X- _ O
evaluate -X- _ O
these -X- _ O
texts -X- _ O
on -X- _ O
coreference -X- _ O
tools -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
biased -X- _ O
by -X- _ O
recency -X- _ O
in -X- _ O
performing -X- _ O
reference -X- _ O
resolution -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
show -X- _ O
how -X- _ O
many -X- _ O
people -X- _ O
agreed -X- _ O
that -X- _ O
the -X- _ O
selected -X- _ O
referent -X- _ O
was -X- _ O
correct -X- _ O
or -X- _ O
incorrect -X- _ O
in -X- _ O
a -X- _ O
“ -X- _ O
yes -X- _ O
- -X- _ O
no -X- _ O
” -X- _ O
question -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
people -X- _ O
agreed -X- _ O
that -X- _ O
the -X- _ O
referent -X- _ O
selected -X- _ O
was -X- _ O
thecorrect -X- _ O
one -X- _ O
across -X- _ O
all -X- _ O
scenes -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
frequency -X- _ O
distributions -X- _ O
seem -X- _ O
consistent -X- _ O
across -X- _ O
both -X- _ O
conditions -X- _ O
. -X- _ O

Stronger -X- _ O
agreement -X- _ O
trends -X- _ O
towards -X- _ O
scenes -X- _ O
with -X- _ O
seats -X- _ O
as -X- _ O
referents -X- _ O
— -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
library -X- _ O
, -X- _ O
boardroom -X- _ O
, -X- _ O
taxicab -X- _ O
, -X- _ O
and -X- _ O
friend -X- _ O
’s -X- _ O
car -X- _ O
. -X- _ O

The -X- _ O
scenes -X- _ O
with -X- _ O
the -X- _ O
most -X- _ O
disagreement -X- _ O
were -X- _ O
the -X- _ O
bookstore -X- _ O
and -X- _ O
home -X- _ O
bathroom -X- _ O
scenes -X- _ O
, -X- _ O
which -X- _ O
used -X- _ O
a -X- _ O
toothbrush -X- _ O
and -X- _ O
magazine -X- _ O
as -X- _ O
candidate -X- _ O
objects -X- _ O
. -X- _ O

For -X- _ O
these -X- _ O
scenes -X- _ O
, -X- _ O
we -X- _ O
hypothesized -X- _ O
contexts -X- _ O
with -X- _ O
a -X- _ O
prohibition -X- _ O
type -X- _ O
norm -X- _ O
where -X- _ O
it -X- _ O
is -X- _ O
unacceptable -X- _ O
for -X- _ O
a -X- _ O
toothbrush -X- _ O
and -X- _ O
a -X- _ O
magazine -X- _ O
to -X- _ O
be -X- _ O
on -X- _ O
the -X- _ O
ground -X- _ O
. -X- _ O

But -X- _ O
these -X- _ O
were -X- _ O
, -X- _ O
perhaps -X- _ O
, -X- _ O
less -X- _ O
airtight -X- _ O
scenarios -X- _ O
. -X- _ O

In -X- _ O
a -X- _ O
home -X- _ O
bathroom -X- _ O
, -X- _ O
magazines -X- _ O
can -X- _ O
be -X- _ O
stowed -X- _ O
in -X- _ O
the -X- _ O
corner -X- _ O
for -X- _ O
casual -X- _ O
reading -X- _ O
, -X- _ O
A -X- _ O
B -X- _ O
Contexts -X- _ O

yes -X- _ O

no -X- _ O

yes -X- _ O
no -X- _ O
Total -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Counts -X- _ O
for -X- _ O
yesornoin -X- _ O
response -X- _ O
asking -X- _ O
whether -X- _ O
the -X- _ O
referent -X- _ O
identified -X- _ O
is -X- _ O
correct -X- _ O
. -X- _ O

Results -X- _ O
reported -X- _ O
for -X- _ O
conditions -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
where -X- _ O
each -X- _ O
condition -X- _ O
is -X- _ O
a -X- _ O
different -X- _ O
ordering -X- _ O
of -X- _ O
the -X- _ O
referents -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
... -X- _ O
shoe -X- _ O
and -X- _ O
spoon -X- _ O
... -X- _ O

v.s -X- _ O
... -X- _ O
. -X- _ O
spoon -X- _ O
and -X- _ O
shoe -X- _ O
... -X- _ O
) -X- _ O

but -X- _ O
a -X- _ O
toothbrush -X- _ O
has -X- _ O
a -X- _ O
its -X- _ O
place -X- _ O
in -X- _ O
a -X- _ O
cabinet -X- _ O
or -X- _ O
cup -X- _ O
holder -X- _ O
. -X- _ O

In -X- _ O
a -X- _ O
bookstore -X- _ O
, -X- _ O
a -X- _ O
magazine -X- _ O
should -X- _ O
belong -X- _ O
on -X- _ O
the -X- _ O
shelf -X- _ O
along -X- _ O
with -X- _ O
other -X- _ O
books -X- _ O
and -X- _ O
magazines -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
stray -X- _ O
toothbrush -X- _ O
in -X- _ O
a -X- _ O
public -X- _ O
space -X- _ O
can -X- _ O
be -X- _ O
left -X- _ O
alone -X- _ O
, -X- _ O
unless -X- _ O
a -X- _ O
norm -X- _ O
of -X- _ O
not -X- _ O
littering -X- _ O
is -X- _ O
competing -X- _ O
. -X- _ O

The -X- _ O
explanations -X- _ O
people -X- _ O
chose -X- _ O
offer -X- _ O
some -X- _ O
more -X- _ O
clarity -X- _ O
to -X- _ O
this -X- _ O
picture -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
provides -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
reasons -X- _ O
people -X- _ O
gave -X- _ O
for -X- _ O
their -X- _ O
agreement -X- _ O
or -X- _ O
disagreement -X- _ O
with -X- _ O
the -X- _ O
selected -X- _ O
referent -X- _ O
. -X- _ O

One -X- _ O
obvious -X- _ O
trend -X- _ O
that -X- _ O
stands -X- _ O
out -X- _ O
is -X- _ O
that -X- _ O
Convention -X- _ O
( -X- _ O
displayed -X- _ O
as -X- _ O
typical -X- _ O
for -X- _ O
the -X- _ O
setting -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
) -X- _ O
outnumbers -X- _ O
the -X- _ O
other -X- _ O
reasons -X- _ O
across -X- _ O
all -X- _ O
scenes -X- _ O
and -X- _ O
conditions -X- _ O
. -X- _ O

Where -X- _ O
there -X- _ O
was -X- _ O
high -X- _ O
consensus -X- _ O
on -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
for -X- _ O
the -X- _ O
seat -X- _ O
related -X- _ O
scenes -X- _ O
, -X- _ O
there -X- _ O
was -X- _ O
a -X- _ O
commensurate -X- _ O
high -X- _ O
rate -X- _ O
of -X- _ O
selecting -X- _ O
the -X- _ O
conventional -X- _ O
explanation -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
library -X- _ O
scene -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
tension -X- _ O
between -X- _ O
conventional -X- _ O
explanation -X- _ O
and -X- _ O
a -X- _ O
convenient -X- _ O
choice -X- _ O
for -X- _ O
choosing -X- _ O
a -X- _ O
seat -X- _ O
at -X- _ O
the -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
seat -X- _ O
next -X- _ O
to -X- _ O
someone -X- _ O
else -X- _ O
. -X- _ O

For -X- _ O
some -X- _ O
, -X- _ O
it -X- _ O
seems -X- _ O
, -X- _ O
the -X- _ O
convention -X- _ O
of -X- _ O
keeping -X- _ O
distance -X- _ O
from -X- _ O
a -X- _ O
stranger -X- _ O
at -X- _ O
a -X- _ O
library -X- _ O
, -X- _ O
as -X- _ O
not -X- _ O
to -X- _ O
cause -X- _ O
a -X- _ O
disruption -X- _ O
, -X- _ O
is -X- _ O
either -X- _ O
not -X- _ O
activated -X- _ O
or -X- _ O
is -X- _ O
overruled -X- _ O
by -X- _ O
convenience -X- _ O
. -X- _ O

Then -X- _ O
there -X- _ O
are -X- _ O
the -X- _ O
bookstore -X- _ O
and -X- _ O
home -X- _ O
bathroom -X- _ O
scene -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
lower -X- _ O
consensus -X- _ O
and -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
a -X- _ O
higher -X- _ O
count -X- _ O
of -X- _ O
alternative -X- _ O
explanations -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
when -X- _ O
people -X- _ O
disagree -X- _ O
that -X- _ O
the -X- _ O
selected -X- _ O
object -X- _ O
was -X- _ O
correct -X- _ O
, -X- _ O
their -X- _ O
explanations -X- _ O
suggest -X- _ O
a -X- _ O
normative -X- _ O
reason -X- _ O
is -X- _ O
stronger -X- _ O
in -X- _ O
the -X- _ O
other -X- _ O
direction -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
magazine -X- _ O
is -X- _ O
more -X- _ O
conventional -X- _ O
in -X- _ O
a -X- _ O
bookstore -X- _ O
( -X- _ O
prescription -X- _ O
) -X- _ O
a -X- _ O
toothbrush -X- _ O
is -X- _ O
unconventional -X- _ O
and -X- _ O
suggests -X- _ O
a -X- _ O
prohibition -X- _ O
norm -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
explanations -X- _ O
for -X- _ O
these -X- _ O
scenes:5 -X- _ O

Convention -X- _ O
Last -X- _ O
First -X- _ O
Time -X- _ O
Sensitive -X- _ O
Convenient -X- _ O
Other -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Counts -X- _ O
for -X- _ O
best -X- _ O
explanation -X- _ O
for -X- _ O
correct -X- _ O
or -X- _ O
incorrect -X- _ O
referent -X- _ O
selected -X- _ O
. -X- _ O

The -X- _ O
shortened -X- _ O
label -X- _ O
Convention -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
typical -X- _ O
for -X- _ O
the -X- _ O
setting -X- _ O
option -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
; -X- _ O
Last -X- _ O
toobject -X- _ O
is -X- _ O
mentioned -X- _ O
more -X- _ O
recently -X- _ O
; -X- _ O
First -X- _ O
toobject -X- _ O
is -X- _ O
mentioned -X- _ O
first -X- _ O
; -X- _ O
Other -X- _ O
toother -X- _ O
with -X- _ O
free -X- _ O
text -X- _ O
response -X- _ O
; -X- _ O
Time -X- _ O
Sensitive -X- _ O
totime -X- _ O
sensitive -X- _ O
option -X- _ O
; -X- _ O
Convenient -X- _ O
tomore -X- _ O
convenient -X- _ O
option -X- _ O
Bookstore -X- _ O
: -X- _ O
toothbrush -X- _ O
does -X- _ O
n’t -X- _ O
belong -X- _ O
... -X- _ O

the -X- _ O
toothbrush -X- _ O
is -X- _ O
the -X- _ O
more -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
place -X- _ O
object -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
implied -X- _ O
to -X- _ O
have -X- _ O
that -X- _ O
removed -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
magazine -X- _ O
the -X- _ O
toothbrush -X- _ O
does -X- _ O
not -X- _ O
match -X- _ O
the -X- _ O
setting -X- _ O
/ -X- _ O
misplaced -X- _ O
Home -X- _ O
Bathroom -X- _ O
: -X- _ O
object -X- _ O
is -X- _ O
irrelevant -X- _ O
to -X- _ O
the -X- _ O
setting -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
removed -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
for -X- _ O
these -X- _ O
scenes -X- _ O
and -X- _ O
others -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
explanations -X- _ O
people -X- _ O
articulate -X- _ O
can -X- _ O
be -X- _ O
classified -X- _ O
as -X- _ O
norms -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
did -X- _ O
not -X- _ O
select -X- _ O
the -X- _ O
normative -X- _ O
option -X- _ O
in -X- _ O
the -X- _ O
multiple -X- _ O
choice -X- _ O
: -X- _ O
Home -X- _ O
Bathroom -X- _ O
: -X- _ O

The -X- _ O
toothbrush -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
the -X- _ O
floor -X- _ O
toothbrush -X- _ O
does -X- _ O
not -X- _ O
belong -X- _ O
on -X- _ O
the -X- _ O
floor -X- _ O
Boardroom -X- _ O
: -X- _ O
The -X- _ O
boss -X- _ O
usually -X- _ O
sits -X- _ O
at -X- _ O
the -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
. -X- _ O

Library -X- _ O
: -X- _ O
The -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
does -X- _ O
n’t -X- _ O
have -X- _ O
anyone -X- _ O
sittingnext -X- _ O
to -X- _ O
it -X- _ O
. -X- _ O

Although -X- _ O
it -X- _ O
was -X- _ O
unclear -X- _ O
for -X- _ O
some -X- _ O
that -X- _ O
typical -X- _ O
for -X- _ O
the -X- _ O
setting -X- _ O
subsumed -X- _ O
the -X- _ O
normative -X- _ O
or -X- _ O
conventional -X- _ O
explanations -X- _ O
, -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
people -X- _ O
gave -X- _ O
normative -X- _ O
explanations -X- _ O
support -X- _ O
that -X- _ O
reasoning -X- _ O
even -X- _ O
more -X- _ O
. -X- _ O

To -X- _ O
summarize -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
same -X- _ O
two -X- _ O
referents -X- _ O
, -X- _ O
people -X- _ O
interpreted -X- _ O
one -X- _ O
referent -X- _ O
as -X- _ O
correct -X- _ O
in -X- _ O
one -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
as -X- _ O
correct -X- _ O
in -X- _ O
another -X- _ O
context -X- _ O
, -X- _ O
each -X- _ O
according -X- _ O
to -X- _ O
specific -X- _ O
norms -X- _ O
that -X- _ O
are -X- _ O
activated -X- _ O
in -X- _ O
that -X- _ O
context -X- _ O
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
social -X- _ O
norms -X- _ O
activated -X- _ O
by -X- _ O
the -X- _ O
context -X- _ O
had -X- _ O
enough -X- _ O
modulatory -X- _ O
influence -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
an -X- _ O
ambiguous -X- _ O
referring -X- _ O
expression -X- _ O
favored -X- _ O
by -X- _ O
the -X- _ O
norm -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
consequence -X- _ O
, -X- _ O
not -X- _ O
knowing -X- _ O
the -X- _ O
norms -X- _ O
that -X- _ O
apply -X- _ O
in -X- _ O
these -X- _ O
context -X- _ O
will -X- _ O
likely -X- _ O
lead -X- _ O
to -X- _ O
incorrect -X- _ O
interpretations -X- _ O
of -X- _ O
referential -X- _ O
expressions -X- _ O
as -X- _ O
other -X- _ O
factors -X- _ O
not -X- _ O
necessarily -X- _ O
congruent -X- _ O
with -X- _ O
the -X- _ O
norm -X- _ O
- -X- _ O
based -X- _ O
interpretation -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
reference -X- _ O
resolution -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
next -X- _ O
section -X- _ O
on -X- _ O
current -X- _ O
NLP -X- _ O
tools -X- _ O
will -X- _ O
demonstrate -X- _ O
. -X- _ O

4.1 -X- _ O
Evaluating -X- _ O
NLP -X- _ O
Tools -X- _ O
To -X- _ O
complement -X- _ O
our -X- _ O
empirical -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
several -X- _ O
coreference -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tools -X- _ O
on -X- _ O
our -X- _ O
experimental -X- _ O
scenes -X- _ O
to -X- _ O
determine -X- _ O
if -X- _ O
they -X- _ O
achieve -X- _ O
human -X- _ O
performance -X- _ O
for -X- _ O
norm -X- _ O
- -X- _ O
guided -X- _ O
reference -X- _ O
resultion -X- _ O
tasks -X- _ O
. -X- _ O

These -X- _ O
include -X- _ O
Neural-6 -X- _ O

NLP -X- _ O
Tool -X- _ O
Context -X- _ O
C -X- _ O
Answer -X- _ O
NeuralCoref -X- _ B-MethodName
Dining -X- _ O
Room -X- _ O

A -X- _ O
coordination -X- _ O
✗ -X- _ O
Dining -X- _ O
Room -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
A -X- _ O

[ -X- _ O
the -X- _ O
worktable -X- _ O
] -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
B -X- _ O

[ -X- _ O
the -X- _ O
worktable -X- _ O
] -X- _ O
✗ -X- _ O
Bookstore -X- _ O
A -X- _ O
coordination -X- _ O
✗ -X- _ O
Bookstore -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Bathroom -X- _ O
A -X- _ O
non -X- _ O
- -X- _ O
referential -X- _ O
✗ -X- _ O
Bathroom -X- _ O
B -X- _ O

non -X- _ O
- -X- _ O
referential -X- _ O
✗ -X- _ O
CoreNLP -X- _ B-MethodName
Dining -X- _ O
Room -X- _ O

A -X- _ O

[ -X- _ O
dinner -X- _ O
] -X- _ O
✗ -X- _ O
Dining -X- _ O
Room -X- _ O
B -X- _ O

[ -X- _ O
a -X- _ O
shoe -X- _ O
] -X- _ O
✓ -X- _ O
Leather -X- _ O
Shop -X- _ O
A -X- _ O

[ -X- _ O
the -X- _ O
room -X- _ O
] -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
B -X- _ O

[ -X- _ O
the -X- _ O
room -X- _ O
] -X- _ O
✗ -X- _ O

Bookstore -X- _ O
A -X- _ O

[ -X- _ O
a -X- _ O
toothbrush -X- _ O
] -X- _ O
✗ -X- _ O
Bookstore -X- _ O
B -X- _ O

[ -X- _ O
a -X- _ O
magazine -X- _ O
] -X- _ O
✓ -X- _ O
Bathroom -X- _ O
A -X- _ O

[ -X- _ O
a -X- _ O
magazine -X- _ O
] -X- _ O
✗ -X- _ O
Bathroom -X- _ O
B -X- _ O

[ -X- _ O
a -X- _ O
toothbrush -X- _ O
] -X- _ O
✓ -X- _ O

AllenNLP -X- _ B-MethodName
Dining -X- _ O
Room -X- _ O

A -X- _ O
coordination -X- _ O
✗ -X- _ O
Dining -X- _ O
Room -X- _ O
B -X- _ O

[ -X- _ O
a -X- _ O
shoe -X- _ O
] -X- _ O
✓ -X- _ O
Leather -X- _ O
Shop -X- _ O
A -X- _ O
coordination -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O

Bookstore -X- _ O
A -X- _ O
coordination -X- _ O
✗ -X- _ O
Bookstore -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Bathroom -X- _ O
A -X- _ O
coordination -X- _ O
✗ -X- _ O
Bathroom -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
GPT-3 -X- _ B-MethodName
: -X- _ O

Dining -X- _ O
Room -X- _ O

A -X- _ O
coordination -X- _ O
✗ -X- _ O
Curie -X- _ O
Dining -X- _ O
Room -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
A -X- _ O
coordination -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Bookstore -X- _ O
A -X- _ O
non -X- _ O
- -X- _ O
referential -X- _ O
✗ -X- _ O
Bookstore -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Bathroom -X- _ O
A -X- _ O
coordination -X- _ O
✗ -X- _ O
Bathroom -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
GPT-3 -X- _ B-MethodName
: -X- _ O

Dining -X- _ O
Room -X- _ O

A -X- _ O
coordination -X- _ O
✗ -X- _ O
Davinci -X- _ B-MethodName
Dining -X- _ O
Room -X- _ O
B -X- _ O

[ -X- _ O
the -X- _ O
spoon -X- _ O
] -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O

A -X- _ O
coordination -X- _ O
✗ -X- _ O
Leather -X- _ O
Shop -X- _ O
B -X- _ O
coordination -X- _ O
✗ -X- _ O
Bookstore -X- _ O
A -X- _ O

[ -X- _ O
toothbrush -X- _ O
] -X- _ O
✗ -X- _ O
Bookstore -X- _ O
B -X- _ O

[ -X- _ O
toothbrush -X- _ O
] -X- _ O
✗ -X- _ O

Bathroom -X- _ O
A -X- _ O

[ -X- _ O
toothbrush -X- _ O
] -X- _ O
✓ -X- _ O
Bathroom -X- _ O
B -X- _ O
[ -X- _ O
toothbrush -X- _ O
] -X- _ O
✓ -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Evaluation -X- _ O
of -X- _ O
coreference -X- _ O
tools -X- _ O
on -X- _ O
contexts -X- _ O
that -X- _ O
use -X- _ O
a -X- _ O
definite -X- _ O
reference -X- _ O
. -X- _ O

The -X- _ O
dining -X- _ O
room -X- _ O
scene -X- _ O
and -X- _ O
leather -X- _ O
shop -X- _ O
scene -X- _ O
both -X- _ O
use -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
remove -X- _ O
it -X- _ O
; -X- _ O
the -X- _ O
bookstore -X- _ O
scene -X- _ O
and -X- _ O
home -X- _ O
bathroom -X- _ O
scene -X- _ O
, -X- _ O
similarly -X- _ O
, -X- _ O
use -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
pick -X- _ O
it -X- _ O
up -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
whether -X- _ O
these -X- _ O
tools -X- _ O
can -X- _ O
detect -X- _ O
if -X- _ O
itis -X- _ O
referential -X- _ O
and -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
object -X- _ O
. -X- _ O

Coref -X- _ B-MethodName
, -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
SpaCy -X- _ O
( -X- _ O
Honnibal -X- _ O
and -X- _ O
Johnson -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
based -X- _ O
on -X- _ O
( -X- _ O
Clark -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Stanford -X- _ O
CoreNLP -X- _ O
( -X- _ O
Finkel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
AllenNLP -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
evaluated -X- _ O
the -X- _ O
GPT-3 -X- _ B-MethodName
base -X- _ O
models -X- _ O
, -X- _ O
Davinci -X- _ B-MethodName
and -X- _ O
Curie -X- _ B-MethodName
, -X- _ O
by -X- _ O
OpenAI -X- _ O
, -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
designed -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O
and -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
tasks -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
specifically -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
scenes -X- _ O
that -X- _ O
use -X- _ O
a -X- _ O
definite -X- _ O
referring -X- _ O
expression -X- _ O
such -X- _ O
as -X- _ O
pick -X- _ O
it -X- _ O
up -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
bookstore -X- _ O
and -X- _ O
home -X- _ O
bathroom -X- _ O
scenes -X- _ O
, -X- _ O
and -X- _ O
remove -X- _ O
it -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
dining -X- _ O
room -X- _ O
and -X- _ O
leather -X- _ O
shop -X- _ O
scenes -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
GPT-3 -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
prompt -X- _ O
the -X- _ O
Davinci -X- _ B-MethodName
model -X- _ O
with -X- _ O
the -X- _ O
phrase -X- _ O
which -X- _ O
one -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
prompt -X- _ O
the -X- _ O
Curie -X- _ B-MethodName
model -X- _ O
with -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O

We -X- _ O
made -X- _ O
this -X- _ O
decision -X- _ O
to -X- _ O
probe -X- _ O
the -X- _ O
different -X- _ O
capabilities -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
; -X- _ O
for -X- _ O
the -X- _ O
Curie -X- _ B-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
not -X- _ O
to -X- _ O
prompt -X- _ O
it -X- _ O
to -X- _ O
see -X- _ O
if -X- _ O
would -X- _ O
coherently -X- _ O
generate -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
resolve -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
likely -X- _ O
to -X- _ O
follow -X- _ O
from -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
in -X- _ O
the -X- _ O
command -X- _ O
( -X- _ O
e.g. -X- _ O
pick -X- _ O
it -X- _ O
up -X- _ O
, -X- _ O
remove -X- _ O
it -X- _ O
) -X- _ O
; -X- _ O
for -X- _ O
the -X- _ O
Davinci -X- _ B-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
tested -X- _ O
the -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
capabilities -X- _ O
by -X- _ O
providing -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O

This -X- _ O
evaluation -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
a -X- _ O
similar -X- _ O
question -X- _ O
as -X- _ O
the -X- _ O
main -X- _ O
study -X- _ O
— -X- _ O
Was -X- _ O
this -X- _ O
the -X- _ O
correct -X- _ O
object -X- _ O
? -X- _ O

— -X- _ O
as -X- _ O
understanding -X- _ O
a -X- _ O
yesno -X- _ O
response -X- _ O
is -X- _ O
more -X- _ O
opaque -X- _ O
and -X- _ O
we -X- _ O
wanted -X- _ O
to -X- _ O
see -X- _ O
if -X- _ O
it -X- _ O
could -X- _ O
return -X- _ O
the -X- _ O
referents -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
were -X- _ O
used -X- _ O
off -X- _ O
the -X- _ O
shelf -X- _ O
without -X- _ O
fine -X- _ O
tuning -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
where -X- _ O
we -X- _ O
list -X- _ O
the -X- _ O
referents -X- _ O
that -X- _ O
the -X- _ O
tools -X- _ O
selected -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
. -X- _ O

We -X- _ O
represent -X- _ O
an -X- _ O
entity -X- _ O
in -X- _ O
brackets -X- _ O
and -X- _ O
also -X- _ O
note -X- _ O
when -X- _ O
the -X- _ O
referent -X- _ O
is -X- _ O
the -X- _ O
coordination -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
referents -X- _ O
( -X- _ O
e.g. -X- _ O
a -X- _ O
shoe -X- _ O
and -X- _ O
a -X- _ O
spoon -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
was -X- _ O
interpreted -X- _ O
as -X- _ O
non -X- _ O
- -X- _ O
referential -X- _ O
. -X- _ O

A -X- _ O
check -X- _ O
mark -X- _ O
✓ -X- _ O
denotes -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
and -X- _ O
an -X- _ O
✗ -X- _ O
denotes -X- _ O
the -X- _ O
incorrect -X- _ O
referent -X- _ O
. -X- _ O

The -X- _ O
experimental -X- _ O
conditions -X- _ O
have -X- _ O
a -X- _ O
role -X- _ O
, -X- _ O
here -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
recency -X- _ O
or -X- _ O
distance -X- _ O
of -X- _ O
the -X- _ O
referent -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
traditional -X- _ O
feature -X- _ O
for -X- _ O
coreference -X- _ O
models -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

Swapping -X- _ O
the -X- _ O
ordering -X- _ O
of -X- _ O
the -X- _ O
referents -X- _ O
ensures -X- _ O
that -X- _ O
if -X- _ O
a -X- _ O
model -X- _ O
resolves -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
consistent -X- _ O
and -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
context -X- _ O
then -X- _ O
the -X- _ O
surface -X- _ O
structure -X- _ O
. -X- _ O

This -X- _ O
swapping -X- _ O
method -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
Emami -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
’s -X- _ O
evaluation -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
KnowRef -X- _ B-DatasetName
test -X- _ O
set -X- _ O
for -X- _ O
consistency -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
only -X- _ O
three -X- _ O
cases -X- _ O
where -X- _ O
the -X- _ O
coreference -X- _ O
models -X- _ O
choose -X- _ O
the -X- _ O
right -X- _ O
referent -X- _ O
. -X- _ O

CoreNLP -X- _ B-MethodName
and -X- _ O
AllenNLP -X- _ B-MethodName
both -X- _ O
correctly -X- _ O
link -X- _ O

[ -X- _ O
a -X- _ O
shoe -X- _ O
] -X- _ O
and -X- _ O
itin -X- _ O
the -X- _ O
dining -X- _ O
room -X- _ O
scene -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
condition -X- _ O
( -X- _ O
condition -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O
shoe -X- _ O
is -X- _ O
mentioned -X- _ O
first -X- _ O
in7 -X- _ O

the -X- _ O
text -X- _ O
. -X- _ O

Although -X- _ O
, -X- _ O
once -X- _ O
the -X- _ O
objects -X- _ O
are -X- _ O
switched -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
choose -X- _ O
the -X- _ O
wrong -X- _ O
object -X- _ O
— -X- _ O
CoreNLP -X- _ B-MethodName
selects -X- _ O
[ -X- _ O
dinner -X- _ O
] -X- _ O
( -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
referents -X- _ O
) -X- _ O
and -X- _ O
AllenNLP -X- _ B-MethodName
selects -X- _ O
both -X- _ O
the -X- _ O
shoe -X- _ O
and -X- _ O
the -X- _ O
spoon -X- _ O
in -X- _ O
a -X- _ O
coordination -X- _ O
. -X- _ O

CoreNLP -X- _ B-MethodName
seems -X- _ O
to -X- _ O
do -X- _ O
the -X- _ O
best -X- _ O
by -X- _ O
selecting -X- _ O
another -X- _ O
correct -X- _ O
referent -X- _ O
: -X- _ O

[ -X- _ O
a -X- _ O
magazine -X- _ O
] -X- _ O
in -X- _ O
the -X- _ O
bookstore -X- _ O
scene -X- _ O
. -X- _ O

But -X- _ O
it -X- _ O
fails -X- _ O
yet -X- _ O
again -X- _ O
once -X- _ O
the -X- _ O
objects -X- _ O
are -X- _ O
swapped -X- _ O
. -X- _ O

The -X- _ O
GPT-3 -X- _ B-MethodName
models -X- _ O
perform -X- _ O
poorly -X- _ O
overall -X- _ O
but -X- _ O
the -X- _ O
Davinci -X- _ B-MethodName
model -X- _ O
, -X- _ O
prompted -X- _ O
by -X- _ O
which -X- _ O
one -X- _ O
, -X- _ O
gets -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
answer -X- _ O
by -X- _ O
picking -X- _ O
out -X- _ O
individual -X- _ O
referents -X- _ O
more -X- _ O
often -X- _ O
than -X- _ O
the -X- _ O
Curie -X- _ B-MethodName
model -X- _ O
. -X- _ O

Davinci -X- _ B-MethodName
is -X- _ O
consistently -X- _ O
incorrect -X- _ O
in -X- _ O
the -X- _ O
bookstore -X- _ O
scene -X- _ O
but -X- _ O
consistently -X- _ O
correct -X- _ O
in -X- _ O
the -X- _ O
bathroom -X- _ O
scene -X- _ O
, -X- _ O
yielding -X- _ O
the -X- _ O
only -X- _ O
correct -X- _ O
result -X- _ O
when -X- _ O
the -X- _ O
referents -X- _ O
are -X- _ O
switched -X- _ O
. -X- _ O

The -X- _ O
correct -X- _ O
referent -X- _ O
selected -X- _ O
in -X- _ O
the -X- _ O
bathroom -X- _ O
, -X- _ O
the -X- _ O
toothbrush -X- _ O
, -X- _ O
was -X- _ O
also -X- _ O
selected -X- _ O
in -X- _ O
the -X- _ O
bookstore -X- _ O
for -X- _ O
both -X- _ O
conditions -X- _ O
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
biased -X- _ O
towards -X- _ O
picking -X- _ O
the -X- _ O
toothbrush -X- _ O
over -X- _ O
the -X- _ O
magazine -X- _ O
more -X- _ O
generally -X- _ O
. -X- _ O

For -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
tools -X- _ O
doing -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
on -X- _ O
these -X- _ O
scenarios -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
theme -X- _ O
of -X- _ O
referring -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
coordination -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
referents -X- _ O
, -X- _ O
when -X- _ O
only -X- _ O
one -X- _ O
referent -X- _ O
should -X- _ O
be -X- _ O
selected -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
clear -X- _ O
these -X- _ O
results -X- _ O
do -X- _ O
not -X- _ O
match -X- _ O
human -X- _ O
intuition -X- _ O
for -X- _ O
this -X- _ O
specific -X- _ O
reference -X- _ B-TaskName
resolution -X- _ I-TaskName
task -X- _ O
and -X- _ O
, -X- _ O
more -X- _ O
importantly -X- _ O
, -X- _ O
fail -X- _ O
to -X- _ O
understanding -X- _ O
social -X- _ O
norms -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
consistently -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
. -X- _ O

5 -X- _ O
Discussion -X- _ O
& -X- _ O
Future -X- _ O
Implementations -X- _ O
The -X- _ O
coreference -X- _ O
task -X- _ O
performed -X- _ O
by -X- _ O
humans -X- _ O
and -X- _ O
the -X- _ O
NLP -X- _ O
tools -X- _ O
show -X- _ O
a -X- _ O
striking -X- _ O
difference -X- _ O
in -X- _ O
outcomes -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
same -X- _ O
context -X- _ O
and -X- _ O
text -X- _ O
, -X- _ O
people -X- _ O
tended -X- _ O
to -X- _ O
agree -X- _ O
on -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
examples -X- _ O
were -X- _ O
stripped -X- _ O
of -X- _ O
linguistic -X- _ O
cues -X- _ O
that -X- _ O
would -X- _ O
give -X- _ O
away -X- _ O
the -X- _ O
referent -X- _ O
, -X- _ O
people -X- _ O
relied -X- _ O
on -X- _ O
context -X- _ O
and -X- _ O
social -X- _ O
norms -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
reasons -X- _ O
they -X- _ O
selected -X- _ O
and -X- _ O
the -X- _ O
written -X- _ O
explanations -X- _ O
they -X- _ O
provided -X- _ O
. -X- _ O

Notably -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
inconsistent -X- _ O
agreement -X- _ O
across -X- _ O
all -X- _ O
scenes -X- _ O
can -X- _ O
be -X- _ O
reconciled -X- _ O
with -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
are -X- _ O
not -X- _ O
equally -X- _ O
shared -X- _ O
across -X- _ O
all -X- _ O
people -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
supported -X- _ O
, -X- _ O
in -X- _ O
part -X- _ O
, -X- _ O
by -X- _ O
the -X- _ O
written -X- _ O
responses -X- _ O
too -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
also -X- _ O
suggest -X- _ O
that -X- _ O
not -X- _ O
every -X- _ O
norm -X- _ O
is -X- _ O
weighed -X- _ O
the -X- _ O
same -X- _ O
; -X- _ O
the -X- _ O
deontic -X- _ O
force -X- _ O
— -X- _ O
how -X- _ O
strongly -X- _ O
the -X- _ O
norm -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
followed -X- _ O
— -X- _ O
potentially -X- _ O
influences -X- _ O
how -X- _ O
the -X- _ O
norm -X- _ O
guides -X- _ O
a -X- _ O
behavior -X- _ O
or -X- _ O
interpretation -X- _ O
and -X- _ O
competes -X- _ O
with -X- _ O
other -X- _ O
norms -X- _ O
. -X- _ O

Admittedly -X- _ O
, -X- _ O
a -X- _ O
limitation -X- _ O
of -X- _ O
our -X- _ O
study -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
explicitly -X- _ O
categorize -X- _ O
our -X- _ O
hypothesized -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
in -X- _ O
a -X- _ O
gradable -X- _ O
fashion -X- _ O
, -X- _ O
but -X- _ O
future -X- _ O
work -X- _ O
will -X- _ O
considerdeontic -X- _ O
force -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grain -X- _ O
understanding -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
. -X- _ O

NLP -X- _ O
tools -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
end -X- _ O
, -X- _ O
tell -X- _ O
a -X- _ O
different -X- _ O
story -X- _ O
. -X- _ O

Many -X- _ O
of -X- _ O
the -X- _ O
tools -X- _ O
specifically -X- _ O
designed -X- _ O
for -X- _ O
coreference -X- _ O
resolution -X- _ O
failed -X- _ O
to -X- _ O
consistently -X- _ O
select -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
. -X- _ O

The -X- _ O
more -X- _ O
powerful -X- _ O
NLP -X- _ O
engines -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
GPT-3 -X- _ B-MethodName
model -X- _ O
, -X- _ O
also -X- _ O
performed -X- _ O
poorly -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
relying -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
system -X- _ O
to -X- _ O
resolve -X- _ O
references -X- _ O
in -X- _ O
these -X- _ O
contexts -X- _ O
would -X- _ O
be -X- _ O
problematic -X- _ O
. -X- _ O

The -X- _ O
Davinci -X- _ B-MethodName
model -X- _ O
when -X- _ O
prompted -X- _ O
by -X- _ O
the -X- _ O
question -X- _ O
which -X- _ O
one -X- _ O
? -X- _ O
justifies -X- _ O
its -X- _ O
response -X- _ O
with -X- _ O
an -X- _ O
explanation -X- _ O
of -X- _ O
grammatical -X- _ O
appropriateness -X- _ O
: -X- _ O
If -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
noun -X- _ O
that -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
clear -X- _ O
that -X- _ O
the -X- _ O
speaker -X- _ O
is -X- _ O
referring -X- _ O
to -X- _ O
the -X- _ O
toothbrush -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
no -X- _ O
other -X- _ O
“ -X- _ O
it -X- _ O
” -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
... -X- _ O

We -X- _ O
would -X- _ O
never -X- _ O
say -X- _ O
, -X- _ O
“ -X- _ O
Pick -X- _ O
up -X- _ O
the -X- _ O
magazine -X- _ O
. -X- _ O
" -X- _ O

This -X- _ O
is -X- _ O
why -X- _ O
it -X- _ O
’s -X- _ O
important -X- _ O
to -X- _ O
know -X- _ O
whether -X- _ O
the -X- _ O
noun -X- _ O
is -X- _ O
the -X- _ O
subject -X- _ O
or -X- _ O
object -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
. -X- _ O

This -X- _ O
explanation -X- _ O
echoes -X- _ O
something -X- _ O
meaningful -X- _ O
about -X- _ O
grammar -X- _ O
, -X- _ O
yet -X- _ O
is -X- _ O
faulty -X- _ O
and -X- _ O
unclear -X- _ O
. -X- _ O

Rather -X- _ O
, -X- _ O
this -X- _ O
argument -X- _ O
is -X- _ O
produced -X- _ O
from -X- _ O
statistical -X- _ O
correlations -X- _ O
the -X- _ O
system -X- _ O
extracted -X- _ O
from -X- _ O
large -X- _ O
corpora -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
the -X- _ O
system -X- _ O
has -X- _ O
no -X- _ O
understanding -X- _ O
of -X- _ O
norms -X- _ O
or -X- _ O
how -X- _ O
to -X- _ O
apply -X- _ O
them -X- _ O
. -X- _ O

The -X- _ O
potential -X- _ O
danger -X- _ O
, -X- _ O
here -X- _ O
, -X- _ O
is -X- _ O
that -X- _ O
simply -X- _ O
employing -X- _ O
deep -X- _ O
learning -X- _ O
systems -X- _ O
without -X- _ O
giving -X- _ O
them -X- _ O
a -X- _ O
sense -X- _ O
of -X- _ O
norms -X- _ O
will -X- _ O
lead -X- _ O
such -X- _ O
systems -X- _ O
to -X- _ O
also -X- _ O
violate -X- _ O
norms -X- _ O
. -X- _ O

While -X- _ O
the -X- _ O
consequences -X- _ O
of -X- _ O
breaking -X- _ O
norms -X- _ O
can -X- _ O
range -X- _ O
in -X- _ O
severity -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
most -X- _ O
extreme -X- _ O
end -X- _ O
, -X- _ O
they -X- _ O
can -X- _ O
include -X- _ O
harm -X- _ O
to -X- _ O
other -X- _ O
people -X- _ O
. -X- _ O

A -X- _ O
norm -X- _ O
aware -X- _ O
reference -X- _ O
resolution -X- _ O
system -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
will -X- _ O
not -X- _ O
only -X- _ O
help -X- _ O
to -X- _ O
disambiguate -X- _ O
referents -X- _ O
but -X- _ O
help -X- _ O
a -X- _ O
system -X- _ O
know -X- _ O
what -X- _ O
notto -X- _ O
do -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
especially -X- _ O
important -X- _ O
with -X- _ O
embodied -X- _ O
agents -X- _ O
whose -X- _ O
actions -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
world -X- _ O
will -X- _ O
be -X- _ O
influenced -X- _ O
by -X- _ O
its -X- _ O
reference -X- _ O
resolution -X- _ O
capabilities -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

5.1 -X- _ O
Implementation -X- _ O
in -X- _ O
Embodied -X- _ O
Agents -X- _ O
Inspired -X- _ O
by -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
outline -X- _ O
a -X- _ O
potential -X- _ O
methodology -X- _ O
for -X- _ O
robots -X- _ O
to -X- _ O
use -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
in -X- _ O
performing -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
inferences -X- _ O
necessary -X- _ O
for -X- _ O
selecting -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
in -X- _ O
our -X- _ O
scenarios -X- _ O
, -X- _ O
a -X- _ O
novel -X- _ O
pragmatic -X- _ O
component -X- _ O
must -X- _ O
be -X- _ O
tightly -X- _ O
integrated -X- _ O
with -X- _ O
vision -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
in -X- _ O
a -X- _ O
robotic -X- _ O
cognitive -X- _ O
architecture -X- _ O
. -X- _ O

All -X- _ O
three -X- _ O
inputs -X- _ O
will -X- _ O
simultaneously -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
a -X- _ O
referring -X- _ O
expression -X- _ O
. -X- _ O

A -X- _ O
pragmatic -X- _ O
component -X- _ O
will -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
knowledge -X- _ O
base -X- _ O
specifically -X- _ O
for -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
it -X- _ O
would -X- _ O
require -X- _ O
a -X- _ O
baseline -X- _ O
representation -X- _ O
of -X- _ O
norms -X- _ O
, -X- _ O
which8 -X- _ O

can -X- _ O
be -X- _ O
collected -X- _ O
experimentally -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
domain -X- _ O
( -X- _ O
Malle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Upon -X- _ O
hearing -X- _ O
natural -X- _ O
language -X- _ O
input -X- _ O
from -X- _ O
a -X- _ O
co -X- _ O
- -X- _ O
located -X- _ O
speaker -X- _ O
, -X- _ O
a -X- _ O
robot -X- _ O
will -X- _ O
begin -X- _ O
incrementally -X- _ O
processing -X- _ O
the -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
look -X- _ O
for -X- _ O
a -X- _ O
referring -X- _ O
expression -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
visual -X- _ O
system -X- _ O
will -X- _ O
scan -X- _ O
the -X- _ O
environment -X- _ O
for -X- _ O
two -X- _ O
purposes -X- _ O
: -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
perceptually -X- _ O
salient -X- _ O
objects -X- _ O
that -X- _ O
potentially -X- _ O
match -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
and -X- _ O
to -X- _ O
trigger -X- _ O
the -X- _ O
setting -X- _ O
to -X- _ O
activate -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
norms -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
spotting -X- _ O
a -X- _ O
fork -X- _ O
, -X- _ O
plate -X- _ O
, -X- _ O
or -X- _ O
table -X- _ O
, -X- _ O
the -X- _ O
robot -X- _ O
can -X- _ O
infer -X- _ O
with -X- _ O
greater -X- _ O
probability -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
located -X- _ O
in -X- _ O
a -X- _ O
dining -X- _ O
room -X- _ O
and -X- _ O
cue -X- _ O
an -X- _ O
inventory -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
operationalized -X- _ O
as -X- _ O
prescriptions -X- _ O
and -X- _ O
prohibitions -X- _ O
. -X- _ O

Some -X- _ O
of -X- _ O
these -X- _ O
prescriptions -X- _ O
, -X- _ O
informally -X- _ O
, -X- _ O
might -X- _ O
be -X- _ O
: -X- _ O
food -X- _ O
or -X- _ O
drinks -X- _ O
are -X- _ O
allowed -X- _ O
on -X- _ O
the -X- _ O
table -X- _ O
oryou -X- _ O
are -X- _ O
allowed -X- _ O
to -X- _ O
sit -X- _ O
at -X- _ O
the -X- _ O
dinner -X- _ O
table -X- _ O
. -X- _ O

Alternatively -X- _ O
, -X- _ O
some -X- _ O
prohibitions -X- _ O
might -X- _ O
be -X- _ O
X -X- _ O
items -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
on -X- _ O
the -X- _ O
dining -X- _ O
table -X- _ O
orfood -X- _ O
and -X- _ O
drink -X- _ O
should -X- _ O
be -X- _ O
contained -X- _ O
on -X- _ O
the -X- _ O
dinner -X- _ O
table -X- _ O
. -X- _ O

Incremental -X- _ O
processing -X- _ O
will -X- _ O
allow -X- _ O
the -X- _ O
robot -X- _ O
to -X- _ O
gradually -X- _ O
look -X- _ O
for -X- _ O
potential -X- _ O
referents -X- _ O
in -X- _ O
the -X- _ O
scene -X- _ O
and -X- _ O
, -X- _ O
if -X- _ O
it -X- _ O
finds -X- _ O
potential -X- _ O
candidates -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
, -X- _ O
it -X- _ O
will -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
joint -X- _ O
probability -X- _ O
of -X- _ O
each -X- _ O
referent -X- _ O
given -X- _ O
the -X- _ O
social -X- _ O
norms -X- _ O
. -X- _ O

The -X- _ O
social -X- _ O
norms -X- _ O
activated -X- _ O
from -X- _ O
the -X- _ O
setting -X- _ O
should -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
interpretation -X- _ O
from -X- _ O
the -X- _ O
start -X- _ O
, -X- _ O
not -X- _ O
only -X- _ O
when -X- _ O
an -X- _ O
ambiguous -X- _ O
situation -X- _ O
arises -X- _ O
, -X- _ O
since -X- _ O
they -X- _ O
can -X- _ O
modulate -X- _ O
the -X- _ O
interpretation -X- _ O
at -X- _ O
any -X- _ O
point -X- _ O
; -X- _ O
as -X- _ O
seen -X- _ O
from -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
form -X- _ O
of -X- _ O
the -X- _ O
referring -X- _ O
expression -X- _ O
, -X- _ O
the -X- _ O
social -X- _ O
norms -X- _ O
can -X- _ O
flip -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
the -X- _ O
referent -X- _ O
when -X- _ O
everything -X- _ O
else -X- _ O
is -X- _ O
constant -X- _ O
. -X- _ O

An -X- _ O
advantage -X- _ O
to -X- _ O
using -X- _ O
an -X- _ O
inventory -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
in -X- _ O
this -X- _ O
way -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
can -X- _ O
eliminate -X- _ O
potential -X- _ O
referents -X- _ O
right -X- _ O
away -X- _ O
. -X- _ O

The -X- _ O
strength -X- _ O
of -X- _ O
the -X- _ O
norm -X- _ O
, -X- _ O
roughly -X- _ O
corresponding -X- _ O
to -X- _ O
their -X- _ O
deontic -X- _ O
force -X- _ O
, -X- _ O
must -X- _ O
be -X- _ O
considered -X- _ O
for -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
application -X- _ O
of -X- _ O
norms -X- _ O
as -X- _ O
some -X- _ O
norms -X- _ O
will -X- _ O
compete -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
critical -X- _ O
to -X- _ O
understand -X- _ O
what -X- _ O
norms -X- _ O
may -X- _ O
or -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
overruled -X- _ O
as -X- _ O
not -X- _ O
to -X- _ O
cause -X- _ O
harm -X- _ O
to -X- _ O
human -X- _ O
users -X- _ O
. -X- _ O

While -X- _ O
norm -X- _ O
activation -X- _ O
begins -X- _ O
early -X- _ O
on -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
continually -X- _ O
update -X- _ O
through -X- _ O
visual -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
input -X- _ O
. -X- _ O

If -X- _ O
the -X- _ O
robot -X- _ O
is -X- _ O
uncertain -X- _ O
about -X- _ O
the -X- _ O
setting -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
ask -X- _ O
clarifying -X- _ O
questions -X- _ O
to -X- _ O
gain -X- _ O
more -X- _ O
information -X- _ O
. -X- _ O

This -X- _ O
approach -X- _ O
seems -X- _ O
applicable -X- _ O
in -X- _ O
preventing -X- _ O
harm -X- _ O
where -X- _ O
it -X- _ O
might -X- _ O
be -X- _ O
better -X- _ O
in -X- _ O
many -X- _ O
instances -X- _ O
to -X- _ O
ask -X- _ O
questions -X- _ O
in -X- _ O
uncertain -X- _ O
contexts -X- _ O
than -X- _ O
to -X- _ O
overstep -X- _ O
boundaries -X- _ O
. -X- _ O

To -X- _ O
walk -X- _ O
through -X- _ O
a -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
scenario -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
scenario -X- _ O
from -X- _ O
our -X- _ O
experiment -X- _ O
, -X- _ O
imagine -X- _ O
someone -X- _ O
commanding -X- _ O
the -X- _ O
robot -X- _ O
: -X- _ O
remove -X- _ O
it -X- _ O
.Even -X- _ O

if -X- _ O
the -X- _ O
speaker -X- _ O
pauses -X- _ O
after -X- _ O
the -X- _ O
verb -X- _ O
remove -X- _ O
, -X- _ O
incremental -X- _ O
processing -X- _ O
begins -X- _ O
to -X- _ O
parse -X- _ O
the -X- _ O
utterance -X- _ O
and -X- _ O
the -X- _ O
robot -X- _ O
visually -X- _ O
scans -X- _ O
the -X- _ O
environment -X- _ O
for -X- _ O
the -X- _ O
setting -X- _ O
and -X- _ O
salient -X- _ O
objects -X- _ O
. -X- _ O

The -X- _ O
robots -X- _ O
activates -X- _ O
the -X- _ O
norms -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
social -X- _ O
norm -X- _ O
knowledge -X- _ O
base -X- _ O
and -X- _ O
continues -X- _ O
processing -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

Once -X- _ O
the -X- _ O
utterance -X- _ O
is -X- _ O
completely -X- _ O
processed -X- _ O
, -X- _ O
the -X- _ O
expression -X- _ O
, -X- _ O
it -X- _ O
, -X- _ O
is -X- _ O
linked -X- _ O
to -X- _ O
either -X- _ O
a -X- _ O
shoe -X- _ O
or -X- _ O
a -X- _ O
spoon -X- _ O
. -X- _ O

With -X- _ O
no -X- _ O
other -X- _ O
cue -X- _ O
from -X- _ O
the -X- _ O
linguistic -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
prohibition -X- _ O
of -X- _ O
shoes -X- _ O
on -X- _ O
dining -X- _ O
room -X- _ O
tables -X- _ O
pushes -X- _ O
the -X- _ O
interpretation -X- _ O
towards -X- _ O
removing -X- _ O
the -X- _ O
shoe -X- _ O
. -X- _ O

The -X- _ O
norm -X- _ O
is -X- _ O
determined -X- _ O
to -X- _ O
be -X- _ O
strong -X- _ O
enough -X- _ O
for -X- _ O
the -X- _ O
robot -X- _ O
to -X- _ O
act -X- _ O
and -X- _ O
so -X- _ O
it -X- _ O
proceeds -X- _ O
to -X- _ O
remove -X- _ O
the -X- _ O
shoe -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
the -X- _ O
robot -X- _ O
successfully -X- _ O
uses -X- _ O
its -X- _ O
norm -X- _ O
knowledge -X- _ O
base -X- _ O
in -X- _ O
tandem -X- _ O
with -X- _ O
its -X- _ O
vision -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
abilities -X- _ O
, -X- _ O
to -X- _ O
handle -X- _ O
what -X- _ O
appears -X- _ O
on -X- _ O
the -X- _ O
surface -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
underspecified -X- _ O
referring -X- _ O
expression -X- _ O
. -X- _ O

6 -X- _ O
Conclusions -X- _ O
We -X- _ O
conducted -X- _ O
a -X- _ O
human -X- _ O
subjects -X- _ O
study -X- _ O
to -X- _ O
demonstrate -X- _ O
how -X- _ O
social -X- _ O
norms -X- _ O
can -X- _ O
guide -X- _ O
reference -X- _ O
resolution -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
text -X- _ O
vignette -X- _ O
and -X- _ O
a -X- _ O
referring -X- _ O
expression -X- _ O
stripped -X- _ O
of -X- _ O
linguistic -X- _ O
cues -X- _ O
, -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
subjects -X- _ O
confirmed -X- _ O
the -X- _ O
intended -X- _ O
referent -X- _ O
in -X- _ O
each -X- _ O
context -X- _ O
and -X- _ O
relied -X- _ O
on -X- _ O
knowledge -X- _ O
of -X- _ O
conventions -X- _ O
to -X- _ O
make -X- _ O
their -X- _ O
decision -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
several -X- _ O
NLP -X- _ O
tools -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
examples -X- _ O
consistently -X- _ O
failed -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
correct -X- _ O
referent -X- _ O
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
these -X- _ O
NLP -X- _ O
tools -X- _ O
critically -X- _ O
lack -X- _ O
an -X- _ O
understanding -X- _ O
of -X- _ O
conventions -X- _ O
and -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
completely -X- _ O
relied -X- _ O
on -X- _ O
for -X- _ O
reference -X- _ O
resolution -X- _ O
as -X- _ O
they -X- _ O
can -X- _ O
also -X- _ O
violate -X- _ O
norms -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
our -X- _ O
findings -X- _ O
into -X- _ O
designing -X- _ O
a -X- _ O
methodology -X- _ O
for -X- _ O
teaching -X- _ O
robots -X- _ O
to -X- _ O
use -X- _ O
social -X- _ O
norms -X- _ O
and -X- _ O
conventions -X- _ O
to -X- _ O
perform -X- _ O
situated -X- _ B-TaskName
reference -X- _ I-TaskName
resolution -X- _ I-TaskName
. -X- _ O

In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
using -X- _ O
visual -X- _ O
scenes -X- _ O
for -X- _ O
activating -X- _ O
norms -X- _ O
and -X- _ O
evaluate -X- _ O
larger -X- _ O
NLP -X- _ O
models -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
to -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
implement -X- _ O
our -X- _ O
methodology -X- _ O
into -X- _ O
a -X- _ O
cognitive -X- _ O
architecture -X- _ O
and -X- _ O
look -X- _ O
more -X- _ O
closely -X- _ O
at -X- _ O
how -X- _ O
the -X- _ O
gradability -X- _ O
of -X- _ O
social -X- _ O
norms -X- _ O
influences -X- _ O
reference -X- _ O
resolution -X- _ O
. -X- _ O

Acknowledgements -X- _ O
We -X- _ O
are -X- _ O
grateful -X- _ O
to -X- _ O
James -X- _ O
Pustejovsky -X- _ O
for -X- _ O
assisting -X- _ O
with -X- _ O
our -X- _ O
experimental -X- _ O
contexts -X- _ O
, -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
feedback -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
SMART -X- _ O
scholarship -X- _ O
for -X- _ O
funding -X- _ O
the -X- _ O
first -X- _ O
author.9 -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
2021 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
1–10 -X- _ O
June -X- _ O
6–11 -X- _ O
, -X- _ O
2021 -X- _ O
. -X- _ O

© -X- _ O
2021 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics1KNOWLEDGE -X- _ O
ROUTER -X- _ O
: -X- _ O
Learning -X- _ O
Disentangled -X- _ O
Representations -X- _ O
for -X- _ O
Knowledge -X- _ O
Graphs -X- _ O
Shuai -X- _ O
Zhang1 -X- _ O
, -X- _ O
Xi -X- _ O
Rao1 -X- _ O
, -X- _ O

Yi -X- _ O
Tay2andCe -X- _ O
Zhang1 -X- _ O

Abstract -X- _ O
The -X- _ O
design -X- _ O
of -X- _ O
expressive -X- _ O
representations -X- _ O
of -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
in -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
endeavor -X- _ O
. -X- _ O

While -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
approaches -X- _ O
have -X- _ O
primarily -X- _ O
focused -X- _ O
on -X- _ O
learning -X- _ O
from -X- _ O
relational -X- _ O
patterns -X- _ O
and -X- _ O
structural -X- _ O
information -X- _ O
, -X- _ O
the -X- _ O
intrinsic -X- _ O
complexity -X- _ O
of -X- _ O
KG -X- _ O
entities -X- _ O
has -X- _ O
been -X- _ O
more -X- _ O
or -X- _ O
less -X- _ O
overlooked -X- _ O
. -X- _ O

More -X- _ O
concretely -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
KG -X- _ O
entities -X- _ O
may -X- _ O
be -X- _ O
more -X- _ O
complex -X- _ O
than -X- _ O
we -X- _ O
think -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
an -X- _ O
entity -X- _ O
may -X- _ O
wear -X- _ O
many -X- _ O
hats -X- _ O
and -X- _ O
relational -X- _ O
triplets -X- _ O
may -X- _ O
form -X- _ O
due -X- _ O
to -X- _ O
more -X- _ O
than -X- _ O
a -X- _ O
single -X- _ O
reason -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
this -X- _ O
paper -X- _ O
proposes -X- _ O
to -X- _ O
learn -X- _ O
disentangled -X- _ O
representations -X- _ O
of -X- _ O
KG -X- _ O
entities -X- _ O
- -X- _ O
a -X- _ O
new -X- _ O
method -X- _ O
that -X- _ O
disentangles -X- _ O
the -X- _ O
inner -X- _ O
latent -X- _ O
properties -X- _ O
of -X- _ O
KG -X- _ O
entities -X- _ O
. -X- _ O

Our -X- _ O
disentangled -X- _ O
process -X- _ O
operates -X- _ O
at -X- _ O
the -X- _ O
graph -X- _ O
level -X- _ O
and -X- _ O
a -X- _ O
neighborhood -X- _ O
mechanism -X- _ O
is -X- _ O
leveraged -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
hidden -X- _ O
properties -X- _ O
of -X- _ O
each -X- _ O
entity -X- _ O
. -X- _ O

This -X- _ O
disentangled -X- _ O
representation -X- _ O
learning -X- _ O
approach -X- _ O
is -X- _ O
model -X- _ O
agnostic -X- _ O
and -X- _ O
compatible -X- _ O
with -X- _ O
canonical -X- _ O
KG -X- _ O
embedding -X- _ O
approaches -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
several -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
equipping -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
models -X- _ O
( -X- _ O
DistMult -X- _ B-MethodName
, -X- _ O
SimplE -X- _ B-MethodName
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
) -X- _ O
with -X- _ O
our -X- _ O
proposed -X- _ O
disentangling -X- _ B-MethodName
mechanism -X- _ I-MethodName
. -X- _ O

Experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
substantially -X- _ O
improves -X- _ O
performance -X- _ O
on -X- _ O
key -X- _ O
metrics -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Knowledge -X- _ O
graphs -X- _ O
( -X- _ O
KG -X- _ O
) -X- _ O
have -X- _ O
emerged -X- _ O
as -X- _ O
a -X- _ O
compelling -X- _ O
abstraction -X- _ O
for -X- _ O
organizing -X- _ O
structured -X- _ O
knowledge -X- _ O
. -X- _ O

They -X- _ O
have -X- _ O
been -X- _ O
playing -X- _ O
crucial -X- _ O
roles -X- _ O
in -X- _ O
many -X- _ O
machine -X- _ O
learning -X- _ O
tasks -X- _ O
. -X- _ O

A -X- _ O
knowledge -X- _ O
graph -X- _ O
represents -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
linked -X- _ O
data -X- _ O
, -X- _ O
describing -X- _ O
entities -X- _ O
of -X- _ O
interest -X- _ O
and -X- _ O
relationships -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O

To -X- _ O
incorporate -X- _ O
KGs -X- _ O
into -X- _ O
other -X- _ O
machine -X- _ O
learning -X- _ O
systems -X- _ O
, -X- _ O
a -X- _ O
prevalent -X- _ O
way -X- _ O
is -X- _ O
mapping -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
of -X- _ O
knowledge -X- _ O
graphs -X- _ O
into -X- _ O
expressive -X- _ O
representations -X- _ O
in -X- _ O
a -X- _ O
low -X- _ O
- -X- _ O
dimensional -X- _ O
space -X- _ O
that -X- _ O
preserves -X- _ O
the -X- _ O
relationships -X- _ O
among -X- _ O
objects -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
knowledge -X- _ B-TaskName
graph -X- _ I-TaskName
embeddings -X- _ I-TaskName
. -X- _ O

Representative -X- _ O
work -X- _ O
such -X- _ O
as -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
gained -X- _ O
intensive -X- _ O
attention -X- _ O
across -X- _ O
the -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O

The -X- _ O
substantial -X- _ O
effectiveness -X- _ O
of -X- _ O
recent -X- _ O
work -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
relational -X- _ O
pattern -X- _ O
modeling -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
suitable -X- _ O
relational -X- _ O
inductive -X- _ O
bias -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
ﬁt -X- _ O
the -X- _ O
structural -X- _ O
information -X- _ O
in -X- _ O
data -X- _ O
. -X- _ O

Nevertheless -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
ignore -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
origination -X- _ O
and -X- _ O
formation -X- _ O
of -X- _ O
KGs -X- _ O
can -X- _ O
be -X- _ O
rather -X- _ O
complex -X- _ O
( -X- _ O
Ehrlinger -X- _ O
and -X- _ O
Wöß -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

They -X- _ O
may -X- _ O
be -X- _ O
collected -X- _ O
, -X- _ O
mined -X- _ O
, -X- _ O
handcrafted -X- _ O
or -X- _ O
merged -X- _ O
in -X- _ O
a -X- _ O
complicated -X- _ O
or -X- _ O
convoluted -X- _ O
process -X- _ O
( -X- _ O
Ji -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Bosseties -X- _ O
in -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
may -X- _ O
be -X- _ O
highly -X- _ O
entangled -X- _ O
and -X- _ O
relational -X- _ O
triplets -X- _ O
may -X- _ O
form -X- _ O
and -X- _ O
be -X- _ O
constructed -X- _ O
for -X- _ O
various -X- _ O
reasons -X- _ O
under -X- _ O
a -X- _ O
plethora -X- _ O
of -X- _ O
different -X- _ O
circumstances -X- _ O
or -X- _ O
contexts -X- _ O
. -X- _ O

Contextual -X- _ O
reasons -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
domains -X- _ O
may -X- _ O
be -X- _ O
taken -X- _ O
into -X- _ O
account -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
. -X- _ O

As -X- _ O
such -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
only -X- _ O
natural -X- _ O
that -X- _ O
KG -X- _ B-TaskName
embedding -X- _ I-TaskName
methods -X- _ O
trained -X- _ O
in -X- _ O
this -X- _ O
fashion -X- _ O
would -X- _ O
result -X- _ O
in -X- _ O
highly -X- _ O
entangled -X- _ O
latent -X- _ O
factors -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
existing -X- _ O
holistic -X- _ O
approaches -X- _ O
fail -X- _ O
to -X- _ O
disentangle -X- _ O
such -X- _ O
factors -X- _ O
and -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
solutions -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
disentangled -X- _ O
representation -X- _ O
learning -X- _ O
has -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
and -X- _ O
attracts -X- _ O
much -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
ﬁeld -X- _ O
of -X- _ O
visual -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O

A -X- _ O
disentangled -X- _ O
representation -X- _ O
should -X- _ O
separate -X- _ O
the -X- _ O
distinct -X- _ O
, -X- _ O
informative -X- _ O
factors -X- _ O
of -X- _ O
variations -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Disentangling -X- _ O
the -X- _ O
latent -X- _ O
factors -X- _ O
hidden -X- _ O
in -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
can -X- _ O
not -X- _ O
only -X- _ O
increase -X- _ O
the -X- _ O
robustness -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
model -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
misleading -X- _ O
correlations -X- _ O
but -X- _ O
also -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
explainability -X- _ O
. -X- _ O

Disentanglement -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
using -X- _ O
either -X- _ O
supervised -X- _ O
signals -X- _ O
or -X- _ O
unsupervised -X- _ O
approaches -X- _ O
. -X- _ O

Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
untangle -X- _ O
the -X- _ O
identity -X- _ O
and -X- _ O
view -X- _ O
features -X- _ O
in -X- _ O
a -X- _ O
supervised -X- _ O
face -X- _ O
recognition -X- _ O
task -X- _ O
. -X- _ O

A -X- _ O
bilinear -X- _ O
model -X- _ O
is -X- _ O
adopted -X- _ O
in -X- _ O
( -X- _ O
Tenenbaum -X- _ O
and -X- _ O
Freeman -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
to -X- _ O
separate -X- _ O
content -X- _ O
from -X- _ O
styles -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
large -X- _ O
body -X- _ O
of -X- _ O
work -X- _ O
on -X- _ O
unsupervised -X- _ O
disentangled -X- _ O
representation -X- _ O
learning -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

Generally -X- _ O
, -X- _ O
the -X- _ O
disentanglement -X- _ O
mechanism -X- _ O
is -X- _ O
integrated -X- _ O
into -X- _ O
unsupervised -X- _ O
learning -X- _ O
frameworks -X- _ O
such -X- _ O
as -X- _ O
variational -X- _ O
autoencoders -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
generative -X- _ O
adversarial -X- _ O
networks -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
quality -X- _ O
of -X- _ O
unsupervised -X- _ O
disentangled -X- _ O
representation -X- _ O
can -X- _ O
even -X- _ O
match -X- _ O
that -X- _ O
learned -X- _ O
from -X- _ O
supervised -X- _ O
label -X- _ O
signals -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
disentangled -X- _ O
representation -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
seek -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
disentanglement -X- _ O
capability -X- _ O
of -X- _ O
entities -X- _ O
representation -X- _ O
in -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

Our -X- _ O
hope -X- _ O
is -X- _ O
that -X- _ O
this -X- _ O
idea -X- _ O
can -X- _ O
address -X- _ O
the -X- _ O
aforementioned -X- _ O
challenge -X- _ O
in -X- _ O
learning -X- _ O
entity -X- _ O
embeddings -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
enabling -X- _ O
the -X- _ O
entities -X- _ O
embeddings -X- _ O
to -X- _ O
better -X- _ O
reﬂect -X- _ O
the -X- _ O
their -X- _ O
inner -X- _ O
properties -X- _ O
. -X- _ O

Unlike -X- _ O
learning -X- _ O
disentangled -X- _ O
representations -X- _ O
in -X- _ O
visual -X- _ O
data -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
challenging -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
discrete -X- _ O
relational -X- _ O
data -X- _ O
. -X- _ O

Most -X- _ O
KGs -X- _ B-TaskName
embedding -X- _ I-TaskName
approaches -X- _ O
operate -X- _ O
at -X- _ O
the -X- _ O
triplet -X- _ O
level -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
uninformative -X- _ O
for -X- _ O
disentanglement -X- _ O
. -X- _ O

Intuitively -X- _ O
, -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
entities -X- _ O
resides -X- _ O
largely -X- _ O
within -X- _ O
the -X- _ O
graph -X- _ O
encoded -X- _ O
through -X- _ O
neighborhood -X- _ O
structures -X- _ O
. -X- _ O

Our -X- _ O
assumption -X- _ O
is -X- _ O
that -X- _ O
an -X- _ O
entity -X- _ O
connects -X- _ O
with -X- _ O
a -X- _ O
certain -X- _ O
group -X- _ O
of -X- _ O
entities -X- _ O
for -X- _ O
a -X- _ O
certain -X- _ O
reason -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
Tim -X- _ O
Robbins -X- _ O
, -X- _ O
as -X- _ O
an -X- _ O
actor -X- _ O
, -X- _ O
starred -X- _ O
in -X- _ O
ﬁlms -X- _ O
such -X- _ O
as -X- _ O
The -X- _ O
Shawshank -X- _ O
Redemption -X- _ O
; -X- _ O
as -X- _ O
a -X- _ O
musician -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
folk -X- _ O
music -X- _ O
group -X- _ O
The -X- _ O
Highwaymen -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
relational -X- _ O
triplets -X- _ O
form -X- _ O
because -X- _ O
of -X- _ O
different -X- _ O
factors -X- _ O
and -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
disentangled -X- _ O
when -X- _ O
looking -X- _ O
it -X- _ O
at -X- _ O
the -X- _ O
graph -X- _ O
level -X- _ O
. -X- _ O

To -X- _ O
summarize -X- _ O
, -X- _ O
our -X- _ O
key -X- _ O
contributions -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
( -X- _ O
KR -X- _ B-MethodName
) -X- _ O
, -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
learns -X- _ O
disentangled -X- _ O
representations -X- _ O
for -X- _ O
entities -X- _ O
in -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

Speciﬁcally -X- _ O
, -X- _ O
a -X- _ O
neighbourhood -X- _ O
routing -X- _ O
mechanism -X- _ O
disentangles -X- _ O
the -X- _ O
hidden -X- _ O
factors -X- _ O
of -X- _ O
entities -X- _ O
from -X- _ O
interactions -X- _ O
with -X- _ O
their -X- _ O
neighbors -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
is -X- _ O
model -X- _ O
agnostic -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
play -X- _ O
with -X- _ O
different -X- _ O
canonical -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
approaches -X- _ O
. -X- _ O

It -X- _ O
enables -X- _ O
those -X- _ O
models -X- _ O
to -X- _ O
have -X- _ O
the -X- _ O
capability -X- _ O
in -X- _ O
learning -X- _ O
disentangled -X- _ O
entity -X- _ O
representations -X- _ O
without -X- _ O
incurring -X- _ O
additional -X- _ O
free -X- _ O
parameters -X- _ O
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
four -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
. -X- _ O

We -X- _ O
apply -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
to -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
DistMult -X- _ B-MethodName
, -X- _ O
SimplE -X- _ B-MethodName
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
and -X- _ O
observe -X- _ O
a -X- _ O
notable -X- _ O
performance -X- _ O
enhancement -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
conduct -X- _ O
model -X- _ O
analysis -X- _ O
to -X- _ O
inspect -X- _ O
the -X- _ O
inner -X- _ O
workings -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router.2 -X- _ I-MethodName
Related -X- _ O
Work -X- _ O
2.1 -X- _ O
Learning -X- _ O
Disentangled -X- _ O
Representations -X- _ O
Learning -X- _ O
representations -X- _ O
from -X- _ O
data -X- _ O
is -X- _ O
the -X- _ O
key -X- _ O
challenge -X- _ O
in -X- _ O
many -X- _ O
machine -X- _ O
learning -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
primary -X- _ O
posit -X- _ O
of -X- _ O
disentangled -X- _ O
representation -X- _ O
learning -X- _ O
is -X- _ O
that -X- _ O
disentangling -X- _ O
the -X- _ O
underlying -X- _ O
structure -X- _ O
of -X- _ O
data -X- _ O
into -X- _ O
disjoint -X- _ O
parts -X- _ O
could -X- _ O
bring -X- _ O
advantages -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
growing -X- _ O
interest -X- _ O
in -X- _ O
learning -X- _ O
disentangled -X- _ O
representations -X- _ O
across -X- _ O
various -X- _ O
applications -X- _ O
. -X- _ O

A -X- _ O
trending -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
is -X- _ O
integrating -X- _ O
disentanglement -X- _ O
into -X- _ O
generative -X- _ O
models -X- _ O
. -X- _ O

( -X- _ O
Tran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
disentangled -X- _ O
generative -X- _ O
adversarial -X- _ O
network -X- _ O
for -X- _ O
face -X- _ O
recognition -X- _ O
and -X- _ O
synthesis -X- _ O
. -X- _ O

The -X- _ O
learned -X- _ O
representation -X- _ O
is -X- _ O
explicitly -X- _ O
disentangled -X- _ O
from -X- _ O
a -X- _ O
pose -X- _ O
variation -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
pose -X- _ O
- -X- _ O
invariant -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
face -X- _ O
recognition -X- _ O
/ -X- _ O
synthesis -X- _ O
task -X- _ O
. -X- _ O

( -X- _ O
Denton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
present -X- _ O
a -X- _ O
disentangled -X- _ O
representation -X- _ O
learning -X- _ O
approach -X- _ O
for -X- _ O
videos -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
approach -X- _ O
separates -X- _ O
each -X- _ O
frame -X- _ O
into -X- _ O
a -X- _ O
timeindependent -X- _ O
component -X- _ O
and -X- _ O
a -X- _ O
temporal -X- _ O
dynamics -X- _ O
aware -X- _ O
component -X- _ O
. -X- _ O

As -X- _ O
such -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
reﬂect -X- _ O
both -X- _ O
the -X- _ O
time -X- _ O
- -X- _ O
invariant -X- _ O
and -X- _ O
temporal -X- _ O
features -X- _ O
of -X- _ O
a -X- _ O
video -X- _ O
. -X- _ O

( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
disentangled -X- _ O
generative -X- _ O
model -X- _ O
for -X- _ O
personal -X- _ O
image -X- _ O
generation -X- _ O
. -X- _ O

It -X- _ O
separates -X- _ O
out -X- _ O
the -X- _ O
foreground -X- _ O
, -X- _ O
background -X- _ O
, -X- _ O
and -X- _ O
pose -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
offers -X- _ O
a -X- _ O
mechanism -X- _ O
to -X- _ O
manipulate -X- _ O
these -X- _ O
three -X- _ O
components -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
control -X- _ O
the -X- _ O
generated -X- _ O
images -X- _ O
. -X- _ O

Some -X- _ O
works -X- _ O
( -X- _ O
Higgins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Burgess -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O

-V -X- _ O
AE -X- _ O
) -X- _ O
integrate -X- _ O
disentanglement -X- _ O
mechanism -X- _ O
with -X- _ O
variational -X- _ O
autoencoder -X- _ O
, -X- _ O
a -X- _ O
probabilistic -X- _ O
generative -X- _ O
model -X- _ O
. -X- _ O


-V -X- _ O
AE -X- _ O
uses -X- _ O
a -X- _ O
regularization -X- _ O
coefﬁcient -X- _ O

to -X- _ O
constrain -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
the -X- _ O
latent -X- _ O
information -X- _ O
channel -X- _ O
. -X- _ O

This -X- _ O
simple -X- _ O
modiﬁcation -X- _ O
enables -X- _ O
latent -X- _ O
representations -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
factorised -X- _ O
. -X- _ O

Drawing -X- _ O
inspiration -X- _ O
from -X- _ O
the -X- _ O
vision -X- _ O
community -X- _ O
, -X- _ O
learning -X- _ O
disentangled -X- _ O
representations -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
investigated -X- _ O
in -X- _ O
areas -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
and -X- _ O
graph -X- _ O
analysis -X- _ O
. -X- _ O

( -X- _ O
Jain -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
propose -X- _ O
an -X- _ O
autoencoders -X- _ O
architecture -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
populations -X- _ O
, -X- _ O
interventions -X- _ O
, -X- _ O
and -X- _ O
outcomes -X- _ O
in -X- _ O
biomedical -X- _ O
texts -X- _ O
. -X- _ O

( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
prism -X- _ O
module -X- _ O
for -X- _ O
semantic -X- _ O
disentanglement -X- _ O
in -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
. -X- _ O

The -X- _ O
prism -X- _ O
module -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
trained -X- _ O
with -X- _ O
downstream -X- _ O
tasks -X- _ O
to -X- _ O
enhance -X- _ O
performance -X- _ O
. -X- _ O

For -X- _ O
graph -X- _ O
analysis -X- _ O
, -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
untangle -X- _ O
the -X- _ O
node -X- _ O
representation -X- _ O
of -X- _ O
graphstructured -X- _ O
data -X- _ O
in -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
present -X- _ O
a -X- _ O
disentangled -X- _ O
variational -X- _ O
autoencoder -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
user -X- _ O
’s -X- _ O
diverse -X- _ O
interests -X- _ O
for -X- _ O
recommender -X- _ O
systems -X- _ O
. -X- _ O

32.2 -X- _ O
Knowledge -X- _ B-TaskName
Graph -X- _ I-TaskName
Embeddings -X- _ I-TaskName
Learning -X- _ I-TaskName
effective -X- _ O
representations -X- _ O
for -X- _ O
knowledge -X- _ O
graphs -X- _ O
is -X- _ O
extensively -X- _ O
studied -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
importance -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
knowledge -X- _ O
graph -X- _ O
completion -X- _ O
, -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
, -X- _ O
web -X- _ O
search -X- _ O
, -X- _ O
and -X- _ O
recommender -X- _ O
systems -X- _ O
. -X- _ O

Among -X- _ O
the -X- _ O
large -X- _ O
body -X- _ O
of -X- _ O
related -X- _ O
literature -X- _ O
, -X- _ O
two -X- _ O
popular -X- _ O
lines -X- _ O
are -X- _ O
translational -X- _ O
approaches -X- _ O
and -X- _ O
semantic -X- _ O
matching -X- _ O
approaches -X- _ O
. -X- _ O

The -X- _ O
groundbreaking -X- _ O
TransE -X- _ B-MethodName
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
sets -X- _ O
the -X- _ O
fundamental -X- _ O
paradigm -X- _ O
for -X- _ O
translational -X- _ O
models -X- _ O
. -X- _ O

Typically -X- _ O
, -X- _ O
the -X- _ O
aim -X- _ O
is -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
translated -X- _ O
( -X- _ O
by -X- _ O
relation -X- _ O
) -X- _ O
head -X- _ O
entity -X- _ O
and -X- _ O
tail -X- _ O
entity -X- _ O
. -X- _ O

Successors -X- _ O
such -X- _ O
as -X- _ O
TransH -X- _ B-MethodName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
TransR -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
all -X- _ O
follow -X- _ O
this -X- _ O
translational -X- _ O
pattern -X- _ O
. -X- _ O

Semantic -X- _ O
matching -X- _ O
methods -X- _ O
calculate -X- _ O
the -X- _ O
semantic -X- _ O
similarities -X- _ O
between -X- _ O
entities -X- _ O
. -X- _ O

A -X- _ O
representative -X- _ O
semantic -X- _ O
model -X- _ O
is -X- _ O
DistMult -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
which -X- _ O
measures -X- _ O
the -X- _ O
plausibility -X- _ O
of -X- _ O
triplets -X- _ O
with -X- _ O
vector -X- _ O
multiplications -X- _ O
. -X- _ O

To -X- _ O
model -X- _ O
more -X- _ O
complex -X- _ O
relation -X- _ O
patterns -X- _ O
, -X- _ O
( -X- _ O
Trouillon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
extend -X- _ O
the -X- _ O
embedding -X- _ O
spaces -X- _ O
to -X- _ O
complex -X- _ O
number -X- _ O
space -X- _ O
or -X- _ O
hyperbolic -X- _ O
space -X- _ O
. -X- _ O

A -X- _ O
fully -X- _ O
expressive -X- _ O
model -X- _ O
named -X- _ O
SimplE -X- _ B-MethodName
( -X- _ O
Kazemi -X- _ O
and -X- _ O
Poole -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
could -X- _ O
achieve -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
capability -X- _ O
of -X- _ O
ComplEx -X- _ B-MethodName
( -X- _ O
Trouillon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
lower -X- _ O
calculation -X- _ O
cost -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
disentangled -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
methods -X- _ O
to -X- _ O
factorize -X- _ O
different -X- _ O
components -X- _ O
/ -X- _ O
aspects -X- _ O
of -X- _ O
entangled -X- _ O
entities -X- _ O
in -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O

To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
efforts -X- _ O
to -X- _ O
induce -X- _ O
disentangled -X- _ O
representations -X- _ O
in -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

Our -X- _ O
disentangled -X- _ O
embedding -X- _ O
algorithm -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
integrated -X- _ O
into -X- _ O
existing -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
models -X- _ O
( -X- _ O
model -X- _ O
agnostic -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O

The -X- _ O
Proposed -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
3.1 -X- _ O
Notation -X- _ O
and -X- _ O
Problem -X- _ O
Formulation -X- _ O
Suppose -X- _ O
we -X- _ O
have -X- _ O
an -X- _ O
entity -X- _ O
set -X- _ O
Eand -X- _ O
a -X- _ O
relation -X- _ O
set -X- _ O
R -X- _ O
, -X- _ O
wherejEj -X- _ O
= -X- _ O
NandjRj -X- _ O
= -X- _ O
M. -X- _ O
A -X- _ O
knowledge -X- _ O
graphG= -X- _ O
( -X- _ O
E -X- _ O
; -X- _ O
R -X- _ O
) -X- _ O
is -X- _ O
made -X- _ O
up -X- _ O
of -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
factsFin -X- _ O
triplet -X- _ O
form -X- _ O
( -X- _ O
h -X- _ O
; -X- _ O
r -X- _ O
; -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
whereh -X- _ O
; -X- _ O
t2Eand -X- _ O
r2R. -X- _ O
The -X- _ O
triplet -X- _ O
( -X- _ O
h -X- _ O
; -X- _ O
r -X- _ O
; -X- _ O
t -X- _ O
) -X- _ O
2F -X- _ O
means -X- _ O
that -X- _ O
entities -X- _ O
handrare -X- _ O
connected -X- _ O
via -X- _ O
a -X- _ O
relation -X- _ O
r. -X- _ O
The -X- _ O
facts -X- _ O
are -X- _ O
usually -X- _ O
directional -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
exchanging -X- _ O
the -X- _ O
head -X- _ O
entity -X- _ O
and -X- _ O
tail -X- _ O
entity -X- _ O
does -X- _ O
not -X- _ O
necessarily -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
legitimate -X- _ O
fact -X- _ O
. -X- _ O

We -X- _ O
are -X- _ O
concerned -X- _ O
with -X- _ O
the -X- _ O
link -X- _ O
prediction -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
embed -X- _ O
the -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
of -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
into -X- _ O
low -X- _ O
- -X- _ O
dimensional -X- _ O
rep -X- _ O
- -X- _ O
Notation -X- _ O
Description -X- _ O
E -X- _ O
Entity -X- _ O
set -X- _ O
. -X- _ O

R -X- _ O
Relation -X- _ O
set -X- _ O
. -X- _ O

E -X- _ O

The -X- _ O
entity -X- _ O
embedding -X- _ O
matrix -X- _ O
. -X- _ O

W -X- _ O

The -X- _ O
relation -X- _ O
embedding -X- _ O
matrix -X- _ O
. -X- _ O

Ee -X- _ O
Theethrow -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
embedding -X- _ O
matrix -X- _ O
. -X- _ O

Wr -X- _ O
Therthrow -X- _ O
of -X- _ O
the -X- _ O
relation -X- _ O
embedding -X- _ O
matrix -X- _ O
. -X- _ O

d -X- _ B-HyperparameterName

The -X- _ O
length -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
embedding -X- _ I-HyperparameterName
vector -X- _ I-HyperparameterName
. -X- _ O

N -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
Neighbourhood -X- _ O
entities -X- _ O
set -X- _ O
of -X- _ O
entity -X- _ O
e. -X- _ O
K -X- _ O

The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
independent -X- _ I-HyperparameterName
components -X- _ I-HyperparameterName
. -X- _ O

T -X- _ O

The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
routing -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
. -X- _ O
xe -X- _ O
; -X- _ O
k -X- _ O

Thekthinitial -X- _ O
vector -X- _ O
for -X- _ O
entity -X- _ O
e. -X- _ O
pe -X- _ O
; -X- _ O
k -X- _ O

Thekthvector -X- _ O
of -X- _ O
entity -X- _ O
eafter -X- _ O
disentanglement -X- _ O
. -X- _ O

se -X- _ O
; -X- _ O
i -X- _ O
; -X- _ O
kThe -X- _ O
similarity -X- _ O
score -X- _ O
between -X- _ O
entity -X- _ O
e -X- _ O
and -X- _ O
entity -X- _ O
iw.r.t -X- _ O
the -X- _ O
kthcomponent -X- _ O
. -X- _ O

wi -X- _ O
; -X- _ O
kThe -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
attends -X- _ O
to -X- _ O
thekthcomponent -X- _ O
of -X- _ O
entity -X- _ O
i. -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
notations -X- _ O
and -X- _ O
denotations -X- _ O
. -X- _ O

resentations -X- _ O
that -X- _ O
can -X- _ O
preserve -X- _ O
the -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
. -X- _ O

A -X- _ O
classical -X- _ O
setting -X- _ O
is -X- _ O
using -X- _ O
an -X- _ O
embedding -X- _ O
matrix -X- _ O
E2RNdto -X- _ O
represent -X- _ O
all -X- _ O
the -X- _ O
entities -X- _ O
and -X- _ O
an -X- _ O
embedding -X- _ O
matrix -X- _ O
W2RMdto -X- _ O
represent -X- _ O
all -X- _ O
the -X- _ O
relations -X- _ O
. -X- _ O

3.2 -X- _ O
Disentangled -X- _ O
Knowledge -X- _ O
Graph -X- _ O
Embeddings -X- _ O
Instead -X- _ O
of -X- _ O
directly -X- _ O
modeling -X- _ O
triplet -X- _ O
facts -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
entities -X- _ O
with -X- _ O
their -X- _ O
neighbors -X- _ O
in -X- _ O
a -X- _ O
message -X- _ O
passing -X- _ O
setting -X- _ O
. -X- _ O

The -X- _ O
neighborhood -X- _ O
entities -X- _ O
could -X- _ O
form -X- _ O
several -X- _ O
clusters -X- _ O
for -X- _ O
different -X- _ O
reasons -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ O
is -X- _ O
updated -X- _ O
by -X- _ O
the -X- _ O
information -X- _ O
accepted -X- _ O
from -X- _ O
its -X- _ O
neighborhood -X- _ O
clusters -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
the -X- _ O
overall -X- _ O
process -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
. -X- _ O

It -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
stages -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
disentangling -X- _ O
the -X- _ O
entities -X- _ O
from -X- _ O
a -X- _ O
graph -X- _ O
perspective -X- _ O
using -X- _ O
neighbourhood -X- _ O
routing -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
scoring -X- _ O
the -X- _ O
facts -X- _ O
using -X- _ O
relations -X- _ O
and -X- _ O
the -X- _ O
disentangled -X- _ O
entities -X- _ O
representations -X- _ O
. -X- _ O

Let -X- _ O
us -X- _ O
build -X- _ O
an -X- _ O
undirected -X- _ O
graph -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

The -X- _ O
relations -X- _ O
are -X- _ O
anonymized -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
know -X- _ O
under -X- _ O
which -X- _ O
conditions -X- _ O
two -X- _ O
entities -X- _ O
are -X- _ O
linked -X- _ O
. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
neighbourhood -X- _ O
of -X- _ O
entity -X- _ O
easN -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
relations -X- _ O
. -X- _ O

Our -X- _ O
neighborhood -X- _ O
routing -X- _ O
approach -X- _ O
operates -X- _ O
on -X- _ O
this -X- _ O
graph -X- _ O
. -X- _ O

Given -X- _ O
an -X- _ O
entity -X- _ O
e -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
disentangled -X- _ O
embedding -X- _ O
that -X- _ O
encodes -X- _ O
various -X- _ O
attributes -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
regard -X- _ O
, -X- _ O
we -X- _ O
suppose -X- _ O
that -X- _ O
each -X- _ O
entity -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
Kindependent -X- _ O
components -X- _ O
, -X- _ O
with -X- _ O
each -X- _ O
component -X- _ O
denoted -X- _ O
by -X- _ O
pe -X- _ O
; -X- _ O
k2Rd -X- _ O
K -X- _ O
, -X- _ O
where -X- _ O
8k= -X- _ O
1 -X- _ O
; -X- _ O
2 -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
K -X- _ O
. -X- _ O

Each -X- _ O
component -X- _ O
stands -X- _ O
for -X- _ O
one -X- _ O
aspect -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
role -X- _ O
of -X- _ O
a -X- _ O
person -X- _ O
. -X- _ O

A -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
overall -X- _ O
procedure -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
Knowledge -X- _ O
Router -X- _ O
algorithm -X- _ O
for -X- _ O
learning -X- _ O
disentangled -X- _ O
entity -X- _ O
representations -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
disentangle -X- _ O
the -X- _ O
entity -X- _ O
embedding -X- _ O
into -X- _ O
four -X- _ O
components -X- _ O
( -X- _ O
K= -X- _ O
4 -X- _ O
) -X- _ O
via -X- _ O
neighborhood -X- _ O
routing -X- _ O
( -X- _ O
iterate -X- _ O
Ttimes -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
components -X- _ O
are -X- _ O
then -X- _ O
concatenated -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
corresponding -X- _ O
entity -X- _ O
. -X- _ O

major -X- _ O
challenge -X- _ O
here -X- _ O
is -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
learned -X- _ O
K -X- _ O
components -X- _ O
to -X- _ O
be -X- _ O
independent -X- _ O
of -X- _ O
one -X- _ O
another -X- _ O
so -X- _ O
that -X- _ O
different -X- _ O
facets -X- _ O
can -X- _ O
be -X- _ O
separately -X- _ O
encoded -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
routing -X- _ O
mechanisms -X- _ O
that -X- _ O
are -X- _ O
inspired -X- _ O
by -X- _ O
capsule -X- _ O
networks -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
Kcomponents -X- _ O
from -X- _ O
both -X- _ O
the -X- _ O
entity -X- _ O
eand -X- _ O
its -X- _ O
neighbourhoods -X- _ O
N -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
this -X- _ O
procedure -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
entity -X- _ O
e -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
initialize -X- _ O
the -X- _ O
Eerandomly -X- _ O
and -X- _ O
evenly -X- _ O
split -X- _ O
it -X- _ O
into -X- _ O
Kparts -X- _ O
. -X- _ O

Thekth -X- _ O
part -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
xe -X- _ O
; -X- _ O
k2Rd -X- _ O
K. -X- _ O
By -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
the -X- _ O
embedding -X- _ O
is -X- _ O
projected -X- _ O
into -X- _ O
different -X- _ O
subspaces -X- _ O
. -X- _ O

To -X- _ O
ensure -X- _ O
computation -X- _ O
stability -X- _ O
, -X- _ O
each -X- _ O
part -X- _ O
is -X- _ O
also -X- _ O
normalized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
xe -X- _ O
; -X- _ O
k -X- _ O

= -X- _ O
xe -X- _ O
; -X- _ O
k -X- _ O
kxe -X- _ O
; -X- _ O
kk2 -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

This -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
initialization -X- _ O
of -X- _ O
pe -X- _ O
; -X- _ O
k -X- _ O
. -X- _ O

Obviously -X- _ O
, -X- _ O
the -X- _ O
information -X- _ O
contained -X- _ O
is -X- _ O
limited -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
reach -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
disentanglement -X- _ O
. -X- _ O

To -X- _ O
enrich -X- _ O
the -X- _ O
information -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
graph -X- _ O
message -X- _ O
passing -X- _ O
mechanism -X- _ O
and -X- _ O
deﬁne -X- _ O
the -X- _ O
update -X- _ O
rule -X- _ O
for -X- _ O
thekthcomponent -X- _ O
of -X- _ O
peas -X- _ O
follows -X- _ O
: -X- _ O
pe -X- _ O
; -X- _ O
k -X- _ O
= -X- _ O
xe -X- _ O
; -X- _ O
k+AGGREGATE -X- _ O
( -X- _ O
fxi -X- _ O
; -X- _ O
k -X- _ O
; -X- _ O
8i2N -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
g -X- _ O
) -X- _ O
; -X- _ O
where -X- _ O
AGGREGATE -X- _ O
represents -X- _ O
the -X- _ O
neighborhood -X- _ O
aggregation -X- _ O
function -X- _ O
( -X- _ O
deﬁned -X- _ O
in -X- _ O
equation -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
same`2normalization -X- _ O
as -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
pe -X- _ O
; -X- _ O
k -X- _ O
afterwards -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
pe -X- _ O
; -X- _ O
kcontains -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
kthaspect -X- _ O
of -X- _ O
both -X- _ O
entity -X- _ O
eand -X- _ O
all -X- _ O
of -X- _ O
its -X- _ O
neighbors -X- _ O
. -X- _ O

Common -X- _ O
aggregating -X- _ O
functions -X- _ O
such -X- _ O
as -X- _ O
mean -X- _ O
pooling -X- _ O
and -X- _ O
sum -X- _ O
pooling -X- _ O
are -X- _ O
viable -X- _ O
, -X- _ O
but -X- _ O
treatingeach -X- _ O
neighbor -X- _ O
equally -X- _ O
when -X- _ O
determining -X- _ O
one -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
representation -X- _ O
is -X- _ O
undoubtedly -X- _ O
not -X- _ O
sensible -X- _ O
. -X- _ O

As -X- _ O
such -X- _ O
, -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
obtain -X- _ O
weights -X- _ O
for -X- _ O
each -X- _ O
neighbor -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
a -X- _ O
scaled -X- _ O
dot -X- _ O
- -X- _ O
product -X- _ O
attention -X- _ O
method -X- _ O
is -X- _ O
applied -X- _ O
. -X- _ O

We -X- _ O
ﬁrst -X- _ O
get -X- _ O
the -X- _ O
dot -X- _ O
product -X- _ O
between -X- _ O
pe -X- _ O
; -X- _ O
k -X- _ O
andxi -X- _ O
; -X- _ O
k -X- _ O
; -X- _ O
8i2N -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
eachk -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
the -X- _ O
following -X- _ O
similarity -X- _ O
score -X- _ O
: -X- _ O
se -X- _ O
; -X- _ O
i -X- _ O
; -X- _ O
k -X- _ O
= -X- _ O
p -X- _ O
> -X- _ O
e -X- _ O
; -X- _ O
kxi -X- _ O
; -X- _ O
kp -X- _ O
which -X- _ O
provides -X- _ O
information -X- _ O
on -X- _ O
how -X- _ O
entity -X- _ O
einteracts -X- _ O
with -X- _ O
its -X- _ O
neighbour -X- _ O
entity -X- _ O
ipertaining -X- _ O
to -X- _ O
the -X- _ O
aspectk -X- _ O
. -X- _ O

Then -X- _ O
the -X- _ O
softmax -X- _ O
function -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
weight -X- _ O
distribution -X- _ O
over -X- _ O
different -X- _ O
components -X- _ O
for -X- _ O
each -X- _ O
neighbour -X- _ O
. -X- _ O

wi -X- _ O
; -X- _ O
k -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
se -X- _ O
; -X- _ O
i -X- _ O
; -X- _ O
k -X- _ O
) -X- _ O
PK -X- _ O
andwi -X- _ O
; -X- _ O
kindicates -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
kthcomponent -X- _ O
of -X- _ O
entity -X- _ O
i -X- _ O
. -X- _ O

Now -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
the -X- _ O
deﬁnition -X- _ O
of -X- _ O
the -X- _ O
AGGREGATE -X- _ O
function -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
AGGREGATE -X- _ O
( -X- _ O
fxi -X- _ O
; -X- _ O
k -X- _ O
; -X- _ O
8i2N -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
g -X- _ O
) -X- _ O
: -X- _ O
= -X- _ O
X -X- _ O
i2N -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
wi -X- _ O
; -X- _ O
kxi -X- _ O
; -X- _ O
k -X- _ O

The -X- _ O
above -X- _ O
process -X- _ O
, -X- _ O
including -X- _ O
equations -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
repeated -X- _ O
for -X- _ O
Titerations -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
a -X- _ O
routing -X- _ O
mechanism -X- _ O
. -X- _ O

Like -X- _ O
capsule -X- _ O
networks -X- _ O
( -X- _ O
Sabour -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
assume -X- _ O
that -X- _ O
entity -X- _ O
( -X- _ O
object -X- _ O
) -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
entity -X- _ O
( -X- _ O
object -X- _ O
) -X- _ O
parts -X- _ O
. -X- _ O

This -X- _ O
routing -X- _ O
method -X- _ O
enables -X- _ O
it -X- _ O
to -X- _ O
model -X- _ O
part -X- _ O
- -X- _ O
whole -X- _ O

5relationships -X- _ O
and -X- _ O
enlarge -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
parts -X- _ O
after -X- _ O
several -X- _ O
routing -X- _ O
iterations -X- _ O
. -X- _ O

Afterwards -X- _ O
, -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
all -X- _ O
Kcomponents -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
represent -X- _ O
that -X- _ O
entity -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
disentangled -X- _ O
representation -X- _ O
peof -X- _ O
the -X- _ O
entityeis -X- _ O
deﬁned -X- _ O
as -X- _ O
: -X- _ O
This -X- _ O
neighborhood -X- _ O
routing -X- _ O
algorithm -X- _ O
is -X- _ O
model -X- _ O
agnostic -X- _ O
as -X- _ O
our -X- _ O
aim -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
an -X- _ O
entity -X- _ O
embedding -X- _ O
matrix -X- _ O
which -X- _ O
is -X- _ O
necessary -X- _ O
for -X- _ O
most -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
methods -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
this -X- _ O
model -X- _ O
will -X- _ O
not -X- _ O
introduce -X- _ O
additional -X- _ O
free -X- _ O
parameters -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
intuition -X- _ O
behind -X- _ O
the -X- _ O
“ -X- _ O
routing -X- _ O
mechanism -X- _ O
” -X- _ O
is -X- _ O
that -X- _ O
each -X- _ O
facet -X- _ O
in -X- _ O
an -X- _ O
entity -X- _ O
has -X- _ O
a -X- _ O
separate -X- _ O
route -X- _ O
to -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
this -X- _ O
entity -X- _ O
. -X- _ O

The -X- _ O
routing -X- _ O
algorithm -X- _ O
will -X- _ O
coordinately -X- _ O
infer -X- _ O
pe -X- _ O
; -X- _ O
k -X- _ O
( -X- _ O
we -X- _ O
can -X- _ O
view -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
center -X- _ O
of -X- _ O
each -X- _ O
cluster -X- _ O
) -X- _ O
and -X- _ O
wi -X- _ O
; -X- _ O
k -X- _ O
( -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
factor -X- _ O
kis -X- _ O
the -X- _ O
reason -X- _ O
why -X- _ O
entity -X- _ O
e -X- _ O
is -X- _ O
connected -X- _ O
with -X- _ O
entity -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O

They -X- _ O
are -X- _ O
coordinately -X- _ O
learned -X- _ O
and -X- _ O
under -X- _ O
the -X- _ O
constraint -X- _ O
that -X- _ O
each -X- _ O
neighbor -X- _ O
should -X- _ O
belong -X- _ O
to -X- _ O
one -X- _ O
cluster -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
reminiscent -X- _ O
of -X- _ O
the -X- _ O
iterative -X- _ O
method -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
EM -X- _ O
algorithm -X- _ O
( -X- _ O
Bishop -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
and -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
lead -X- _ O
to -X- _ O
convergence -X- _ O
and -X- _ O
meaningful -X- _ O
disentangled -X- _ O
representations -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
Until -X- _ O
now -X- _ O
, -X- _ O
the -X- _ O
relation -X- _ O
embeddings -X- _ O
are -X- _ O
not -X- _ O
utilized -X- _ O
as -X- _ O
all -X- _ O
relations -X- _ O
are -X- _ O
anonymous -X- _ O
during -X- _ O
graph -X- _ O
construction -X- _ O
. -X- _ O

This -X- _ O
algorithm -X- _ O
will -X- _ O
be -X- _ O
jointly -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
facts -X- _ O
scoring -X- _ O
algorithms -X- _ O
. -X- _ O

3.3 -X- _ O
Facts -X- _ O
Scoring -X- _ O
using -X- _ O
Disentangled -X- _ O
Entities -X- _ O
Using -X- _ O
disentangled -X- _ O
entity -X- _ O
embeddings -X- _ O
alone -X- _ O
can -X- _ O
not -X- _ O
recover -X- _ O
the -X- _ O
facts -X- _ O
in -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O

It -X- _ O
shall -X- _ O
be -X- _ O
further -X- _ O
updated -X- _ O
simultaneously -X- _ O
with -X- _ O
the -X- _ O
relation -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
fact -X- _ O
scoring -X- _ O
process -X- _ O
. -X- _ O

To -X- _ O
predict -X- _ O
whether -X- _ O
a -X- _ O
triplet -X- _ O
hh -X- _ O
; -X- _ O
r -X- _ O
; -X- _ O
tiholds -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
fetch -X- _ O
the -X- _ O
learned -X- _ O
disentangled -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
head -X- _ O
and -X- _ O
tail -X- _ O
entities -X- _ O
, -X- _ O
phandpt -X- _ O
. -X- _ O

Then -X- _ O
we -X- _ O
adopt -X- _ O
three -X- _ O
methods -X- _ O
for -X- _ O
triplet -X- _ O
scoring -X- _ O
including -X- _ O
DistMult -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
SimplE -X- _ B-MethodName

( -X- _ O
Kazemi -X- _ O
and -X- _ O
Poole -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
model -X- _ O
after -X- _ O
disentanglement -X- _ O
as -X- _ O
: -X- _ O
KRDistMult -X- _ B-MethodName
, -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
SimplE -X- _ I-MethodName
, -X- _ O
and -X- _ O

KR -X- _ B-MethodName
- -X- _ I-MethodName
QuatE -X- _ I-MethodName
. -X- _ O

The -X- _ O
scoring -X- _ O
function -X- _ O
of -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
DistMult -X- _ I-MethodName
is -X- _ O
deﬁned -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
whereh -X- _ O
; -X- _ O
 -X- _ O
; -X- _ O
idenotes -X- _ O
the -X- _ O
standard -X- _ O
componentwise -X- _ O
multi -X- _ O
- -X- _ O
linear -X- _ O
dot -X- _ O
product -X- _ O
. -X- _ O

SimplE -X- _ B-MethodName
needs -X- _ O
an -X- _ O
additional -X- _ O
entity -X- _ O
embedding -X- _ O
matrix -X- _ O
H2RNdand -X- _ O
an -X- _ O
additional -X- _ O
relation -X- _ O
embedding -X- _ O
matrix -X- _ O
V2RMd -X- _ O
. -X- _ O

We -X- _ O
perform -X- _ O
the -X- _ O
same -X- _ O
disentanglement -X- _ O
process -X- _ O
on -X- _ O
Hand -X- _ O
denote -X- _ O
the -X- _ O
disentangled -X- _ O
representation -X- _ O
of -X- _ O
entity -X- _ O
easqe -X- _ O
, -X- _ O
the -X- _ O
scoring -X- _ O
function -X- _ O
of -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
SimplE -X- _ I-MethodName
( -X- _ O
SimplE -X- _ O
- -X- _ O
avg -X- _ O
is -X- _ O
adopted -X- _ O
since -X- _ O
it -X- _ O
outperforms -X- _ O
SimplE -X- _ O
- -X- _ O
ignr -X- _ O
) -X- _ O
is -X- _ O
: -X- _ O

( -X- _ O
h -X- _ O
; -X- _ O
r -X- _ O
; -X- _ O
t -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
hWr -X- _ O
; -X- _ O
ph -X- _ O
; -X- _ O
qti+hVr -X- _ O
; -X- _ O
qh -X- _ O
; -X- _ O
pti -X- _ O
) -X- _ O
1 -X- _ O
For -X- _ O
QuatE -X- _ B-MethodName
, -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
are -X- _ O
represented -X- _ O
with -X- _ O
quaternions -X- _ O
. -X- _ O

Each -X- _ O
quaternion -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
real -X- _ O
component -X- _ O
and -X- _ O
three -X- _ O
imaginary -X- _ O
components -X- _ O
. -X- _ O

LetQ2HNddenote -X- _ O
the -X- _ O
quaternion -X- _ O
entity -X- _ O
embedding -X- _ O
and -X- _ O
W2HMddenote -X- _ O
the -X- _ O
quaternion -X- _ O
relation -X- _ O
embedding -X- _ O
, -X- _ O
where -X- _ O
His -X- _ O
the -X- _ O
quaternion -X- _ O
space -X- _ O
. -X- _ O

Each -X- _ O
entity -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
Qe -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
the -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
algorithm -X- _ O
on -X- _ O
each -X- _ O
component -X- _ O
ofQe -X- _ O
. -X- _ O

The -X- _ O
scoring -X- _ O
function -X- _ O
of -X- _ O
KR -X- _ O
- -X- _ O
QuatE -X- _ O
is -X- _ O
: -X- _ O
h -X- _ O
Wr -X- _ O
jWrjQKR -X- _ O
where -X- _ O
“ -X- _ O
" -X- _ O
is -X- _ O
Hamilton -X- _ O
product -X- _ O
; -X- _ O
“ -X- _ O
 -X- _ O
" -X- _ O
represents -X- _ O
the -X- _ O
quaternion -X- _ O
inner -X- _ O
product -X- _ O
; -X- _ O
QKRdenotes -X- _ O
the -X- _ O
entity -X- _ O
representation -X- _ O
after -X- _ O
disentanglement -X- _ O
. -X- _ O

As -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
is -X- _ O
model -X- _ O
agnostic -X- _ O
, -X- _ O
other -X- _ O
scoring -X- _ O
functions -X- _ O
are -X- _ O
also -X- _ O
applicable -X- _ O
. -X- _ O

3.4 -X- _ O
Objective -X- _ O
Functions -X- _ O
To -X- _ O
learn -X- _ O
a -X- _ O
disentangled -X- _ O
KG -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
following -X- _ O
negative -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
loss -X- _ O
: -X- _ O

SSX -X- _ O
whereSis -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
( -X- _ O
triplets -X- _ O
) -X- _ O
; -X- _ O

y -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
binary -X- _ O
label -X- _ O
indicating -X- _ O
whether -X- _ O
the -X- _ O
ith -X- _ O
triplet -X- _ O
holds -X- _ O
or -X- _ O
not -X- _ O
; -X- _ O

( -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
prediction -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
triplet -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
with -X- _ O
commonly -X- _ O
used -X- _ O
minibatch -X- _ O
gradient -X- _ O
descent -X- _ O
optimizers -X- _ O
. -X- _ O

3.5 -X- _ O
Complexity -X- _ O
Analysis -X- _ O

The -X- _ O
disentanglement -X- _ O
process -X- _ O
of -X- _ O
each -X- _ O
node -X- _ O
needs -X- _ O
O -X- _ O
( -X- _ O
jN -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
jd -X- _ O
KK+T -X- _ O
( -X- _ O
jN -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
jd -X- _ O
KK+d -X- _ O
KK -X- _ O
) -X- _ O
) -X- _ O
time -X- _ O
complexity -X- _ O
, -X- _ O
where -X- _ O
jN -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
jis -X- _ O
neighborhood -X- _ O
size -X- _ O
. -X- _ O

After -X- _ O
simpliﬁcation -X- _ O
, -X- _ O
the -X- _ O
time -X- _ O
complexity -X- _ O
is -X- _ O
O -X- _ O
( -X- _ O
TjN -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
jd -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
will -X- _ O
not -X- _ O
incur -X- _ O
a -X- _ O
high -X- _ O
computational -X- _ O
cost -X- _ O
since -X- _ O
Tis -X- _ B-HyperparameterName
usually -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
neighborhood -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
determined -X- _ O
by -X- _ O
the -X- _ O
average -X- _ O
degree -X- _ O
and -X- _ O
can -X- _ O
usually -X- _ O
be -X- _ O
constrainted -X- _ O
by -X- _ O
a -X- _ O
constant -X- _ O
value -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
10 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O

With -X- _ O
regard -X- _ O
to -X- _ O
fact -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
Statistics -X- _ O
of -X- _ O
datasets -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

scoring -X- _ O
, -X- _ O
it -X- _ O
requires -X- _ O
O -X- _ O
( -X- _ O
d -X- _ B-HyperparameterName
) -X- _ O
time -X- _ O
complexity -X- _ O
for -X- _ O
each -X- _ O
triplet -X- _ O
in -X- _ O
general -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
several -X- _ O
benchmark -X- _ O
datasets -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
. -X- _ O

We -X- _ O
target -X- _ O
at -X- _ O
answering -X- _ O
: -X- _ O
RQ -X- _ O
I -X- _ O
: -X- _ O
whether -X- _ O
the -X- _ O
disentanglement -X- _ O
method -X- _ O
can -X- _ O
enhance -X- _ O
the -X- _ O
traditional -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
methods -X- _ O
? -X- _ O

RQ -X- _ O
II -X- _ O
: -X- _ O
Model -X- _ O
- -X- _ O
agnosticism -X- _ O
: -X- _ O
can -X- _ O
it -X- _ O
effectively -X- _ O
work -X- _ O
with -X- _ O
different -X- _ O
baseline -X- _ O
models -X- _ O
? -X- _ O

RQ -X- _ O
III -X- _ O
: -X- _ O
How -X- _ O
do -X- _ O
certain -X- _ O
important -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
impact -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
and -X- _ O
what -X- _ O
has -X- _ O
the -X- _ O
disentanglement -X- _ O
algorithm -X- _ O
learned -X- _ O
? -X- _ O

Are -X- _ O
they -X- _ O
meaningful -X- _ O
? -X- _ O

4.1 -X- _ O
Datasets -X- _ O
Description -X- _ O
We -X- _ O
use -X- _ O
four -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
including -X- _ O
ICEWS14 -X- _ B-DatasetName
, -X- _ O
ICEWS05 -X- _ B-DatasetName
- -X- _ I-DatasetName
15 -X- _ I-DatasetName
, -X- _ O
WikiData -X- _ B-DatasetName
, -X- _ O
and -X- _ O
FB15k237 -X- _ B-DatasetName
. -X- _ O

The -X- _ O
reason -X- _ O
for -X- _ O
using -X- _ O
these -X- _ O
is -X- _ O
that -X- _ O
their -X- _ O
entities -X- _ O
are -X- _ O
complicated -X- _ O
and -X- _ O
highly -X- _ O
entangled -X- _ O
. -X- _ O

The -X- _ O
WordNet -X- _ O
dataset -X- _ O
is -X- _ O
not -X- _ O
appropriate -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
as -X- _ O
the -X- _ O
entities -X- _ O
in -X- _ O
WordNet -X- _ O
are -X- _ O
already -X- _ O
disentangled1 -X- _ O
. -X- _ O

FB15k-237 -X- _ B-DatasetName
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
Freebase -X- _ O
knowledge -X- _ O
base -X- _ O
which -X- _ O
contains -X- _ O
general -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
world -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
widely -X- _ O
used -X- _ O
version -X- _ O
generated -X- _ O
by -X- _ O
( -X- _ O
Dettmers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
where -X- _ O
inverse -X- _ O
relations -X- _ O
are -X- _ O
eliminated -X- _ O
to -X- _ O
avoid -X- _ O
data -X- _ O
leakage -X- _ O
. -X- _ O

WikiData -X- _ B-DatasetName
is -X- _ O
sampled -X- _ O
from -X- _ O
Wikidata2 -X- _ O
, -X- _ O
a -X- _ O
collaborative -X- _ O
open -X- _ O
knowledge -X- _ O
base -X- _ O
. -X- _ O

The -X- _ O
knowledge -X- _ O
is -X- _ O
relatively -X- _ O
up -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
date -X- _ O
compared -X- _ O
with -X- _ O
FB15k-237 -X- _ B-DatasetName
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
version -X- _ O
provided -X- _ O
by -X- _ O
( -X- _ O
García -X- _ O
- -X- _ O
Durán -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Timestamp -X- _ O
is -X- _ O
discarded -X- _ O
. -X- _ O

ICEWS -X- _ B-DatasetName
( -X- _ O
García -X- _ O
- -X- _ O
Durán -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
integrated -X- _ O
crisis -X- _ O
early -X- _ O
warning -X- _ O
system3 -X- _ O
which -X- _ O
was -X- _ O
built -X- _ O
to -X- _ O
monitor -X- _ O
and -X- _ O
forecast -X- _ O
national -X- _ O
and -X- _ O
internal -X- _ O
crises -X- _ O
. -X- _ O

The -X- _ O
datasets -X- _ O
contain -X- _ O
political -X- _ O
events -X- _ O
that -X- _ O
connect -X- _ O
entities -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
countries -X- _ O
, -X- _ O
presidents -X- _ O
, -X- _ O
intergovernmental -X- _ O
organizations -X- _ O
) -X- _ O
to -X- _ O
other -X- _ O
entities -X- _ O
via -X- _ O
predicates -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
make -X- _ O
a -X- _ O
visit -X- _ O
" -X- _ O
, -X- _ O
“ -X- _ O
sign -X- _ O
formal -X- _ O
agreement -X- _ O
" -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

ICES14 -X- _ B-DatasetName
contains -X- _ O
events -X- _ O
in -X- _ O
the -X- _ O
year -X- _ O
2014 -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
ICEWS05 -X- _ B-DatasetName
- -X- _ I-DatasetName
15 -X- _ I-DatasetName
contains -X- _ O
with -X- _ O
ﬁve -X- _ O
different -X- _ O
entities -X- _ O
in -X- _ O
WordNet -X- _ O
. -X- _ O

2https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.wikidata.org -X- _ O
/ -X- _ O
3http -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.icews.com -X- _ O
/ -X- _ O
events -X- _ O
occurring -X- _ O
between -X- _ O
2005 -X- _ O
and -X- _ O
2015 -X- _ O
. -X- _ O

Temporal -X- _ O
information -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Data -X- _ O
statistics -X- _ O
and -X- _ O
the -X- _ O
train -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
are -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

4.2 -X- _ O
Evaluation -X- _ O
Protocol -X- _ O
We -X- _ O
adopt -X- _ O
four -X- _ O
commonly -X- _ O
used -X- _ O
evaluation -X- _ O
metrics -X- _ O
including -X- _ O
hit -X- _ B-MetricName
rate -X- _ I-MetricName
with -X- _ I-MetricName
given -X- _ I-MetricName
cut -X- _ I-MetricName
- -X- _ I-MetricName
off -X- _ I-MetricName
( -X- _ O
HR -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
, -X- _ O
HR -X- _ B-MetricName
@ -X- _ I-MetricName
3 -X- _ I-MetricName
, -X- _ O
HR -X- _ B-MetricName
@ -X- _ I-MetricName
10 -X- _ I-MetricName
) -X- _ O
and -X- _ O
mean -X- _ B-MetricName
reciprocal -X- _ I-MetricName
rank -X- _ I-MetricName
( -X- _ O
MRR -X- _ B-MetricName
) -X- _ O
. -X- _ O

HR -X- _ B-MetricName
measures -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
true -X- _ O
triples -X- _ O
of -X- _ O
the -X- _ O
ranked -X- _ O
list -X- _ O
. -X- _ O

MRR -X- _ B-MetricName
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
rank -X- _ O
inverse -X- _ O
which -X- _ O
reﬂects -X- _ O
the -X- _ O
ranking -X- _ O
quality -X- _ O
. -X- _ O

Evaluation -X- _ O
is -X- _ O
performed -X- _ O
under -X- _ O
the -X- _ O
commonly -X- _ O
used -X- _ O
ﬁltered -X- _ O
setting -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
reasonable -X- _ O
and -X- _ O
stable -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
unﬁltered -X- _ O
setting -X- _ O
. -X- _ O

4.3 -X- _ O
Baselines -X- _ O
To -X- _ O
demonstrate -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
with -X- _ O
several -X- _ O
representative -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
approaches -X- _ O
including -X- _ O
TransE -X- _ B-MethodName
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
DistMult -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
ComplEx -X- _ B-MethodName
( -X- _ O
Trouillon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O

SimplE -X- _ B-MethodName
( -X- _ O
Kazemi -X- _ O
and -X- _ O
Poole -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
FB15k-237 -X- _ B-DatasetName
, -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
RotatE -X- _ B-MethodName

( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
RGCN -X- _ B-MethodName
( -X- _ O
Schlichtkrull -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
are -X- _ O
also -X- _ O
included -X- _ O
. -X- _ O

4.4 -X- _ O
Implementation -X- _ O
Details -X- _ O
We -X- _ O
implement -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
pytorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
run -X- _ O
it -X- _ O
on -X- _ O
TITAN -X- _ O
XP -X- _ O
GPUs -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
Adam -X- _ O
optimizer -X- _ B-HyperparameterName
to -X- _ O
learn -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to0:01without -X- _ B-HyperparameterValue
further -X- _ O
tuning -X- _ O
. -X- _ O

The -X- _ O
embedding -X- _ B-HyperparameterName
sizedis -X- _ I-HyperparameterName
set -X- _ O
to -X- _ O
100and -X- _ B-HyperparameterValue
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
is -X- _ O
ﬁxed -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
selected -X- _ O
fromf128 -X- _ B-HyperparameterValue
; -X- _ O
512 -X- _ B-HyperparameterValue
; -X- _ O
1024 -X- _ B-HyperparameterValue

g -X- _ O
. -X- _ O

The -X- _ O
regularization -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
disentanglement -X- _ O
algorithm -X- _ O
, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
componentsKis -X- _ I-HyperparameterName
selected -X- _ O
fromf2 -X- _ B-HyperparameterValue
; -X- _ O
4 -X- _ B-HyperparameterValue
; -X- _ O
5 -X- _ B-HyperparameterValue
; -X- _ O
10g -X- _ B-HyperparameterValue
( -X- _ O
Kshould -X- _ O
be -X- _ O
divisible -X- _ O
by -X- _ O
d -X- _ O
) -X- _ O
; -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
routing -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
Tis -X- _ I-HyperparameterName
tuned -X- _ O
amongstf2 -X- _ B-HyperparameterValue
; -X- _ O
3 -X- _ B-HyperparameterValue
; -X- _ O
4 -X- _ B-HyperparameterValue
; -X- _ O
5 -X- _ B-HyperparameterValue
; -X- _ O
7 -X- _ B-HyperparameterValue
; -X- _ O
10 -X- _ B-HyperparameterValue
g -X- _ O
. -X- _ O

The -X- _ O
hyperparameters -X- _ O
are -X- _ O
determined -X- _ O
by -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

Each -X- _ O
experiment -X- _ O
runs -X- _ O
ﬁve -X- _ O
times -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
is -X- _ O
reported -X- _ O
. -X- _ O

For -X- _ O
convenience -X- _ O
of -X- _ O
implementation -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
neighbor -X- _ I-HyperparameterName
sizes -X- _ I-HyperparameterName
are -X- _ O
: -X- _ O
16 -X- _ B-HyperparameterValue
( -X- _ O
FB15K-237 -X- _ O
) -X- _ O
, -X- _ O
We -X- _ O
apply -X- _ O
zero -X- _ O
padding -X- _ O
to -X- _ O
entities -X- _ O
that -X- _ O
have -X- _ O
fewer -X- _ O
neighbors -X- _ O
. -X- _ O

4.5 -X- _ O
Main -X- _ O
Results -X- _ O
The -X- _ O
test -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
four -X- _ O
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Tables -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
. -X- _ O

Evidently -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
make -X- _ O
the -X- _ O

Table -X- _ O
3 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
the -X- _ O
FB15K-237 -X- _ O
dataset -X- _ O
. -X- _ O

Best -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

“ -X- _ O
D -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
S -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
D -X- _ O
” -X- _ O
stand -X- _ O
for -X- _ O
DistMult -X- _ B-MethodName
, -X- _ O
SimplE -X- _ B-MethodName
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
, -X- _ O
respectively -X- _ O
. -X- _ O

“ -X- _ O
~ -X- _ O
” -X- _ O
: -X- _ O
results -X- _ O
from -X- _ O
( -X- _ O
Schlichtkrull -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

“ -X- _ O
? -X- _ O
” -X- _ O
: -X- _ O
results -X- _ O
from -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
adversarial -X- _ O
negative -X- _ O
sampling -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
. -X- _ O

“ -X- _ O
 -X- _ O
” -X- _ O
: -X- _ O
results -X- _ O
from -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
without -X- _ O
N3 -X- _ O
regularization -X- _ O
and -X- _ O
type -X- _ O
constraints -X- _ O
) -X- _ O
. -X- _ O

Models -X- _ O
WikiData -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
WikiData -X- _ O
. -X- _ O

Best -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

“ -X- _ O
D -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
S -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
D -X- _ O
” -X- _ O
stand -X- _ O
for -X- _ O
DistMult -X- _ B-MethodName
, -X- _ O
SimplE -X- _ B-MethodName
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
, -X- _ O
respectively -X- _ O
. -X- _ O

following -X- _ O
observations -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Models -X- _ O
with -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
outperform -X- _ O
the -X- _ O
counterparts -X- _ O
without -X- _ O
it -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
, -X- _ O
conﬁrming -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
and -X- _ O
assuring -X- _ O
the -X- _ O
beneﬁts -X- _ O
of -X- _ O
learning -X- _ O
disentangled -X- _ O
representations -X- _ O
. -X- _ O

This -X- _ O
clearly -X- _ O
answers -X- _ O
our -X- _ O
RQ -X- _ O
I -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
On -X- _ O
the -X- _ O
four -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
a -X- _ O
consistent -X- _ O
enhancement -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
on -X- _ O
both -X- _ O
traditional -X- _ O
embedding -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
DistMult -X- _ B-MethodName
, -X- _ O
SimplE -X- _ B-MethodName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
hypercomplex -X- _ O
number -X- _ O
based -X- _ O
model -X- _ O
QuatE -X- _ B-MethodName
. -X- _ O

This -X- _ O
is -X- _ O
expected -X- _ O
as -X- _ O
our -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
is -X- _ O
model -X- _ O
agnostic -X- _ O
( -X- _ O
RQ -X- _ O
II -X- _ O
) -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
integrated -X- _ O
to -X- _ O
canonical -X- _ O
knowledge -X- _ O
embedding -X- _ O
models -X- _ O
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
The -X- _ O
model -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
QuatE -X- _ I-MethodName
is -X- _ O
usually -X- _ O
the -X- _ O
best -X- _ O
performer -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
generalization -X- _ O
capability -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
in -X- _ O
more -X- _ O
complex -X- _ O
embedding -X- _ O
spaces -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
FB15k-237 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
QuatE -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
re -X- _ O
- -X- _ O
cent -X- _ O
translational -X- _ O
model -X- _ O
RotatE -X- _ B-MethodName
and -X- _ O
the -X- _ O
semantic -X- _ O
matching -X- _ O
model -X- _ O
QuatE. -X- _ B-MethodName
Models -X- _ O
such -X- _ O
as -X- _ O
DistMult -X- _ B-MethodName
and -X- _ O
SimplE -X- _ B-MethodName
are -X- _ O
also -X- _ O
outperformed -X- _ O
by -X- _ O
KRDistMult -X- _ B-MethodName
and -X- _ O

KR -X- _ B-MethodName
- -X- _ I-MethodName
SimplE -X- _ I-MethodName
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
good -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
KR -X- _ B-HyperparameterName
- -X- _ O
models -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
graph -X- _ O
convolutional -X- _ O
networks -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
R -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
GCN -X- _ I-HyperparameterName
. -X- _ O

This -X- _ O
implies -X- _ O
that -X- _ O
simply -X- _ O
/ -X- _ O
naively -X- _ O
incorporating -X- _ O
graph -X- _ O
structures -X- _ O
might -X- _ O
not -X- _ O
lead -X- _ O
to -X- _ O
good -X- _ O
performance -X- _ O
. -X- _ O

Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
also -X- _ O
operates -X- _ O
at -X- _ O
the -X- _ O
graph -X- _ O
level -X- _ O
, -X- _ O
moreover -X- _ O
, -X- _ O
the -X- _ O
neighborhood -X- _ O
information -X- _ O
is -X- _ O
effectively -X- _ O
utilized -X- _ O
for -X- _ O
disentanglement -X- _ O
. -X- _ O

Similar -X- _ O
trends -X- _ O
are -X- _ O
also -X- _ O
observed -X- _ O
on -X- _ O
WikiData -X- _ B-DatasetName
. -X- _ O

Interestingly -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
differences -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
KR -X- _ B-MethodName
- -X- _ O
models -X- _ O
are -X- _ O
quite -X- _ O
small -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O

We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
has -X- _ O
already -X- _ O
been -X- _ O
quite -X- _ O
high -X- _ O
, -X- _ O
making -X- _ O
further -X- _ O
improvement -X- _ O
more -X- _ O
difﬁcult -X- _ O
. -X- _ O

Among -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
SimplE -X- _ B-MethodName
is -X- _ O
the -X- _ O
best -X- _ O
performer -X- _ O
. -X- _ O

We -X- _ O
notice -X- _ O
that -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
pure -X- _ O
QuatE -X- _ B-MethodName
does -X- _ O
not -X- _ O
show -X- _ O
impressive -X- _ O
performance -X- _ O
, -X- _ O
the -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
enhances -X- _ O
its -X- _ O
results -X- _ O
and -X- _ O
enables -X- _ O
it -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
two -X- _ O
ICEWS -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
disentanglement -X- _ O
usually -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
performance -X- _ O
boost -X- _ O
. -X- _ O

The -X- _ O
average -X- _ O
performance -X- _ O
gains -X- _ O
of -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
based -X- _ O
models -X- _ O
( -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
DistMult -X- _ I-MethodName
, -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
SimplE -X- _ I-MethodName
, -X- _ O
KRQuatE -X- _ B-MethodName
) -X- _ O
are -X- _ O
high -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
models -X- _ O
( -X- _ O
DistMult -X- _ B-MethodName
, -X- _ O
SimplE -X- _ B-MethodName
, -X- _ O
and -X- _ O
QuatE -X- _ B-MethodName
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
QuatE -X- _ I-MethodName
outperforms -X- _ O
other -X- _ O
models -X- _ O
signiﬁcantly -X- _ O
. -X- _ O

To -X- _ O
conclude -X- _ O
, -X- _ O
our -X- _ O
experimental -X- _ O
evidence -X- _ O
shows -X- _ O
that -X- _ O
disentangling -X- _ O
the -X- _ O
entities -X- _ O
can -X- _ O
indeed -X- _ O
bring -X- _ O
performance -X- _ O
increase -X- _ O
and -X- _ O
the -X- _ O
proposed -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
can -X- _ O
effectively -X- _ O
be -X- _ O
integrated -X- _ O
into -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O

4.6 -X- _ O
Model -X- _ O
Analysis -X- _ O
To -X- _ O
answer -X- _ O
RQ -X- _ O
III -X- _ O
and -X- _ O
gain -X- _ O
further -X- _ O
insights -X- _ O
, -X- _ O
we -X- _ O
empirically -X- _ O
analyze -X- _ O
the -X- _ O
important -X- _ O
ingredients -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
via -X- _ O
qualitative -X- _ O
analysis -X- _ O
and -X- _ O
visualization -X- _ O
. -X- _ O

4.6.1 -X- _ O
Visualization -X- _ O
of -X- _ O
similarity -X- _ O
scores -X- _ O
The -X- _ O
attention -X- _ O
mechanism -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
achieving -X- _ O
the -X- _ O
ﬁnal -X- _ O
disentanglement -X- _ O
. -X- _ O

To -X- _ O
show -X- _ O
its -X- _ O
efﬁcacy -X- _ O
, -X- _ O
we -X- _ O
visualize -X- _ O
four -X- _ O
examples -X- _ O
of -X- _ O
attention -X- _ O
weights -X- _ O
wi -X- _ O
; -X- _ O
k -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
color -X- _ O
scale -X- _ O
represents -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O

Each -X- _ O
row -X- _ O
represents -X- _ O
a -X- _ O
neighbor -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
entity -X- _ O
and -X- _ O
each -X- _ O
column -X- _ O
represents -X- _ O
a -X- _ O
disentangled -X- _ O
component -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
a -X- _ O
clear -X- _ O
staggered -X- _ O
pattern -X- _ O
in -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
upper -X- _ O
left -X- _ O
ﬁgure -X- _ O
, -X- _ O
the -X- _ O
neighbors -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
ICEWS14 -X- _ B-DatasetName
and -X- _ O
ICEWS05 -X- _ B-DatasetName
- -X- _ I-DatasetName
15 -X- _ I-DatasetName
. -X- _ O

Best -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

“ -X- _ O
? -X- _ O
” -X- _ O
: -X- _ O
results -X- _ O
from -X- _ O
( -X- _ O
García -X- _ O
- -X- _ O
Durán -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
100for -X- _ B-HyperparameterValue
all -X- _ O
models -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
Four -X- _ O
examples -X- _ O
of -X- _ O
attention -X- _ O
weights -X- _ O
learned -X- _ O
during -X- _ O
the -X- _ O
routing -X- _ O
process -X- _ O
. -X- _ O

Te -X- _ O
upper -X- _ O
two -X- _ O
examples -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
WikiData -X- _ B-DatasetName
( -X- _ O
K= -X- _ B-HyperparameterName
2 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
the -X- _ O
lower -X- _ O
two -X- _ O
examples -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
ICEWS14 -X- _ B-DatasetName
( -X- _ O
K= -X- _ B-HyperparameterName
4 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O

Rows -X- _ O
represent -X- _ O
neighbors -X- _ O
and -X- _ O
columns -X- _ O
represent -X- _ O
disentangled -X- _ O
components -X- _ O
. -X- _ O

Best -X- _ O
viewed -X- _ O
in -X- _ O
color -X- _ O
. -X- _ O

1 -X- _ O
; -X- _ O
2 -X- _ O
; -X- _ O
3give -X- _ O
higher -X- _ O
weights -X- _ O
to -X- _ O
the -X- _ O
second -X- _ O
component -X- _ O
while -X- _ O
0gives -X- _ O
a -X- _ O
stronger -X- _ O
weight -X- _ O
to -X- _ O
the -X- _ O
ﬁrst -X- _ O
component -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
ﬁgures -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
are -X- _ O
also -X- _ O
staggered -X- _ O
among -X- _ O
the -X- _ O
disentangled -X- _ O
components -X- _ O
. -X- _ O

4.6.2 -X- _ O
Case -X- _ O
study -X- _ O
We -X- _ O
randomly -X- _ O
pick -X- _ O
one -X- _ O
entity -X- _ O
( -X- _ O
Michael -X- _ O
Rensing -X- _ O
, -X- _ O
a -X- _ O
German -X- _ O
footballer -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
WikiData -X- _ B-DatasetName
and -X- _ O
show -X- _ O
the -X- _ O
learned -X- _ O
weight -X- _ O
between -X- _ O
him -X- _ O
and -X- _ O
his -X- _ O
neighborhood -X- _ O
entities -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
FC -X- _ O
Bayern -X- _ O
Munich -X- _ O
andJan -X- _ O
Kirchhoff -X- _ O
( -X- _ O
who -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
team -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
FC -X- _ O
Bayern -X- _ O
Munich -X- _ O
club -X- _ O
) -X- _ O
contribute -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
ﬁrst -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
Michael -X- _ O
Rensing -X- _ O
, -X- _ O
while -X- _ O
Germany -X- _ O
national -X- _ O
under18 -X- _ O
football -X- _ O
team -X- _ O
andGermany -X- _ O
national -X- _ O
under-21 -X- _ O
football -X- _ O
team -X- _ O
make -X- _ O
larger -X- _ O
contributions -X- _ O
to -X- _ O
the -X- _ O
second -X- _ O
component -X- _ O
. -X- _ O

Clearly -X- _ O
, -X- _ O
the -X- _ O
ﬁrst -X- _ O
component -X- _ O
captures -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
Michael -X- _ O
Rensing -X- _ O
is -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
theFC -X- _ O
Bayern -X- _ O
Munich -X- _ O
association -X- _ O
football -X- _ O
club -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
component -X- _ O
reﬂects -X- _ O
that -X- _ O
he -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
Case -X- _ O
study -X- _ O
on -X- _ O
WikiData -X- _ O
for -X- _ O
the -X- _ O
German -X- _ O
footballer -X- _ O
Michael -X- _ O
Rensing -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
The -X- _ O
impact -X- _ O
of -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
components -X- _ I-HyperparameterName
K -X- _ I-HyperparameterName
on -X- _ O
ICEWS14 -X- _ B-DatasetName
. -X- _ O

( -X- _ O
b -X- _ O
) -X- _ O
The -X- _ O
impact -X- _ O
of -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
neighborhood -X- _ I-HyperparameterName
routing -X- _ I-HyperparameterName
iteration -X- _ I-HyperparameterName
Ton -X- _ I-HyperparameterName
ICEWS14 -X- _ B-DatasetName
. -X- _ O

Germany -X- _ O
national -X- _ O
football -X- _ O
team -X- _ O
member -X- _ O
. -X- _ O

This -X- _ O
case -X- _ O
justiﬁes -X- _ O
our -X- _ O
assumption -X- _ O
that -X- _ O
entities -X- _ O
are -X- _ O
connected -X- _ O
for -X- _ O
different -X- _ O
reasons -X- _ O
and -X- _ O
demonstrates -X- _ O
that -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
disentangle -X- _ O
the -X- _ O
underlying -X- _ O
factors -X- _ O
effectively -X- _ O
. -X- _ O

4.6.3 -X- _ O
Impact -X- _ O
of -X- _ O
size -X- _ B-HyperparameterName
K -X- _ I-HyperparameterName

We -X- _ O
analyze -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
K. -X- _ B-HyperparameterName
Intuitively -X- _ O
, -X- _ O
Kis -X- _ B-HyperparameterName
difﬁcult -X- _ O
to -X- _ O
choose -X- _ O
since -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
prior -X- _ O
information -X- _ O
on -X- _ O
how -X- _ O
many -X- _ O
components -X- _ O
we -X- _ O
should -X- _ O
decompose -X- _ O
each -X- _ O
entity -X- _ O
into -X- _ O
. -X- _ O

The -X- _ O
test -X- _ O
results -X- _ O
with -X- _ O
varying -X- _ O
Kon -X- _ B-HyperparameterName
ICEWS14 -X- _ B-DatasetName
of -X- _ O
KR -X- _ B-MethodName
- -X- _ I-MethodName
QuatE -X- _ I-MethodName
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O

formance -X- _ O
degradation -X- _ O
. -X- _ O

One -X- _ O
possible -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
not -X- _ O
enough -X- _ O
neighborhood -X- _ O
entities -X- _ O
to -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
20groups -X- _ O
. -X- _ O

Empirically -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
settingKto -X- _ B-HyperparameterName
a -X- _ O
small -X- _ O
value -X- _ O
around -X- _ O
2to5can -X- _ B-HyperparameterValue
usually -X- _ O
render -X- _ O
reasonable -X- _ O
results -X- _ O
. -X- _ O

A -X- _ O
practical -X- _ O
suggestion -X- _ O
is -X- _ O
thatKshould -X- _ B-HyperparameterName
not -X- _ O
exceed -X- _ O
the -X- _ O
average -X- _ O
degree -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O

4.6.4 -X- _ O
Impact -X- _ O
of -X- _ O
routing -X- _ B-HyperparameterName
iteration -X- _ I-HyperparameterName
T -X- _ I-HyperparameterName

We -X- _ O
study -X- _ O
the -X- _ O
inﬂuence -X- _ O
of -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
routing -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
is -X- _ O
stable -X- _ O
when -X- _ O
using -X- _ O
different -X- _ O
iterations -X- _ O
. -X- _ O

The -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
algorithm -X- _ O
is -X- _ O
not -X- _ O
prone -X- _ O
to -X- _ O
saturation -X- _ O
and -X- _ O
has -X- _ O
good -X- _ O
convergence -X- _ O
properties -X- _ O
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
using -X- _ O
a -X- _ O
small -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
iterations -X- _ I-HyperparameterName
( -X- _ O
e.g. -X- _ O
, -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
could -X- _ O
lead -X- _ O
to -X- _ O
ideal -X- _ O
enhancement -X- _ O
without -X- _ O
putting -X- _ O
on -X- _ O
much -X- _ O
computation -X- _ O
burden -X- _ O
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
, -X- _ O
an -X- _ O
algorithm -X- _ O
for -X- _ O
learning -X- _ O
disentangled -X- _ O
entity -X- _ O
representations -X- _ O
in -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O

Our -X- _ O
method -X- _ O
is -X- _ O
model -X- _ O
agnostic -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
many -X- _ O
canonical -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
methods -X- _ O
. -X- _ O

Extensive -X- _ O
experiments -X- _ O
on -X- _ O
four -X- _ O
benchmarking -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
equipping -X- _ O
popular -X- _ O
embedding -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
proposed -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
can -X- _ O
outperform -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
recent -X- _ O
strong -X- _ O
baselines -X- _ O
. -X- _ O

Via -X- _ O
qualitative -X- _ O
model -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
discover -X- _ O
that -X- _ O
Knowledge -X- _ B-MethodName
Router -X- _ I-MethodName
can -X- _ O
effectively -X- _ O
learns -X- _ O
the -X- _ O
hidden -X- _ O
factors -X- _ O
connecting -X- _ O
entities -X- _ O
, -X- _ O
thus -X- _ O
leading -X- _ O
to -X- _ O
disentanglement -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
showcase -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
certain -X- _ O
important -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
and -X- _ O
give -X- _ O
suggestions -X- _ O
on -X- _ O
hyperparameters -X- _ O
tuning -X- _ O
. -X- _ O

Proceedings -X- _ O
of -X- _ O
NAACL -X- _ O
- -X- _ O
HLT -X- _ O
2019 -X- _ O
, -X- _ O
pages -X- _ O
1–10 -X- _ O
Minneapolis -X- _ O
, -X- _ O
Minnesota -X- _ O
, -X- _ O
June -X- _ O
2 -X- _ O
- -X- _ O
June -X- _ O
7 -X- _ O
, -X- _ O
2019 -X- _ O
. -X- _ O

c -X- _ O

2019 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics1Entity -X- _ B-TaskName
Recognition -X- _ I-TaskName
at -X- _ O
First -X- _ O
Sight -X- _ O
: -X- _ O
Improving -X- _ O
NER -X- _ B-TaskName
with -X- _ O
Eye -X- _ O
Movement -X- _ O
Information -X- _ O
Nora -X- _ O
Hollenstein -X- _ O
ETH -X- _ O
Zurich -X- _ O
noraho -X- _ O
@ -X- _ O
ethz.chCe -X- _ O
Zhang -X- _ O
ETH -X- _ O
Zurich -X- _ O
ce.zhang -X- _ O
@ -X- _ O
inf.ethz.ch -X- _ O
Abstract -X- _ O
Previous -X- _ O
research -X- _ O
shows -X- _ O
that -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
contains -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
properties -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
eye -X- _ O
movement -X- _ O
features -X- _ O
from -X- _ O
three -X- _ O
corpora -X- _ O
with -X- _ O
recorded -X- _ O
gaze -X- _ O
information -X- _ O
to -X- _ O
augment -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
neural -X- _ O
model -X- _ O
for -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
with -X- _ O
gaze -X- _ O
embeddings -X- _ O
. -X- _ O

These -X- _ O
corpora -X- _ O
were -X- _ O
manually -X- _ O
annotated -X- _ O
with -X- _ O
named -X- _ O
entity -X- _ O
labels -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
gaze -X- _ O
features -X- _ O
, -X- _ O
generalized -X- _ O
on -X- _ O
word -X- _ O
type -X- _ O
level -X- _ O
, -X- _ O
eliminate -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
recorded -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

The -X- _ O
gaze -X- _ O
- -X- _ O
augmented -X- _ O
models -X- _ O
for -X- _ O
NER -X- _ B-TaskName
using -X- _ O
tokenlevel -X- _ O
and -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
outperform -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
the -X- _ O
beneﬁts -X- _ O
of -X- _ O
eyetracking -X- _ O
features -X- _ O
by -X- _ O
evaluating -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
on -X- _ O
both -X- _ O
individual -X- _ O
datasets -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
in -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
. -X- _ O

1 -X- _ O

Introduction -X- _ O
The -X- _ O
ﬁeld -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
includes -X- _ O
studies -X- _ O
of -X- _ O
tasks -X- _ O
of -X- _ O
different -X- _ O
granularity -X- _ O
and -X- _ O
depths -X- _ O
of -X- _ O
semantics -X- _ O
: -X- _ O
from -X- _ O
lower -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
tokenization -X- _ O
and -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
tagging -X- _ O
up -X- _ O
to -X- _ O
higher -X- _ O
level -X- _ O
tasks -X- _ O
of -X- _ O
information -X- _ O
extraction -X- _ O
such -X- _ O
as -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
, -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
role -X- _ O
labeling -X- _ O
( -X- _ O
Collobert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
NLP -X- _ O
systems -X- _ O
become -X- _ O
increasingly -X- _ O
prevalent -X- _ O
in -X- _ O
society -X- _ O
, -X- _ O
how -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
information -X- _ O
passively -X- _ O
collected -X- _ O
from -X- _ O
human -X- _ O
readers -X- _ O
, -X- _ O
e.g. -X- _ O
eye -X- _ O
movement -X- _ O
signals -X- _ O
, -X- _ O
is -X- _ O
becoming -X- _ O
more -X- _ O
interesting -X- _ O
to -X- _ O
researchers -X- _ O
. -X- _ O

Previous -X- _ O
research -X- _ O
in -X- _ O
this -X- _ O
area -X- _ O
has -X- _ O
shown -X- _ O
promising -X- _ O
results -X- _ O
: -X- _ O
Eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
tagging -X- _ O
( -X- _ O
Barrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
sentiment -X- _ O
analysis -X- _ O
( -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
prediction -X- _ O
of -X- _ O
multiword -X- _ O
expressions -X- _ O
( -X- _ O
Rohanian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
word -X- _ O
embedding -X- _ O
evaluation -X- _ O
( -X- _ O
Søgaard -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
these -X- _ O
studies -X- _ O
focus -X- _ O
on -X- _ O
either -X- _ O
relatively -X- _ O
lower -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
tagging -X- _ O
and -X- _ O
multiword -X- _ O
expressions -X- _ O
) -X- _ O
or -X- _ O
relativelyglobal -X- _ O
properties -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
sentiment -X- _ O
analysis -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
a -X- _ O
hypothesis -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
level -X- _ O
: -X- _ O
Can -X- _ O
eye -X- _ O
movement -X- _ O
signals -X- _ O
also -X- _ O
help -X- _ O
improve -X- _ O
higher -X- _ O
- -X- _ O
level -X- _ O
semantic -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
extracting -X- _ O
information -X- _ O
from -X- _ O
text -X- _ O
? -X- _ O

The -X- _ O
answer -X- _ O
to -X- _ O
this -X- _ O
question -X- _ O
is -X- _ O
not -X- _ O
obvious -X- _ O
. -X- _ O

On -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
improvement -X- _ O
attributed -X- _ O
to -X- _ O
eye -X- _ O
movement -X- _ O
signals -X- _ O
on -X- _ O
lower -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
implies -X- _ O
that -X- _ O
such -X- _ O
signals -X- _ O
do -X- _ O
contain -X- _ O
linguistic -X- _ O
information -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
whether -X- _ O
these -X- _ O
signals -X- _ O
can -X- _ O
also -X- _ O
provide -X- _ O
signiﬁcant -X- _ O
improvement -X- _ O
for -X- _ O
tasks -X- _ O
dealing -X- _ O
with -X- _ O
higher -X- _ O
- -X- _ O
level -X- _ O
semantics -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
eye -X- _ O
movement -X- _ O
patterns -X- _ O
contain -X- _ O
signals -X- _ O
related -X- _ O
to -X- _ O
higher -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
implied -X- _ O
by -X- _ O
a -X- _ O
recent -X- _ O
psycholinguistic -X- _ O
study -X- _ O
( -X- _ O
Tokunaga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
noisy -X- _ O
as -X- _ O
these -X- _ O
signals -X- _ O
are -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
straightforward -X- _ O
whether -X- _ O
they -X- _ O
would -X- _ O
help -X- _ O
, -X- _ O
if -X- _ O
not -X- _ O
hurt -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
ﬁrst -X- _ O
study -X- _ O
of -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
gaze -X- _ O
features -X- _ O
to -X- _ O
automatic -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
from -X- _ O
text -X- _ O
. -X- _ O

We -X- _ O
test -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
is -X- _ O
beneﬁcial -X- _ O
for -X- _ O
entity -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
neural -X- _ O
named -X- _ O
entity -X- _ O
tagger -X- _ O
augmented -X- _ O
with -X- _ O
embedding -X- _ O
layers -X- _ O
of -X- _ O
gaze -X- _ O
features -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
work -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
annotate -X- _ O
three -X- _ O
eyetracking -X- _ O
corpora -X- _ O
with -X- _ O
named -X- _ O
entity -X- _ O
labels -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
neural -X- _ O
NER -X- _ B-TaskName
system -X- _ O
with -X- _ O
gaze -X- _ O
features -X- _ O
. -X- _ O

This -X- _ O
collection -X- _ O
of -X- _ O
corpora -X- _ O
facilitates -X- _ O
future -X- _ O
research -X- _ O
in -X- _ O
related -X- _ O
topics -X- _ O
. -X- _ O

The -X- _ O
annotations -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O

Beyond -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
neural -X- _ O
architecture -X- _ O
for -X- _ O
NER -X- _ B-TaskName
, -X- _ O
which -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
textual -X- _ O
information -X- _ O
, -X- _ O
incorporates -X- _ O
embedding -X- _ O
layers -X- _ O
to -X- _ O
encode -X- _ O
eye -X- _ O
movement -X- _ O
information -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
gaze -X- _ O
features -X- _ O
generalized -X- _ O
to -X- _ O
word -X- _ O
types -X- _ O
eliminate -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
recorded -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

This -X- _ O

2makes -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
in -X- _ O
NLP -X- _ O
applications -X- _ O
more -X- _ O
feasible -X- _ O
since -X- _ O
recorded -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
context -X- _ O
is -X- _ O
not -X- _ O
required -X- _ O
anymore -X- _ O
at -X- _ O
prediction -X- _ O
time -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
appear -X- _ O
to -X- _ O
be -X- _ O
particularly -X- _ O
useful -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
systems -X- _ O
. -X- _ O

Our -X- _ O
hypotheses -X- _ O
are -X- _ O
evaluated -X- _ O
not -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
available -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
corpora -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
on -X- _ O
an -X- _ O
external -X- _ O
benchmark -X- _ O
dataset -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
gaze -X- _ O
information -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
The -X- _ O
beneﬁts -X- _ O
of -X- _ O
eye -X- _ O
movement -X- _ O
data -X- _ O
for -X- _ O
machine -X- _ O
learning -X- _ O
have -X- _ O
been -X- _ O
assessed -X- _ O
in -X- _ O
various -X- _ O
domains -X- _ O
, -X- _ O
including -X- _ O
NLP -X- _ O
and -X- _ O
computer -X- _ O
vision -X- _ O
. -X- _ O

Eye -X- _ O
- -X- _ O
trackers -X- _ O
provide -X- _ O
millisecond -X- _ O
- -X- _ O
accurate -X- _ O
records -X- _ O
on -X- _ O
where -X- _ O
humans -X- _ O
look -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
reading -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
becoming -X- _ O
cheaper -X- _ O
and -X- _ O
more -X- _ O
easily -X- _ O
available -X- _ O
by -X- _ O
the -X- _ O
day -X- _ O
( -X- _ O
San -X- _ O
Agustin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O

Sewell -X- _ O
and -X- _ O
Komogortsev -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O

Although -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
is -X- _ O
still -X- _ O
being -X- _ O
recorded -X- _ O
in -X- _ O
controlled -X- _ O
experiment -X- _ O
environments -X- _ O
, -X- _ O
this -X- _ O
will -X- _ O
likely -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
near -X- _ O
future -X- _ O
. -X- _ O

Recent -X- _ O
approaches -X- _ O
have -X- _ O
shown -X- _ O
substantial -X- _ O
improvements -X- _ O
in -X- _ O
recording -X- _ O
gaze -X- _ O
data -X- _ O
while -X- _ O
reading -X- _ O
by -X- _ O
using -X- _ O
cameras -X- _ O
of -X- _ O
mobile -X- _ O
devices -X- _ O
( -X- _ O
G -X- _ O
´ -X- _ O
omezPoveda -X- _ O
and -X- _ O
Gaudioso -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Papoutsaki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
will -X- _ O
probably -X- _ O
be -X- _ O
more -X- _ O
accessible -X- _ O
and -X- _ O
available -X- _ O
in -X- _ O
much -X- _ O
larger -X- _ O
volumes -X- _ O
in -X- _ O
due -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
facilitate -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
sizable -X- _ O
datasets -X- _ O
enormously -X- _ O
. -X- _ O

Tokunaga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
recently -X- _ O
analyzed -X- _ O
eyetracking -X- _ O
signals -X- _ O
during -X- _ O
the -X- _ O
annotation -X- _ O
of -X- _ O
named -X- _ O
entities -X- _ O
to -X- _ O
ﬁnd -X- _ O
effective -X- _ O
features -X- _ O
for -X- _ O
NER -X- _ B-TaskName
. -X- _ O

Their -X- _ O
work -X- _ O
proves -X- _ O
that -X- _ O
humans -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
a -X- _ O
broad -X- _ O
context -X- _ O
to -X- _ O
identify -X- _ O
named -X- _ O
entities -X- _ O
, -X- _ O
including -X- _ O
predicate -X- _ O
- -X- _ O
argument -X- _ O
structure -X- _ O
. -X- _ O

This -X- _ O
further -X- _ O
strengthens -X- _ O
our -X- _ O
intuition -X- _ O
to -X- _ O
use -X- _ O
eye -X- _ O
movement -X- _ O
information -X- _ O
to -X- _ O
improve -X- _ O
existing -X- _ O
NER -X- _ B-TaskName
systems -X- _ O
. -X- _ O

And -X- _ O
going -X- _ O
even -X- _ O
a -X- _ O
step -X- _ O
further -X- _ O
, -X- _ O
it -X- _ O
opens -X- _ O
the -X- _ O
possibility -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
entity -X- _ O
annotation -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
reader -X- _ O
’s -X- _ O
eye -X- _ O
movements -X- _ O
. -X- _ O

The -X- _ O
beneﬁt -X- _ O
of -X- _ O
eye -X- _ O
movement -X- _ O
data -X- _ O
is -X- _ O
backed -X- _ O
up -X- _ O
by -X- _ O
extensive -X- _ O
psycholinguistic -X- _ O
studies -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
when -X- _ O
humans -X- _ O
read -X- _ O
a -X- _ O
text -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
focus -X- _ O
on -X- _ O
every -X- _ O
single -X- _ O
word -X- _ O
. -X- _ O

The -X- _ O
number -X- _ O
of -X- _ O
ﬁxations -X- _ O
and -X- _ O
the -X- _ O
ﬁxation -X- _ O
duration -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
depends -X- _ O
on -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
linguistic -X- _ O
factors -X- _ O
( -X- _ O
Clifton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Demberg -X- _ O
and -X- _ O
Keller -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
readers -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
ﬁxate -X- _ O
on -X- _ O
open -X- _ O
- -X- _ O
class -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
notpredictable -X- _ O
from -X- _ O
context -X- _ O
( -X- _ O
Rayner -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
. -X- _ O

Reading -X- _ O
patterns -X- _ O
are -X- _ O
a -X- _ O
reliable -X- _ O
indicator -X- _ O
of -X- _ O
syntactical -X- _ O
categories -X- _ O
( -X- _ O
Barrett -X- _ O
and -X- _ O
Søgaard -X- _ O
, -X- _ O
2015a -X- _ O
) -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
word -X- _ O
frequency -X- _ O
and -X- _ O
word -X- _ O
familiarity -X- _ O
inﬂuence -X- _ O
how -X- _ O
long -X- _ O
readers -X- _ O
look -X- _ O
at -X- _ O
a -X- _ O
word -X- _ O
. -X- _ O

The -X- _ O
frequency -X- _ O
effect -X- _ O
was -X- _ O
ﬁrst -X- _ O
noted -X- _ O
by -X- _ O
Rayner -X- _ O
( -X- _ O
1977 -X- _ O
) -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
reported -X- _ O
in -X- _ O
various -X- _ O
studies -X- _ O
since -X- _ O
, -X- _ O
e.g. -X- _ O
Just -X- _ O
and -X- _ O
Carpenter -X- _ O
( -X- _ O
1980 -X- _ O
) -X- _ O
and -X- _ O
Cop -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
although -X- _ O
two -X- _ O
words -X- _ O
may -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
frequency -X- _ O
value -X- _ O
, -X- _ O
they -X- _ O
may -X- _ O
differ -X- _ O
in -X- _ O
familiarity -X- _ O
( -X- _ O
especially -X- _ O
for -X- _ O
infrequent -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O

Effects -X- _ O
of -X- _ O
word -X- _ O
familiarity -X- _ O
on -X- _ O
ﬁxation -X- _ O
time -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
demonstrated -X- _ O
in -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
recent -X- _ O
studies -X- _ O
( -X- _ O
Juhasz -X- _ O
and -X- _ O
Rayner -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Williams -X- _ O
and -X- _ O
Morris -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
the -X- _ O
positive -X- _ O
effect -X- _ O
of -X- _ O
ﬁxation -X- _ O
information -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
has -X- _ O
recently -X- _ O
been -X- _ O
shown -X- _ O
by -X- _ O
Barrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
ﬁxation -X- _ O
duration -X- _ O
. -X- _ O

State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
NER -X- _ B-TaskName
Non -X- _ O
- -X- _ O
linear -X- _ O
neural -X- _ O
networks -X- _ O
with -X- _ O
distributed -X- _ O
word -X- _ O
representations -X- _ O
as -X- _ O
input -X- _ O
have -X- _ O
become -X- _ O
increasingly -X- _ O
successful -X- _ O
for -X- _ O
any -X- _ O
sequence -X- _ O
labeling -X- _ O
task -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Chiu -X- _ O
and -X- _ O
Nichols -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Ma -X- _ O
and -X- _ O
Hovy -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
same -X- _ O
applies -X- _ O
to -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
: -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
systems -X- _ O
are -X- _ O
combinations -X- _ O
of -X- _ O
neural -X- _ O
networks -X- _ O
such -X- _ O
as -X- _ O
LSTMs -X- _ O
or -X- _ O
CNNs -X- _ O
and -X- _ O
conditional -X- _ O
random -X- _ O
ﬁelds -X- _ O
( -X- _ O
CRFs -X- _ O
) -X- _ O
( -X- _ O
Strauss -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
developed -X- _ O
such -X- _ O
a -X- _ O
neural -X- _ O
architecture -X- _ O
for -X- _ O
NER -X- _ B-TaskName
, -X- _ O
which -X- _ O
we -X- _ O
employ -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
and -X- _ O
enhance -X- _ O
with -X- _ O
eye -X- _ O
movement -X- _ O
features -X- _ O
. -X- _ O

Their -X- _ O
model -X- _ O
successfully -X- _ O
combines -X- _ O
wordlevel -X- _ O
and -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
augment -X- _ O
with -X- _ O
embedding -X- _ O
layers -X- _ O
for -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
. -X- _ O

3 -X- _ O
Eye -X- _ O
- -X- _ O
tracking -X- _ O
corpora -X- _ O

For -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
resort -X- _ O
to -X- _ O
three -X- _ O
eyetracking -X- _ O
data -X- _ O
resources -X- _ O
: -X- _ O
the -X- _ O
Dundee -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Kennedy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
GECO -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Cop -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
ZuCo -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Hollenstein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
information -X- _ O
extraction -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
that -X- _ O
the -X- _ O
readers -X- _ O
process -X- _ O
longer -X- _ O
fragments -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
i.e. -X- _ O
complete -X- _ O
sentences -X- _ O
instead -X- _ O
of -X- _ O
single -X- _ O
words -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
case -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
datasets -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ O
and -X- _ O
size -X- _ O
of -X- _ O
these -X- _ O
datasets -X- _ O
. -X- _ O

In -X- _ O
total -X- _ O
, -X- _ O
they -X- _ O
comprise -X- _ O
142,441 -X- _ O
tokens -X- _ O
with -X- _ O
gaze -X- _ O
information -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
also -X- _ O
shows -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
mean -X- _ O
ﬁxation -X- _ O
times -X- _ O
between -X- _ O
the -X- _ O
datasets -X- _ O
( -X- _ O
i.e. -X- _ O
ﬁxation -X- _ O
duration -X- _ O
( -X- _ O
the -X- _ O
average -X- _ O
duration -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
ﬁxation -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
in -X- _ O

domain -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
news -X- _ O
articles -X- _ O
literaturemovie -X- _ O
reviews -X- _ O
, -X- _ O
Wikipedia -X- _ O
articlesTable -X- _ O
1 -X- _ O
: -X- _ O
Descriptive -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
corpora -X- _ O
, -X- _ O
including -X- _ O
domain -X- _ O
, -X- _ O
size -X- _ O
and -X- _ O
mean -X- _ O
ﬁxation -X- _ O
and -X- _ O
gaze -X- _ O
duration -X- _ O
per -X- _ O
token -X- _ O
. -X- _ O

Dundee -X- _ B-DatasetName
GECO -X- _ B-DatasetName
ZuCo -X- _ B-DatasetName
Total -X- _ O
all -X- _ O
unique -X- _ O
all -X- _ O
unique -X- _ O
all -X- _ O
unique -X- _ O
all -X- _ O
unique -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Number -X- _ O
and -X- _ O
distribution -X- _ O
of -X- _ O
named -X- _ O
entity -X- _ O
annotations -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
corpora -X- _ O
. -X- _ O
milliseconds -X- _ O
) -X- _ O
and -X- _ O
gaze -X- _ O
duration -X- _ O
( -X- _ O
the -X- _ O
average -X- _ O
duration -X- _ O
of -X- _ O
all -X- _ O
ﬁxations -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

Dundee -X- _ B-DatasetName
Corpus -X- _ O

The -X- _ O
gaze -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
Dundee -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Kennedy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
was -X- _ O
recorded -X- _ O
with -X- _ O
aDr -X- _ O
. -X- _ O

Bouis -X- _ O
Oculometer -X- _ O
Eyetracker -X- _ O
. -X- _ O

The -X- _ O
English -X- _ O
section -X- _ O
of -X- _ O
this -X- _ O
corpus -X- _ O
comprises -X- _ O
58,598 -X- _ O
tokens -X- _ O
in -X- _ O
2,367 -X- _ O
sentences -X- _ O
. -X- _ O

It -X- _ O
contains -X- _ O
eye -X- _ O
movement -X- _ O
information -X- _ O
of -X- _ O
ten -X- _ O
native -X- _ O
English -X- _ O
speakers -X- _ O
as -X- _ O
they -X- _ O
read -X- _ O
the -X- _ O
same -X- _ O
20 -X- _ O
newspaper -X- _ O
articles -X- _ O
from -X- _ O
The -X- _ O
Independent -X- _ O
. -X- _ O

The -X- _ O
text -X- _ O
was -X- _ O
presented -X- _ O
to -X- _ O
the -X- _ O
readers -X- _ O
on -X- _ O
a -X- _ O
screen -X- _ O
ﬁve -X- _ O
lines -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O

This -X- _ O
data -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
psycholinguistic -X- _ O
research -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
reading -X- _ O
behavior -X- _ O
of -X- _ O
subjects -X- _ O
while -X- _ O
reading -X- _ O
sentences -X- _ O
in -X- _ O
context -X- _ O
under -X- _ O
relatively -X- _ O
naturalistic -X- _ O
conditions -X- _ O
. -X- _ O

GECO -X- _ B-DatasetName
Corpus -X- _ O
The -X- _ B-DatasetName
Ghent -X- _ I-DatasetName
Eye -X- _ I-DatasetName
- -X- _ I-DatasetName
Tracking -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
Cop -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
recent -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
eye -X- _ O
movements -X- _ O
of -X- _ O
monolingual -X- _ O
and -X- _ O
bilingual -X- _ O
subjects -X- _ O
during -X- _ O
reading -X- _ O
. -X- _ O

The -X- _ O
data -X- _ O
was -X- _ O
recorded -X- _ O
with -X- _ O
an -X- _ O
EyeLink -X- _ O
1000 -X- _ O
system -X- _ O
. -X- _ O

The -X- _ O
text -X- _ O
was -X- _ O
presented -X- _ O
one -X- _ O
paragraph -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O

The -X- _ O
subjects -X- _ O
read -X- _ O
the -X- _ O
entire -X- _ O
novel -X- _ O
The -X- _ O
Mysterious -X- _ O
Affair -X- _ O
at -X- _ O
Styles -X- _ O
by -X- _ O
Agatha -X- _ O
Christie -X- _ O
( -X- _ O
1920 -X- _ O
) -X- _ O
containing -X- _ O
68,606 -X- _ O
tokens -X- _ O
in -X- _ O
5,424 -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
only -X- _ O
the -X- _ O
monolingual -X- _ O
data -X- _ O
recorded -X- _ O
from -X- _ O
the -X- _ O
14 -X- _ O
native -X- _ O
English -X- _ O
speakers -X- _ O
for -X- _ O
this -X- _ O
work -X- _ O
to -X- _ O
maintain -X- _ O
consistency -X- _ O
across -X- _ O
corpora -X- _ O
. -X- _ O

ZuCo -X- _ B-DatasetName
Corpus -X- _ O
The -X- _ O
Zurich -X- _ B-DatasetName
Cognitive -X- _ I-DatasetName
Language -X- _ I-DatasetName
Processing -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
Hollenstein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
combined -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
and -X- _ O
EEG -X- _ O
dataset -X- _ O
. -X- _ O

The -X- _ O
gaze -X- _ O
data -X- _ O
was -X- _ O
also -X- _ O
recorded -X- _ O
with -X- _ O
an -X- _ O
EyeLink -X- _ O
1000 -X- _ O
system -X- _ O
. -X- _ O

The -X- _ O
full -X- _ O
corpus -X- _ O
contains -X- _ O
1,100 -X- _ O
English -X- _ O
sentences -X- _ O
read -X- _ O
by -X- _ O
12 -X- _ O
adult -X- _ O
native -X- _ O
speakers -X- _ O
. -X- _ O

The -X- _ O
sentences -X- _ O
were -X- _ O
presented -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
position -X- _ O
on -X- _ O
the -X- _ O
screen -X- _ O
one -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
present -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
eye -X- _ O
movement -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
two -X- _ O
reading -X- _ O
tasks -X- _ O
of -X- _ O
this -X- _ O
corpus -X- _ O
( -X- _ O
700 -X- _ O
sentences -X- _ O
, -X- _ O
15,237 -X- _ O
tokens -X- _ O
) -X- _ O
, -X- _ O
since -X- _ O
these -X- _ O
tasks -X- _ O
encouraged -X- _ O
natural -X- _ O
reading -X- _ O
. -X- _ O

The -X- _ O
reading -X- _ O
material -X- _ O
included -X- _ O
sentences -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
from -X- _ O
the -X- _ O
Stanford -X- _ O
Sentiment -X- _ O
Treebank -X- _ O
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Wikipedia -X- _ O
dataset -X- _ O
by -X- _ O
Culotta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2006 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
purposes -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
all -X- _ O
datasets -X- _ O
were -X- _ O
manually -X- _ O
annotated -X- _ O
with -X- _ O
named -X- _ O
entity -X- _ O
labels -X- _ O
for -X- _ O
three -X- _ O
categories -X- _ O
: -X- _ O
PERSON -X- _ O
, -X- _ O
ORGANIZATION -X- _ O
and -X- _ O
LOCATION -X- _ O
. -X- _ O

The -X- _ O
annotations -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
DS3Lab -X- _ O
/ -X- _ O
ner -X- _ O
- -X- _ O
at -X- _ O
- -X- _ O
first -X- _ O
- -X- _ O
sight -X- _ O
. -X- _ O

The -X- _ O
datasets -X- _ O
were -X- _ O
annotated -X- _ O
by -X- _ O
two -X- _ O
NLP -X- _ O
experts -X- _ O
. -X- _ O

The -X- _ O
IOB -X- _ O
tagging -X- _ O
scheme -X- _ O
was -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
labeling -X- _ O
. -X- _ O

We -X- _ O
followed -X- _ O
the -X- _ O
ACE -X- _ O
Annotation -X- _ O
Guidelines -X- _ O
( -X- _ O
Linguistic -X- _ O
Data -X- _ O
Consortium -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

All -X- _ O
conﬂicts -X- _ O
in -X- _ O
labelling -X- _ O
were -X- _ O
resolved -X- _ O
by -X- _ O
adjudication -X- _ O
between -X- _ O
both -X- _ O
annotators -X- _ O
. -X- _ O

An -X- _ O
inter- -X- _ O

nﬁxations -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
ﬁxations -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
ﬁxation -X- _ O
probability -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
wwill -X- _ O
be -X- _ O
ﬁxated -X- _ O
mean -X- _ O
ﬁxation -X- _ O
duration -X- _ O
mean -X- _ O
of -X- _ O
all -X- _ O
ﬁxation -X- _ O
durations -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
Early -X- _ O
ﬁrst -X- _ O
ﬁxation -X- _ O
duration -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
ﬁxation -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
ﬁrst -X- _ O
pass -X- _ O
duration -X- _ O
sum -X- _ O
of -X- _ O
all -X- _ O
ﬁxation -X- _ O
durations -X- _ O
during -X- _ O
the -X- _ O
ﬁrst -X- _ O
pass -X- _ O
Late -X- _ O
total -X- _ O
ﬁxation -X- _ O
duration -X- _ O
sum -X- _ O
of -X- _ O
all -X- _ O
ﬁxation -X- _ O
durations -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
w -X- _ O
nre-ﬁxations -X- _ O
number -X- _ O
of -X- _ O
times -X- _ O
a -X- _ O
word -X- _ O
wis -X- _ O
ﬁxated -X- _ O
( -X- _ O
after -X- _ O
the -X- _ O
ﬁrst -X- _ O
ﬁxation -X- _ O
) -X- _ O
re -X- _ O
- -X- _ O
read -X- _ O
probability -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
wwill -X- _ O
be -X- _ O
read -X- _ O
more -X- _ O
than -X- _ O
once -X- _ O
Context -X- _ O
total -X- _ O
regression -X- _ O
- -X- _ O
from -X- _ O
duration -X- _ O
combined -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
regressions -X- _ O
that -X- _ O
began -X- _ O
at -X- _ O
word -X- _ O
w -X- _ O
w-2ﬁxation -X- _ O
probability -X- _ O
ﬁxation -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
before -X- _ O
the -X- _ O
previous -X- _ O
word -X- _ O
w-1ﬁxation -X- _ O
probability -X- _ O
ﬁxation -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
word -X- _ O
w+1 -X- _ O
ﬁxation -X- _ O
probability -X- _ O
ﬁxation -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
w+2 -X- _ O
ﬁxation -X- _ O
probability -X- _ O
ﬁxation -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
after -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
w-2ﬁxation -X- _ O
duration -X- _ O
ﬁxation -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
before -X- _ O
the -X- _ O
previous -X- _ O
word -X- _ O
w-1ﬁxation -X- _ O
duration -X- _ O
ﬁxation -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
word -X- _ O
w+1 -X- _ O
ﬁxation -X- _ O
duration -X- _ O
ﬁxation -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
w+2 -X- _ O
ﬁxation -X- _ O
duration -X- _ O
ﬁxation -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
after -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Gaze -X- _ O
features -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
Dundee -X- _ B-DatasetName
, -X- _ O
GECO -X- _ B-DatasetName
and -X- _ O
ZuCo -X- _ B-DatasetName
corpora -X- _ O
. -X- _ O

annotator -X- _ O
reliability -X- _ O
analysis -X- _ O
on -X- _ O
10,000 -X- _ O
tokens -X- _ O
( -X- _ O
511 -X- _ O
sentences -X- _ O
) -X- _ O
sampled -X- _ O
from -X- _ O
all -X- _ O
three -X- _ O
datasets -X- _ O
yielded -X- _ O
an -X- _ O
agreement -X- _ O
of -X- _ O
83.5 -X- _ O
% -X- _ O
on -X- _ O
the -X- _ O
entity -X- _ O
labels -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
annotated -X- _ O
entities -X- _ O
in -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O

The -X- _ O
distribution -X- _ O
of -X- _ O
entities -X- _ O
between -X- _ O
the -X- _ O
corpora -X- _ O
is -X- _ O
highly -X- _ O
unbalanced -X- _ O
: -X- _ O
Dundee -X- _ B-DatasetName
and -X- _ O
ZuCo -X- _ B-DatasetName
, -X- _ O
the -X- _ O
datasets -X- _ O
containing -X- _ O
more -X- _ O
heterogeneous -X- _ O
texts -X- _ O
and -X- _ O
thus -X- _ O
, -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
ratio -X- _ O
of -X- _ O
unique -X- _ O
entity -X- _ O
occurrences -X- _ O
, -X- _ O
versus -X- _ O
GECO -X- _ B-DatasetName
, -X- _ O
a -X- _ O
homogeneous -X- _ O
corpus -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
novel -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
named -X- _ O
entities -X- _ O
are -X- _ O
very -X- _ O
repetitive -X- _ O
. -X- _ O

4 -X- _ O
Eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
The -X- _ O
gaze -X- _ O
data -X- _ O
of -X- _ O
all -X- _ O
three -X- _ O
corpora -X- _ O
was -X- _ O
recorded -X- _ O
for -X- _ O
multiple -X- _ O
readers -X- _ O
by -X- _ O
conducting -X- _ O
experiments -X- _ O
in -X- _ O
a -X- _ O
controlled -X- _ O
environment -X- _ O
using -X- _ O
specialized -X- _ O
equipment -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
consider -X- _ O
that -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
same -X- _ O
features -X- _ O
for -X- _ O
all -X- _ O
corpora -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
certainly -X- _ O
practical -X- _ O
aspects -X- _ O
that -X- _ O
differ -X- _ O
across -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
factors -X- _ O
are -X- _ O
expected -X- _ O
to -X- _ O
inﬂuence -X- _ O
reading -X- _ O
: -X- _ O
experiment -X- _ O
procedures -X- _ O
; -X- _ O
text -X- _ O
presentation -X- _ O
; -X- _ O
recording -X- _ O
hardware -X- _ O
, -X- _ O
software -X- _ O
and -X- _ O
quality -X- _ O
; -X- _ O
sampling -X- _ O
rates -X- _ O
; -X- _ O
initial -X- _ O
calibration -X- _ O
and -X- _ O
ﬁltering -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
human -X- _ O
factors -X- _ O
such -X- _ O
as -X- _ O
head -X- _ O
movements -X- _ O
and -X- _ O
lack -X- _ O
of -X- _ O
attention -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
separate -X- _ O
normalization -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
should -X- _ O
better -X- _ O
preserve -X- _ O
thesignal -X- _ O
within -X- _ O
each -X- _ O
corpus -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
reason -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregation -X- _ O
was -X- _ O
computed -X- _ O
on -X- _ O
the -X- _ O
normalized -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
especially -X- _ O
relevant -X- _ O
for -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
and -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
corpus -X- _ O
experiments -X- _ O
described -X- _ O
below -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
add -X- _ O
gaze -X- _ O
information -X- _ O
to -X- _ O
the -X- _ O
neural -X- _ O
network -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
selected -X- _ O
as -X- _ O
many -X- _ O
features -X- _ O
as -X- _ O
available -X- _ O
from -X- _ O
those -X- _ O
present -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
corpora -X- _ O
. -X- _ O

Previous -X- _ O
research -X- _ O
shows -X- _ O
beneﬁts -X- _ O
in -X- _ O
combining -X- _ O
multiple -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
of -X- _ O
different -X- _ O
stages -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
reading -X- _ O
process -X- _ O
( -X- _ O
Barrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
The -X- _ O
features -X- _ O
extracted -X- _ O
follow -X- _ O
closely -X- _ O
on -X- _ O
Barrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
described -X- _ O
above -X- _ O
, -X- _ O
psycholinguistic -X- _ O
research -X- _ O
has -X- _ O
shown -X- _ O
how -X- _ O
ﬁxation -X- _ O
duration -X- _ O
and -X- _ O
probability -X- _ O
differ -X- _ O
between -X- _ O
word -X- _ O
classes -X- _ O
and -X- _ O
syntactic -X- _ O
comprehension -X- _ O
processes -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
the -X- _ O
features -X- _ O
focus -X- _ O
on -X- _ O
representing -X- _ O
these -X- _ O
nuances -X- _ O
as -X- _ O
broadly -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
covering -X- _ O
the -X- _ O
complete -X- _ O
reading -X- _ O
time -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
at -X- _ O
different -X- _ O
stages -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
eye -X- _ O
movement -X- _ O
features -X- _ O
incorporated -X- _ O
into -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O

We -X- _ O
split -X- _ O
the -X- _ O
17 -X- _ O
features -X- _ O
into -X- _ O
4 -X- _ O
distinct -X- _ O
groups -X- _ O
( -X- _ O
analogous -X- _ O
to -X- _ O
Barrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
deﬁne -X- _ O
the -X- _ O
different -X- _ O
stages -X- _ O
of -X- _ O
the -X- _ O
reading -X- _ O
process -X- _ O
: -X- _ O
1.BASIC -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
capture -X- _ O
characteristics -X- _ O
on -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
e.g. -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
all -X- _ O

5ﬁxations -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
or -X- _ O
the -X- _ O
probability -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
will -X- _ O
be -X- _ O
ﬁxated -X- _ O
( -X- _ O
namely -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
subjects -X- _ O
who -X- _ O
ﬁxated -X- _ O
the -X- _ O
word -X- _ O
divided -X- _ O
by -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
subjects -X- _ O
) -X- _ O
. -X- _ O

2.EARLY -X- _ O
gaze -X- _ O
measures -X- _ O
capture -X- _ O
lexical -X- _ O
access -X- _ O
and -X- _ O
early -X- _ O
syntactic -X- _ O
processing -X- _ O
and -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
ﬁrst -X- _ O
time -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
ﬁxated -X- _ O
. -X- _ O

3.LATE -X- _ O
measures -X- _ O
reﬂect -X- _ O
the -X- _ O
late -X- _ O
syntactic -X- _ O
processing -X- _ O
and -X- _ O
general -X- _ O
disambiguation -X- _ O
. -X- _ O

These -X- _ O
features -X- _ O
are -X- _ O
signiﬁcant -X- _ O
for -X- _ O
words -X- _ O
which -X- _ O
were -X- _ O
ﬁxated -X- _ O
more -X- _ O
than -X- _ O
once -X- _ O
. -X- _ O

4.CONTEXT -X- _ O
features -X- _ O
capture -X- _ O
the -X- _ O
gaze -X- _ O
measures -X- _ O
of -X- _ O
the -X- _ O
surrounding -X- _ O
tokens -X- _ O
. -X- _ O

These -X- _ O
features -X- _ O
consider -X- _ O
the -X- _ O
ﬁxation -X- _ O
probability -X- _ O
and -X- _ O
duration -X- _ O
up -X- _ O
to -X- _ O
two -X- _ O
tokens -X- _ O
to -X- _ O
the -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
token -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
regressions -X- _ O
starting -X- _ O
at -X- _ O
the -X- _ O
current -X- _ O
word -X- _ O
are -X- _ O
also -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
meaningful -X- _ O
for -X- _ O
the -X- _ O
syntactic -X- _ O
processing -X- _ O
of -X- _ O
full -X- _ O
sentences -X- _ O
. -X- _ O

The -X- _ O
eye -X- _ O
movement -X- _ O
measurements -X- _ O
were -X- _ O
averaged -X- _ O
over -X- _ O
all -X- _ O
native -X- _ O
- -X- _ O
speaking -X- _ O
readers -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
to -X- _ O
obtain -X- _ O
more -X- _ O
robust -X- _ O
estimates -X- _ O
. -X- _ O

The -X- _ O
small -X- _ O
size -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
datasets -X- _ O
often -X- _ O
limits -X- _ O
the -X- _ O
potential -X- _ O
for -X- _ O
training -X- _ O
data -X- _ O
- -X- _ O
intensive -X- _ O
algorithms -X- _ O
and -X- _ O
causes -X- _ O
overﬁtting -X- _ O
in -X- _ O
benchmark -X- _ O
evaluation -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
sparse -X- _ O
samples -X- _ O
of -X- _ O
gaze -X- _ O
measurements -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
limited -X- _ O
number -X- _ O
of -X- _ O
observations -X- _ O
available -X- _ O
, -X- _ O
we -X- _ O
normalize -X- _ O
the -X- _ O
data -X- _ O
by -X- _ O
splitting -X- _ O
the -X- _ O
feature -X- _ O
values -X- _ O
into -X- _ O
quantiles -X- _ O
to -X- _ O
avoid -X- _ O
sparsity -X- _ O
issues -X- _ O
. -X- _ O

The -X- _ O
best -X- _ O
results -X- _ O
were -X- _ O
achieved -X- _ O
with -X- _ O
24 -X- _ O
bins -X- _ O
. -X- _ O

This -X- _ O
normalization -X- _ O
is -X- _ O
conducted -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
corpus -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
special -X- _ O
care -X- _ O
had -X- _ O
to -X- _ O
be -X- _ O
taken -X- _ O
regarding -X- _ O
tokenization -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
recorded -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
considers -X- _ O
only -X- _ O
whitespace -X- _ O
separation -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
string -X- _ O
John -X- _ O
’s -X- _ O
would -X- _ O
constitute -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
for -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
feature -X- _ O
extraction -X- _ O
, -X- _ O
but -X- _ O
would -X- _ O
be -X- _ O
split -X- _ O
into -X- _ O
John -X- _ O
and’sfor -X- _ O
NER -X- _ B-TaskName
, -X- _ O
with -X- _ O
the -X- _ O
former -X- _ O
token -X- _ O
holding -X- _ O
the -X- _ O
label -X- _ O
PERSON -X- _ O
and -X- _ O
the -X- _ O
latter -X- _ O
no -X- _ O
label -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O

Our -X- _ O
strategy -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
was -X- _ O
to -X- _ O
assign -X- _ O
the -X- _ O
same -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
gaze -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
originating -X- _ O
token -X- _ O
to -X- _ O
split -X- _ O
tokens -X- _ O
. -X- _ O

4.1 -X- _ O
Type -X- _ O
aggregation -X- _ O
Barrett -X- _ O
and -X- _ O
Søgaard -X- _ O
( -X- _ O
2015b -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
typelevel -X- _ O
aggregation -X- _ O
of -X- _ O
gaze -X- _ O
features -X- _ O
results -X- _ O
in -X- _ O
larger -X- _ O
improvements -X- _ O
for -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
tagging -X- _ O
. -X- _ O

Following -X- _ O
their -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
conducted -X- _ O
exper -X- _ O
- -X- _ O
iments -X- _ O
with -X- _ O
type -X- _ O
aggregation -X- _ O
for -X- _ O
NER -X- _ B-TaskName
. -X- _ O

This -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
feature -X- _ O
values -X- _ O
were -X- _ O
averaged -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
type -X- _ O
over -X- _ O
all -X- _ O
occurrences -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
all -X- _ O
noccurrences -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
“ -X- _ O
island -X- _ O
” -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
occurrences -X- _ O
n -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
corpus -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
the -X- _ O
aggregated -X- _ O
corpora -X- _ O
, -X- _ O
a -X- _ O
lexicon -X- _ O
of -X- _ O
lower -X- _ O
- -X- _ O
cased -X- _ O
word -X- _ O
types -X- _ O
with -X- _ O
their -X- _ O
averaged -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
feature -X- _ O
values -X- _ O
was -X- _ O
compiled -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
as -X- _ O
input -X- _ O
for -X- _ O
the -X- _ O
network -X- _ O
, -X- _ O
either -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
aggregates -X- _ O
for -X- _ O
each -X- _ O
individual -X- _ O
corpus -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
or -X- _ O
the -X- _ O
values -X- _ O
from -X- _ O
the -X- _ O
combined -X- _ O
lexicon -X- _ O
, -X- _ O
which -X- _ O
increases -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
word -X- _ O
types -X- _ O
with -X- _ O
known -X- _ O
gaze -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

The -X- _ O
goal -X- _ O
of -X- _ O
type -X- _ O
aggregation -X- _ O
is -X- _ O
twofold -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
it -X- _ O
eliminates -X- _ O
the -X- _ O
requirement -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
when -X- _ O
applying -X- _ O
the -X- _ O
models -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
larger -X- _ O
the -X- _ O
lexicon -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
unseen -X- _ O
data -X- _ O
receive -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

For -X- _ O
those -X- _ O
tokens -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
lexicon -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
a -X- _ O
placeholder -X- _ O
for -X- _ O
unknown -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
on -X- _ O
any -X- _ O
dataset -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
improvements -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
with -X- _ O
aggregated -X- _ O
gaze -X- _ O
data -X- _ O
without -X- _ O
requiring -X- _ O
large -X- _ O
quantities -X- _ O
of -X- _ O
recorded -X- _ O
data -X- _ O
. -X- _ O

5 -X- _ O
Model -X- _ O
The -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
were -X- _ O
executed -X- _ O
using -X- _ O
an -X- _ O
enhanced -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
system -X- _ O
presented -X- _ O
by -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
hybrid -X- _ O
approach -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
bidirectional -X- _ O
LSTMs -X- _ O
and -X- _ O
conditional -X- _ O
random -X- _ O
ﬁelds -X- _ O
and -X- _ O
relies -X- _ O
mainly -X- _ O
on -X- _ O
two -X- _ O
sources -X- _ O
of -X- _ O
information -X- _ O
: -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
representations -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
the -X- _ O
originally -X- _ O
proposed -X- _ O
values -X- _ O
for -X- _ O
all -X- _ O
parameters -X- _ O
were -X- _ O
maintained -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
the -X- _ O
bidirectional -X- _ O
LSTMs -X- _ O
for -X- _ O
characterbased -X- _ O
embeddings -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
corpus -X- _ O
at -X- _ O
hand -X- _ O
with -X- _ O
dimensions -X- _ B-HyperparameterName
set -X- _ O
to -X- _ O
25 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
lookup -X- _ O
table -X- _ O
tor -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
was -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
GloVe -X- _ O
vectors -X- _ O
of -X- _ O
100 -X- _ B-HyperparameterValue
dimensions -X- _ B-HyperparameterName
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
uses -X- _ O
a -X- _ O
single -X- _ O
layer -X- _ O
for -X- _ O
the -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
LSTMs -X- _ O
. -X- _ O

All -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
at -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O

Moreover -X- _ O
, -X- _ O
all -X- _ O
digits -X- _ O
were -X- _ O
replaced -X- _ O
with -X- _ O
zeros -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
model1was -X- _ O
modiﬁed -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
gaze -X- _ O
features -X- _ O
as -X- _ O
additional -X- _ O
embedding -X- _ O
layers -X- _ O
to -X- _ O
the -X- _ O
network -X- _ O
. -X- _ O

The -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
bidirectional -X- _ O
LSTM -X- _ O
, -X- _ O
is -X- _ O
concatenated -X- _ O
with -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
from -X- _ O
1https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
glample -X- _ O
/ -X- _ O
tagger -X- _ O

l1MannersCanadaDavidwasborninr1c1l2r2c2l3r3c3l4r4c4l5r5c5l6r6c6B -X- _ O
- -X- _ O
LOCOOOI -X- _ O
- -X- _ O
PERB -X- _ O
- -X- _ O
PERCRF -X- _ O
layerbiLSTMencodercharacter -X- _ O
+ -X- _ O

word+ -X- _ O
gaze -X- _ O
embeddingswordcharactergaze -X- _ O
f1gaze -X- _ O
f2 -X- _ O
… -X- _ O
gaze -X- _ O
f17Figure -X- _ O
1 -X- _ O
: -X- _ O
Main -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
. -X- _ O

Character -X- _ O
and -X- _ O
word -X- _ O
embeddings -X- _ O
concatenated -X- _ O
with -X- _ O
gaze -X- _ O
features -X- _ O
are -X- _ O
given -X- _ O
to -X- _ O
a -X- _ O
bidirectional -X- _ O
LSTM -X- _ O
. -X- _ O

lirepresents -X- _ O
the -X- _ O
word -X- _ O
iand -X- _ O
its -X- _ O
left -X- _ O
context -X- _ O
, -X- _ O
rirepresents -X- _ O
the -X- _ O
word -X- _ O
iand -X- _ O
its -X- _ O
right -X- _ O
context -X- _ O
. -X- _ O

Concatenating -X- _ O
these -X- _ O
two -X- _ O
vectors -X- _ O
yields -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
iin -X- _ O
its -X- _ O
context -X- _ O
, -X- _ O
ci -X- _ O
. -X- _ O

a -X- _ O
word -X- _ O
lookup -X- _ O
table -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
augmented -X- _ O
model -X- _ O
with -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
information -X- _ O
, -X- _ O
the -X- _ O
embedding -X- _ O
for -X- _ O
each -X- _ O
discrete -X- _ O
gaze -X- _ O
feature -X- _ O
is -X- _ O
also -X- _ O
concatenated -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

The -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
gaze -X- _ O
feature -X- _ O
embeddings -X- _ O
is -X- _ O
equal -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
quantiles -X- _ O
. -X- _ O

This -X- _ O
architecture -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Word -X- _ O
length -X- _ O
and -X- _ O
word -X- _ O
frequency -X- _ O
are -X- _ O
known -X- _ O
to -X- _ O
correlate -X- _ O
and -X- _ O
interact -X- _ O
with -X- _ O
gaze -X- _ O
features -X- _ O
( -X- _ O
Tomanek -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
why -X- _ O
we -X- _ O
selected -X- _ O
a -X- _ O
base -X- _ O
model -X- _ O
that -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
with -X- _ O
word- -X- _ O
and -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
. -X- _ O

6 -X- _ O
Results -X- _ O
Our -X- _ O
main -X- _ O
ﬁnding -X- _ O
is -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
enhanced -X- _ O
with -X- _ O
gaze -X- _ O
features -X- _ O
consistently -X- _ O
outperform -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O

As -X- _ O
our -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
and -X- _ O
evaluated -X- _ O
the -X- _ O
original -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
neural -X- _ O
architecture -X- _ O
and -X- _ O
parameters -X- _ O
proposed -X- _ O
by -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
GECO -X- _ B-DatasetName
, -X- _ O
Dundee -X- _ B-DatasetName
, -X- _ O
and -X- _ O
ZuCo -X- _ B-DatasetName
corpora -X- _ O

and -X- _ O
compared -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
models -X- _ O
that -X- _ O
were -X- _ O
enriched -X- _ O
with -X- _ O
eyetracking -X- _ O
measures -X- _ O
. -X- _ O

The -X- _ O
best -X- _ O
improvements -X- _ O
on -X- _ O
F -X- _ B-MetricName
1score -X- _ I-MetricName
over -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
are -X- _ O
signiﬁcant -X- _ O
under -X- _ O
one -X- _ O
- -X- _ O
sided -X- _ O
t -X- _ O
- -X- _ O
tests -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0.05 -X- _ O
) -X- _ O
. -X- _ O

All -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
with -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
validation -X- _ O
( -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
training -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
development -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
test -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
) -X- _ O
and -X- _ O
early -X- _ O
stopping -X- _ O
was -X- _ O
performed -X- _ O
after -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
of -X- _ O
no -X- _ O
improvement -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
to -X- _ O
reduce -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
individual -X- _ O
datasets -X- _ O
is -X- _ O
tested -X- _ O
, -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
one -X- _ O
combined -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
all -X- _ O
three -X- _ O
corpora -X- _ O
( -X- _ O
consisting -X- _ O
of -X- _ O
142,441 -X- _ O
tokens -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
weevaluate -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
using -X- _ O
individual -X- _ O
type -X- _ O
lexicons -X- _ O
for -X- _ O
each -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
combining -X- _ O
the -X- _ O
three -X- _ O
type -X- _ O
lexicons -X- _ O
of -X- _ O
each -X- _ O
corpus -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
cross -X- _ O
- -X- _ O
corpus -X- _ O
scenarios -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
in -X- _ O
NER -X- _ B-TaskName
for -X- _ O
domain -X- _ O
adaptation -X- _ O
. -X- _ O

Both -X- _ O
settings -X- _ O
were -X- _ O
also -X- _ O
tested -X- _ O
on -X- _ O
an -X- _ O
external -X- _ O
corpus -X- _ O
without -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
, -X- _ O
namely -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O

6.1 -X- _ O
Individual -X- _ O
dataset -X- _ O
evaluation -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
analyzed -X- _ O
how -X- _ O
augmenting -X- _ O
the -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
system -X- _ O
with -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
affects -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
individual -X- _ O
datasets -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
improvements -X- _ O
achieved -X- _ O
by -X- _ O
adding -X- _ O
all -X- _ O
17 -X- _ O
gaze -X- _ O
features -X- _ O
to -X- _ O
the -X- _ O
neural -X- _ O
architecture -X- _ O
, -X- _ O
and -X- _ O
training -X- _ O
models -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
corpora -X- _ O
, -X- _ O
and -X- _ O
on -X- _ O
the -X- _ O
combined -X- _ O
dataset -X- _ O
containing -X- _ O
allsentences -X- _ O
from -X- _ O
the -X- _ O
Dundee -X- _ B-DatasetName
, -X- _ O
GECO -X- _ B-DatasetName
and -X- _ O
ZuCo -X- _ B-DatasetName
corpora -X- _ O
. -X- _ O

Noticeably -X- _ O
, -X- _ O
adding -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
gaze -X- _ O
features -X- _ O
improves -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
individually -X- _ O
and -X- _ O
combined -X- _ O
, -X- _ O
even -X- _ O
on -X- _ O
the -X- _ O
GECO -X- _ B-DatasetName
corpus -X- _ O
, -X- _ O
which -X- _ O
yields -X- _ O
a -X- _ O
high -X- _ O
baseline -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
homogeneity -X- _ O
of -X- _ O
the -X- _ O
contained -X- _ O
named -X- _ O
entities -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
Table -X- _ O
4 -X- _ O
also -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
making -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
typeaggregated -X- _ O
features -X- _ O
instead -X- _ O
of -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
gaze -X- _ O
features -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
different -X- _ O
experiments -X- _ O
for -X- _ O
these -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
: -X- _ O
Using -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
types -X- _ O
occurring -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
only -X- _ O
, -X- _ O
or -X- _ O
using -X- _ O
the -X- _ O
aggregated -X- _ O
features -X- _ O
of -X- _ O
all -X- _ O
word -X- _ O
types -X- _ O
in -X- _ O
the -X- _ O
three -X- _ O
corpora -X- _ O
( -X- _ O
as -X- _ O
describe -X- _ O
above -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
gaze -X- _ O
fea- -X- _ O

Dundee -X- _ O
Geco -X- _ O
ZuCo -X- _ O
All -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
P -X- _ B-MetricName
) -X- _ O
, -X- _ O
recall -X- _ B-MetricName
( -X- _ O
R -X- _ B-MetricName
) -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
F -X- _ B-MetricName
) -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
individual -X- _ O
datasets -X- _ O
( -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
bold -X- _ O
; -X- _ O
* -X- _ O
indicates -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
on -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
) -X- _ O
. -X- _ O

With -X- _ O
gaze -X- _ O
are -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
on -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
type -X- _ O
individual -X- _ O
are -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
gaze -X- _ O
features -X- _ O
of -X- _ O
this -X- _ O
corpus -X- _ O
only -X- _ O
, -X- _ O
while -X- _ O
type -X- _ O
combined -X- _ O
are -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
computed -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

ture -X- _ O
levels -X- _ O
varies -X- _ O
between -X- _ O
datasets -X- _ O
, -X- _ O
but -X- _ O
both -X- _ O
the -X- _ O
original -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
individual -X- _ O
and -X- _ O
combined -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
achieve -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
baselines -X- _ O
of -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

To -X- _ O
sum -X- _ O
up -X- _ O
, -X- _ O
the -X- _ O
largest -X- _ O
improvement -X- _ O
with -X- _ O
eyetracking -X- _ O
features -X- _ O
is -X- _ O
achieved -X- _ O
when -X- _ O
combining -X- _ O
all -X- _ O
corpora -X- _ O
into -X- _ O
one -X- _ O
larger -X- _ O
dataset -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
additional -X- _ O
4 -X- _ B-MetricValue
% -X- _ I-MetricValue
is -X- _ O
gained -X- _ O
in -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
by -X- _ O
using -X- _ O
typeaggregated -X- _ O
features -X- _ O
. -X- _ O

Evidently -X- _ O
, -X- _ O
a -X- _ O
larger -X- _ O
mixeddomain -X- _ O
dataset -X- _ O
beneﬁts -X- _ O
from -X- _ O
the -X- _ O
type -X- _ O
aggregation -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
original -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
gaze -X- _ O
features -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
individual -X- _ O
datasets -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
additional -X- _ O
gain -X- _ O
when -X- _ O
training -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
higher -X- _ O
signal -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
noise -X- _ O
ratio -X- _ O
of -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
from -X- _ O
multiple -X- _ O
datasets -X- _ O
. -X- _ O

Evaluation -X- _ O
on -X- _ O
CoNLL-2003 -X- _ B-DatasetName
Going -X- _ O
on -X- _ O
step -X- _ O
further -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
gaze -X- _ O
features -X- _ O
on -X- _ O
an -X- _ O
external -X- _ O
corpus -X- _ O
with -X- _ O
no -X- _ O
eye -X- _ O
movement -X- _ O
information -X- _ O
available -X- _ O
. -X- _ O

The -X- _ O
CoNLL-2003 -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
has -X- _ O
beenCoNLL-2003 -X- _ B-DatasetName
P -X- _ B-MetricName
R -X- _ B-MetricName
F -X- _ B-MetricName
Table -X- _ O
5 -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
P -X- _ B-MetricName
) -X- _ O
, -X- _ O
recall -X- _ B-MetricName
( -X- _ O
R -X- _ B-MetricName
) -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
F -X- _ B-MetricName
) -X- _ O
for -X- _ O
using -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
gaze -X- _ O
features -X- _ O
on -X- _ O
the -X- _ O
CoNLL2003 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
* -X- _ O
marks -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
improvement -X- _ O
) -X- _ O
. -X- _ O

widely -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
benchmark -X- _ O
dataset -X- _ O
for -X- _ O
NER -X- _ B-TaskName
in -X- _ O
different -X- _ O
shared -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
English -X- _ O
part -X- _ O
of -X- _ O
this -X- _ O
corpus -X- _ O
consists -X- _ O
of -X- _ O
Reuters -X- _ O
news -X- _ O
stories -X- _ O
and -X- _ O
contains -X- _ O
302,811 -X- _ O
tokens -X- _ O
in -X- _ O
22,137 -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
this -X- _ O
dataset -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
corpus -X- _ O
without -X- _ O
gaze -X- _ O
information -X- _ O
. -X- _ O

Only -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
( -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
combined -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
corpora -X- _ O
) -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
each -X- _ O
word -X- _ O
. -X- _ O

Merely -X- _ O
76 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
corpus -X- _ O
also -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
eyetracking -X- _ O
corpora -X- _ O
described -X- _ O
above -X- _ O
and -X- _ O
thus -X- _ O
receive -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
without -X- _ O
aggregated -X- _ O
gaze -X- _ O
information -X- _ O
available -X- _ O
receive -X- _ O
a -X- _ O
placeholder -X- _ O
for -X- _ O
the -X- _ O
unknown -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
to -X- _ O
avoid -X- _ O
overﬁtting -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
train -X- _ O
on -X- _ O
the -X- _ O
ofﬁcial -X- _ O
train -X- _ O
/ -X- _ O
test -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
but -X- _ O
perform -X- _ O
10 -X- _ B-HyperparameterValue
- -X- _ O
fold -X- _ O
cross -X- _ B-HyperparameterName
validation -X- _ I-HyperparameterName
. -X- _ O

Applying -X- _ O
the -X- _ O
same -X- _ O
experiment -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
augmented -X- _ O
NER -X- _ B-TaskName
model -X- _ O
with -X- _ O
gaze -X- _ O
features -X- _ O
on -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
data -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
to -X- _ O
a -X- _ O
baseline -X- _ O
model -X- _ O
without -X- _ O
any -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
. -X- _ O

We -X- _ O
achieve -X- _ O
a -X- _ O
minor -X- _ O
, -X- _ O
but -X- _ O
nonetheless -X- _ O
signiﬁcant -X- _ O
improvement -X- _ O
( -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
strongly -X- _ O
supports -X- _ O
the -X- _ O
generalizability -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
typeaggregated -X- _ O
features -X- _ O
on -X- _ O
unseen -X- _ O
data -X- _ O
. -X- _ O

6.2 -X- _ O
Cross -X- _ O
- -X- _ O
dataset -X- _ O
evaluation -X- _ O
In -X- _ O
a -X- _ O
second -X- _ O
evaluation -X- _ O
scenario -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
for -X- _ O
NER -X- _ B-TaskName
across -X- _ O
corpora -X- _ O
. -X- _ O

The -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
leverage -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
for -X- _ O
domain -X- _ O
adaptation -X- _ O
. -X- _ O

To -X- _ O
show -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
across -X- _ O
domains -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
features -X- _ O
on -X- _ O
100 -X- _ O
% -X- _ O
of -X- _ O
corpus -X- _ O
A -X- _ O
and -X- _ O
a -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
corpus -X- _ O
B -X- _ O
and -X- _ O
test -X- _ O
on -X- _ O
the -X- _ O
remaining -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
corpus -X- _ O
B -X- _ O
, -X- _ O
alternating -X- _ O
only -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
each -X- _ O
fold -X- _ O
. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
cross -X- _ O
- -X- _ O
corpus -X- _ O
evaluation -X- _ O
. -X- _ O

The -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
varies -X- _ O
between -X- _ O
the -X- _ O
different -X- _ O
combinations -X- _ O
of -X- _ O
datasets -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
inclusion -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
improves -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
combinations -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
ZuCo -X- _ B-DatasetName
corpus -X- _ O

P -X- _ O
R -X- _ O
F -X- _ O
P -X- _ O
R -X- _ O
F -X- _ O
P -X- _ O
R -X- _ O
F -X- _ O
Table -X- _ O
6 -X- _ O
: -X- _ O
Cross -X- _ O
- -X- _ O
corpus -X- _ O
results -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
P -X- _ B-MetricName
) -X- _ O
, -X- _ O
recall -X- _ B-MetricName
( -X- _ O
R -X- _ B-MetricName
) -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
F -X- _ B-MetricName
) -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
one -X- _ O
dataset -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
another -X- _ O
( -X- _ O
rows -X- _ O
= -X- _ O
training -X- _ O
dataset -X- _ O
; -X- _ O
columns -X- _ O
= -X- _ O
test -X- _ O
dataset -X- _ O
; -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
bold -X- _ O
; -X- _ O
* -X- _ O
indicates -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
baseline -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
without -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
, -X- _ O
token -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
type -X- _ O
are -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
computed -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
GECO -X- _ B-DatasetName
corpus -X- _ O
. -X- _ O

Presumably -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
training -X- _ O
data -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
ZuCo -X- _ B-DatasetName
corpus -X- _ O
and -X- _ O
the -X- _ O
homogeneity -X- _ O
of -X- _ O
the -X- _ O
named -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
GECO -X- _ B-DatasetName
corpus -X- _ O
. -X- _ O

CoNLL-2003 -X- _ O
P -X- _ O
R -X- _ O
F -X- _ O
Table -X- _ O
7 -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
P -X- _ B-MetricName
) -X- _ O
, -X- _ O
recall -X- _ B-MetricName
( -X- _ O
R -X- _ B-MetricName
) -X- _ O
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
F -X- _ B-MetricName
) -X- _ O
for -X- _ O
using -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
gaze -X- _ O
features -X- _ O
trained -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
datasets -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
* -X- _ O
marks -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
improvement -X- _ O
) -X- _ O
. -X- _ O

Evaluation -X- _ O
on -X- _ O
CoNLL-2003 -X- _ B-DatasetName
Analogous -X- _ O
to -X- _ O
the -X- _ O
individual -X- _ O
dataset -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
test -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
in -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
dataset -X- _ O
scenario -X- _ O
on -X- _ O
an -X- _ O
external -X- _ O
benchmark -X- _ O
dataset -X- _ O
. -X- _ O

Again -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
corpus -X- _ O
for -X- _ O
this -X- _ O
purpose -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Dundee -X- _ B-DatasetName
, -X- _ O
GECO -X- _ B-DatasetName
andZuCo -X- _ B-DatasetName
corpora -X- _ O
using -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
and -X- _ O
test -X- _ O
this -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
ConLL-2003 -X- _ B-DatasetName
data -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
shows -X- _ O
that -X- _ O
compared -X- _ O
to -X- _ O
a -X- _ O
baseline -X- _ O
without -X- _ O
gaze -X- _ O
features -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
improve -X- _ O
by -X- _ O
3 -X- _ B-MetricValue
% -X- _ I-MetricValue
F -X- _ B-MetricName
1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
. -X- _ O

These -X- _ O
results -X- _ O
underpin -X- _ O
our -X- _ O
hypothesis -X- _ O
of -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
generalizing -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
features -X- _ O
on -X- _ O
word -X- _ O
type -X- _ O
level -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
no -X- _ O
recorded -X- _ O
gaze -X- _ O
data -X- _ O
is -X- _ O
required -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

7 -X- _ O
Discussion -X- _ O
The -X- _ O
models -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
show -X- _ O
that -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
contain -X- _ O
valuable -X- _ O
semantic -X- _ O
information -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
leveraged -X- _ O
effectively -X- _ O
by -X- _ O
NER -X- _ B-TaskName
systems -X- _ O
. -X- _ O

While -X- _ O
the -X- _ O
individual -X- _ O
datasets -X- _ O
are -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Results -X- _ O
per -X- _ O
class -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
all -X- _ O
gaze -X- _ O
datasets -X- _ O
combined -X- _ O
. -X- _ O

still -X- _ O
limited -X- _ O
in -X- _ O
size -X- _ O
, -X- _ O
the -X- _ O
largest -X- _ O
improvement -X- _ O
is -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
making -X- _ O
use -X- _ O
of -X- _ O
allthe -X- _ O
available -X- _ O
data -X- _ O
. -X- _ O

At -X- _ O
a -X- _ O
closer -X- _ O
look -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
leveraging -X- _ O
gaze -X- _ O
data -X- _ O
yield -X- _ O
a -X- _ O
considerably -X- _ O
higher -X- _ O
increase -X- _ O
in -X- _ O
recall -X- _ O
when -X- _ O
comparing -X- _ O
to -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
a -X- _ O
classwise -X- _ O
analysis -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
entity -X- _ O
type -X- _ O
beneﬁting -X- _ O
the -X- _ O
most -X- _ O
from -X- _ O
the -X- _ O
gaze -X- _ O
features -X- _ O
over -X- _ O
all -X- _ O
models -X- _ O
is -X- _ O
ORGANIZATION -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
difﬁcult -X- _ O
class -X- _ O
to -X- _ O
predict -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
this -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
per -X- _ O
class -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
gaze -X- _ O
corpora -X- _ O
jointly -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
individual -X- _ O
dataset -X- _ O
evaluation -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
combined -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
feature -X- _ O
aggregation -X- _ O
from -X- _ O
all -X- _ O
datasets -X- _ O
does -X- _ O
not -X- _ O
yield -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
, -X- _ O
since -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
these -X- _ O
corpora -X- _ O
already -X- _ O
has -X- _ O
accurate -X- _ O
eyetracking -X- _ O
features -X- _ O
on -X- _ O
toke -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
under- -X- _ O

9standable -X- _ O
that -X- _ O
in -X- _ O
this -X- _ O
scenario -X- _ O
the -X- _ O
original -X- _ O
gaze -X- _ O
features -X- _ O
and -X- _ O
the -X- _ O
gaze -X- _ O
features -X- _ O
aggregated -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
individual -X- _ O
datasets -X- _ O
result -X- _ O
in -X- _ O
better -X- _ O
models -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
when -X- _ O
evaluating -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
in -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
corpus -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
lead -X- _ O
to -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
. -X- _ O

Type -X- _ O
aggregation -X- _ O
evidently -X- _ O
reduces -X- _ O
the -X- _ O
ﬁnegrained -X- _ O
nuances -X- _ O
contained -X- _ O
in -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
information -X- _ O
and -X- _ O
eliminates -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
disambiguation -X- _ O
between -X- _ O
homographic -X- _ O
tokens -X- _ O
. -X- _ O

Nevertheless -X- _ O
, -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
disambiguation -X- _ O
is -X- _ O
not -X- _ O
crucial -X- _ O
for -X- _ O
named -X- _ O
entities -X- _ O
, -X- _ O
which -X- _ O
mainly -X- _ O
consist -X- _ O
of -X- _ O
proper -X- _ O
nouns -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
entities -X- _ O
tend -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
context -X- _ O
. -X- _ O

Especially -X- _ O
noteworthy -X- _ O
is -X- _ O
the -X- _ O
gain -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
benchmark -X- _ O
corpus -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
that -X- _ O
aggregated -X- _ O
eyetracking -X- _ O
features -X- _ O
from -X- _ O
other -X- _ O
datasets -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
unseen -X- _ O
sentence -X- _ O
and -X- _ O
show -X- _ O
improvements -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
more -X- _ O
than -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
have -X- _ O
unknown -X- _ O
gaze -X- _ O
feature -X- _ O
values -X- _ O
. -X- _ O

While -X- _ O
the -X- _ O
high -X- _ O
number -X- _ O
of -X- _ O
unknown -X- _ O
values -X- _ O
is -X- _ O
certainly -X- _ O
a -X- _ O
limitation -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
it -X- _ O
shows -X- _ O
at -X- _ O
once -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
not -X- _ O
requiring -X- _ O
original -X- _ O
gaze -X- _ O
features -X- _ O
at -X- _ O
prediction -X- _ O
time -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
the -X- _ O
trained -X- _ O
NER -X- _ B-TaskName
models -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
robustly -X- _ O
on -X- _ O
unseen -X- _ O
data -X- _ O
. -X- _ O

8 -X- _ O
Conclusion -X- _ O
We -X- _ O
presented -X- _ O
the -X- _ O
ﬁrst -X- _ O
study -X- _ O
of -X- _ O
augmenting -X- _ O
a -X- _ O
NER -X- _ B-TaskName
system -X- _ O
with -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
information -X- _ O
. -X- _ O

Our -X- _ O
results -X- _ O
highlight -X- _ O
the -X- _ O
beneﬁts -X- _ O
of -X- _ O
leveraging -X- _ O
cognitive -X- _ O
cues -X- _ O
such -X- _ O
as -X- _ O
eye -X- _ O
movements -X- _ O
to -X- _ O
improve -X- _ O
entity -X- _ O
recognition -X- _ O
models -X- _ O
. -X- _ O

The -X- _ O
manually -X- _ O
annotated -X- _ O
named -X- _ O
entity -X- _ O
labels -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
corpora -X- _ O
are -X- _ O
freely -X- _ O
available -X- _ O
. -X- _ O

We -X- _ O
augmented -X- _ O
a -X- _ O
neural -X- _ O
NER -X- _ B-TaskName
architecture -X- _ O
with -X- _ O
gaze -X- _ O
features -X- _ O
. -X- _ O

Experiments -X- _ O
were -X- _ O
performed -X- _ O
using -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
features -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
human -X- _ O
reading -X- _ O
process -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
show -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
for -X- _ O
all -X- _ O
corpora -X- _ O
individually -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
gaze -X- _ O
features -X- _ O
are -X- _ O
effective -X- _ O
in -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
, -X- _ O
even -X- _ O
on -X- _ O
an -X- _ O
external -X- _ O
benchmark -X- _ O
corpus -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
these -X- _ O
type -X- _ O
- -X- _ O
aggregated -X- _ O
features -X- _ O
are -X- _ O
a -X- _ O
step -X- _ O
towards -X- _ O
leveraging -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
for -X- _ O
information -X- _ O
extraction -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
, -X- _ O
without -X- _ O
requiring -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
recorded -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
at -X- _ O
prediction -X- _ O
time -X- _ O
. -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
2022 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
12 -X- _ O
- -X- _ O
37 -X- _ O
July -X- _ O
10 -X- _ O
- -X- _ O
15 -X- _ O
, -X- _ O
2022 -X- _ O
© -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Learning -X- _ O
Natural -X- _ O
Language -X- _ O
Generation -X- _ O
with -X- _ O
Truncated -X- _ O
Reinforcement -X- _ O
Learning -X- _ O
Alice -X- _ O
Martin -X- _ O
Samovar -X- _ O
, -X- _ O
Télécom -X- _ O
SudParis -X- _ O
, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris -X- _ O
, -X- _ O
Palaiseau -X- _ O
CMAP -X- _ O
, -X- _ O
École -X- _ O
Polytechnique -X- _ O
, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris -X- _ O
, -X- _ O
Palaiseau -X- _ O
Guillaume -X- _ O
Quispe -X- _ O

andCharles -X- _ O
Ollion -X- _ O
CMAP -X- _ O
, -X- _ O
École -X- _ O
Polytechnique -X- _ O
, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris -X- _ O
, -X- _ O
Palaiseau -X- _ O
Sylvain -X- _ O
Le -X- _ O
Corff -X- _ O
Samovar -X- _ O
, -X- _ O
Télécom -X- _ O
SudParis -X- _ O
, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris -X- _ O
, -X- _ O

Palaiseau -X- _ O
Florian -X- _ O
Strub -X- _ O
Deep -X- _ O
MindOlivier -X- _ O
Pietquin -X- _ O
Google -X- _ O
Brain -X- _ O
Abstract -X- _ O
This -X- _ O
paper -X- _ O
introduces -X- _ O
TRUncated -X- _ B-MethodName
ReinForcement -X- _ I-MethodName
Learning -X- _ I-MethodName
for -X- _ I-MethodName
Language -X- _ I-MethodName
( -X- _ O
TrufLL -X- _ B-MethodName
) -X- _ O
, -X- _ O
an -X- _ O
original -X- _ O
approach -X- _ O
to -X- _ O
train -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
learning -X- _ O
phase -X- _ O
, -X- _ O
by -X- _ O
only -X- _ O
using -X- _ O
reinforcement -X- _ O
learning -X- _ O
( -X- _ O
RL -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
RL -X- _ O
methods -X- _ O
unsuccessfully -X- _ O
scale -X- _ O
to -X- _ O
large -X- _ O
action -X- _ O
spaces -X- _ O
, -X- _ O
we -X- _ O
dynamically -X- _ O
truncate -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
using -X- _ O
a -X- _ O
generic -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

TrufLL -X- _ B-MethodName
thus -X- _ O
enables -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
language -X- _ O
agent -X- _ O
by -X- _ O
solely -X- _ O
interacting -X- _ O
with -X- _ O
its -X- _ O
environment -X- _ O
without -X- _ O
any -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
prior -X- _ O
knowledge -X- _ O
; -X- _ O
it -X- _ O
is -X- _ O
only -X- _ O
guided -X- _ O
with -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
avoids -X- _ O
the -X- _ O
dependency -X- _ O
to -X- _ O
labelled -X- _ O
datasets -X- _ O
and -X- _ O
inherently -X- _ O
reduces -X- _ O
pretrained -X- _ O
policy -X- _ O
flaws -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
or -X- _ O
exposure -X- _ O
biases -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
TrufLL -X- _ B-MethodName
on -X- _ O
two -X- _ O
visual -X- _ B-TaskName
question -X- _ I-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
report -X- _ O
positive -X- _ O
results -X- _ O
over -X- _ O
performance -X- _ O
and -X- _ O
language -X- _ O
metrics -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
then -X- _ O
corroborate -X- _ O
with -X- _ O
a -X- _ O
human -X- _ O
evaluation -X- _ O
. -X- _ O

To -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
approach -X- _ O
that -X- _ O
successfully -X- _ O
learns -X- _ O
a -X- _ O
language -X- _ O
generation -X- _ O
policy -X- _ O
without -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
reinforcement -X- _ O
learning.1 -X- _ O
1 -X- _ O
Introduction -X- _ O
Since -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
generic -X- _ O
language -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
massive -X- _ O
unlabelled -X- _ O
text -X- _ O
corpora -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
art -X- _ O
language -X- _ O
processing -X- _ O
systems -X- _ O
rely -X- _ O
on -X- _ O
sequential -X- _ O
transfer -X- _ O
learning -X- _ O
( -X- _ O
Ruder -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
pretrained -X- _ O
Language -X- _ O
Model -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
supervised -X- _ O
learning -X- _ O
( -X- _ O
SL -X- _ O
) -X- _ O
AMDonati -X- _ O
/ -X- _ O
RL -X- _ O
- -X- _ O
NLP -X- _ O
Agent -X- _ O
VQA -X- _ O
modelboycar -X- _ O
tallthe -X- _ O

Truncationrun -X- _ O
Language -X- _ O

ModelWhat -X- _ O
is -X- _ O
the -X- _ O
tall -X- _ O
boy -X- _ O
holding -X- _ O
? -X- _ O

What -X- _ O
is -X- _ O
the -X- _ O
... -X- _ O
Bat -X- _ O
Batr=1Agent -X- _ O
Truncation -X- _ O
with -X- _ O
LM -X- _ O
BatFigure -X- _ O
1 -X- _ O
: -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O

In -X- _ O
a -X- _ O
conditional -X- _ O
language -X- _ O
generation -X- _ O
task -X- _ O
as -X- _ O
VQG -X- _ B-TaskName
, -X- _ O
TrufLL -X- _ B-MethodName
truncates -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
’ -X- _ O
run -X- _ O
, -X- _ O
’ -X- _ O
and -X- _ O
’ -X- _ O
the -X- _ O
’ -X- _ O
are -X- _ O
syntactically -X- _ O
incorrect -X- _ O
and -X- _ O
thus -X- _ O
truncated -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
’ -X- _ O
car -X- _ O
’ -X- _ O
is -X- _ O
not -X- _ O
trimmed -X- _ O
as -X- _ O
the -X- _ O
LM -X- _ O
is -X- _ O
not -X- _ O
visually -X- _ O
grounded -X- _ O
. -X- _ O

( -X- _ O
right -X- _ O
) -X- _ O

In -X- _ O
a -X- _ O
VQG -X- _ B-TaskName
training -X- _ O
loop -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
generates -X- _ O
a -X- _ O
question -X- _ O
given -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
then -X- _ O
fed -X- _ O
to -X- _ O
a -X- _ O
VQA -X- _ O
model -X- _ O
predicting -X- _ O
an -X- _ O
expected -X- _ O
answer -X- _ O
. -X- _ O

If -X- _ O
both -X- _ O
answers -X- _ O
match -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
rewarded -X- _ O
. -X- _ O

objective -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
such -X- _ O
an -X- _ O
approach -X- _ O
suffers -X- _ O
from -X- _ O
several -X- _ O
issues -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
when -X- _ O
a -X- _ O
model -X- _ O
forgets -X- _ O
previously -X- _ O
learned -X- _ O
knowledge -X- _ O
and -X- _ O
overfits -X- _ O
to -X- _ O
target -X- _ O
domains -X- _ O
, -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
computational -X- _ O
inefficiency -X- _ O
from -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
billion -X- _ O
- -X- _ O
parameters -X- _ O
networks -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
supervised -X- _ O
datasets -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
language -X- _ O
models -X- _ O
learned -X- _ O
with -X- _ O
SL -X- _ O
suffer -X- _ O
from -X- _ O
well -X- _ O
- -X- _ O
studied -X- _ O
text -X- _ O
degeneration -X- _ O
issues -X- _ O
( -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
exposure -X- _ O
bias -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
language -X- _ O
biases -X- _ O
( -X- _ O
Saleh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jaques -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
diversity -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
text -X- _ O
generation -X- _ O
can -X- _ O
be -X- _ O
naturally -X- _ O
framed -X- _ O
as -X- _ O
a -X- _ O
sequential -X- _ O
decision -X- _ O
making -X- _ O
problem -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
seen -X- _ O
as -X- _ O
successive -X- _ O
actions -X- _ O
over -X- _ O
a -X- _ O
vocabulary -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
some -X- _ O
researchers -X- _ O
have -X- _ O
recently -X- _ O
focused -X- _ O
on -X- _ O
learning -X- _ O
language -X- _ O
models -X- _ O
using -X- _ O
instead12 -X- _ O

Reinforcement -X- _ O
Learning -X- _ O
( -X- _ O
RL -X- _ O
) -X- _ O
( -X- _ O
Strub -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

RL -X- _ O
methods -X- _ O
allow -X- _ O
acquiring -X- _ O
language -X- _ O
through -X- _ O
interactions -X- _ O
within -X- _ O
rich -X- _ O
and -X- _ O
diverse -X- _ O
environments -X- _ O
( -X- _ O
Luketina -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
help -X- _ O
understanding -X- _ O
language -X- _ O
acquisition -X- _ O
and -X- _ O
language -X- _ O
pragmatics -X- _ O
( -X- _ O
Lazaridou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Bisk -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

" -X- _ O
Reward -X- _ O
is -X- _ O
enough -X- _ O
" -X- _ O
( -X- _ O
Silver -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
highlights -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
using -X- _ O
RL -X- _ O
for -X- _ O
AI -X- _ O
systems -X- _ O
to -X- _ O
acquire -X- _ O
language -X- _ O
in -X- _ O
its -X- _ O
full -X- _ O
richness -X- _ O
. -X- _ O

Indeed -X- _ O
, -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
language -X- _ O
may -X- _ O
be -X- _ O
intertwined -X- _ O
with -X- _ O
other -X- _ O
modalities -X- _ O
of -X- _ O
action -X- _ O
and -X- _ O
observation -X- _ O
, -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
language -X- _ O
varies -X- _ O
according -X- _ O
to -X- _ O
situations -X- _ O
and -X- _ O
behaviours -X- _ O
, -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
it -X- _ O
is -X- _ O
consequential -X- _ O
and -X- _ O
purposeful -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
some -X- _ O
linguistic -X- _ O
problems -X- _ O
are -X- _ O
better -X- _ O
solved -X- _ O
dynamically -X- _ O
, -X- _ O
through -X- _ O
experience -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
using -X- _ O
a -X- _ O
diplomatic -X- _ O
tone -X- _ O
in -X- _ O
a -X- _ O
speech -X- _ O
. -X- _ O
) -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
RL -X- _ O
allows -X- _ O
optimizing -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
differentiable -X- _ O
learning -X- _ O
signal -X- _ O
, -X- _ O
hence -X- _ O
handles -X- _ O
more -X- _ O
diverse -X- _ O
objective -X- _ O
functions -X- _ O
, -X- _ O
and -X- _ O
also -X- _ O
avoids -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
degeneration -X- _ O
issues -X- _ O
previously -X- _ O
mentioned -X- _ O
. -X- _ O

So -X- _ O
far -X- _ O
, -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
text -X- _ O
- -X- _ O
generation -X- _ O
tasks -X- _ O
have -X- _ O
relied -X- _ O
on -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
to -X- _ O
ease -X- _ O
learning -X- _ O
: -X- _ O
the -X- _ O
policy -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
SL -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
dataset -X- _ O
, -X- _ O
before -X- _ O
being -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
policy -X- _ O
gradient -X- _ O
methods -X- _ O
( -X- _ O
Sutton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
hand -X- _ O
. -X- _ O

Those -X- _ O
approaches -X- _ O
often -X- _ O
require -X- _ O
human -X- _ O
- -X- _ O
labelled -X- _ O
datasets -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
combining -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
phases -X- _ O
either -X- _ O
barely -X- _ O
change -X- _ O
the -X- _ O
policy -X- _ O
distribution -X- _ O
, -X- _ O
or -X- _ O
induces -X- _ O
language -X- _ O
drift -X- _ O
( -X- _ O
Lazaridou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O

i.e -X- _ O
the -X- _ O
generated -X- _ O
language -X- _ O
drifts -X- _ O
semantically -X- _ O
or -X- _ O
syntactically -X- _ O
from -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
at -X- _ O
learning -X- _ O
a -X- _ O
conditional -X- _ O
language -X- _ O
model -X- _ O
using -X- _ O
RL -X- _ O
without -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
we -X- _ O
get -X- _ O
free -X- _ O
from -X- _ O
datasets -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
we -X- _ O
avoid -X- _ O
the -X- _ O
text -X- _ O
generation -X- _ O
flaws -X- _ O
induced -X- _ O
by -X- _ O
the -X- _ O
common -X- _ O
methods -X- _ O
. -X- _ O

While -X- _ O
appealing -X- _ O
, -X- _ O
such -X- _ O
an -X- _ O
approach -X- _ O
requires -X- _ O
overcoming -X- _ O
the -X- _ O
hurdle -X- _ O
of -X- _ O
the -X- _ O
combinatorial -X- _ O
language -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
a -X- _ O
vocabulary -X- _ O
usually -X- _ O
containing -X- _ O
more -X- _ O
than -X- _ O
10,000 -X- _ O
words -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
while -X- _ O
large -X- _ O
and -X- _ O
discrete -X- _ O
, -X- _ O
a -X- _ O
language -X- _ O
action -X- _ O
space -X- _ O
contains -X- _ O
a -X- _ O
specific -X- _ O
structure -X- _ O
, -X- _ O
made -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
syntactical -X- _ O
and -X- _ O
semantics -X- _ O
rules -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
language -X- _ O
. -X- _ O

TrufLL -X- _ B-MethodName
leverages -X- _ O
such -X- _ O
structure -X- _ O
to -X- _ O
drive -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
the -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
agent -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

At -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
generation -X- _ O
process -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
truncates -X- _ O
its -X- _ O
effective -X- _ O
action -X- _ O
space -X- _ O
to -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
words -X- _ O
provided -X- _ O
by -X- _ O
a -X- _ O
pretrained -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Such -X- _ O
an -X- _ O
approach -X- _ O
injects -X- _ O
a -X- _ O
generic -X- _ O
prior -X- _ O
linguistic -X- _ O
knowledge -X- _ O
into -X- _ O
the -X- _ O
RL -X- _ O
algorithm -X- _ O
, -X- _ O
is -X- _ O
usable -X- _ O
on -X- _ O
tasks -X- _ O
lacking -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
transferred -X- _ O
to -X- _ O
new -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
canbe -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
language -X- _ O
generation -X- _ O
task -X- _ O
given -X- _ O
a -X- _ O
generic -X- _ O
LM -X- _ O
and -X- _ O
a -X- _ O
reward -X- _ O
. -X- _ O

We -X- _ O
here -X- _ O
evaluate -X- _ O
it -X- _ O
on -X- _ O
two -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Generation -X- _ I-TaskName
( -X- _ O
VQG -X- _ B-TaskName
) -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
synthetic -X- _ O
CLEVR -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
natural -X- _ O
language -X- _ O
VQAv2 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Unlike -X- _ O
alternative -X- _ O
RL -X- _ O
without -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
manages -X- _ O
to -X- _ O
ask -X- _ O
meaningful -X- _ O
and -X- _ O
valid -X- _ O
questions -X- _ O
on -X- _ O
large -X- _ O
vocabularies -X- _ O
, -X- _ O
exhibiting -X- _ O
success -X- _ O
rate -X- _ O
and -X- _ O
language -X- _ O
metrics -X- _ O
close -X- _ O
to -X- _ O
pretrain -X- _ O
models -X- _ O
with -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
while -X- _ O
producing -X- _ O
more -X- _ O
original -X- _ O
language -X- _ O
. -X- _ O

2 -X- _ O
Background -X- _ O
Language -X- _ O
Generation -X- _ O
as -X- _ O
an -X- _ O
RL -X- _ O
Problem -X- _ O
. -X- _ O

We -X- _ O
cast -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
based -X- _ O
text -X- _ O
generation -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
Markov -X- _ O
Decision -X- _ O
Process -X- _ O
to -X- _ O
apply -X- _ O
RL -X- _ O
methods -X- _ O
( -X- _ O
Sutton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
agent -X- _ O
generates -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
w -X- _ O
< -X- _ O
t= -X- _ O
( -X- _ O
w0 -X- _ O
, -X- _ O
w1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
w -X- _ O
t−1 -X- _ O
) -X- _ O
drawn -X- _ O
from -X- _ O
a -X- _ O
vocabulary -X- _ O
V -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
initial -X- _ O
context -X- _ O
cassociated -X- _ O
with -X- _ O
a -X- _ O
reward -X- _ O
rt -X- _ O
. -X- _ O

Translation -X- _ O
, -X- _ O
text -X- _ O
summarization -X- _ O
or -X- _ O
image -X- _ O
captioning -X- _ O
are -X- _ O
examples -X- _ O
of -X- _ O
such -X- _ O
tasks -X- _ O
respectively -X- _ O
using -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
, -X- _ O
a -X- _ O
text -X- _ O
article -X- _ O
, -X- _ O
or -X- _ O
an -X- _ O
image -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O

During -X- _ O
this -X- _ O
process -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
may -X- _ O
be -X- _ O
rewarded -X- _ O
with -X- _ O
language -X- _ O
scores -X- _ O
( -X- _ O
Ranzato -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
human -X- _ O
preferences -X- _ O
( -X- _ O
Stiennon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
task -X- _ O
completion -X- _ O
scores -X- _ O
( -X- _ O
Strub -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
a -X- _ O
language -X- _ O
generation -X- _ O
agent -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
a -X- _ O
policy -X- _ O
πθ -X- _ O
( -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
V -X- _ O
) -X- _ O
parametrized -X- _ O
by -X- _ O
θ -X- _ O
, -X- _ O
first -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
c. -X- _ O
At -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
samples -X- _ O
a -X- _ O
new -X- _ O
word -X- _ O
wtfrom -X- _ O
its -X- _ O
policy -X- _ O
πθ -X- _ O
( -X- _ O
wt|w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
moves -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
( -X- _ O
w -X- _ O
< -X- _ O
t+1 -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
and -X- _ O
receives -X- _ O
a -X- _ O
reward -X- _ O
rt -X- _ O
= -X- _ O
r -X- _ O
( -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
wt -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
ris -X- _ O
a -X- _ O
reward -X- _ O
function -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
aims -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
that -X- _ O
maximizes -X- _ O
Eπθ -X- _ O
[ -X- _ O
/ -X- _ O
summationtextT -X- _ O
t=0rt -X- _ O
] -X- _ O
,2while -X- _ O
generating -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
w -X- _ O
< -X- _ O
T -X- _ O
, -X- _ O
where -X- _ O
Eπθis -X- _ O
the -X- _ O
expectation -X- _ O
under -X- _ O
πθ -X- _ O
, -X- _ O
andTthe -X- _ O
maximal -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
sequence -X- _ O
. -X- _ O

Policy -X- _ O
Gradient -X- _ O

This -X- _ O
optimization -X- _ O
process -X- _ O
may -X- _ O
be -X- _ O
performed -X- _ O
through -X- _ O
Policy -X- _ O
Gradient -X- _ O
( -X- _ O
PG -X- _ O
) -X- _ O
algorithms -X- _ O
( -X- _ O
Sutton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
language -X- _ O
literature -X- _ O
, -X- _ O
REINFORCE -X- _ O
( -X- _ O
Williams -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
simple -X- _ O
Monte -X- _ O
Carlo -X- _ O
approximation -X- _ O
of -X- _ O
this -X- _ O
gradient -X- _ O
( -X- _ O
Strub -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
.Yet -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
Proximal -X- _ O
Policy -X- _ O
Optimization -X- _ O
approach -X- _ O
( -X- _ O
PPO -X- _ O
) -X- _ O
( -X- _ O
Schulman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
lower -X- _ O
variance -X- _ O
and -X- _ O
better -X- _ O
convergence -X- _ O
rate -X- _ O
; -X- _ O
PPO -X- _ O
clips -X- _ O
the -X- _ O
gradient -X- _ O
estimate -X- _ O
to -X- _ O
have -X- _ O
smooth -X- _ O
policy -X- _ O
updates -X- _ O
. -X- _ O

For -X- _ O
all -X- _ O
0≤t≤T -X- _ O
, -X- _ O
letst= -X- _ O
( -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
andat -X- _ O
= -X- _ O
wtbe -X- _ O
the -X- _ O
state -X- _ O
and -X- _ O
action -X- _ O
at -X- _ O
time -X- _ O
t. -X- _ O
Policy -X- _ O
gradient -X- _ O
methods -X- _ O
γ=1and -X- _ O
omit -X- _ O
the -X- _ O
discount -X- _ O
factor -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
for -X- _ O
clarity.13 -X- _ O

minimize -X- _ O
the -X- _ O
objective -X- _ O
: -X- _ O
Lpg -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
=Eπθ -X- _ O
/ -X- _ O
bracketleftiggT -X- _ O
/ -X- _ O
summationdisplay -X- _ O
t=0logπθ -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
ˆAt -X- _ O
/ -X- _ O
bracketrightigg -X- _ O
where -X- _ O
ˆAtis -X- _ O
an -X- _ O
estimator -X- _ O
of -X- _ O
the -X- _ O
advantage -X- _ O
function -X- _ O
, -X- _ O
here -X- _ O
defined -X- _ O
as -X- _ O
ˆAt= -X- _ O
/ -X- _ O
summationtextT -X- _ O
u -X- _ O
= -X- _ O
tru−Vϕ -X- _ O
( -X- _ O
st -X- _ O
) -X- _ O
with -X- _ O
Vϕ -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
an -X- _ O
estimator -X- _ O
of -X- _ O
the -X- _ O
value -X- _ O
function -X- _ O
Vπθ -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O

= -X- _ O
Eπθ -X- _ O
[ -X- _ O
/ -X- _ O
summationtextT -X- _ O
u -X- _ O
= -X- _ O
tr -X- _ O
( -X- _ O
su -X- _ O
, -X- _ O
au -X- _ O
) -X- _ O
|st -X- _ O
= -X- _ O
s -X- _ O
] -X- _ O
. -X- _ O

PPO -X- _ O
then -X- _ O
keeps -X- _ O
track -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
policy -X- _ O
πθoldbefore -X- _ O
the -X- _ O
PG -X- _ O
update -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
: -X- _ O
Lppo -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
=Eπθold -X- _ O
/ -X- _ O
bracketleftiggT -X- _ O
/ -X- _ O
summationdisplay -X- _ O
t,1+ϵ -X- _ O
) -X- _ O
ˆAt -X- _ O
/ -X- _ O
bracketrightigg -X- _ O
where -X- _ O
for -X- _ O
all -X- _ O
real -X- _ O
numbers -X- _ O
a -X- _ O
, -X- _ O
b -X- _ O
, -X- _ O
a∧b= -X- _ O
min -X- _ O
( -X- _ O
a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
t -X- _ O
= -X- _ O
πθ -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
/ -X- _ O
πθold -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
, -X- _ O
ϵis -X- _ O
a -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
controlling -X- _ O
the -X- _ O
magnitude -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
updates -X- _ O
, -X- _ O
and -X- _ O
clip -X- _ O
( -X- _ O
a -X- _ O
, -X- _ O
x -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
function -X- _ O
that -X- _ O
clips -X- _ O
xin -X- _ O
interval -X- _ O
[ -X- _ O
a -X- _ O
, -X- _ O
b -X- _ O
] -X- _ O
. -X- _ O

The -X- _ O
expectation -X- _ O
is -X- _ O
estimated -X- _ O
in -X- _ O
practice -X- _ O
using -X- _ O
a -X- _ O
Monte -X- _ O
Carlo -X- _ O
approach -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
empirical -X- _ O
average -X- _ O
over -X- _ O
a -X- _ O
finite -X- _ O
batch -X- _ O
of -X- _ O
episodes -X- _ O
, -X- _ O
i.e -X- _ O
a -X- _ O
succession -X- _ O
of -X- _ O
transitions -X- _ O
/ -X- _ O
parenleftbig -X- _ O
st -X- _ O
, -X- _ O
at∼πθold -X- _ O
( -X- _ O
.|st -X- _ O
) -X- _ O
, -X- _ O
rt -X- _ O
/ -X- _ O
parenrightbig -X- _ O
from -X- _ O
an -X- _ O
initial -X- _ O
state -X- _ O
s0to -X- _ O
a -X- _ O
terminal -X- _ O
state -X- _ O
sT. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
loss -X- _ O
is -X- _ O
completed -X- _ O
first -X- _ O
with -X- _ O
a -X- _ O
value -X- _ O
- -X- _ O
based -X- _ O
loss -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
baseline -X- _ O
Vϕ -X- _ O
that -X- _ O
reduces -X- _ O
the -X- _ O
gradient -X- _ O
variance -X- _ O
; -X- _ O
it -X- _ O
computes -X- _ O
for -X- _ O
each -X- _ O
timestep -X- _ O
tof -X- _ O
an -X- _ O
episode -X- _ O
the -X- _ O
mean -X- _ O
squared -X- _ O
error -X- _ O
| -X- _ O
/ -X- _ O
summationtextT -X- _ O
u -X- _ O
= -X- _ O
tru−Vϕ -X- _ O
( -X- _ O
st -X- _ O
) -X- _ O
|2.3Secondly -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
is -X- _ O
completed -X- _ O
with -X- _ O
an -X- _ O
entropy -X- _ O
term -X- _ O
to -X- _ O
soften -X- _ O
the -X- _ O
policy -X- _ O
distribution -X- _ O
, -X- _ O
which -X- _ O
computes -X- _ O
for -X- _ O
each -X- _ O
timestep -X- _ O
tof -X- _ O
an -X- _ O
episode -X- _ O
H -X- _ O
( -X- _ O
πθ -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
His -X- _ O
the -X- _ O
entropy -X- _ O
function -X- _ O
. -X- _ O

3 -X- _ O

TrufLL -X- _ B-MethodName

We -X- _ O
here -X- _ O
aim -X- _ O
at -X- _ O
making -X- _ O
RL -X- _ O
methods -X- _ O
feasible -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
setting -X- _ O
by -X- _ O
dynamically -X- _ O
reducing -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
by -X- _ O
restricting -X- _ O
the -X- _ O
language -X- _ O
agent -X- _ O
to -X- _ O
select -X- _ O
a -X- _ O
word -X- _ O
within -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O

We -X- _ O
detail -X- _ O
below -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
’s -X- _ O
truncation -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
associated -X- _ O
RL -X- _ O
algorithm -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
language -X- _ O
agent -X- _ O
. -X- _ O

3.1 -X- _ O
Dynamic -X- _ O
Vocabulary -X- _ O
Truncation -X- _ O
TrufLL -X- _ B-MethodName
combines -X- _ O
two -X- _ O
distinct -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
vocabulary -X- _ O
V -X- _ O
: -X- _ O
a -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
πθand -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
fLM -X- _ O
. -X- _ O

At -X- _ O
each -X- _ O
timestep -X- _ O
t -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
restricts -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
with -X- _ O
: -X- _ O
V− -X- _ O
t= -X- _ O
{ -X- _ O
w|w∈V -X- _ O
, -X- _ O
gtrunc -X- _ O
( -X- _ O
w|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
=1 -X- _ O
} -X- _ O
, -X- _ O
1998 -X- _ O
; -X- _ O
Schulman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Espeholt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
.where -X- _ O
gtrunc -X- _ O
is -X- _ O
a -X- _ O
truncation -X- _ O
function -X- _ O
based -X- _ O
on -X- _ O
fLM -X- _ O
which -X- _ O
either -X- _ O
associates -X- _ O
0 -X- _ O
or -X- _ O
1 -X- _ O
with -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
given -X- _ O
the -X- _ O
past -X- _ O
words -X- _ O
w -X- _ O
< -X- _ O
t. -X- _ O
From -X- _ O
a -X- _ O
language -X- _ O
modelling -X- _ O
perspective -X- _ O
, -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
agent -X- _ O
is -X- _ O
reduced -X- _ O
from -X- _ O
VtoV−where -X- _ O
|V−|≪|V| -X- _ O
, -X- _ O
with|·|the -X- _ O
cardinal -X- _ O
of -X- _ O
a -X- _ O
finite -X- _ O
set -X- _ O
. -X- _ O

From -X- _ O
a -X- _ O
RL -X- _ O
perspective -X- _ O
, -X- _ O
the -X- _ O
RL -X- _ O
agent -X- _ O
follows -X- _ O
a -X- _ O
truncated -X- _ O
policyπ− -X- _ O
θwhich -X- _ O
only -X- _ O
samples -X- _ O
actions -X- _ O
over -X- _ O
the -X- _ O
subset -X- _ O
V− -X- _ O
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
such -X- _ O
a -X- _ O
policy -X- _ O
is -X- _ O
computed -X- _ O
using -X- _ O
a -X- _ O
masked -X- _ O
softmax -X- _ O
function -X- _ O
over -X- _ O
the -X- _ O
truncated -X- _ O
vocabulary -X- _ O
V− -X- _ O
t -X- _ O
: -X- _ O
θ -X- _ O
( -X- _ O
.|w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
=softmax -X- _ O
( -X- _ O
m∗logits -X- _ O
πθ -X- _ O
( -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
) -X- _ O
where -X- _ O
m=1when -X- _ O
gtrunc -X- _ O
( -X- _ O
w|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
=1 -X- _ O
otherwise -X- _ O
m=−∞. -X- _ O
3.2 -X- _ O
Truncation -X- _ O
Functions -X- _ O

We -X- _ O
here -X- _ O
list -X- _ O
the -X- _ O
different -X- _ O
truncation -X- _ O
functions -X- _ O
gtrunc -X- _ O
explored -X- _ O
through -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O

Top -X- _ O
- -X- _ O
k -X- _ O
words -X- _ O
: -X- _ O
This -X- _ O
function -X- _ O
selects -X- _ O
the -X- _ O
kwords -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
given -X- _ O
by -X- _ O
fLM -X- _ O
( -X- _ O
.|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
: -X- _ O
gtop -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
( -X- _ O
wt|w -X- _ O
< -X- _ O
t -X- _ O
; -X- _ O
k -X- _ O
) -X- _ O
=1wt∈top -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
( -X- _ O
fLM -X- _ O
( -X- _ O
.|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

Probability -X- _ O
threshold -X- _ O
( -X- _ O
α -X- _ O
) -X- _ O
: -X- _ O
This -X- _ O
function -X- _ O
only -X- _ O
keeps -X- _ O
words -X- _ O
having -X- _ O
a -X- _ O
probability -X- _ O
fLM -X- _ O
( -X- _ O
.|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
greater -X- _ O
thanα -X- _ O
: -X- _ O
Top -X- _ O
- -X- _ O
p -X- _ O
: -X- _ O

This -X- _ O
function -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
nucleus -X- _ O
sampling -X- _ O
( -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
keeps -X- _ O
the -X- _ O
most -X- _ O
likely -X- _ O
words -X- _ O
contained -X- _ O
in -X- _ O
a -X- _ O
probability -X- _ O
mass -X- _ O
pof -X- _ O
fLM -X- _ O
( -X- _ O
.|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
Vp -X- _ O
tas -X- _ O
: -X- _ O
Vp -X- _ O
t= -X- _ O
argmin -X- _ O
|Vt| -X- _ O
, -X- _ O
Vt⊂V -X- _ O
{ -X- _ O
w|w∈Vt -X- _ O
, -X- _ O
/ -X- _ O
summationdisplay -X- _ O
w∈VtfLM -X- _ O
( -X- _ O
w|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
> -X- _ O
p -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
readily -X- _ O
, -X- _ O
gtop -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
( -X- _ O
wt|w -X- _ O
< -X- _ O
t -X- _ O
; -X- _ O
p -X- _ O
) -X- _ O
=1wt∈Vp -X- _ O
t. -X- _ O
Sample -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
: -X- _ O
This -X- _ O
function -X- _ O
randomly -X- _ O
samples -X- _ O
k -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
replacement -X- _ O
to -X- _ O
directly -X- _ O
build -X- _ O
the -X- _ O
truncated -X- _ O
vocabulary -X- _ O
: -X- _ O
gsample -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
( -X- _ O
wt|w -X- _ O
< -X- _ O
t -X- _ O
; -X- _ O
k -X- _ O
) -X- _ O
=1wt∈ -X- _ O
{ -X- _ O
wi∼fLM -X- _ O
( -X- _ O
.|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
i∈ -X- _ O
/ -X- _ O
llbracket1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
k -X- _ O
/ -X- _ O
rrbracket -X- _ O
} -X- _ O
. -X- _ O

Only -X- _ O
top -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
provides -X- _ O
a -X- _ O
fixed -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O

pth -X- _ O
( -X- _ O
α -X- _ O
) -X- _ O
, -X- _ O
top -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
sample -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
have -X- _ O
a -X- _ O
dynamic -X- _ O
truncation -X- _ O
, -X- _ O
whose -X- _ O
size -X- _ O
at -X- _ O
tdepends -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
entropy -X- _ O
. -X- _ O

3.3 -X- _ O
Task -X- _ O
- -X- _ O
Specific -X- _ O
vs. -X- _ O
Generic -X- _ O
LM -X- _ O

We -X- _ O
benchmark -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
truncation -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
language -X- _ O
corpora -X- _ O
. -X- _ O

Such -X- _ O
a -X- _ O
model -X- _ O
provides -X- _ O
a -X- _ O
generic -X- _ O
linguistic -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
RL -X- _ O
agent -X- _ O
exploration -X- _ O
process -X- _ O
, -X- _ O
solely -X- _ O
encoding -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
information -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand,14 -X- _ O

we -X- _ O
use -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
language -X- _ O
model -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
supervised -X- _ O
dataset -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O

Such -X- _ O
a -X- _ O
model -X- _ O
provides -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
linguistic -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
, -X- _ O
and -X- _ O
captures -X- _ O
language -X- _ O
pragmatics -X- _ O
. -X- _ O

We -X- _ O
emphasize -X- _ O
that -X- _ O
this -X- _ O
paper -X- _ O
aims -X- _ O
at -X- _ O
leveraging -X- _ O
taskagnostic -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
they -X- _ O
discard -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
completeness -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
study -X- _ O
the -X- _ O
truncation -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
LM -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
benchmark -X- _ O
to -X- _ O
assess -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O

4 -X- _ O
Experimental -X- _ O
Setting -X- _ O
We -X- _ O
here -X- _ O
list -X- _ O
the -X- _ O
experimental -X- _ O
setting -X- _ O
and -X- _ O
detail -X- _ O
the -X- _ O
network -X- _ O
and -X- _ O
hyperparameters -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
. -X- _ O

4.1 -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Generation -X- _ I-TaskName
We -X- _ O
showcase -X- _ O
TrufLL -X- _ B-MethodName
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Generation -X- _ I-TaskName
( -X- _ O
VQG -X- _ B-TaskName
) -X- _ O
( -X- _ O
Mostafazadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
Visual -X- _ O
Jeopardy -X- _ O
! -X- _ O
™ -X- _ O
( -X- _ O
Ferrucci -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
agent -X- _ O
observes -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
and -X- _ O
has -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
question -X- _ O
that -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
answer -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

Such -X- _ O
a -X- _ O
task -X- _ O
presents -X- _ O
multiple -X- _ O
advantages -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
by -X- _ O
combining -X- _ O
vision -X- _ O
, -X- _ O
scene -X- _ O
understanding -X- _ O
and -X- _ O
language -X- _ O
generation -X- _ O
, -X- _ O
it -X- _ O
requires -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
reasoning -X- _ O
and -X- _ O
exhibits -X- _ O
a -X- _ O
large -X- _ O
spectrum -X- _ O
of -X- _ O
language -X- _ O
difficulties -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
the -X- _ O
success -X- _ O
criterion -X- _ O
is -X- _ O
naturally -X- _ O
non -X- _ O
- -X- _ O
differentiable -X- _ O
, -X- _ O
hence -X- _ O
a -X- _ O
natural -X- _ O
fit -X- _ O
for -X- _ O
RL -X- _ O
methods -X- _ O
. -X- _ O

Such -X- _ O
a -X- _ O
criterion -X- _ O
, -X- _ O
unlike -X- _ O
metrics -X- _ O
based -X- _ O
on -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
sentences -X- _ O
, -X- _ O
allows -X- _ O
generating -X- _ O
diverse -X- _ O
grounded -X- _ O
questions -X- _ O
given -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
the -X- _ O
initial -X- _ O
context -X- _ O
cis -X- _ O
composed -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
A -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
RL -X- _ O
agent -X- _ O
then -X- _ O
generates -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
w -X- _ O
< -X- _ O
tof -X- _ O
maximum -X- _ O
length -X- _ O
T. -X- _ O
We -X- _ O
then -X- _ O
provide -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
to -X- _ O
a -X- _ O
pretrained -X- _ O
VQA -X- _ O
model -X- _ O
. -X- _ O

This -X- _ O
model -X- _ O
takes -X- _ O
as -X- _ O
inputs -X- _ O
the -X- _ O
image -X- _ O
I -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
w -X- _ O
< -X- _ O
tand -X- _ O
outputs -X- _ O
a -X- _ O
predicted -X- _ O
answer -X- _ O
ˆA -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
receives -X- _ O
a -X- _ O
reward -X- _ O
r -X- _ O
( -X- _ O
wt -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
AandˆA. -X- _ O
4.2 -X- _ O
Datasets -X- _ O
We -X- _ O
evaluate -X- _ O
TrufLL -X- _ B-MethodName
on -X- _ O
the -X- _ O
CLEVR -X- _ B-DatasetName
and -X- _ O

VQAv2 -X- _ B-DatasetName
datasets -X- _ O
to -X- _ O
simulate -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
VQG -X- _ O
datasets -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
datasets -X- _ O
have -X- _ O
been -X- _ O
originally -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Visual -X- _ O
Question -X- _ O
Answering -X- _ O
( -X- _ O
VQA -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
classification -X- _ O
algorithms -X- _ O
predicting -X- _ O
an -X- _ O
answer -X- _ O
given -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
question -X- _ O
pair -X- _ O
. -X- _ O

CLEVR -X- _ B-DatasetName

The -X- _ O
CLEVR -X- _ B-DatasetName
VQA -X- _ O
dataset -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
made -X- _ O
of -X- _ O
template -X- _ O
questions -X- _ O
on -X- _ O
synthetic -X- _ O
images -X- _ O
, -X- _ O
which -X- _ O
contain -X- _ O
simple -X- _ O
objects -X- _ O
with -X- _ O
four -X- _ O
distinct -X- _ O
properties -X- _ O
( -X- _ O
shape -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
color -X- _ O
, -X- _ O
size -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
vocabulary -X- _ O
contains -X- _ O
86 -X- _ O
words -X- _ O
and -X- _ O
28 -X- _ O
potential -X- _ O
answers -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
a -X- _ O
valuable -X- _ O
proof -X- _ O
of -X- _ O
concept -X- _ O
for -X- _ O
assessingTrufLL -X- _ B-MethodName
. -X- _ O

Both -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
single -X- _ O
- -X- _ O
layer -X- _ O
LSTMs -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
with -X- _ O
512 -X- _ O
units -X- _ O
, -X- _ O
and -X- _ O
512 -X- _ O
word -X- _ O
embedding -X- _ O
dimension -X- _ O
. -X- _ O

The -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
LM -X- _ O
is -X- _ O
trained -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
train -X- _ O
dataset -X- _ O
of -X- _ O
CLEVR -X- _ B-DatasetName
questions -X- _ O
. -X- _ O

The -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
mixture -X- _ O
of -X- _ O
CLOSURE -X- _ B-DatasetName
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
CLEVR -X- _ B-DatasetName
- -X- _ I-DatasetName
Dialog -X- _ I-DatasetName
( -X- _ O
Kottur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
datasets -X- _ O
. -X- _ O

Although -X- _ O
those -X- _ O
two -X- _ O
datasets -X- _ O
share -X- _ O
the -X- _ O
CLEVR -X- _ B-DatasetName
vocabulary -X- _ O
, -X- _ O
their -X- _ O
language -X- _ O
distribution -X- _ O
differs -X- _ O
from -X- _ O
vanilla -X- _ O
CLEVR -X- _ B-DatasetName
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
pretrained -X- _ O
GT -X- _ O
- -X- _ O
V -X- _ O
ector -X- _ O
- -X- _ O
NMN -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
reward -X- _ O
r -X- _ O
( -X- _ O
wt -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
= -X- _ O
1A=ˆA -X- _ O
, -X- _ O
t -X- _ O
= -X- _ O
T−1 -X- _ O
, -X- _ O
where -X- _ O
1is -X- _ O
the -X- _ O
indicator -X- _ O
function -X- _ O
. -X- _ O

VQAv2 -X- _ B-DatasetName

The -X- _ O
VQAv2 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
made -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
open -X- _ O
- -X- _ O
formed -X- _ O
questions -X- _ O
on -X- _ O
images -X- _ O
from -X- _ O
the -X- _ O
MS -X- _ O
- -X- _ O
Coco -X- _ O
Dataset -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
has -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
14,810 -X- _ O
words -X- _ O
and -X- _ O
3,149 -X- _ O
answers -X- _ O
. -X- _ O

The -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
layer -X- _ O
LSTM -X- _ O
with -X- _ O
512 -X- _ O
units -X- _ O
and -X- _ O
a -X- _ O
512 -X- _ O
word -X- _ O
embedding -X- _ O
dimension -X- _ O
, -X- _ O
pretrained -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
training -X- _ O
dataset -X- _ O
of -X- _ O
VQAv2 -X- _ B-DatasetName
questions -X- _ O
. -X- _ O

The -X- _ O
External -X- _ O
Language -X- _ O
Model -X- _ O
is -X- _ O
Open -X- _ O
- -X- _ O
AI -X- _ O
’s -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
language -X- _ O
model -X- _ O
outputs -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
50,257tokens -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
masked -X- _ O
softmax -X- _ O
function -X- _ O
to -X- _ O
restrict -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
to -X- _ O
the -X- _ O
14,810tokens -X- _ O
of -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Unlike -X- _ O
most -X- _ O
NLP -X- _ O
tasks -X- _ O
relying -X- _ O
on -X- _ O
pretrained -X- _ O
generic -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
dataset -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
generalization -X- _ O
capabilities -X- _ O
of -X- _ O
GPT-2 -X- _ B-MethodName
, -X- _ O
by -X- _ O
feeding -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
prompt -X- _ O
" -X- _ O
Here -X- _ O
are -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
: -X- _ O
" -X- _ O
followed -X- _ O
by -X- _ O
100 -X- _ O
random -X- _ O
questions -X- _ O
q -X- _ O
< -X- _ O
100from -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O

The -X- _ O
truncation -X- _ O
is -X- _ O
then -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
fgpt2 -X- _ O
LM -X- _ O
( -X- _ O
.|q -X- _ O
< -X- _ O
100 -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
pretrained -X- _ O
VilBERT -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
reward -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
answers -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
as -X- _ O
reward -X- _ O
a -X- _ O
decreasing -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
rank -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
answer -X- _ O
further -X- _ O
explained -X- _ O
in -X- _ O
Appendix -X- _ O
A.5 -X- _ O
. -X- _ O

In -X- _ O
these -X- _ O
two -X- _ O
settings -X- _ O
, -X- _ O
we -X- _ O
acknowledge -X- _ O
that -X- _ O
the -X- _ O
task -X- _ O
dataset -X- _ O
is -X- _ O
still -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
VQA -X- _ O
models -X- _ O
. -X- _ O

Please -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
VQA -X- _ O
modules -X- _ O
are -X- _ O
only -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
environment -X- _ O
, -X- _ O
i.e. -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
positive -X- _ O
/ -X- _ O
negative -X- _ O
feedback -X- _ O
to -X- _ O
the -X- _ O
agent -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
settings -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
would -X- _ O
still -X- _ O
work -X- _ O
if -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
VQA -X- _ O
model -X- _ O
by -X- _ O
any -X- _ O
language -X- _ O
interface -X- _ O
: -X- _ O
text -X- _ O
- -X- _ O
game -X- _ O
( -X- _ O
e.g. -X- _ O
Zork -X- _ O
) -X- _ O
, -X- _ O
expert -X- _ O
- -X- _ O
systems -X- _ O
, -X- _ O
or -X- _ O
humans -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
VQG -X- _ B-TaskName
framework -X- _ O
as -X- _ O
a -X- _ O
proof -X- _ O
of -X- _ O
concept -X- _ O
that -X- _ O
natural -X- _ O
language -X- _ O
can -X- _ O
be -X- _ O
learned -X- _ O
through -X- _ O
pure -X- _ O
interaction -X- _ O
given -X- _ O
any -X- _ O
task -X- _ O
reward -X- _ O
. -X- _ O

Other -X- _ O
language -X- _ O
generation -X- _ O
applications -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
5.3.15 -X- _ O

4.3 -X- _ O
Baselines -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
i.e. -X- _ O
without -X- _ O
the -X- _ O
usual -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
by -X- _ O
solely -X- _ O
interacting -X- _ O
with -X- _ O
another -X- _ O
language -X- _ O
system -X- _ O
, -X- _ O
the -X- _ O
VQA -X- _ O
model -X- _ O
, -X- _ O
when -X- _ O
supported -X- _ O
by -X- _ O
truncation -X- _ O
methods -X- _ O
. -X- _ O

The -X- _ O
truncation -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
LM -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
one -X- _ O
with -X- _ O
the -X- _ O
External -X- _ O
LM -X- _ O
is -X- _ O
referred -X- _ O
as -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
emphasize -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
training -X- _ O
an -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
through -X- _ O
two -X- _ O
baselines -X- _ O
. -X- _ O

We -X- _ O
trained -X- _ O
a -X- _ O
simple -X- _ O
on -X- _ O
- -X- _ O
policy -X- _ O
PPO -X- _ O
algorithm -X- _ O
without -X- _ O
any -X- _ O
action -X- _ O
space -X- _ O
pruning -X- _ O
, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
scratch -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
added -X- _ O
a -X- _ O
Kullback -X- _ O
- -X- _ O
Leibler -X- _ O
( -X- _ O
KL -X- _ O
) -X- _ O
regularization -X- _ O
term -X- _ O
to -X- _ O
the -X- _ O
loss -X- _ O
, -X- _ O
λKLKL -X- _ O
( -X- _ O
πθ||fLM -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
λKL -X- _ O
> -X- _ O
0 -X- _ O
, -X- _ O
to -X- _ O
incorporate -X- _ O
language -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
agent -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Jaques -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
scratch -X- _ O
+ -X- _ O
KL -X- _ O
- -X- _ O
task -X- _ O
when -X- _ O
distilling -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
scratch -X- _ O
+ -X- _ O
KL -X- _ O
- -X- _ O
ext -X- _ O
with -X- _ O
the -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
two -X- _ O
baselines -X- _ O
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
. -X- _ O

We -X- _ O
trained -X- _ O
a -X- _ O
language -X- _ O
agent -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
dataset -X- _ O
with -X- _ O
a -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
objective -X- _ O
, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
pretrain -X- _ B-MethodName
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
agent -X- _ O
with -X- _ O
PPO -X- _ O
without -X- _ O
truncation -X- _ O
, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
. -X- _ O

These -X- _ O
two -X- _ O
baselines -X- _ O
should -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
gold -X- _ O
standards -X- _ O
as -X- _ O
they -X- _ O
rely -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
data -X- _ O
; -X- _ O
additionally -X- _ O
, -X- _ O
pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
is -X- _ O
today -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
method -X- _ O
for -X- _ O
learning -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
LM -X- _ O
. -X- _ O

4.4 -X- _ O
Metrics -X- _ O
and -X- _ O
Evaluation -X- _ O
Methods -X- _ O
Evaluating -X- _ O
text -X- _ O
generation -X- _ O
is -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
research -X- _ O
problem -X- _ O
in -X- _ O
language -X- _ O
literature -X- _ O
. -X- _ O

We -X- _ O
decompose -X- _ O
automatic -X- _ O
language -X- _ O
evaluation -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
to -X- _ O
assess -X- _ O
different -X- _ O
facets -X- _ O
of -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
a -X- _ O
human -X- _ O
evaluation -X- _ O
study -X- _ O
. -X- _ O

Performance -X- _ O
metrics -X- _ O
. -X- _ O

We -X- _ O
measure -X- _ O
the -X- _ O
taskcompletion -X- _ B-MetricName
score -X- _ I-MetricName
or -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
which -X- _ O
states -X- _ O
whether -X- _ O
the -X- _ O
target -X- _ O
answer -X- _ O
Ais -X- _ O
the -X- _ O
top -X- _ O
answer -X- _ O
of -X- _ O
the -X- _ O
VQA -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
5 -X- _ I-MetricName
( -X- _ O
R -X- _ B-MetricName
@ -X- _ I-MetricName
5 -X- _ I-MetricName
) -X- _ O
, -X- _ O
which -X- _ O
assesses -X- _ O
whether -X- _ O
Ais -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
top -X- _ O
answers -X- _ O
. -X- _ O

These -X- _ O
scores -X- _ O
measure -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
solving -X- _ O
abilities -X- _ O
of -X- _ O
the -X- _ O
agent -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
are -X- _ O
also -X- _ O
conditioned -X- _ O
by -X- _ O
the -X- _ O
VQA -X- _ O
model -X- _ O
abilities -X- _ O
. -X- _ O

Language -X- _ O
Metrics -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
metrics -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Banerjee -X- _ O
and -X- _ O
Lavie -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
and -X- _ O
CIDEr -X- _ B-MetricName
( -X- _ O
V -X- _ O
edantam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
questions -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
set -X- _ O
. -X- _ O

While -X- _ O
those -X- _ O
scores -X- _ O
can -X- _ O
capture -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
properties -X- _ O
of -X- _ O
language -X- _ O
, -X- _ O
they -X- _ O
also -X- _ O
fall -X- _ O
short -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
open -X- _ O
- -X- _ O
form -X- _ O
language -X- _ O
, -X- _ O
e.g. -X- _ O
anidentical -X- _ O
answer -X- _ O
may -X- _ O
arise -X- _ O
from -X- _ O
two -X- _ O
non -X- _ O
- -X- _ O
overlapping -X- _ O
but -X- _ O
syntactically -X- _ O
correct -X- _ O
questions -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
compute -X- _ O
two -X- _ O
metrics -X- _ O
assessing -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
independently -X- _ O
of -X- _ O
reference -X- _ O
questions -X- _ O
, -X- _ O
the -X- _ O
perplexity -X- _ B-MetricName
of -X- _ I-MetricName
the -X- _ I-MetricName
question -X- _ I-MetricName
given -X- _ I-MetricName
an -X- _ I-MetricName
external -X- _ I-MetricName
LM -X- _ I-MetricName
( -X- _ O
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
its -X- _ O
perplexity -X- _ B-MetricName
given -X- _ I-MetricName
the -X- _ I-MetricName
task -X- _ I-MetricName
- -X- _ I-MetricName
related -X- _ I-MetricName
LM -X- _ I-MetricName
( -X- _ O
ppl -X- _ B-MetricName
- -X- _ I-MetricName
t -X- _ I-MetricName
) -X- _ O
. -X- _ O

Diversity -X- _ O
Metrics -X- _ O
. -X- _ O

We -X- _ O
here -X- _ O
estimate -X- _ O
a -X- _ O
self -X- _ B-MetricName
- -X- _ I-MetricName
BLEU -X- _ I-MetricName
( -X- _ O
sBLEU -X- _ B-MetricName
) -X- _ O
score -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
over -X- _ O
10 -X- _ O
questions -X- _ O
generated -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
image -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
. -X- _ O

Although -X- _ O
such -X- _ O
score -X- _ O
detects -X- _ O
potential -X- _ O
mode -X- _ O
collapse -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
language -X- _ O
utters -X- _ O
identical -X- _ O
sequences -X- _ O
of -X- _ O
words -X- _ O
, -X- _ O
it -X- _ O
also -X- _ O
values -X- _ O
babbling -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
outputting -X- _ O
random -X- _ O
words -X- _ O
. -X- _ O

We -X- _ O
thus -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
probability -X- _ O
mass -X- _ O
of -X- _ O
the -X- _ O
ten -X- _ O
most -X- _ O
frequent -X- _ O
words -X- _ O
( -X- _ O
Choshen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
peakiness -X- _ B-MetricName
( -X- _ O
peak -X- _ B-MetricName
) -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
task -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
performed -X- _ O
human -X- _ O
evaluation -X- _ O
by -X- _ O
surveying -X- _ O
53 -X- _ O
participants -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
50 -X- _ O
questions -X- _ O
produced -X- _ O
by -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

The -X- _ O
study -X- _ O
( -X- _ O
further -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
C -X- _ O
) -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
pairwise -X- _ O
comparison -X- _ O
of -X- _ O
question -X- _ O
samples -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
concurrent -X- _ O
algorithms -X- _ O
according -X- _ O
to -X- _ O
four -X- _ O
criteria -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
the -X- _ O
language -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
samples -X- _ O
, -X- _ O
by -X- _ O
asking -X- _ O
the -X- _ O
participants -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
syntactically -X- _ O
and -X- _ O
semantically -X- _ O
correct -X- _ O
question -X- _ O
among -X- _ O
the -X- _ O
two -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
pair -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
language -X- _ O
grounding -X- _ O
, -X- _ O
i.e -X- _ O
adequacy -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
to -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
, -X- _ O
by -X- _ O
asking -X- _ O
the -X- _ O
participants -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
question -X- _ O
most -X- _ O
suitable -X- _ O
given -X- _ O
the -X- _ O
two -X- _ O
elements -X- _ O
. -X- _ O

Thirdly -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
the -X- _ O
language -X- _ O
originality -X- _ O
and -X- _ O
diversity -X- _ O
, -X- _ O
by -X- _ O
asking -X- _ O
participants -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
question -X- _ O
the -X- _ O
most -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
reference -X- _ O
question -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
syntax -X- _ O
errors -X- _ O
by -X- _ O
asking -X- _ O
participants -X- _ O
to -X- _ O
tick -X- _ O
the -X- _ O
question -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
grammatically -X- _ O
incorrect -X- _ O
. -X- _ O

Examples -X- _ O
of -X- _ O
questions -X- _ O
asked -X- _ O
during -X- _ O
the -X- _ O
study -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
C. -X- _ O
4.5 -X- _ O
Sampling -X- _ O
methods -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O
When -X- _ O
generating -X- _ O
text -X- _ O
from -X- _ O
a -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
and -X- _ O
diversity -X- _ O
of -X- _ O
samples -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
decoding -X- _ O
algorithm -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
three -X- _ O
text -X- _ O
generation -X- _ O
methods -X- _ O
. -X- _ O

greedy -X- _ O
uses -X- _ O
theargmax -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
, -X- _ O
while -X- _ O
sampling -X- _ O
uses -X- _ O
the -X- _ O
multinomial -X- _ O
distribution -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
sampled -X- _ O
ten -X- _ O
text -X- _ O
sequences -X- _ O
from -X- _ O
the -X- _ O
policy -X- _ O
, -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
one -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
perplexity -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
lm -X- _ O
- -X- _ O
ranking -X- _ O
. -X- _ O

This -X- _ O
process -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
recently -X- _ O
in -X- _ O
Text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Image -X- _ O
Generation -X- _ O
tasks -X- _ O
( -X- _ O
Ramesh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
.16 -X- _ O

Method -X- _ O
Score -X- _ O
R -X- _ B-MetricName
@ -X- _ I-MetricName
5 -X- _ I-MetricName
BLEU -X- _ B-MetricName
Meteor -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
t -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
sBLEU -X- _ B-MetricName

( -X- _ O
↓ -X- _ O
) -X- _ O
peak -X- _ B-MetricName
. -X- _ O

( -X- _ O
↓ -X- _ O
) -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
CLEVR -X- _ B-DatasetName
metrics -X- _ O
on -X- _ O
5k -X- _ O
test -X- _ O
episodes -X- _ O
with -X- _ O
50k -X- _ O
train -X- _ O
episodes -X- _ O
on -X- _ O
20k -X- _ O
Images -X- _ O
. -X- _ O

Scores -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
three -X- _ O
decoding -X- _ O
procedures -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
and -X- _ O
over -X- _ O
5 -X- _ O
seeds -X- _ O
; -X- _ O
standard -X- _ O
deviations -X- _ O
are -X- _ O
displayed -X- _ O
when -X- _ O
greater -X- _ O
than -X- _ O
0.01for -X- _ O
accuracy -X- _ O
metrics -X- _ O
. -X- _ O

We -X- _ O
here -X- _ O
report -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
task -X- _ O
- -X- _ O
success -X- _ O
: -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
scratch+KL -X- _ O
baselines -X- _ O
with -X- _ O
λKL= -X- _ O
0.1 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
truncation -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ O
threshold -X- _ O
, -X- _ O
pth -X- _ O
( -X- _ O
α=0.05 -X- _ O
) -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
underlined -X- _ O
, -X- _ O
best -X- _ O
values -X- _ O
without -X- _ O
task -X- _ O
- -X- _ O
data -X- _ O
( -X- _ O
from -X- _ O
scratch -X- _ O
) -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

Human -X- _ O
There -X- _ O
is -X- _ O
a -X- _ O
blue -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
big -X- _ O
cyan -X- _ O
metallic -X- _ O
object -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
size -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
Small -X- _ O
pretrain -X- _ B-MethodName
There -X- _ O
is -X- _ O
a -X- _ O
red -X- _ O
metallic -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
yellow -X- _ O
rubber -X- _ O
block -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
size -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName

RL -X- _ O
What -X- _ O
size -X- _ O
is -X- _ O
the -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
matte -X- _ O
cube -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
scratch -X- _ O
size -X- _ O
sphere -X- _ O
small -X- _ O
blue -X- _ O
or -X- _ O
a -X- _ O
yellow -X- _ O
green -X- _ O
large -X- _ O
else -X- _ O
in -X- _ O
cylinders -X- _ O
cubes -X- _ O
color -X- _ O
and -X- _ O
how -X- _ O
matte -X- _ O
objects -X- _ O
cube -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
How -X- _ O
big -X- _ O
is -X- _ O
the -X- _ O
shiny -X- _ O
cylinder -X- _ O
? -X- _ O

scratch+KL -X- _ O
- -X- _ O
ext -X- _ O
How -X- _ O
many -X- _ O
other -X- _ O
objects -X- _ O
in -X- _ O
the -X- _ O
are -X- _ O
of -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
that -X- _ O
shiny -X- _ O
object -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
How -X- _ O
big -X- _ O
is -X- _ O
the -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
matte -X- _ O
thing -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
cyan -X- _ O
thing -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
Human -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
cat -X- _ O
A -X- _ O
: -X- _ O
Black -X- _ O
pretrain -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
cat -X- _ O
’s -X- _ O
collar -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
cat -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
scratch -X- _ O
AmazingAmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
their -X- _ O
hat -X- _ O
of -X- _ O
the -X- _ O
fingers -X- _ O
of -X- _ O
this -X- _ O
? -X- _ O

scratch+KL -X- _ O
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
is -X- _ O
a -X- _ O
bit -X- _ O
of -X- _ O
the -X- _ O
way -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
is -X- _ O
her -X- _ O
outfit -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
can -X- _ O
these -X- _ O
cats -X- _ O
look -X- _ O
like -X- _ O
in -X- _ O
real -X- _ O
life -X- _ O
? -X- _ O

□ -X- _ O
✓ -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Samples -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
and -X- _ O
VQA -X- _ O
: -X- _ O
the -X- _ O
checkbox -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
question -X- _ O
generates -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
. -X- _ O

5 -X- _ O
Results -X- _ O
5.1 -X- _ O
CLEVR -X- _ B-DatasetName
results -X- _ O
Quantitative -X- _ O
performance -X- _ O
: -X- _ O
In -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
vanilla -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
fails -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
decent -X- _ O
performance -X- _ O
even -X- _ O
with -X- _ O
synthetic -X- _ O
language -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
adding -X- _ O
a -X- _ O
KL -X- _ O
regularisation -X- _ O
term -X- _ O
does -X- _ O
kick -X- _ O
- -X- _ O
start -X- _ O
the -X- _ O
learning -X- _ O
process -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
as -X- _ O
soon -X- _ O
as -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
dynamic -X- _ O
truncation -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
matches -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
performance -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
external -X- _ O
LM -X- _ O
, -X- _ O
and -X- _ O
even -X- _ O
outperforms -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
LM -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
synthetic -X- _ O
VQG -X- _ B-TaskName
setting -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
seems -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
viable -X- _ O
and -X- _ O
promising -X- _ O
procedure -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
training -X- _ O
phase -X- _ O
. -X- _ O

Pretrained -X- _ O
baselines -X- _ O
have -X- _ O
high -X- _ O
language -X- _ O
scores -X- _ O
when -X- _ O
assessed -X- _ O
with -X- _ O
datasetbased -X- _ O
metrics -X- _ O
, -X- _ O
e.g -X- _ O
BLEU -X- _ B-MetricName
or -X- _ O
task -X- _ B-MetricName
- -X- _ I-MetricName
perplexity -X- _ I-MetricName
. -X- _ O

Yet -X- _ O
, -X- _ O
they -X- _ O
also -X- _ O
remain -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
distribution -X- _ O
with -X- _ O
a -X- _ O
medium -X- _ O
external -X- _ O
perplexity -X- _ O
. -X- _ O

Noticeably -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
LM -X- _ O
follows -X- _ O
the -X- _ O
same -X- _ O
pattern -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
the -X- _ O
external -X- _ O
LM -X- _ O
reports -X- _ O
poor -X- _ O
dataset -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
scores -X- _ O
, -X- _ O
while -X- _ O
maintaining -X- _ O
a -X- _ O
low -X- _ O
external -X- _ O
perplexity -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
seems -X- _ O
to -X- _ O
correctly -X- _ O
capture -X- _ O
the -X- _ O
language -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
initial -X- _ O
LM -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
performance -X- _ O
score -X- _ O
is -X- _ O
high -X- _ O
when -X- _ O
using -X- _ O
an -X- _ O
external -X- _ O
LM -X- _ O
, -X- _ O
it -X- _ O
suggests -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
on -X- _ O
a -X- _ O
language -X- _ O
task -X- _ O
with -X- _ O
- -X- _ O
out -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
dataset -X- _ O
. -X- _ O

Less -X- _ O
positively -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
diversity -X- _ O
metrics -X- _ O
suggest -X- _ O
potential -X- _ O
mode -X- _ O
collapse -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
high -X- _ O
peakiness -X- _ B-MetricName
and -X- _ O
self -X- _ B-MetricName
- -X- _ I-MetricName
BLEU -X- _ I-MetricName
score -X- _ O
. -X- _ O

Qualitative -X- _ O
performance -X- _ O
: -X- _ O
We -X- _ O
display -X- _ O
qualitative -X- _ O
samples -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
and -X- _ O
Appendix -X- _ O
D. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
generate -X- _ O
either -X- _ O
a -X- _ O
question -X- _ O
inconsistent -X- _ O
with -X- _ O
the -X- _ O
visual -X- _ O
context -X- _ O
, -X- _ O
or -X- _ O
which -X- _ O
fails -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
expected -X- _ O
answer -X- _ O
. -X- _ O

They -X- _ O
inaccurately -X- _ O
capture -X- _ O
the -X- _ O
pragmatics -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
generate -X- _ O
adequate -X- _ O
questions -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
expected -X- _ O
answer -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
often -X- _ O
grounded -X- _ O
with -X- _ O
different -X- _ O
objects -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
remarkable -X- _ O
that -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
generic -X- _ O
LM -X- _ O
still -X- _ O
manages -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
necessary -X- _ O
subtleties -X- _ O
of -X- _ O
VQG -X- _ B-TaskName
, -X- _ O
without -X- _ O
any -X- _ O
prior -X- _ O
task -X- _ O
knowledge -X- _ O
. -X- _ O

Despite -X- _ O
a -X- _ O
peaky -X- _ O
distribution -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
has -X- _ O
moderate -X- _ O
repetitions -X- _ O
across -X- _ O
images -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
mostly -X- _ O
overconfident -X- _ O
. -X- _ O

As -X- _ O
for -X- _ O
the -X- _ O
scratch+KL -X- _ O
samples -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
either -X- _ O
not -X- _ O
grounded -X- _ O
, -X- _ O
or -X- _ O
showcase -X- _ O
degenerated -X- _ O
language -X- _ O
. -X- _ O

Truncation -X- _ O
function -X- _ O
in -X- _ O
CLEVR -X- _ B-DatasetName
: -X- _ O
In -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
different -X- _ O
truncation -X- _ O
functions -X- _ O
defined -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
. -X- _ O

While -X- _ O
all -X- _ O
truncation -X- _ O
methods -X- _ O
report -X- _ O
similar -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
the -X- _ O
dynamic -X- _ O
truncation -X- _ O
functions -X- _ O
, -X- _ O
i.e.pth -X- _ O
( -X- _ O
α -X- _ O
) -X- _ O
, -X- _ O
top -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
andsample -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
outperform -X- _ O
the -X- _ O
top -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
regarding -X- _ O
language -X- _ O
metrics -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
the -X- _ O
sample -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
one -X- _ O
, -X- _ O
which -X- _ O
generates -X- _ O
a -X- _ O
stochastic -X- _ O
truncated17 -X- _ O

Trunc -X- _ O
. -X- _ O

Score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
sBLEU -X- _ B-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
CLEVR -X- _ B-DatasetName
task -X- _ O
: -X- _ O
Truncation -X- _ O
functions -X- _ O
with -X- _ O
parameters -X- _ O
: -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
underlined -X- _ O
, -X- _ O
best -X- _ O
values -X- _ O
for -X- _ O
each -X- _ O
TrufLL -X- _ B-MethodName
algorithms -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

action -X- _ O
space -X- _ O
, -X- _ O
while -X- _ O
having -X- _ O
a -X- _ O
lower -X- _ O
performance -X- _ O
, -X- _ O
yields -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
correct -X- _ O
and -X- _ O
diverse -X- _ O
language -X- _ O
, -X- _ O
with -X- _ O
higher -X- _ O
language -X- _ B-MetricName
scores -X- _ I-MetricName
and -X- _ O
a -X- _ O
lower -X- _ O
self -X- _ B-MetricName
- -X- _ I-MetricName
BLEU -X- _ I-MetricName
. -X- _ O

A -X- _ O
stochastic -X- _ O
action -X- _ O
space -X- _ O
might -X- _ O
be -X- _ O
harder -X- _ O
to -X- _ O
explore -X- _ O
efficiently -X- _ O
for -X- _ O
reaching -X- _ O
good -X- _ O
task -X- _ O
- -X- _ O
solving -X- _ O
abilities -X- _ O
, -X- _ O
but -X- _ O
might -X- _ O
strengthen -X- _ O
the -X- _ O
agent -X- _ O
language -X- _ O
generation -X- _ O
properties -X- _ O
. -X- _ O

5.2 -X- _ O
VQAv2 -X- _ B-DatasetName
task -X- _ O
In -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
TrufLL -X- _ B-MethodName
seems -X- _ O
a -X- _ O
promising -X- _ O
approach -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
language -X- _ O
policy -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
by -X- _ O
solely -X- _ O
interacting -X- _ O
with -X- _ O
another -X- _ O
language -X- _ O
system -X- _ O
. -X- _ O

We -X- _ O
scale -X- _ O
our -X- _ O
approach -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
with -X- _ O
large -X- _ O
vocabulary -X- _ O
( -X- _ O
15k -X- _ O
tokens -X- _ O
) -X- _ O
through -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Quantitative -X- _ O
performance -X- _ O
: -X- _ O
Table -X- _ O
3 -X- _ O
reports -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
results -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
baselines -X- _ O
present -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
than -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
. -X- _ O

First -X- _ O
, -X- _ O
the -X- _ O
scratch -X- _ O
baselines -X- _ O
keep -X- _ O
failing -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
valuable -X- _ O
policy -X- _ O
, -X- _ O
with -X- _ O
performance -X- _ O
scores -X- _ O
and -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
metrics -X- _ O
close -X- _ O
to -X- _ O
zero -X- _ O
. -X- _ O

Although -X- _ O
TrufLL -X- _ B-MethodName
does -X- _ O
not -X- _ O
outperform -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
anymore -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
leads -X- _ O
to -X- _ O
similar -X- _ O
performances -X- _ O
, -X- _ O
and -X- _ O
satisfactory -X- _ O
language -X- _ O
scores -X- _ O
. -X- _ O

The -X- _ O
similarity -X- _ O
between -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
and -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
results -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
truncation -X- _ O
approach -X- _ O
is -X- _ O
viable -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
generic -X- _ O
LM -X- _ O
whose -X- _ O
original -X- _ O
vocabulary -X- _ O
distribution -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
displays -X- _ O
a -X- _ O
self -X- _ B-MetricName
- -X- _ I-MetricName
BLEU -X- _ I-MetricName
score -X- _ I-MetricName
similar -X- _ O
to -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
poor -X- _ O
diversity -X- _ O
behavior -X- _ O
observed -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
is -X- _ O
likely -X- _ O
attributable -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
vocabulary -X- _ O
and -X- _ O
synthetic -X- _ O
language -X- _ O
distribution -X- _ O
. -X- _ O

Qualitative -X- _ O
performance -X- _ O
: -X- _ O
In -X- _ O
Figure -X- _ O
2 -X- _ O
and -X- _ O
Appendix -X- _ O
D -X- _ O
, -X- _ O
we -X- _ O
display -X- _ O
question -X- _ O
samples -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O

TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
successfully -X- _ O
generate -X- _ O
a -X- _ O
question -X- _ O
giving -X- _ O
the -X- _ O
expected -X- _ O
answer -X- _ O
( -X- _ O
" -X- _ O
Black -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
baselines -X- _ O
fail -X- _ O
, -X- _ O
and -X- _ O
even -X- _ O
showcase -X- _ O
degenerated -X- _ O
language -X- _ O
. -X- _ O

Pretrained -X- _ O
baselines -X- _ O
tend -X- _ O
to -X- _ O
output -X- _ O
a -X- _ O
question -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
question -X- _ O
whereas -X- _ O
TrufLL -X- _ B-MethodName
outputs -X- _ O
originalquestions -X- _ O
which -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
VQA -X- _ O
distribution -X- _ O
, -X- _ O
yet -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
: -X- _ O
Figure -X- _ O
3 -X- _ O
details -X- _ O
the -X- _ O
Human -X- _ O
Evaluation -X- _ O
results -X- _ O
. -X- _ O

Among -X- _ O
the -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
baselines -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
as -X- _ O
the -X- _ O
only -X- _ O
model -X- _ O
producing -X- _ O
sometimes -X- _ O
meaningful -X- _ O
questions -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
it -X- _ O
fails -X- _ O
to -X- _ O
generate -X- _ O
correct -X- _ O
and -X- _ O
grounded -X- _ O
language -X- _ O
; -X- _ O
it -X- _ O
is -X- _ O
thus -X- _ O
not -X- _ O
a -X- _ O
viable -X- _ O
approach -X- _ O
despite -X- _ O
its -X- _ O
diverse -X- _ O
output -X- _ O
. -X- _ O

In -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
automatic -X- _ O
metrics -X- _ O
, -X- _ O
the -X- _ O
supervised -X- _ O
baselines -X- _ O
produce -X- _ O
the -X- _ O
best -X- _ O
language -X- _ O
, -X- _ O
while -X- _ O
being -X- _ O
accurately -X- _ O
grounded -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
they -X- _ O
exhibit -X- _ O
significantly -X- _ O
less -X- _ O
diversity -X- _ O
with -X- _ O
the -X- _ O
reference -X- _ O
language -X- _ O
; -X- _ O
this -X- _ O
suggests -X- _ O
in -X- _ O
particular -X- _ O
that -X- _ O
pretrain+RL -X- _ B-MethodName
fails -X- _ O
to -X- _ O
go -X- _ O
beyond -X- _ O
the -X- _ O
initial -X- _ O
task -X- _ O
- -X- _ O
data -X- _ O
distribution -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
unlike -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
which -X- _ O
suffers -X- _ O
from -X- _ O
syntactic -X- _ O
errors -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
produces -X- _ O
language -X- _ O
that -X- _ O
qualitatively -X- _ O
competes -X- _ O
with -X- _ O
pretrain -X- _ O
models -X- _ O
( -X- _ O
53 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
ratio -X- _ O
of -X- _ O
syntactic -X- _ O
uncorrect -X- _ O
samples -X- _ O
. -X- _ O

Although -X- _ O
its -X- _ O
questions -X- _ O
are -X- _ O
less -X- _ O
grounded -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
diverse -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
they -X- _ O
follow -X- _ O
a -X- _ O
different -X- _ O
distribution -X- _ O
from -X- _ O
the -X- _ O
initial -X- _ O
VQA -X- _ O
dataset -X- _ O
. -X- _ O

It -X- _ O
confirms -X- _ O
that -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
could -X- _ O
be -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
as -X- _ O
it -X- _ O
has -X- _ O
an -X- _ O
excellent -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
language -X- _ O
quality -X- _ O
, -X- _ O
diversity -X- _ O
, -X- _ O
and -X- _ O
grounding -X- _ O
. -X- _ O

Decoding -X- _ O
procedure -X- _ O
: -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
text -X- _ O
sampling -X- _ O
procedures -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
. -X- _ O

While -X- _ O
greedy -X- _ O
decoding -X- _ O
produces -X- _ O
the -X- _ O
best -X- _ O
outcome -X- _ O
for -X- _ O
pretrained -X- _ O
models -X- _ O
, -X- _ O
lm -X- _ O
- -X- _ O
ranking -X- _ O
provides -X- _ O
an -X- _ O
excellent -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
task -X- _ O
performance -X- _ O
and -X- _ O
language -X- _ O
quality -X- _ O
with -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
. -X- _ O

As -X- _ O
PG -X- _ O
solely -X- _ O
optimizes -X- _ O
the -X- _ O
task -X- _ O
success -X- _ O
ratio -X- _ O
, -X- _ O
this -X- _ O
may -X- _ O
reduce -X- _ O
overall -X- _ O
language -X- _ O
quality -X- _ O
, -X- _ O
the -X- _ O
re -X- _ O
- -X- _ O
ranking -X- _ O
thus -X- _ O
retrieves -X- _ O
the -X- _ O
best -X- _ O
syntactically -X- _ O
sentences -X- _ O
a -X- _ O
posteriori -X- _ O
. -X- _ O

5.3 -X- _ O
Discussion -X- _ O
Removing -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
evaluation -X- _ O
with -X- _ O
offpolicy -X- _ O
RL -X- _ O
. -X- _ O

So -X- _ O
far -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
directly -X- _ O
learns -X- _ O
the -X- _ O
truncated -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
truncated -X- _ O
vocabulary -X- _ O
V− -X- _ O
tin -X- _ O
an -X- _ O
on -X- _ O
- -X- _ O
policy -X- _ O
scheme -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
the -X- _ O
algorithm -X- _ O
requires -X- _ O
the -X- _ O
truncation -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
fortiori -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
if -X- _ O
we -X- _ O
can -X- _ O
directly -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
removing -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

In -X- _ O
such -X- _ O
a -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
training -X- _ O
scheme -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
trajectories -X- _ O
used -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
behavior -X- _ O
πθat -X- _ O
training -X- _ O
time -X- _ O
are -X- _ O
sampled -X- _ O
under -X- _ O
a -X- _ O
different -X- _ O
policy -X- _ O
, -X- _ O
the -X- _ O
truncated -X- _ O
policy -X- _ O
θ -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
unbiased -X- _ O
the -X- _ O
PG -X- _ O
by -X- _ O
using -X- _ O
an -X- _ O
importance -X- _ O
sampling -X- _ O
term -X- _ O
between -X- _ O
the -X- _ O
exploratory -X- _ O
policy -X- _ O
π− -X- _ O
θand -X- _ O
the -X- _ O
behavior -X- _ O
policy -X- _ O
πθ -X- _ O
( -X- _ O
Degris -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
,18 -X- _ O

Method -X- _ O
Score -X- _ O
R -X- _ B-MetricName
@ -X- _ I-MetricName
5 -X- _ I-MetricName
BLEU -X- _ B-MetricName
Meteor -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
t -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
sBLEU -X- _ B-MetricName

( -X- _ O
↓ -X- _ O
) -X- _ O
peak -X- _ B-MetricName
. -X- _ O

( -X- _ O
↓ -X- _ O
) -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
VQAv2 -X- _ B-DatasetName
metrics -X- _ O
on -X- _ O
20k -X- _ O
test -X- _ O
episodes -X- _ O
with -X- _ O
100k -X- _ O
train -X- _ O
episodes -X- _ O
. -X- _ O

Scores -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
three -X- _ O
decoding -X- _ O
procedures -X- _ O
. -X- _ O

scratch+KL -X- _ O

hasλKL=0.05 -X- _ O
, -X- _ O
the -X- _ O
truncation -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
and -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
are -X- _ O
respectively -X- _ O
pth -X- _ O
( -X- _ O
α=0.005 -X- _ O
) -X- _ O
and -X- _ O
pth -X- _ O
( -X- _ O
α=0.0075 -X- _ O
) -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
underlined -X- _ O
, -X- _ O
best -X- _ O
values -X- _ O
without -X- _ O
task -X- _ O
- -X- _ O
data -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

pretrain -X- _ B-MethodName
pretrain+RL -X- _ B-MethodName
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
pretrain -X- _ B-MethodName
[ -X- _ O
2 -X- _ O
] -X- _ O
pretrain+RL -X- _ B-MethodName
[ -X- _ O
1 -X- _ O
] -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O

[ -X- _ O
4 -X- _ O
] -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

[ -X- _ O
5 -X- _ O
] -X- _ O
Language -X- _ O
Quality -X- _ O
pretrain -X- _ B-MethodName
pretrain+RL -X- _ B-MethodName
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
pretrain -X- _ B-MethodName
[ -X- _ O
1 -X- _ O
] -X- _ O
pretrain+RL -X- _ B-MethodName
[ -X- _ O
2 -X- _ O
] -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O

[ -X- _ O
5 -X- _ O
] -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

[ -X- _ O
4 -X- _ O
] -X- _ O
23 -X- _ B-MetricValue
% -X- _ I-MetricValue
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
72 -X- _ B-MetricValue
% -X- _ I-MetricValue
53 -X- _ B-MetricValue
% -X- _ I-MetricValue
Language -X- _ O
Grounding -X- _ O
pretrain -X- _ B-MethodName
pretrain+RL -X- _ B-MethodName
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
pretrain -X- _ B-MethodName
[ -X- _ O
5 -X- _ O
] -X- _ O
pretrain+RL -X- _ B-MethodName

[ -X- _ O
4 -X- _ O
] -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
[ -X- _ O
1 -X- _ O
] -X- _ O
TruFLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

[ -X- _ O
3 -X- _ O
] -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
64 -X- _ B-MetricValue
% -X- _ I-MetricValue
34 -X- _ B-MetricValue
% -X- _ I-MetricValue
55 -X- _ B-MetricValue
% -X- _ I-MetricValue
Diversity -X- _ O
/ -X- _ O
Originality -X- _ O
Pairwise -X- _ O
comparisons -X- _ O
: -X- _ O
% -X- _ O
of -X- _ O
questions -X- _ O
chosen -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
bold -X- _ O
( -X- _ O
rows -X- _ O
) -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
concurrent -X- _ O
model -X- _ O
( -X- _ O
columns -X- _ O
) -X- _ O
. -X- _ O

pretrain -X- _ B-MethodName
( -X- _ O
2 -X- _ O
) -X- _ O
pretrain+RL -X- _ B-MethodName
( -X- _ O
3 -X- _ O
) -X- _ O
scratch+KL -X- _ O
- -X- _ O
task -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
VQAv2 -X- _ B-DatasetName
results -X- _ O
for -X- _ O
Human -X- _ O
Evaluation -X- _ O
study -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
4.4 -X- _ O
. -X- _ O

The -X- _ O
three -X- _ O
matrices -X- _ O
on -X- _ O
top -X- _ O
are -X- _ O
pairwise -X- _ O
comparisons -X- _ O
: -X- _ O
each -X- _ O
cell -X- _ O
displays -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
questions -X- _ O
chosen -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
row -X- _ O
( -X- _ O
bold -X- _ O
) -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
concurrent -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
column -X- _ O
. -X- _ O

The -X- _ O
table -X- _ O
at -X- _ O
the -X- _ O
bottom -X- _ O
displays -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
incorrect -X- _ O
questions -X- _ O
coming -X- _ O
from -X- _ O
each -X- _ O
model -X- _ O
among -X- _ O
all -X- _ O
incorrect -X- _ O
samples -X- _ O
. -X- _ O

In -X- _ O
all -X- _ O
figures -X- _ O
, -X- _ O
bracket -X- _ O
numbers -X- _ O
indicates -X- _ O
the -X- _ O
model -X- _ O
rank -X- _ O
per -X- _ O
criteria -X- _ O
, -X- _ O
from -X- _ O
1= -X- _ O
" -X- _ O
best -X- _ O
" -X- _ O
to -X- _ O
5= -X- _ O
" -X- _ O
worst -X- _ O
" -X- _ O
. -X- _ O

Method -X- _ O
Text -X- _ O
- -X- _ O
gen -X- _ O
Score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
Table -X- _ O
4 -X- _ O
: -X- _ O
VQAv2 -X- _ B-DatasetName
: -X- _ O
Ablation -X- _ O
on -X- _ O
the -X- _ O
sampling -X- _ O
methods -X- _ O
. -X- _ O

Overall -X- _ O
best -X- _ O
values -X- _ O
are -X- _ O
underlined -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
best -X- _ O
values -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
the -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
PPO -X- _ O
loss -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
: -X- _ O
Loff -X- _ O
θ -X- _ O
/ -X- _ O
bracketleftbig -X- _ O
t,1+ϵ -X- _ O
) -X- _ O
At -X- _ O
) -X- _ O
/ -X- _ O
bracketrightbig -X- _ O
where -X- _ O
¯ρθ -X- _ O
πθold -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
πθold -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
θold -X- _ O
( -X- _ O
at|st -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
new -X- _ O
ratio.4 -X- _ O
Table -X- _ O
5 -X- _ O
displays -X- _ O
the -X- _ O
on -X- _ O
- -X- _ O
policy -X- _ O
and -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
VQG -X- _ B-TaskName
tasks -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
further -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
B.3 -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
importance -X- _ O
sampling -X- _ O
ratio.monitor -X- _ O
the -X- _ O
probability -X- _ O
mass -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space -X- _ O
( -X- _ O
sumVA -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
policy -X- _ O
only -X- _ O
samples -X- _ O
words -X- _ O
within -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space -X- _ O
when -X- _ O
sumVA -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
without -X- _ O
needing -X- _ O
the -X- _ O
truncation -X- _ O
. -X- _ O

On -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
offhas -X- _ O
lower -X- _ O
- -X- _ O
yet -X- _ O
close -X- _ O
- -X- _ O
performance -X- _ O
on -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
scores -X- _ O
than -X- _ O
TrufLL -X- _ B-MethodName
. -X- _ O

As -X- _ O
its -X- _ O
sumVA -X- _ O
ratios -X- _ O
are -X- _ O
very -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
has -X- _ O
learned -X- _ O
to -X- _ O
generalize -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
manage -X- _ O
to -X- _ O
sufficiently -X- _ O
scale -X- _ O
to -X- _ O
VQAv2 -X- _ B-DatasetName
. -X- _ O

It -X- _ O
could -X- _ O
be -X- _ O
improved -X- _ O
with -X- _ O
regularisation -X- _ O
techniques -X- _ O
and -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
TruFLL -X- _ B-MethodName
within -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
RL -X- _ O
algorithms -X- _ O
. -X- _ O

We -X- _ O
leave -X- _ O
such -X- _ O
possibilities -X- _ O
to -X- _ O
future -X- _ O
works -X- _ O
. -X- _ O

Algo -X- _ O
Score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
sBLEU -X- _ B-MetricName

sumV -X- _ O
A -X- _ O
CLEVR -X- _ B-DatasetName
VQAv2 -X- _ B-DatasetName
Table -X- _ O
5 -X- _ O
: -X- _ O
On -X- _ O
- -X- _ O
policy -X- _ O
vs. -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
scores -X- _ O
: -X- _ O
when -X- _ O
training -X- _ O
with -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time.19 -X- _ O

Additional -X- _ O
experiments -X- _ O
. -X- _ O

We -X- _ O
sweep -X- _ O
over -X- _ O
truncation -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
of -X- _ O
Appendix -X- _ O
B. -X- _ O
In -X- _ O
Table -X- _ O
8 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
rewarding -X- _ O
an -X- _ O
agent -X- _ O
with -X- _ O
a -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
in -X- _ O
both -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
scores -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
. -X- _ O

In -X- _ O
VQA -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
temperature -X- _ O
scheduling -X- _ O
on -X- _ O
the -X- _ O
LM -X- _ O
to -X- _ O
perform -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
truncations -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
of -X- _ O
B.2 -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
. -X- _ O

Generalization -X- _ O
of -X- _ O
the -X- _ O
approach -X- _ O
. -X- _ O

TrufLL -X- _ B-MethodName
learns -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
able -X- _ O
to -X- _ O
solve -X- _ O
specific -X- _ O
Natural -X- _ O
Language -X- _ O
Generation -X- _ O
tasks -X- _ O
given -X- _ O
a -X- _ O
context -X- _ O
c. -X- _ O
For -X- _ O
solving -X- _ O
such -X- _ O
tasks -X- _ O
, -X- _ O
it -X- _ O
only -X- _ O
requires -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
a -X- _ O
reward -X- _ O
function -X- _ O
that -X- _ O
scores -X- _ O
the -X- _ O
language -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
RL -X- _ O
agent -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
eventually -X- _ O
a -X- _ O
few -X- _ O
natural -X- _ O
language -X- _ O
demonstrations -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
prompt -X- _ O
to -X- _ O
the -X- _ O
generic -X- _ O
language -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
truncation -X- _ O
algorithm -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
the -X- _ O
method -X- _ O
is -X- _ O
transferable -X- _ O
to -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
NLG -X- _ O
tasks -X- _ O
, -X- _ O
without -X- _ O
requiring -X- _ O
upfront -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
labelled -X- _ O
datasets -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
the -X- _ O
RL -X- _ O
framework -X- _ O
allows -X- _ O
to -X- _ O
optimize -X- _ O
non -X- _ O
- -X- _ O
differentiable -X- _ O
objectives -X- _ O
, -X- _ O
making -X- _ O
TrufLL -X- _ B-MethodName
a -X- _ O
natural -X- _ O
choice -X- _ O
to -X- _ O
learn -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialogs -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
De -X- _ O
Vries -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Other -X- _ O
interesting -X- _ O
tasks -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
include -X- _ O
the -X- _ O
ones -X- _ O
typically -X- _ O
found -X- _ O
in -X- _ O
Vision -X- _ O
and -X- _ O
Language -X- _ O
Representation -X- _ O
Learning -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Image -X- _ O
Captioning -X- _ O
, -X- _ O
Grounding -X- _ O
Referring -X- _ O
Expressions -X- _ O
( -X- _ O
generation -X- _ O
of -X- _ O
a -X- _ O
referring -X- _ O
expression -X- _ O
over -X- _ O
a -X- _ O
specific -X- _ O
bounding -X- _ O
box -X- _ O
of -X- _ O
an -X- _ O
image -X- _ O
) -X- _ O
, -X- _ O
Captionbased -X- _ O
Image -X- _ O
Retrieval -X- _ O
( -X- _ O
generation -X- _ O
of -X- _ O
a -X- _ O
caption -X- _ O
that -X- _ O
discriminates -X- _ O
an -X- _ O
image -X- _ O
between -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
images -X- _ O
) -X- _ O
. -X- _ O

Reward -X- _ O
functions -X- _ O
for -X- _ O
such -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
based -X- _ O
on -X- _ O
similarity -X- _ O
scores -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
associated -X- _ O
image -X- _ O
or -X- _ O
image -X- _ O
region -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
using -X- _ O
pretrained -X- _ O
language -X- _ O
representations -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
pretrained -X- _ O
systems -X- _ O
such -X- _ O
as -X- _ O
ViLBERT -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
context -X- _ O
can -X- _ O
be -X- _ O
any -X- _ O
kind -X- _ O
of -X- _ O
data -X- _ O
structure -X- _ O
( -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
database -X- _ O
, -X- _ O
video -X- _ O
, -X- _ O
etc -X- _ O
) -X- _ O
: -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
linguistic -X- _ O
input -X- _ O
, -X- _ O
TrufLL -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
for -X- _ O
instance -X- _ O
to -X- _ O
text -X- _ O
summarization -X- _ O
, -X- _ O
paraphrase -X- _ O
generation -X- _ O
( -X- _ O
with -X- _ O
reward -X- _ O
functions -X- _ O
based -X- _ O
on -X- _ O
similarity -X- _ O
scores -X- _ O
between -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
language -X- _ O
) -X- _ O
or -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
games -X- _ O
( -X- _ O
Ammanabrolu -X- _ O
and -X- _ O
Riedl -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

6 -X- _ O
Related -X- _ O
work -X- _ O
RL -X- _ O
and -X- _ O
NLP -X- _ O
Tasks -X- _ O
. -X- _ O

Following -X- _ O
( -X- _ O
Singh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Lemon -X- _ O
and -X- _ O
Pietquin -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
recent -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
taskoriented -X- _ O
dialogues -X- _ O
( -X- _ O
De -X- _ O
Vries -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
policy -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
generally -X- _ O
pretrained -X- _ O
with -X- _ O
SL -X- _ O
followed -X- _ O
RLfine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Fan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
focused -X- _ O
on -X- _ O
tackling -X- _ O
VQG -X- _ B-TaskName
tasks -X- _ O
with -X- _ O
RL -X- _ O
, -X- _ O
respectively -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
and -X- _ O
on -X- _ O
the -X- _ O
VQG -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
the -X- _ O
former -X- _ O
uses -X- _ O
slot -X- _ O
filling -X- _ O
with -X- _ O
template -X- _ O
questions -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
later -X- _ O
computes -X- _ O
a -X- _ O
mixed -X- _ O
objective -X- _ O
with -X- _ O
a -X- _ O
MLE -X- _ O
loss -X- _ O
using -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
sentences -X- _ O
. -X- _ O

Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
Rennie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
use -X- _ O
RL -X- _ O
to -X- _ O
train -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
an -X- _ O
alternative -X- _ O
to -X- _ O
SL -X- _ O
to -X- _ O
prevent -X- _ O
typical -X- _ O
text -X- _ O
degeneration -X- _ O
issues -X- _ O
, -X- _ O
but -X- _ O
within -X- _ O
training -X- _ O
algorithms -X- _ O
relying -X- _ O
on -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
examples -X- _ O
from -X- _ O
labelled -X- _ O
datasets -X- _ O
. -X- _ O

RL -X- _ O
methods -X- _ O
for -X- _ O
Language -X- _ O
Action -X- _ O
Spaces -X- _ O
. -X- _ O

Several -X- _ O
RL -X- _ O
algorithms -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
to -X- _ O
tackle -X- _ O
large -X- _ O
discrete -X- _ O
action -X- _ O
spaces -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
Dulac -X- _ O
- -X- _ O
Arnold -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
; -X- _ O

Tennenholtz -X- _ O
and -X- _ O
Mannor -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Chandak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
embed -X- _ O
the -X- _ O
actions -X- _ O
into -X- _ O
a -X- _ O
continuous -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
classic -X- _ O
RL -X- _ O
algorithms -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
over -X- _ O
this -X- _ O
continuous -X- _ O
space -X- _ O
. -X- _ O

Zahavy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O

Seurin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposes -X- _ O
Q -X- _ O
- -X- _ O
learning -X- _ O
algorithms -X- _ O
with -X- _ O
an -X- _ O
elimination -X- _ O
signal -X- _ O
to -X- _ O
eliminate -X- _ O
forbidden -X- _ O
actions -X- _ O
. -X- _ O

Closer -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
a -X- _ O
few -X- _ O
algorithms -X- _ O
( -X- _ O
Ammanabrolu -X- _ O
and -X- _ O
Riedl -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
language -X- _ O
to -X- _ O
prune -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
of -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
games -X- _ O
, -X- _ O
but -X- _ O
within -X- _ O
value -X- _ O
- -X- _ O
based -X- _ O
algorithms -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
less -X- _ O
scalable -X- _ O
to -X- _ O
large -X- _ O
vocabularies -X- _ O
. -X- _ O

Similarly -X- _ O
to -X- _ O
TrufLL -X- _ B-MethodName
, -X- _ O
CALM -X- _ B-MethodName
( -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
combines -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
prune -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
with -X- _ O
a -X- _ O
DeepQ -X- _ O
network -X- _ O
, -X- _ O
aka -X- _ O
DRNN -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
its -X- _ O
truncation -X- _ O
language -X- _ O
model -X- _ O
remains -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
RL -X- _ O
dataset -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
CALM -X- _ B-MethodName
is -X- _ O
only -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
697 -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
on -X- _ O
4 -X- _ O
- -X- _ O
words -X- _ O
action -X- _ O
sequences -X- _ O
. -X- _ O

Learning -X- _ O
Language -X- _ O
Models -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

( -X- _ O
Ziegler -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Garg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
finetune -X- _ O
pretrained -X- _ O
GPT-2 -X- _ B-MethodName
models -X- _ O
with -X- _ O
RL -X- _ O
for -X- _ O
language -X- _ O
generation -X- _ O
tasks -X- _ O
without -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
data -X- _ O
, -X- _ O
only -X- _ O
using -X- _ O
reward -X- _ O
signals -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
they -X- _ O
still -X- _ O
face -X- _ O
optimization -X- _ O
and -X- _ O
computational -X- _ O
challenges -X- _ O
( -X- _ O
Parisotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

7 -X- _ O
Conclusion -X- _ O
We -X- _ O
proposed -X- _ O
TrufLL -X- _ B-MethodName
, -X- _ O
an -X- _ O
original -X- _ O
approach -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
( -X- _ O
NLG -X- _ B-TaskName
) -X- _ O
task -X- _ O
using -X- _ O
RL -X- _ O
, -X- _ O
without -X- _ O
the -X- _ O
usual -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
requiring -X- _ O
supervised -X- _ O
datasets -X- _ O
. -X- _ O

To -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
algorithm -X- _ O
dedicated -X- _ O
to -X- _ O
learning -X- _ O
a -X- _ O
word -X- _ O
- -X- _ O
based -X- _ O
text -X- _ O
- -X- _ O
generation -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
while -X- _ O
scaling -X- _ O
to -X- _ O
large -X- _ O
vocabularies -X- _ O
. -X- _ O

Although -X- _ O
it -X- _ O
comes -X- _ O
with -X- _ O
its -X- _ O
limitations -X- _ O
, -X- _ O
the -X- _ O
truncated -X- _ O
RL -X- _ O
algorithm -X- _ O
provided -X- _ O
by -X- _ O
TrufLL -X- _ B-MethodName
gets -X- _ O
free -X- _ O
from -X- _ O
labelled -X- _ O
data -X- _ O
in -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
presents -X- _ O
interesting -X- _ O
language -X- _ O
generation -X- _ O
properties -X- _ O
, -X- _ O
and -X- _ O
provides -X- _ O
a -X- _ O
generic -X- _ O
and -X- _ O
transferable -X- _ O
method -X- _ O
to -X- _ O
learn -X- _ O
any -X- _ O
NLG -X- _ O
problem.20 -X- _ O

A -X- _ O
Dataset -X- _ O
and -X- _ O
training -X- _ O
details -X- _ O
A.1 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
For -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
METEOR -X- _ B-MetricName
scores -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
NLTK5implementations -X- _ O
with -X- _ O
the -X- _ O
smoothing -X- _ O
function -X- _ O
number -X- _ O
2 -X- _ O
for -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
CIDEr -X- _ B-MetricName
score -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
nlg -X- _ O
- -X- _ O
eval -X- _ O
implementation6 -X- _ O
. -X- _ O

A.2 -X- _ O
Answer -X- _ O
filtering -X- _ O
For -X- _ O
each -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
yesandnoquestion -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
which -X- _ O
frequency -X- _ O
largely -X- _ O
exceeds -X- _ O
other -X- _ O
answers -X- _ O
, -X- _ O
to -X- _ O
avoid -X- _ O
any -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
generation -X- _ O
process -X- _ O
, -X- _ O
as -X- _ O
usually -X- _ O
done -X- _ O
in -X- _ O
the -X- _ O
VQG -X- _ B-TaskName
litterature -X- _ O
( -X- _ O
Mostafazadeh -X- _ O
A.3 -X- _ O
Dataset -X- _ O
split -X- _ O
For -X- _ O
CLEVR -X- _ B-DatasetName
( -X- _ O
resp -X- _ O
. -X- _ O

VQAv2 -X- _ B-DatasetName
) -X- _ O

, -X- _ O
the -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
50k -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O

100k -X- _ O
) -X- _ O
episodes -X- _ O
over -X- _ O
the -X- _ O
first -X- _ O
20k -X- _ O
images -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O

all -X- _ O
the -X- _ O
images -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
then -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
5k -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O
20k -X- _ O
) -X- _ O
images -X- _ O
of -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
we -X- _ O
uniformly -X- _ O
sample -X- _ O
the -X- _ O
answer -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
reference -X- _ O
answers -X- _ O
for -X- _ O
each -X- _ O
image -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
answers -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
questions -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
20 -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O
10 -X- _ O
) -X- _ O
words -X- _ O
. -X- _ O

A.4 -X- _ O
Language -X- _ O
Agent -X- _ O
Networks -X- _ O
and -X- _ O
Training -X- _ O
For -X- _ O
CLEVR -X- _ B-DatasetName
( -X- _ O
resp -X- _ O
. -X- _ O

VQAv2 -X- _ B-DatasetName
) -X- _ O

, -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
layer -X- _ O
LSTM -X- _ O
with -X- _ O
64 -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O

256 -X- _ O
) -X- _ O
units -X- _ O
for -X- _ O
the -X- _ O
policy -X- _ O
network -X- _ O
. -X- _ O

At -X- _ O
every -X- _ O
time -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
LSTM -X- _ O
input -X- _ O
is -X- _ O
then -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
of -X- _ O
dimension -X- _ O
32 -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O
128 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
embedding -X- _ O
of -X- _ O
dimension -X- _ O
32 -X- _ O
( -X- _ O
resp -X- _ O
. -X- _ O
128 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
representation -X- _ O
. -X- _ O

For -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
the -X- _ O
image -X- _ O
representation -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
pretrained -X- _ O
ResNet50 -X- _ O
and -X- _ O
projected -X- _ O
into -X- _ O
a -X- _ O
tensor -X- _ O
of -X- _ O
size -X- _ O
( -X- _ O
32,7,7 -X- _ O
) -X- _ O
before -X- _ O
being -X- _ O
flattened -X- _ O
. -X- _ O

For -X- _ O
VQAv2 -X- _ B-DatasetName
, -X- _ O
the -X- _ O
image -X- _ O
representation -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
200 -X- _ O
bounding -X- _ O
box -X- _ O
features -X- _ O
of -X- _ O
dimension -X- _ O
1048 -X- _ O
, -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
optimize -X- _ O
the -X- _ O
full -X- _ O
loss -X- _ O
L -X- _ O
= -X- _ O
LPPO+αLV -X- _ O
F+βLEwithα=0.5 -X- _ O
, -X- _ O
β=0.01and -X- _ O
a -X- _ O
PPO -X- _ O
clipping -X- _ B-MetricName
ratio -X- _ I-MetricName
ϵ=0.02 -X- _ B-MetricName
( -X- _ O
resp -X- _ O
. -X- _ O
0.01 -X- _ B-MetricValue
) -X- _ O
for -X- _ O
CLEVR -X- _ B-DatasetName
( -X- _ O
resp -X- _ O
. -X- _ O

VQAv2 -X- _ B-DatasetName
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
Adam -X- _ O
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
lr -X- _ B-HyperparameterName
) -X- _ O
of -X- _ O
10−3for -X- _ B-HyperparameterValue
TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
scratch -X- _ O
baseline -X- _ O
, -X- _ O
10−5 -X- _ B-HyperparameterValue
( -X- _ O
resp -X- _ O
. -X- _ O

10−6 -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
RL -X- _ O
algorithms -X- _ O
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
( -X- _ O
resp -X- _ O
. -X- _ O

VQAv2 -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
5∗10−4for -X- _ B-HyperparameterValue
models -X- _ O
including -X- _ O
a -X- _ O
KL -X- _ O
regularization -X- _ O
term -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
bs -X- _ B-HyperparameterName
) -X- _ O
of -X- _ O
128 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
models -X- _ O
except -X- _ O
the -X- _ O
ones -X- _ O
with -X- _ O
KL -X- _ O
regularization -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
. -X- _ O

Finally -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
baselines -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
gradient -X- _ B-HyperparameterName
clipping -X- _ I-HyperparameterName
( -X- _ O
gladclip -X- _ B-HyperparameterName
) -X- _ O
of -X- _ O
1 -X- _ B-HyperparameterValue
( -X- _ O
resp -X- _ O
. -X- _ O
5 -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
CLEVR -X- _ B-DatasetName
and -X- _ O
VQAv2 -X- _ B-DatasetName
. -X- _ O

Such -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
were -X- _ O
selected -X- _ O
, -X- _ O
after -X- _ O
conducting -X- _ O
an -X- _ O
extensive -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
search -X- _ O
. -X- _ O

The -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
tested -X- _ O
for -X- _ O
VQAv2 -X- _ B-DatasetName
policy -X- _ O
networks -X- _ O
with -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
256 -X- _ B-HyperparameterValue
and -X- _ O
1024 -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
, -X- _ O
with -X- _ O
respectively -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
128 -X- _ B-HyperparameterValue
and -X- _ O
512 -X- _ B-HyperparameterValue
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimensions -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
kept -X- _ O
the -X- _ O
network -X- _ O
size -X- _ O
giving -X- _ O
the -X- _ O
best -X- _ O
performances -X- _ O
, -X- _ O
i.e. -X- _ O
policy -X- _ O
network -X- _ O
of -X- _ O
256 -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
and -X- _ O
128 -X- _ B-HyperparameterValue
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
. -X- _ O

A.5 -X- _ O
Reward -X- _ O
formula -X- _ O
for -X- _ O
VQAv2 -X- _ B-DatasetName
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
detail -X- _ O
the -X- _ O
reward -X- _ O
function -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
task -X- _ O
. -X- _ O

r -X- _ O
( -X- _ O
wt -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
t -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
=1rk -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
≤10 -X- _ O
, -X- _ O
t -X- _ O
= -X- _ O
T−1e−rk -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
/ -X- _ O
2 -X- _ O
, -X- _ O
withrk -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
the -X- _ O
rank -X- _ O
of -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
answer -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
VQA -X- _ O
model -X- _ O
, -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
actual -X- _ O
answer -X- _ O
from -X- _ O
the -X- _ O
terminal -X- _ O
state -X- _ O
( -X- _ O
c -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
T -X- _ O
) -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
rk -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
=rank -X- _ O
( -X- _ O
VQA -X- _ O
( -X- _ O
c -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
T -X- _ O
) -X- _ O
[ -X- _ O
A -X- _ O
] -X- _ O
) -X- _ O
, -X- _ O
withVQA -X- _ O
( -X- _ O
c -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
T -X- _ O
) -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
VQA -X- _ O
model -X- _ O
over -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
answers -X- _ O
, -X- _ O
and -X- _ O
rank -X- _ O
the -X- _ O
function -X- _ O
which -X- _ O
ranks -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
answer -X- _ O
Awithin -X- _ O
VQA -X- _ O
( -X- _ O
c -X- _ O
, -X- _ O
w -X- _ O
< -X- _ O
T -X- _ O
) -X- _ O
probability -X- _ O
distribution -X- _ O
. -X- _ O

B -X- _ O
Additional -X- _ O
experiments -X- _ O
B.1 -X- _ O
CLEVR -X- _ B-DatasetName
Table -X- _ O
6 -X- _ O
displays -X- _ O
the -X- _ O
complete -X- _ O
ablation -X- _ O
on -X- _ O
the -X- _ O
truncation -X- _ O
functions -X- _ O
with -X- _ O
parameters -X- _ O
sweep -X- _ O
. -X- _ O

The -X- _ O
’ -X- _ O
sizeV -X- _ O
A -X- _ O
’ -X- _ O
variable -X- _ O
indicates -X- _ O
the -X- _ O
average -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space -X- _ O
for -X- _ O
each -X- _ O
truncation -X- _ O
function -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
displays -X- _ O
the -X- _ O
5https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.nltk.org -X- _ O
/ -X- _ O
6https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
Maluuba -X- _ O
/ -X- _ O
nlg-eval25 -X- _ O

ablation -X- _ O
over -X- _ O
the -X- _ O
three -X- _ O
decoding -X- _ O
procedures -X- _ O
defined -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
. -X- _ O

Such -X- _ O
an -X- _ O
ablation -X- _ O
presents -X- _ O
a -X- _ O
similar -X- _ O
pattern -X- _ O
than -X- _ O
VQAv2 -X- _ B-DatasetName
results -X- _ O
described -X- _ O
in -X- _ O
section -X- _ O
5.2 -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
Table -X- _ O
8 -X- _ O
reports -X- _ O
CLEVR -X- _ B-DatasetName
metrics -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
as -X- _ O
the -X- _ O
reward -X- _ O
. -X- _ O

While -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
task -X- _ O
TrufLL -X- _ B-MethodName
still -X- _ O
exhibits -X- _ O
promising -X- _ O
language -X- _ O
scores -X- _ O
, -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
metrics -X- _ O
remain -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
. -X- _ O

This -X- _ O
illustrates -X- _ O
that -X- _ O
using -X- _ O
a -X- _ O
language -X- _ O
similarity -X- _ O
score -X- _ O
as -X- _ O
a -X- _ O
reward -X- _ O
signal -X- _ O
is -X- _ O
much -X- _ O
less -X- _ O
interesting -X- _ O
than -X- _ O
a -X- _ O
reward -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
task -X- _ O
completion -X- _ O
score -X- _ O
. -X- _ O

Table -X- _ O
6 -X- _ O
: -X- _ O
CLEVR -X- _ B-DatasetName
task -X- _ O
: -X- _ O
Ablation -X- _ O
on -X- _ O
the -X- _ O
truncation -X- _ O
functions -X- _ O
with -X- _ O
parameters -X- _ O
sweep -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

trunc -X- _ O
. -X- _ O

Score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
sBLEU -X- _ B-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O

Size -X- _ O
V -X- _ O
A -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Table -X- _ O
7 -X- _ O
: -X- _ O
CLEVR -X- _ B-DatasetName
task -X- _ O
: -X- _ O
Ablation -X- _ O
on -X- _ O
sampling -X- _ O
methods -X- _ O
. -X- _ O

Best -X- _ O
overall -X- _ O
values -X- _ O
are -X- _ O
underlined -X- _ O
, -X- _ O
while -X- _ O
best -X- _ O
values -X- _ O
for -X- _ O
TruFLL -X- _ B-MethodName
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

method -X- _ O
text -X- _ O
- -X- _ O
gen -X- _ O
score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
B.2 -X- _ O
VQAv2 -X- _ B-DatasetName
Temperature -X- _ O
scheduling -X- _ O
: -X- _ O
On -X- _ O
the -X- _ O
CLEVR -X- _ B-DatasetName
task -X- _ O
, -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
dynamic -X- _ O
truncations -X- _ O
outperform -X- _ O
static -X- _ O
ones -X- _ O
such -X- _ O
as -X- _ O
top -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
: -X- _ O
indeed -X- _ O
, -X- _ O
they -X- _ O
better -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
inherent -X- _ O
variability -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
structure -X- _ O
at -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O

When -X- _ O
scaling -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
15k -X- _ O
words -X- _ O
of -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
task -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
dynamically -X- _ O
decrease -X- _ O
the -X- _ O
truncation -X- _ O
size -X- _ O
through -X- _ O
training -X- _ O
, -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
decreasing -X- _ O
temperature -X- _ O
schedule -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

While -X- _ O
temperature -X- _ O
scaling -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
usually -X- _ O
used -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
smoothness -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
distribution -X- _ O
, -X- _ O
temperature -X- _ O
schedules -X- _ O
during -X- _ O
training -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
several -X- _ O
settings -X- _ O
( -X- _ O
Jang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
fLM -X- _ O
( -X- _ O
wi|w -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
distribution -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
softmax -X- _ O
( -X- _ O
xi -X- _ O
) -X- _ O
=e−xi -X- _ O
/ -X- _ O
τ -X- _ O
/ -X- _ O
/ -X- _ O
summationtext -X- _ O
je−xj -X- _ O
/ -X- _ O
τ -X- _ O
, -X- _ O
with -X- _ O
xjthe -X- _ O
LM -X- _ O
logits -X- _ O
and -X- _ O
τthe -X- _ O
temperature -X- _ O
, -X- _ O
which -X- _ O
decreases -X- _ O
fromτmaxtoτminby -X- _ O
a -X- _ O
factor -X- _ O
TFevery -X- _ O
Tutraining -X- _ O
step -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
9 -X- _ O
, -X- _ O
both -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
and -X- _ O
TrufLL26 -X- _ B-MethodName

Table -X- _ O
8 -X- _ O
: -X- _ O
CLEVR -X- _ B-MetricName
, -X- _ O
BLEU -X- _ B-MetricName
reward -X- _ O
. -X- _ O

Scores -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
three -X- _ O
decoding -X- _ O
procedures -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
and -X- _ O
over -X- _ O
5 -X- _ O
seeds -X- _ O
, -X- _ O
standard -X- _ O
deviation -X- _ O
are -X- _ O
displayed -X- _ O
whenever -X- _ O
greater -X- _ O
than -X- _ O
0.01for -X- _ O
accuracy -X- _ O
metrics -X- _ O
. -X- _ O

We -X- _ O
here -X- _ O
report -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
task -X- _ O
- -X- _ O
success -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
scratch -X- _ O
with -X- _ O
KL -X- _ O
regularization -X- _ O
baseline -X- _ O
with -X- _ O
λKL=0.1 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
truncation -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ O
threshold -X- _ O
, -X- _ O
pth -X- _ O
( -X- _ O
α=0.05 -X- _ O
) -X- _ O
. -X- _ O

Baseline -X- _ O
and -X- _ O
Metrics -X- _ O
are -X- _ O
respectively -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
4.4 -X- _ O
and -X- _ O
4.3 -X- _ O
. -X- _ O

Best -X- _ O
overall -X- _ O
values -X- _ O
are -X- _ O
underlined -X- _ O
, -X- _ O
while -X- _ O
best -X- _ O
values -X- _ O
for -X- _ O
models -X- _ O
without -X- _ O
task -X- _ O
- -X- _ O
data -X- _ O
( -X- _ O
i.e -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
algorithms -X- _ O
) -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

Method -X- _ O
Score -X- _ O
R -X- _ B-MetricName
@ -X- _ I-MetricName
5 -X- _ I-MetricName
BLEU -X- _ B-MetricName
Meteor -X- _ O
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
t -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
sBLEU -X- _ B-MetricName

( -X- _ O
↓ -X- _ O
) -X- _ O
peak -X- _ B-MetricName
. -X- _ O

( -X- _ O
↓ -X- _ O
) -X- _ O
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
benefit -X- _ O
slightly -X- _ O
from -X- _ O
truncation -X- _ O
with -X- _ O
a -X- _ O
temperature -X- _ O
schedule -X- _ O
compared -X- _ O
to -X- _ O
a -X- _ O
vanilla -X- _ O
truncation -X- _ O
. -X- _ O

The -X- _ O
former -X- _ O
displays -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
/ -X- _ O
language -X- _ O
scores -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
for -X- _ O
the -X- _ O
schedule -X- _ O
" -X- _ O
τ -X- _ O
: -X- _ O
3 -X- _ O
> -X- _ O
1 -X- _ O
. -X- _ O
& -X- _ O
Tu=5,000 -X- _ O
" -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
has -X- _ O
the -X- _ O
best -X- _ O
metrics -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
for -X- _ O
" -X- _ O
τ -X- _ O
: -X- _ O
1.5 -X- _ O
> -X- _ O
1 -X- _ O
. -X- _ O
& -X- _ O
Tu=5,000 -X- _ O
" -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
Figure -X- _ O
4 -X- _ O
displays -X- _ O
the -X- _ O
evolution -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
return -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O

As -X- _ O
expected -X- _ O
, -X- _ O
the -X- _ O
pretrain+RL -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
baseline -X- _ O
return -X- _ O
does -X- _ O
not -X- _ O
evolve -X- _ O
much -X- _ O
, -X- _ O
confirming -X- _ O
that -X- _ O
the -X- _ O
policy -X- _ O
distribution -X- _ O
almost -X- _ O
does -X- _ O
not -X- _ O
shift -X- _ O
through -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
phase -X- _ O
. -X- _ O

The -X- _ O
training -X- _ O
curves -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
present -X- _ O
a -X- _ O
steady -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
return -X- _ O
until -X- _ O
reaching -X- _ O
convergence -X- _ O
, -X- _ O
confirming -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
by -X- _ O
guiding -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
provides -X- _ O
a -X- _ O
sufficient -X- _ O
learning -X- _ O
signal -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
scratch+KL -X- _ O
baselines -X- _ O
stay -X- _ O
stuck -X- _ O
to -X- _ O
a -X- _ O
low -X- _ O
training -X- _ O
return -X- _ O
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
KL -X- _ O
regularization -X- _ O
term -X- _ O
, -X- _ O
while -X- _ O
encouraging -X- _ O
the -X- _ O
policy -X- _ O
distribution -X- _ O
to -X- _ O
resemble -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
distribution -X- _ O
, -X- _ O
fails -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
task -X- _ O
pragmatics -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
generating -X- _ O
a -X- _ O
language -X- _ O
that -X- _ O
is -X- _ O
visually -X- _ O
grounded -X- _ O
. -X- _ O

Table -X- _ O
9 -X- _ O
: -X- _ O
VQA -X- _ O
task -X- _ O
: -X- _ O
Ablation -X- _ O
on -X- _ O
the -X- _ O
temperature -X- _ O
schedules -X- _ O
. -X- _ O

" -X- _ O
no -X- _ O
temp -X- _ O
. -X- _ O

sch -X- _ O
" -X- _ O
is -X- _ O
a -X- _ O
classic -X- _ O
truncation -X- _ O
without -X- _ O
temperature -X- _ O
scheduling -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
report -X- _ O
different -X- _ O
schedules -X- _ O
τ -X- _ O
: -X- _ O
τmax -X- _ O
> -X- _ O
τmin -X- _ O
, -X- _ O
Tu -X- _ O
, -X- _ O
with -X- _ O
τmax -X- _ O
, -X- _ O
τmin -X- _ O
, -X- _ O
Tu -X- _ O
, -X- _ O
andTf=0.75as -X- _ O
defined -X- _ O
in -X- _ O
section -X- _ O
B.2 -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

.Scheduling -X- _ O
Score -X- _ O
BLEU -X- _ B-MetricName

CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
sBLEU -X- _ B-MetricName
( -X- _ O
↓ -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

B.3 -X- _ O
Additional -X- _ O
discussion -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
. -X- _ O

Although -X- _ O
TrufLL -X- _ B-MethodName
aims -X- _ O
at -X- _ O
providing -X- _ O
a -X- _ O
robust -X- _ O
method -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
almost -X- _ O
) -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
whether -X- _ O
such -X- _ O
algorithm -X- _ O
can -X- _ O
be -X- _ O
complementary -X- _ O
to -X- _ O
RL -X- _ O
algorithms -X- _ O
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
TrufLL -X- _ B-MethodName
from -X- _ O
a -X- _ O
pretrained -X- _ O
policy -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
TrufLL -X- _ B-MethodName
pretrain -X- _ O
. -X- _ O

In -X- _ O
table -X- _ O
10 -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
TrufLL -X- _ B-MethodName
pretrain -X- _ O
marginally -X- _ O
improves -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
pretrain+RL -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
baseline -X- _ O
, -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
leads -X- _ O
to -X- _ O
performance -X- _ O
degradation -X- _ O
on -X- _ O
VQAv2 -X- _ B-DatasetName
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
vocabulary -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
distribution -X- _ O
learned -X- _ O
by -X- _ O
the -X- _ O
SL -X- _ O
pretrained -X- _ O
policy -X- _ O
is -X- _ O
significantly -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
one -X- _ O
learned -X- _ O
with -X- _ O
TrufLL -X- _ B-MethodName
. -X- _ O

On -X- _ O
- -X- _ O
policy -X- _ O
TrufLL -X- _ B-MethodName
versus -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
TrufLL -X- _ B-MethodName
. -X- _ O

To -X- _ O
ease -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
add -X- _ O
a -X- _ O
KLregularization -X- _ O
term -X- _ O
in -X- _ O
the -X- _ O
RL -X- _ O
loss -X- _ O
( -X- _ O
Jaques -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
TrufLL -X- _ B-MethodName
off -X- _ O
, -X- _ O
KL -X- _ O
. -X- _ O

Intuitively -X- _ O
, -X- _ O
it -X- _ O
encourages -X- _ O
the -X- _ O
policy -X- _ O
to -X- _ O
stay -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
’s -X- _ O
distribution -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
distribution -X- _ O
support -X- _ O
attributing -X- _ O
negligible -X- _ O
probabilities -X- _ O
to -X- _ O
words -X- _ O
outside -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space.27 -X- _ O

Figure -X- _ O
4 -X- _ O
: -X- _ O
VQAv2 -X- _ B-DatasetName
: -X- _ O
Training -X- _ O
curves -X- _ O
. -X- _ O

Reward -X- _ O
is -X- _ O
a -X- _ O
rolling -X- _ O
average -X- _ O
over -X- _ O
5000 -X- _ O
timesteps -X- _ O
. -X- _ O

Table -X- _ O
10 -X- _ O
: -X- _ O
TrufLL -X- _ B-MethodName
pretrain -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
2 -X- _ O
tasks -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
pretrain+RL -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
baseline -X- _ O
as -X- _ O
a -X- _ O
comparison -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

Algo -X- _ O
Score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
sBLEU -X- _ B-MetricName
CLEVR -X- _ B-DatasetName
VQAv2 -X- _ B-DatasetName
Table -X- _ O
11 -X- _ O
displays -X- _ O
the -X- _ O
full -X- _ O
results -X- _ O
of -X- _ O
on -X- _ O
- -X- _ O
policy -X- _ O
versus -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
scores -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
and -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
full -X- _ O
results -X- _ O
emphasize -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
the -X- _ O
approach -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
vocabulary -X- _ O
of -X- _ O
VQAv2 -X- _ B-DatasetName
. -X- _ O

Indeed -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
setting -X- _ O
for -X- _ O
such -X- _ O
a -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
exploding -X- _ O
values -X- _ O
for -X- _ O
e -X- _ O
- -X- _ O
ppl -X- _ O
suggest -X- _ O
that -X- _ O
the -X- _ O
optimized -X- _ O
language -X- _ O
agent -X- _ O
samples -X- _ O
incoherent -X- _ O
words -X- _ O
taken -X- _ O
outside -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
as -X- _ O
corroborated -X- _ O
by -X- _ O
the -X- _ O
low -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
sumVA -X- _ O
ratio -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
TrufLL -X- _ B-MethodName
off -X- _ O
, -X- _ O
KLtrades -X- _ O
off -X- _ O
task -X- _ O
performance -X- _ O
for -X- _ O
language -X- _ O
quality -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
TrufLL -X- _ B-MethodName
off -X- _ O
, -X- _ O
on -X- _ O
VQAv2 -X- _ B-DatasetName
, -X- _ O
it -X- _ O
mainly -X- _ O
provides -X- _ O
a -X- _ O
better -X- _ O
learning -X- _ O
signal -X- _ O
for -X- _ O
the -X- _ O
complete -X- _ O
( -X- _ O
large -X- _ O
) -X- _ O
vocabulary -X- _ O
. -X- _ O

In -X- _ O
such -X- _ O
a -X- _ O
setting -X- _ O
, -X- _ O
it -X- _ O
hence -X- _ O
improves -X- _ O
the -X- _ O
global -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
version -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
, -X- _ O
and -X- _ O
enables -X- _ O
a -X- _ O
much -X- _ O
better -X- _ O
generalization -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
of -X- _ O
the -X- _ O
global -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary -X- _ O
. -X- _ O

Yet -X- _ O
, -X- _ O
keeping -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
remains -X- _ O
crucial -X- _ O
with -X- _ O
large -X- _ O
vocabulary -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
for -X- _ O
VQAv2 -X- _ B-DatasetName
, -X- _ O
the -X- _ O
poor -X- _ O
performances -X- _ O
ofTrufLL -X- _ B-MethodName
off -X- _ O
, -X- _ O
KLon -X- _ O
the -X- _ O
external -X- _ O
LM -X- _ O
is -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
numerical -X- _ O
instability -X- _ O
challenges -X- _ O
when -X- _ O
using -X- _ O
GPT-2 -X- _ B-MethodName
as -X- _ O
the -X- _ O
target -X- _ O
policy -X- _ O
of -X- _ O
the -X- _ O
KL -X- _ O
regularization -X- _ O
term -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
on -X- _ O
- -X- _ O
policy -X- _ O
versus -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
scores -X- _ O
split -X- _ O
per -X- _ O
sampling -X- _ O
procedure -X- _ O
are -X- _ O
displayed -X- _ O
in -X- _ O
table -X- _ O
12 -X- _ O
: -X- _ O
unsurprisingly -X- _ O
, -X- _ O
greedy -X- _ O
decoding -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
offoutperforms -X- _ O
the -X- _ O
two -X- _ O
sampling -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
penalized -X- _ O
by -X- _ O
the -X- _ O
imperfect -X- _ O
generalization -X- _ O
of -X- _ O
the -X- _ O
optimized -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary.28 -X- _ O

Table -X- _ O
11 -X- _ O
: -X- _ O
On -X- _ O
- -X- _ O
policy -X- _ O
vs. -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
scores -X- _ O
for -X- _ O
different -X- _ O
variants -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
: -X- _ O
when -X- _ O
training -X- _ O
with -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

TrufLL -X- _ B-MethodName
off -X- _ O
, -X- _ O
KLis -X- _ O
evaluated -X- _ O
with -X- _ O
λKL=0.05 -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

Algo -X- _ O
Score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
ppl -X- _ B-MetricName
- -X- _ I-MetricName
e -X- _ I-MetricName
sBLEU -X- _ B-MetricName

sumV -X- _ O
A -X- _ O
CLEVR -X- _ B-DatasetName
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

VQAv2 -X- _ B-DatasetName
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

Table -X- _ O
12 -X- _ O
: -X- _ O
On -X- _ O
- -X- _ O
policy -X- _ O
vs. -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
scores -X- _ O
per -X- _ O
decoding -X- _ O
procedure -X- _ O
: -X- _ O
when -X- _ O
training -X- _ O
with -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

TrufLL -X- _ B-MethodName
off -X- _ O
, -X- _ O
KLis -X- _ O
evaluated -X- _ O
with -X- _ O
λKL=0.05 -X- _ O
. -X- _ O

Best -X- _ O
values -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

method -X- _ O
text -X- _ O
- -X- _ O
gen -X- _ O
score -X- _ O
BLEU -X- _ B-MetricName
CIDEr -X- _ B-MetricName
e -X- _ B-MetricName
- -X- _ I-MetricName
ppl -X- _ I-MetricName
CLEVR -X- _ B-DatasetName
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

VQAv2 -X- _ B-DatasetName
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

C -X- _ O
Human -X- _ O
Evaluation -X- _ O
details -X- _ O
For -X- _ O
the -X- _ O
Human -X- _ O
Evaluation -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
designed -X- _ O
one -X- _ O
form -X- _ O
per -X- _ O
participant -X- _ O
, -X- _ O
with -X- _ O
three -X- _ O
sections -X- _ O
evaluating -X- _ O
respectively -X- _ O
the -X- _ O
language -X- _ O
quality -X- _ O
, -X- _ O
language -X- _ O
grounding -X- _ O
and -X- _ O
diversity -X- _ O
criteria -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
five -X- _ O
evaluated -X- _ O
models -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
ten -X- _ O
different -X- _ O
model -X- _ O
pairs -X- _ O
: -X- _ O
each -X- _ O
section -X- _ O
of -X- _ O
the -X- _ O
form -X- _ O
contains -X- _ O
10 -X- _ O
pairwise -X- _ O
comparison -X- _ O
covering -X- _ O
all -X- _ O
the -X- _ O
possible -X- _ O
model -X- _ O
pairs -X- _ O
for -X- _ O
the -X- _ O
criteria -X- _ O
. -X- _ O

Each -X- _ O
pairwise -X- _ O
comparison -X- _ O
is -X- _ O
sampled -X- _ O
uniformly -X- _ O
over -X- _ O
the -X- _ O
50 -X- _ O
first -X- _ O
question -X- _ O
samples -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
algorithms -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
. -X- _ O

The -X- _ O
evaluation -X- _ O
of -X- _ O
syntax -X- _ O
errors -X- _ O
was -X- _ O
made -X- _ O
within -X- _ O
the -X- _ O
diversity -X- _ O
section -X- _ O
: -X- _ O
for -X- _ O
each -X- _ O
questions -X- _ O
pair -X- _ O
, -X- _ O
we -X- _ O
asked -X- _ O
participants -X- _ O
to -X- _ O
tick -X- _ O
the -X- _ O
questions -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
grammatically -X- _ O
incorrect -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
displays -X- _ O
one -X- _ O
pairwise -X- _ O
comparison -X- _ O
example -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
sections -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
full -X- _ O
form -X- _ O
example -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
the -X- _ O
following -X- _ O
url -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
forms.gle -X- _ O
/ -X- _ O
kkL38x31wF7A9YKx5 -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
Language -X- _ O
Quality -X- _ O
pairwise -X- _ O
comparison -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Language -X- _ O
Grounding -X- _ O
pairwise -X- _ O
comparison -X- _ O
Figure -X- _ O
5 -X- _ O
: -X- _ O
Examples -X- _ O
of -X- _ O
pairwise -X- _ O
comparison -X- _ O
for -X- _ O
each -X- _ O
evaluated -X- _ O
criteria.31 -X- _ O

( -X- _ O
c -X- _ O
) -X- _ O
Diversity -X- _ O
/ -X- _ O
Originality -X- _ O
with -X- _ O
reference -X- _ O
question -X- _ O
. -X- _ O

Pairwise -X- _ O
comparison -X- _ O
and -X- _ O
evaluation -X- _ O
of -X- _ O
syntax -X- _ O
errors -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
: -X- _ O
Examples -X- _ O
of -X- _ O
pairwise -X- _ O
comparison -X- _ O
for -X- _ O
each -X- _ O
evaluated -X- _ O
criteria -X- _ O
. -X- _ O

( -X- _ O
cont -X- _ O
. -X- _ O
) -X- _ O

D -X- _ O
Additional -X- _ O
VQG -X- _ B-TaskName
Samples -X- _ O
Figure -X- _ O
6 -X- _ O
and -X- _ O
Figure -X- _ O
7 -X- _ O
display -X- _ O
the -X- _ O
10 -X- _ O
first -X- _ O
dialog -X- _ O
samples -X- _ O
produced -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
, -X- _ O
while -X- _ O
figures -X- _ O
8 -X- _ O
, -X- _ O
9 -X- _ O
, -X- _ O
and -X- _ O
10 -X- _ O
display -X- _ O
the -X- _ O
15 -X- _ O
first -X- _ O
dialog -X- _ O
samples -X- _ O
produced -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
on -X- _ O

VQAv2.32 -X- _ O

Human -X- _ O
the -X- _ O
big -X- _ O
yellow -X- _ O
object -X- _ O
is -X- _ O
what -X- _ O
shape -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
sphere -X- _ O
pretrain -X- _ B-MethodName
there -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
rubber -X- _ O
cylinder -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
shape -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
person -X- _ O
’s -X- _ O
head -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
yellow -X- _ O
on -X- _ O
or -X- _ O
an -X- _ O
material -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
gray -X- _ O
thing -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
does -X- _ O
that -X- _ O
tiny -X- _ O
object -X- _ O
have -X- _ O
objects -X- _ O
to -X- _ O
its -X- _ O
left -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
shape -X- _ O
is -X- _ O
the -X- _ O
big -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
matte -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

what -X- _ O
is -X- _ O
the -X- _ O
shape -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
behind -X- _ O
the -X- _ O
big -X- _ O
yellow -X- _ O
thing -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
? -X- _ O

Human -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
objects -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
red -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

A:3 -X- _ O
pretrain -X- _ B-MethodName
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
purple -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
objects -X- _ O
are -X- _ O
either -X- _ O
large -X- _ O
green -X- _ O
metallic -X- _ O
objects -X- _ O
or -X- _ O
tiny -X- _ O
objects -X- _ O
that -X- _ O
are -X- _ O
behind -X- _ O
the -X- _ O
tiny -X- _ O
purple -X- _ O
metallic -X- _ O
thing -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
tiny -X- _ O
cubes -X- _ O
things -X- _ O
things -X- _ O
things -X- _ O
things -X- _ O
things -X- _ O
both -X- _ O
things -X- _ O
as -X- _ O
things -X- _ O
that -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
objects -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
material -X- _ O
as -X- _ O
the -X- _ O
tiny -X- _ O
cyan -X- _ O
thing -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
are -X- _ O
there -X- _ O
any -X- _ O
blue -X- _ O
objects -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
objects -X- _ O
are -X- _ O
either -X- _ O
big -X- _ O
objects -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
yellow -X- _ O
object -X- _ O
or -X- _ O
big -X- _ O
matte -X- _ O
objects -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
objects -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
object -X- _ O
? -X- _ O

Human -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
material -X- _ O
as -X- _ O
the -X- _ O
large -X- _ O
green -X- _ O
object -X- _ O
? -X- _ O

A:3 -X- _ O
pretrain -X- _ B-MethodName
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
purple -X- _ O
rubber -X- _ O
cylinder -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
objects -X- _ O
are -X- _ O
either -X- _ O
tiny -X- _ O
cyan -X- _ O
things -X- _ O
or -X- _ O
big -X- _ O
cyan -X- _ O
things -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
tiny -X- _ O
cubes -X- _ O
things -X- _ O
things -X- _ O
things -X- _ O
things -X- _ O
things -X- _ O
both -X- _ O
things -X- _ O
as -X- _ O
things -X- _ O
that -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
objects -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
yellow -X- _ O
object -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
how -X- _ O
many -X- _ O
things -X- _ O
does -X- _ O
that -X- _ O
large -X- _ O
thing -X- _ O
have -X- _ O
to -X- _ O
its -X- _ O
behind -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
green -X- _ O
cylinder -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
objects -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
in -X- _ O
the -X- _ O
cylinder -X- _ O
? -X- _ O

Human -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
purple -X- _ O
metallic -X- _ O
thing -X- _ O
? -X- _ O

A:1 -X- _ O
pretrain -X- _ B-MethodName
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
objects -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
tiny -X- _ O
rubber -X- _ O
cylinder -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
purple -X- _ O
objects -X- _ O
are -X- _ O
either -X- _ O
small -X- _ O
matte -X- _ O
objects -X- _ O
or -X- _ O
big -X- _ O
matte -X- _ O
blocks -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
gray -X- _ O
in -X- _ O
big -X- _ O
purple -X- _ O
purple -X- _ O
purple -X- _ O
many -X- _ O
or -X- _ O
many -X- _ O
gray -X- _ O
matte -X- _ O
matte -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
large -X- _ O
rubber -X- _ O
cylinder -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
in -X- _ O
the -X- _ O
are -X- _ O
of -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
large -X- _ O
cylinder -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
tiny -X- _ O
things -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
large -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
in -X- _ O
the -X- _ O
are -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
that -X- _ O
large -X- _ O
thing -X- _ O
? -X- _ O

Human -X- _ O
what -X- _ O
shape -X- _ O
is -X- _ O
the -X- _ O
big -X- _ O
matte -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
right -X- _ O
side -X- _ O
ofthe -X- _ O
big -X- _ O
cyan -X- _ O
matte -X- _ O
object -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
cylinder -X- _ O
pretrain -X- _ B-MethodName
the -X- _ O
cyan -X- _ O
matte -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
brown -X- _ O
object -X- _ O
is -X- _ O
what -X- _ O
shape -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
shape -X- _ O
is -X- _ O
the -X- _ O
cyan -X- _ O
matte -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
behind -X- _ O
the -X- _ O
cylinder -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
yellow -X- _ O
big -X- _ O
either -X- _ O
either -X- _ O
that -X- _ O
that -X- _ O
that -X- _ O
more -X- _ O
that -X- _ O
metal -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
gray -X- _ O
thing -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
blocks -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
things -X- _ O
in -X- _ O
the -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
tiny -X- _ O
things -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
large -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

what -X- _ O
is -X- _ O
the -X- _ O
shape -X- _ O
of -X- _ O
that -X- _ O
large -X- _ O
thing -X- _ O
? -X- _ O

Figure -X- _ O
6 -X- _ O
: -X- _ O
Samples -X- _ O
on -X- _ O
CLEVR.33 -X- _ B-DatasetName

Human -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
rubber -X- _ O
cylinder -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
big -X- _ O
cylinder -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
small -X- _ O
pretrain -X- _ B-MethodName
there -X- _ O
is -X- _ O
a -X- _ O
purple -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
purple -X- _ O
rubber -X- _ O
cylinder -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
shape -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
size -X- _ O
is -X- _ O
the -X- _ O
gray -X- _ O
ball -X- _ O
that -X- _ O
is -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
purple -X- _ O
sphere -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
that -X- _ O
greater -X- _ O
tiny -X- _ O
as -X- _ O
shiny -X- _ O
both -X- _ O
are -X- _ O
a -X- _ O
tiny -X- _ O
it -X- _ O
either -X- _ O
ball -X- _ O
right -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
big -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
big -X- _ O
matte -X- _ O
cylinder -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
shape -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
how -X- _ O
material -X- _ O
is -X- _ O
the -X- _ O
yellow -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
big -X- _ O
is -X- _ O
the -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
matte -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
size -X- _ O
is -X- _ O
the -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
behind -X- _ O
the -X- _ O
large -X- _ O
red -X- _ O
thing -X- _ O
? -X- _ O

Human -X- _ B-MethodName
There -X- _ O
is -X- _ O
a -X- _ O
shiny -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
both -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
matte -X- _ O
thing -X- _ O
and -X- _ O
behind -X- _ O
the -X- _ O
large -X- _ O
yellow -X- _ O
cube -X- _ O
; -X- _ O
what -X- _ O
size -X- _ O
is -X- _ O
it -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
small -X- _ O
pretrain -X- _ B-MethodName
there -X- _ O
is -X- _ O
a -X- _ O
big -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
rubber -X- _ O
cylinder -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
shape -X- _ O
pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
there -X- _ O
is -X- _ O
a -X- _ O
brown -X- _ O
matte -X- _ O
object -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
cyan -X- _ O
object -X- _ O
; -X- _ O
what -X- _ O
shape -X- _ O
is -X- _ O
it -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
yellow -X- _ O
big -X- _ O
either -X- _ O
either -X- _ O
that -X- _ O
that -X- _ O
that -X- _ O
more -X- _ O
that -X- _ O
metal -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
gray -X- _ O
thing -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
material -X- _ O
of -X- _ O
that -X- _ O
block -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
shape -X- _ O
is -X- _ O
the -X- _ O
big -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
the -X- _ O
big -X- _ O
cyan -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

what -X- _ O
is -X- _ O
the -X- _ O
shape -X- _ O
of -X- _ O
that -X- _ O
large -X- _ O
thing -X- _ O
? -X- _ O

Human -X- _ B-MethodName
there -X- _ O
is -X- _ O
a -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
rubber -X- _ O
cylinder -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
shape -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
sphere -X- _ O
pretrain -X- _ B-MethodName
there -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
rubber -X- _ O
cylinder -X- _ O
; -X- _ O
what -X- _ O
is -X- _ O
its -X- _ O
shape -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
shape -X- _ O
is -X- _ O
the -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
the -X- _ O
cylinder -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
yellow -X- _ O
yellow -X- _ O
and -X- _ O
cube -X- _ O
shape -X- _ O
behind -X- _ O
cubes -X- _ O
shape -X- _ O
less -X- _ O
small -X- _ O
equal -X- _ O
shape -X- _ O
small -X- _ O
equal -X- _ O
large -X- _ O
large -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
in -X- _ O
the -X- _ O
color -X- _ O
are -X- _ O
of -X- _ O
same -X- _ O
material -X- _ O
as -X- _ O
the -X- _ O
green -X- _ O
shiny -X- _ O
object -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
how -X- _ O
many -X- _ O
spheres -X- _ O
anything -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
shape -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
cyan -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
And -X- _ O
shape -X- _ O
? -X- _ O

Human -X- _ B-MethodName
what -X- _ O
is -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
asthe -X- _ O
large -X- _ O
gray -X- _ O
object -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
green -X- _ O
pretrain -X- _ B-MethodName
there -X- _ O
is -X- _ O
another -X- _ O
rubber -X- _ O
object -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
brown -X- _ O
object -X- _ O
; -X- _ O
what -X- _ O
color -X- _ O
is -X- _ O
it -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
the -X- _ O
tiny -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
sphere -X- _ O
less -X- _ O
how -X- _ O
an -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
objects -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
tiny -X- _ O
blue -X- _ O
object -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
what -X- _ O
size -X- _ O
is -X- _ O
that -X- _ O
cylinder -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
color -X- _ O
of -X- _ O
the -X- _ O
tiny -X- _ O
matte -X- _ O
thing -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
what -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
small -X- _ O
thing -X- _ O
? -X- _ O

Human -X- _ B-MethodName
what -X- _ O
number -X- _ O
of -X- _ O
shiny -X- _ O
objects -X- _ O
are -X- _ O
cyan -X- _ O
spheres -X- _ O
or -X- _ O
tiny -X- _ O
balls -X- _ O
? -X- _ O

A:4 -X- _ O
pretrain -X- _ B-MethodName
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
brown -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
cyan -X- _ O
rubber -X- _ O
thing -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
many -X- _ O
yellow -X- _ O
do -X- _ O
do -X- _ O
do -X- _ O
either -X- _ O
do -X- _ O
either -X- _ O
do -X- _ O
balls -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O

what -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
there -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
shape -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
gray -X- _ O
thing -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
of -X- _ O
same -X- _ O
color -X- _ O
as -X- _ O
ball -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
material -X- _ O
as -X- _ O
the -X- _ O
small -X- _ O
cyan -X- _ O
cylinder -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
how -X- _ O
many -X- _ O
other -X- _ O
things -X- _ O
in -X- _ O
the -X- _ O
material -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
thing -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
material -X- _ O
as -X- _ O
green -X- _ O
thing -X- _ O
? -X- _ O

Figure -X- _ O
7 -X- _ O
: -X- _ O
Samples -X- _ O
on -X- _ O
Clevr.34 -X- _ O

Human -X- _ B-MethodName
How -X- _ O
many -X- _ O
trains -X- _ O
? -X- _ O

A:1 -X- _ O
pretrain -X- _ B-MethodName
How -X- _ O
many -X- _ O
trains -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
picture -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName

RL -X- _ O

How -X- _ O
many -X- _ O
trains -X- _ O
are -X- _ O
shown -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
How -X- _ O
many -X- _ O
people -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
picture -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
windows -X- _ O
are -X- _ O
here -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
different -X- _ O
ways -X- _ O
would -X- _ O
we -X- _ O
take -X- _ O
them -X- _ O
to -X- _ O
reach -X- _ O
Human -X- _ B-MethodName

What -X- _ O
is -X- _ O
the -X- _ O
man -X- _ O
wearing -X- _ O
over -X- _ O
his -X- _ O
shirt -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
nothing -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
is -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
person -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
is -X- _ O
written -X- _ O
on -X- _ O
the -X- _ O
person -X- _ O
’s -X- _ O
right -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
Is -X- _ O
this -X- _ O
child -X- _ O
old -X- _ O
or -X- _ O
unloaded -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
of -X- _ O
the -X- _ O
world -X- _ O
’s -X- _ O
a -X- _ O
few -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
different -X- _ O
shapes -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
and -X- _ O
used -X- _ O
by -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
planes -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
on -X- _ O
top -X- _ O
? -X- _ O

Human -X- _ B-MethodName
Is -X- _ O
the -X- _ O
fence -X- _ O
in -X- _ O
the -X- _ O
background -X- _ O
metal -X- _ O
or -X- _ O
wood -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
metal -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
kind -X- _ O
of -X- _ O
dog -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
dog -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
kind -X- _ O
of -X- _ O
dog -X- _ O
is -X- _ O
this -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
is -X- _ O
150 -X- _ O
seated -X- _ O
over -X- _ O
theware -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
to -X- _ O
be -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

Which -X- _ O
item -X- _ O
has -X- _ O
more -X- _ O
aggressive -X- _ O
up -X- _ O
their -X- _ O
legs -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
different -X- _ O
species -X- _ O
have -X- _ O
been -X- _ O
captured -X- _ O
and -X- _ O
tagged -X- _ O
here -X- _ O

Human -X- _ B-MethodName
What -X- _ O
is -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
the -X- _ O
red -X- _ O
book -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
harry -X- _ O
potter -X- _ O
pretrain -X- _ B-MethodName

What -X- _ O
is -X- _ O
the -X- _ O
cat -X- _ O
inside -X- _ O
of -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
Is -X- _ O
the -X- _ O
cat -X- _ O
inside -X- _ O
or -X- _ O
outside -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
man -X- _ O
’s -X- _ O
shirt -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName
The -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
world -X- _ O
’s -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

Which -X- _ O
item -X- _ O
appears -X- _ O
higher -X- _ O
into -X- _ O
one -X- _ O
and -X- _ O
lower -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
was -X- _ O
that -X- _ O
? -X- _ O

Human -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
fire -X- _ O
hydrant -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
red -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
hydrant -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
hydrant -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
man -X- _ O
’s -X- _ O
bat -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
thing -X- _ O
that -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Which -X- _ O
color -X- _ O
is -X- _ O
this -X- _ O
fire -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
will -X- _ O
your -X- _ O
feet -X- _ O
color -X- _ O
look -X- _ O
? -X- _ O

Human -X- _ B-MethodName
How -X- _ O
many -X- _ O
wheels -X- _ O
does -X- _ O
the -X- _ O
truck -X- _ O
have -X- _ O
? -X- _ O

A:3 -X- _ O
pretrain -X- _ B-MethodName
How -X- _ O
many -X- _ O
people -X- _ O
are -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
bus -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName

RL -X- _ O
How -X- _ O
many -X- _ O
slices -X- _ O
ofists -X- _ O
are -X- _ O
on -X- _ O
the -X- _ O
plate -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
Is -X- _ O
summer -X- _ O
out -X- _ O
or -X- _ O
cloudy -X- _ O
next -X- _ O
to -X- _ O
Winchester -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
most -X- _ O
recent -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
recent -X- _ O
years -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
pieces -X- _ O
are -X- _ O
here -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
different -X- _ O
objects -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
? -X- _ O

Figure -X- _ O
8 -X- _ O
: -X- _ O
Samples -X- _ O
on -X- _ O
VQA.35 -X- _ O

Human -X- _ B-MethodName
What -X- _ O
is -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
round -X- _ O
dome -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
flag -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
top -X- _ O
right -X- _ O
mean -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName

RL -X- _ O
What -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
front -X- _ O
of -X- _ O
this -X- _ O
event -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
zombie -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
mouse -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
is -X- _ O
a -X- _ O
bit -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Where -X- _ O
could -X- _ O
one -X- _ O
travel -X- _ O
park -X- _ O
located -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
will -X- _ O
your -X- _ O
shoes -X- _ O
look -X- _ O
? -X- _ O

Human -X- _ B-MethodName
Where -X- _ O
is -X- _ O
the -X- _ O
chain -X- _ O
link -X- _ O
fence -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
background -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
is -X- _ O
he -X- _ O
holding -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O

What -X- _ O
is -X- _ O
he -X- _ O
fire -X- _ O
hydrant -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
mazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O

Who -X- _ O
is -X- _ O
closest -X- _ O
to -X- _ O
the -X- _ O
paint -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
is -X- _ O
a -X- _ O
great -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Which -X- _ O
item -X- _ O
represents -X- _ O
than -X- _ O
both -X- _ O
ends -X- _ O
and -X- _ O
lower -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
How -X- _ O
much -X- _ O
food -X- _ O
has -X- _ O
it -X- _ O
given -X- _ O
him -X- _ O
? -X- _ O

Human -X- _ B-MethodName
What -X- _ O
activity -X- _ O
are -X- _ O
these -X- _ O
people -X- _ O
doing -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
surfing -X- _ O
pretrain -X- _ B-MethodName

What -X- _ O
is -X- _ O
the -X- _ O
person -X- _ O
doing -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O

What -X- _ O
is -X- _ O
the -X- _ O
person -X- _ O
doing -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
noodles -X- _ O
noodles -X- _ O
noodles -X- _ O
noodles -X- _ O
noodles -X- _ O
noodles -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
How -X- _ O
many -X- _ O
umbrellas -X- _ O
are -X- _ O
visible -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Which -X- _ O
game -X- _ O
does -X- _ O
he -X- _ O
play -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
was -X- _ O
that -X- _ O
for -X- _ O
? -X- _ O

Human -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
umbrella -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
black -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
cat -X- _ O
? -X- _ O
pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
cat -X- _ O
? -X- _ O
scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
man -X- _ O
’s -X- _ O
shirt -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
other -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
past -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

Which -X- _ O
item -X- _ O
does -X- _ O
n’t -X- _ O
both -X- _ O
turn -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
of -X- _ O
clothing -X- _ O
did -X- _ O
he -X- _ O
get -X- _ O
? -X- _ O

Human -X- _ B-MethodName
How -X- _ O
many -X- _ O
planes -X- _ O
are -X- _ O
shown -X- _ O
? -X- _ O

A:1 -X- _ O
pretrain -X- _ B-MethodName
How -X- _ O
many -X- _ O
jets -X- _ O
are -X- _ O
there -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName

RL -X- _ O
How -X- _ O
many -X- _ O
jets -X- _ O
are -X- _ O
there -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
How -X- _ O
many -X- _ O
skater -X- _ O
does -X- _ O
Green -X- _ O
cents -X- _ O
have -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ I-MethodName
ext -X- _ I-MethodName

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
surf -X- _ O
worthy -X- _ O
are -X- _ O
here -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

How -X- _ O
many -X- _ O
different -X- _ O
ways -X- _ O
should -X- _ O
one -X- _ O
ask -X- _ O
if -X- _ O
she -X- _ O
wants -X- _ O
Human -X- _ B-MethodName

What -X- _ O
is -X- _ O
this -X- _ O
animal -X- _ O
called -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
horse -X- _ O
pretrain -X- _ B-MethodName

What -X- _ O
is -X- _ O
the -X- _ O
animal -X- _ O
on -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
animal -X- _ O
is -X- _ O
shown -X- _ O
on -X- _ O
the -X- _ O
ground -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
has -X- _ O
to -X- _ O
make -X- _ O
of -X- _ O
the -X- _ O
pies -X- _ O
that -X- _ O
, -X- _ O
should -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
next -X- _ O
week -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
week -X- _ O
, -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Which -X- _ O
item -X- _ O
does -X- _ O
n’t -X- _ O
turn -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
was -X- _ O
that -X- _ O
? -X- _ O

Figure -X- _ O
9 -X- _ O
: -X- _ O
Samples -X- _ O
on -X- _ O
VQA.36 -X- _ O

Human -X- _ B-MethodName
What -X- _ O
color -X- _ O
spot -X- _ O
does -X- _ O
the -X- _ O
horse -X- _ O
have -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
white -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
animal -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName

What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
door -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
A -X- _ O
TM -X- _ O
basketball -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
same -X- _ O
thing -X- _ O
that -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
of -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Which -X- _ O
color -X- _ O
is -X- _ O
his -X- _ O
socks -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
will -X- _ O
your -X- _ O
shoes -X- _ O
look -X- _ O
? -X- _ O

Human -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
girls -X- _ O
pants -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
blue -X- _ O
pretrain -X- _ B-MethodName
What -X- _ O
color -X- _ O
is -X- _ O
the -X- _ O
man -X- _ O
’s -X- _ O
blue -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
color -X- _ O
are -X- _ O
the -X- _ O
bird -X- _ O
’s -X- _ O
pants -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
first -X- _ O
thing -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O
Which -X- _ O
color -X- _ O
is -X- _ O
this -X- _ O
fire -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
color -X- _ O
of -X- _ O
clothing -X- _ O
did -X- _ O
he -X- _ O
get -X- _ O
? -X- _ O

Human -X- _ B-MethodName
What -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
woman -X- _ O
’s -X- _ O
head -X- _ O
? -X- _ O

A -X- _ O
: -X- _ O
helmet -X- _ O
pretrain -X- _ B-MethodName

What -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
girl -X- _ O
’s -X- _ O
head -X- _ O
? -X- _ O

pretrain -X- _ B-MethodName

+ -X- _ O
RL -X- _ O
What -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
person -X- _ O
’s -X- _ O
head -X- _ O
? -X- _ O

scratch -X- _ B-MethodName
AmazingAmazingAmazingAmazingAmazingAmazing -X- _ O
scratch+KL -X- _ B-MethodName
- -X- _ O
task -X- _ O
Who -X- _ O
is -X- _ O
behind -X- _ O
the -X- _ O
horse -X- _ O
? -X- _ O

scratch+KL -X- _ B-MethodName
- -X- _ O
ext -X- _ O

The -X- _ O
the -X- _ O
same -X- _ O
thing -X- _ O
that -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
to -X- _ O
the -X- _ O
TrufLL -X- _ B-MethodName
( -X- _ O
Task -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

Which -X- _ O
item -X- _ O
does -X- _ O
n’t -X- _ O
turn -X- _ O
? -X- _ O

TrufLL -X- _ B-MethodName
( -X- _ O
Ext -X- _ O
- -X- _ O
LM -X- _ O
) -X- _ O

What -X- _ O
was -X- _ O
that -X- _ O
? -X- _ O

Figure -X- _ O
10 -X- _ O
: -X- _ O
Samples -X- _ O
on -X- _ O
VQA.37 -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
2022 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
38 -X- _ O
- -X- _ O
45 -X- _ O
July -X- _ O
10 -X- _ O
- -X- _ O
15 -X- _ O
, -X- _ O
2022 -X- _ O
© -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Language -X- _ O
Model -X- _ O
Augmented -X- _ O
Monotonic -X- _ O
Attention -X- _ O
for -X- _ O
Simultaneous -X- _ O
Translation -X- _ O
Sathish -X- _ O
Indurthi§∗Mohd -X- _ O
Abbas -X- _ O
Zaidi‡ -X- _ O
Beomseok -X- _ O
Lee‡†Nikhil -X- _ O
Kumar -X- _ O
Lakumarapu‡†Sangha -X- _ O
Kim‡ -X- _ O
‡Samsung -X- _ O
Research -X- _ O
, -X- _ O
South -X- _ O
Korea§Zoom -X- _ O
AI -X- _ O
Lab -X- _ O
, -X- _ O
Singapore -X- _ O
sathishreddy.indurthi -X- _ O
@ -X- _ O
zoom.us -X- _ O
, -X- _ O
{ -X- _ O
abbas.zaidi -X- _ O
, -X- _ O
bsgunn.lee -X- _ O
, -X- _ O
n07.kumar -X- _ O
, -X- _ O
sangha01.kim -X- _ O
} -X- _ O
@ -X- _ O
samsung.com -X- _ O

Abstract -X- _ O
The -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
adaptive -X- _ O
policies -X- _ O
for -X- _ O
simultaneous -X- _ B-TaskName
neural -X- _ I-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
SNMT -X- _ B-TaskName
) -X- _ O
use -X- _ O
monotonic -X- _ O
attention -X- _ O
to -X- _ O
perform -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
decisions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
partial -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sequences -X- _ O
. -X- _ O

The -X- _ O
lack -X- _ O
of -X- _ O
sufficient -X- _ O
information -X- _ O
might -X- _ O
cause -X- _ O
the -X- _ O
monotonic -X- _ O
attention -X- _ O
to -X- _ O
take -X- _ O
poor -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
decisions -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
turn -X- _ O
negatively -X- _ O
affects -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
SNMT -X- _ B-TaskName
model -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
human -X- _ O
translators -X- _ O
make -X- _ O
better -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
decisions -X- _ O
since -X- _ O
they -X- _ O
can -X- _ O
anticipate -X- _ O
the -X- _ O
immediate -X- _ O
future -X- _ O
words -X- _ O
using -X- _ O
linguistic -X- _ O
information -X- _ O
and -X- _ O
domain -X- _ O
knowledge -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
framework -X- _ O
to -X- _ O
aid -X- _ O
monotonic -X- _ O
attention -X- _ O
with -X- _ O
an -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
improve -X- _ O
its -X- _ O
decisions -X- _ O
. -X- _ O

Experiments -X- _ O
on -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
English -X- _ O
- -X- _ O
German -X- _ O
and -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
speech -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
translation -X- _ O
tasks -X- _ O
show -X- _ O
the -X- _ O
future -X- _ O
information -X- _ O
from -X- _ O
language -X- _ O
model -X- _ O
improves -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
monotonic -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
model -X- _ O
further -X- _ O
. -X- _ O

1 -X- _ O

Introduction -X- _ O
A -X- _ O
typical -X- _ O
application -X- _ O
of -X- _ O
simultaneous -X- _ B-TaskName
neural -X- _ I-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
SNMT -X- _ B-TaskName
) -X- _ O
is -X- _ O
conversational -X- _ O
speech -X- _ O
or -X- _ O
live -X- _ O
video -X- _ O
caption -X- _ O
translation -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
achieve -X- _ O
live -X- _ O
translation -X- _ O
, -X- _ O
an -X- _ O
SNMT -X- _ B-TaskName
model -X- _ O
alternates -X- _ O
between -X- _ O
performing -X- _ O
read -X- _ O
from -X- _ O
source -X- _ O
sequence -X- _ O
and -X- _ O
write -X- _ O
to -X- _ O
target -X- _ O
sequence -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
decide -X- _ O
whether -X- _ O
to -X- _ O
read -X- _ O
orwrite -X- _ O
at -X- _ O
certain -X- _ O
moment -X- _ O
, -X- _ O
either -X- _ O
a -X- _ O
fixed -X- _ O
or -X- _ O
an -X- _ O
adaptive -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
policy -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
. -X- _ O

Earlier -X- _ O
approaches -X- _ O
in -X- _ O
simultaneous -X- _ O
translation -X- _ O
such -X- _ O
as -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019a -X- _ O
) -X- _ O
and -X- _ O
Dalvi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
employ -X- _ O
a -X- _ O
fixed -X- _ O
policy -X- _ O
that -X- _ O
alternate -X- _ O
between -X- _ O
read -X- _ O
andwrite -X- _ O
after -X- _ O
the -X- _ O
waiting -X- _ O
period -X- _ O
of -X- _ O
ktokens -X- _ O
. -X- _ O

To -X- _ O
alleviate -X- _ O
possible -X- _ O
long -X- _ O
delay -X- _ O
of -X- _ O
fixed -X- _ O
polices -X- _ O
, -X- _ O
recent -X- _ O
works -X- _ O
such -X- _ O
as -X- _ O
monotonic -X- _ B-MethodName
infinite -X- _ I-MethodName
lookback -X- _ I-MethodName
attention -X- _ I-MethodName
( -X- _ O
MILk -X- _ B-MethodName
) -X- _ O
( -X- _ O
Arivazhagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
monotonic -X- _ B-MethodName
multihead -X- _ I-MethodName
attention -X- _ I-MethodName
( -X- _ O
MMA -X- _ B-MethodName
) -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019c -X- _ O
) -X- _ O
developed -X- _ O
flexible -X- _ O
policies -X- _ O
using -X- _ O
monotonic -X- _ O
attention -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

∗⋆Work -X- _ O
done -X- _ O
while -X- _ O
at -X- _ O
Samsung -X- _ O
Research -X- _ O
†Equal -X- _ O
contribution -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
finetuned -X- _ O
XLM -X- _ O
- -X- _ O
RoBERTa -X- _ O
language -X- _ O
model -X- _ O
predicts -X- _ O
German -X- _ O
words -X- _ O
using -X- _ O
the -X- _ O
prefix -X- _ O
as -X- _ O
input. -X- _ O
( -X- _ O
Green -X- _ O
: -X- _ O
Correct -X- _ O
, -X- _ O
Red -X- _ O
: -X- _ O
Incorrect -X- _ O
, -X- _ O
Black -X- _ O
: -X- _ O
Neutral -X- _ O
) -X- _ O
. -X- _ O

While -X- _ O
these -X- _ O
monotonic -X- _ O
attention -X- _ O
anticipates -X- _ O
target -X- _ O
words -X- _ O
using -X- _ O
only -X- _ O
available -X- _ O
prefix -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sequence -X- _ O
, -X- _ O
human -X- _ O
translators -X- _ O
anticipate -X- _ O
the -X- _ O
target -X- _ O
words -X- _ O
using -X- _ O
their -X- _ O
language -X- _ O
expertise -X- _ O
( -X- _ O
linguistic -X- _ O
anticipation -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
contextual -X- _ O
information -X- _ O
( -X- _ O
extra -X- _ O
- -X- _ O
linguistic -X- _ O
anticipation -X- _ O
) -X- _ O
( -X- _ O
Vandepitte -X- _ O
, -X- _ O
2001 -X- _ O
) -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
human -X- _ O
translation -X- _ O
experts -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
augment -X- _ O
monotonic -X- _ O
attention -X- _ O
with -X- _ O
future -X- _ O
information -X- _ O
using -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O

( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
Integrating -X- _ O
the -X- _ O
external -X- _ O
information -X- _ O
effectively -X- _ O
into -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
MT -X- _ O
) -X- _ O
systems -X- _ O
has -X- _ O
been -X- _ O
explored -X- _ O
by -X- _ O
several -X- _ O
works -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
integrating -X- _ O
future -X- _ O
information -X- _ O
implicitly -X- _ O
into -X- _ O
SNMT -X- _ B-TaskName
system -X- _ O
during -X- _ O
training -X- _ O
is -X- _ O
explored -X- _ O
in -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
by -X- _ O
simultaneously -X- _ O
training -X- _ O
different -X- _ O
wait- -X- _ O
kSNMT -X- _ O
systems -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
no -X- _ O
previous -X- _ O
works -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
explicit -X- _ O
future -X- _ O
information -X- _ O
both -X- _ O
during -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
. -X- _ O

To -X- _ O
utilize -X- _ O
explicit -X- _ O
future -X- _ O
information -X- _ O
, -X- _ O
we -X- _ O
explored -X- _ O
to -X- _ O
integrate -X- _ O
future -X- _ O
information -X- _ O
from -X- _ O
LM -X- _ O
directly -X- _ O
into -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
MMA -X- _ O
model -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
it -X- _ O
did -X- _ O
not -X- _ O
provide -X- _ O
any -X- _ O
improvements -X- _ O
( -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
, -X- _ O
thus -X- _ O
motivating -X- _ O
us -X- _ O
to -X- _ O
explore -X- _ O
a -X- _ O
tighter -X- _ O
integration -X- _ O
of -X- _ O
the -X- _ O
LM -X- _ O
information -X- _ O
into -X- _ O
SNMT -X- _ B-TaskName
model -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explicitly -X- _ O
use -X- _ O
plausible -X- _ O
future38 -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
Overview -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
language -X- _ O
model -X- _ O
augmented -X- _ O
monotonic -X- _ O
attention -X- _ O
for -X- _ O
SNMT -X- _ B-TaskName
. -X- _ O

information -X- _ O
from -X- _ O
LM -X- _ O
during -X- _ O
training -X- _ O
by -X- _ O
transforming -X- _ O
the -X- _ O
monotonic -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
at -X- _ O
each -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
LM -X- _ O
takes -X- _ O
the -X- _ O
prefix -X- _ O
target -X- _ O
( -X- _ O
and -X- _ O
source -X- _ O
, -X- _ O
for -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
LM -X- _ O
) -X- _ O
sequence -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
probable -X- _ O
future -X- _ O
information -X- _ O
. -X- _ O

We -X- _ O
hypothesize -X- _ O
that -X- _ O
aiding -X- _ O
the -X- _ O
monotonic -X- _ O
attention -X- _ O
with -X- _ O
this -X- _ O
future -X- _ O
information -X- _ O
can -X- _ O
improve -X- _ O
MMA -X- _ O
model -X- _ O
’s -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
policy -X- _ O
, -X- _ O
eventually -X- _ O
leading -X- _ O
to -X- _ O
better -X- _ O
translation -X- _ O
with -X- _ O
less -X- _ O
delay -X- _ O
. -X- _ O

Several -X- _ O
experiments -X- _ O
on -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
( -X- _ O
Di -X- _ O
Gangi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O

EnglishGerman -X- _ O
and -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
speech -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
translation -X- _ O
tasks -X- _ O
with -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
show -X- _ O
clear -X- _ O
improvements -X- _ O
of -X- _ O
latency -X- _ O
- -X- _ O
quality -X- _ O
trade -X- _ O
- -X- _ O
offs -X- _ O
over -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
MMA -X- _ O
models -X- _ O
. -X- _ O

2 -X- _ O
Monotonic -X- _ B-MethodName
Attention -X- _ I-MethodName
with -X- _ I-MethodName
Future -X- _ I-MethodName
Information -X- _ I-MethodName
Model -X- _ I-MethodName
2.1 -X- _ O
Monotonic -X- _ O
Attention -X- _ O
In -X- _ O
simultaneous -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
SNMT -X- _ B-TaskName
) -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
yi∈ydepends -X- _ O
on -X- _ O
the -X- _ O
partial -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sequences -X- _ O
( -X- _ O
x≤j∈x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
i∈y -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
sequence -X- _ O
- -X- _ O
tosequence -X- _ O
based -X- _ O
SNMT -X- _ B-TaskName
model -X- _ O
, -X- _ O
each -X- _ O
target -X- _ O
token -X- _ O
yi -X- _ O
is -X- _ O
generated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
yi -X- _ O
= -X- _ O
Output -X- _ O
( -X- _ O
si -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
E -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
andD -X- _ O
( -X- _ O
. -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
layers -X- _ O
, -X- _ O
and -X- _ O
ciis -X- _ O
a -X- _ O
context -X- _ O
vector -X- _ O
. -X- _ O

In -X- _ O
monotonic -X- _ O
attention -X- _ O
based -X- _ O
SNMT -X- _ B-TaskName
, -X- _ O
the -X- _ O
context -X- _ O
vector -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
ei -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
MonotonicEnergy -X- _ O
( -X- _ O
si−1 -X- _ O
, -X- _ O
hj -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
pi -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
Sigmoid -X- _ O
( -X- _ O
ei -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
zi -X- _ O
, -X- _ O
j∼Bernoulli -X- _ O
( -X- _ O
pi -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
When -X- _ O
generating -X- _ O
a -X- _ O
target -X- _ O
token -X- _ O
yi -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
chooses -X- _ O
whether -X- _ O
to -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
based -X- _ O
on -X- _ O
Bernoulli -X- _ O
selection -X- _ O
probability -X- _ O
pi -X- _ O
, -X- _ O
j -X- _ O
. -X- _ O

When -X- _ O
zi -X- _ O
, -X- _ O
j= -X- _ O
1 -X- _ O
( -X- _ O
write -X- _ O
) -X- _ O
, -X- _ O
model -X- _ O
sets -X- _ O
ti -X- _ O
= -X- _ O
j -X- _ O
, -X- _ O
ci -X- _ O
= -X- _ O
hjand -X- _ O
generates -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
yi -X- _ O
. -X- _ O

Forzi -X- _ O
, -X- _ O
j= -X- _ O
0 -X- _ O
( -X- _ O
read -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
sets -X- _ O
ti -X- _ O
= -X- _ O
j+ -X- _ O
1and -X- _ O
repeats -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
to -X- _ O
6 -X- _ O
. -X- _ O

Here -X- _ O
tirefers -X- _ O
to -X- _ O
the -X- _ O
index -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
when -X- _ O
decoder -X- _ O
needs -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
ith -X- _ O
target -X- _ O
token -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
hard -X- _ O
alignment -X- _ O
of -X- _ O
ci -X- _ O
= -X- _ O
hj -X- _ O
, -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
compute -X- _ O
an -X- _ O
expected -X- _ O
alignment -X- _ O
in -X- _ O
a -X- _ O
recurrent -X- _ O
manner -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
closed -X- _ O
- -X- _ O
form -X- _ O
parallel -X- _ O
solution -X- _ O
. -X- _ O

Arivazhagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
adopt -X- _ O
monotonic -X- _ O
attention -X- _ O
into -X- _ O
SNMT -X- _ B-TaskName
and -X- _ O
later -X- _ O
, -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019c -X- _ O
) -X- _ O
extend -X- _ O
it -X- _ O
to -X- _ O
MMA -X- _ O
to -X- _ O
integrate -X- _ O
it -X- _ O
into -X- _ O
the -X- _ O
Transformer -X- _ O
model -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

2.2 -X- _ O
Monotonic -X- _ O
Attention -X- _ O
with -X- _ O
Future -X- _ O
Information -X- _ O

The -X- _ O
monotonic -X- _ O
attention -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
performs -X- _ O
anticipation -X- _ O
based -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
currently -X- _ O
available -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
information -X- _ O
. -X- _ O

To -X- _ O
augment -X- _ O
this -X- _ O
anticipation -X- _ O
process -X- _ O
using -X- _ O
future -X- _ O
information -X- _ O
extracted -X- _ O
using -X- _ O
LMs -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
following -X- _ O
modifications -X- _ O
to -X- _ O
the -X- _ O
monotonic -X- _ O
attention -X- _ O
. -X- _ O

Future -X- _ O
Representation -X- _ O
Layer -X- _ O
: -X- _ O
At -X- _ O
every -X- _ O
decoding -X- _ O
step -X- _ O
i -X- _ O
, -X- _ O
the -X- _ O
previous -X- _ O
target -X- _ O
token -X- _ O
yi−1is -X- _ O
equipped -X- _ O
with -X- _ O
a -X- _ O
plausible -X- _ O
future -X- _ O
token -X- _ O
ˆyias -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
token -X- _ O
ˆyicomes -X- _ O
from -X- _ O
an -X- _ O
LM -X- _ O
possibly -X- _ O
with -X- _ O
a -X- _ O
different -X- _ O
tokenizer -X- _ O
and -X- _ O
vocabulary -X- _ O
set -X- _ O
, -X- _ O
applying -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
tokenizer -X- _ O
and -X- _ O
vocabulary -X- _ O
might -X- _ O
split -X- _ O
the -X- _ O
token -X- _ O
ˆyifurther -X- _ O
into -X- _ O
multiple -X- _ O
sub -X- _ O
- -X- _ O
tokens -X- _ O
{ -X- _ O
ˆy1 -X- _ O
i -X- _ O
} -X- _ O
. -X- _ O

To -X- _ O
get -X- _ O
a -X- _ O
single -X- _ O
future -X- _ O
token -X- _ O
representation -X- _ O
˜si∈ -X- _ O
Rdfrom -X- _ O
all -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
token -X- _ O
summary -X- _ O
layer -X- _ O
: -X- _ O
TheΓrepresents -X- _ O
a -X- _ O
general -X- _ O
sequence -X- _ O
representation -X- _ O
layer -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
Transformer -X- _ O
encoder -X- _ O
layer -X- _ O
or -X- _ O
a -X- _ O
simple -X- _ O
normalized -X- _ O
sum -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
token -X- _ O
representations.39 -X- _ O

We -X- _ O
enrich -X- _ O
˜siat -X- _ O
every -X- _ O
layer -X- _ O
lof -X- _ O
the -X- _ O
decoder -X- _ O
block -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
residual -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
. -X- _ O

˜sl -X- _ O
i -X- _ O
= -X- _ O
FFN -X- _ O
( -X- _ O
˜yl−1 -X- _ O
Monotonic -X- _ O
Energy -X- _ O
Layer -X- _ O
with -X- _ O
Future -X- _ O
Information -X- _ O
: -X- _ O

Despite -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
add -X- _ O
the -X- _ O
plausible -X- _ O
future -X- _ O
information -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
( -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
or -X- _ O
append -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
representation -X- _ O
yi−1 -X- _ O
, -X- _ O
the -X- _ O
MMA -X- _ O
read -X- _ O
/ -X- _ O
write -X- _ O
decisions -X- _ O
happen -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
˜siinto -X- _ O
the -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
instead -X- _ O
. -X- _ O

The -X- _ O
integration -X- _ O
is -X- _ O
carried -X- _ O
out -X- _ O
by -X- _ O
modifying -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
- -X- _ O
Eq -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O

We -X- _ O
compute -X- _ O
the -X- _ O
monotonic -X- _ O
energy -X- _ O
for -X- _ O
future -X- _ O
information -X- _ O
using -X- _ O
the -X- _ O
enriched -X- _ O
future -X- _ O
token -X- _ O
representation -X- _ O
˜siavailable -X- _ O
at -X- _ O
each -X- _ O
layer -X- _ O
: -X- _ O
˜ei -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
MonotonicEnergy -X- _ O
( -X- _ O
˜si -X- _ O
, -X- _ O
hj -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
We -X- _ O
integrate -X- _ O
the -X- _ O
future -X- _ O
monotonic -X- _ O
energy -X- _ O
function -X- _ O
into -X- _ O
Eq -X- _ O
. -X- _ O
5 -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
˜pi -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
Sigmoid -X- _ O
( -X- _ O
ei -X- _ O
, -X- _ O
j+ -X- _ O
˜ei -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
After -X- _ O
computing -X- _ O
˜pi -X- _ O
, -X- _ O
j -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
cisimilar -X- _ O
to -X- _ O
MMA -X- _ O
model -X- _ O
. -X- _ O

This -X- _ O
way -X- _ O
of -X- _ O
integration -X- _ O
of -X- _ O
future -X- _ O
information -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
condition -X- _ O
the -X- _ O
LM -X- _ O
output -X- _ O
usage -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
can -X- _ O
control -X- _ O
the -X- _ O
relative -X- _ O
weightage -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
LM -X- _ O
output -X- _ O
by -X- _ O
varying -X- _ O
the -X- _ O
˜ei -X- _ O
, -X- _ O
j -X- _ O
. -X- _ O

In -X- _ O
case -X- _ O
of -X- _ O
insufficient -X- _ O
source -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
low -X- _ O
latency -X- _ O
regime -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
decision -X- _ O
policy -X- _ O
to -X- _ O
rely -X- _ O
more -X- _ O
on -X- _ O
˜ei -X- _ O
, -X- _ O
j. -X- _ O
Inference -X- _ O
: -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
the -X- _ O
start -X- _ O
token -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
any -X- _ O
plausible -X- _ O
information -X- _ O
. -X- _ O

After -X- _ O
predicting -X- _ O
the -X- _ O
first -X- _ O
target -X- _ O
token -X- _ O
, -X- _ O
for -X- _ O
every -X- _ O
subsequent -X- _ O
prediction -X- _ O
of -X- _ O
target -X- _ O
token -X- _ O
yi -X- _ O
, -X- _ O
we -X- _ O
invoke -X- _ O
the -X- _ O
LM -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
next -X- _ O
plausible -X- _ O
future -X- _ O
token -X- _ O
and -X- _ O
integrate -X- _ O
this -X- _ O
new -X- _ O
information -X- _ O
into -X- _ O
Eq -X- _ O
. -X- _ O
10 -X- _ O
. -X- _ O

3 -X- _ O
Experiments -X- _ O
and -X- _ O
Results -X- _ O
3.1 -X- _ O
Experimental -X- _ O
Settings -X- _ O
Datasets -X- _ O
and -X- _ O
Metrics -X- _ O
: -X- _ O
We -X- _ O
conduct -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
English -X- _ O
( -X- _ O
En -X- _ O
) -X- _ O
-German -X- _ O
( -X- _ O
De -X- _ O
) -X- _ O
and -X- _ O
English -X- _ O
( -X- _ O
En -X- _ O
) -X- _ O
-French -X- _ O
( -X- _ O
Fr -X- _ O
) -X- _ O
speech -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
( -X- _ O
ST -X- _ O
) -X- _ O
translation -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
speech -X- _ O
sequence -X- _ O
is -X- _ O
represented -X- _ O
using -X- _ O
80 -X- _ O
- -X- _ O
dimensional -X- _ O
log -X- _ O
- -X- _ O
mel -X- _ O
filter -X- _ O
bank -X- _ O
features -X- _ O
. -X- _ O

The -X- _ O
target -X- _ O
sequence -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
subwords -X- _ O
using -X- _ O
a -X- _ O
SentencePiece -X- _ O
( -X- _ O
Kudo -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
unigram -X- _ O
vocabulary -X- _ O
of -X- _ O
size -X- _ O
10,000 -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
latency -X- _ O
and -X- _ O
quality -X- _ O
aspects -X- _ O
. -X- _ O

Weuse -X- _ O
Average -X- _ B-MetricName
Lagging -X- _ I-MetricName
( -X- _ O
AL -X- _ B-MetricName
) -X- _ O
as -X- _ O
our -X- _ O
latency -X- _ O
metric -X- _ O
and -X- _ O
case -X- _ O
- -X- _ O
sensitive -X- _ O
detokenized -X- _ O
SacreBLEU -X- _ B-MetricName
( -X- _ O
Post -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
best -X- _ O
models -X- _ O
are -X- _ O
chosen -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
results -X- _ O
and -X- _ O
reported -X- _ O
results -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
test -X- _ I-DatasetName
( -X- _ O
tst -X- _ O
- -X- _ O
COMMON -X- _ O
) -X- _ O
sets -X- _ O
. -X- _ O

Language -X- _ O
Models -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
proposed -X- _ O
modified -X- _ O
MMA -X- _ O
model -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pretrained -X- _ O
XLM -X- _ O
- -X- _ O
RoBERTa -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
model -X- _ O
from -X- _ O
Huggingface -X- _ O
Transformers1model -X- _ O
repository -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
LM -X- _ O
output -X- _ O
can -X- _ O
be -X- _ O
very -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
and -X- _ O
might -X- _ O
not -X- _ O
directly -X- _ O
suit -X- _ O
/ -X- _ O
cater -X- _ O
to -X- _ O
our -X- _ O
task -X- _ O
and -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
target -X- _ O
text -X- _ O
data -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
smaller -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
SLM -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
6 -X- _ O
Transformer -X- _ O
decoder -X- _ O
layers -X- _ O
, -X- _ O
512 -X- _ O
hidden -X- _ O
- -X- _ O
states -X- _ O
and -X- _ O
24 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
data -X- _ O
along -X- _ O
with -X- _ O
additional -X- _ O
data -X- _ O
augmentation -X- _ O
to -X- _ O
reduce -X- _ O
overfitting -X- _ O
. -X- _ O

The -X- _ O
SLM -X- _ O
helps -X- _ O
to -X- _ O
remove -X- _ O
the -X- _ O
issues -X- _ O
related -X- _ O
to -X- _ O
vocabulary -X- _ O
mismatch -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
Section -X- _ O
2.2 -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O
: -X- _ O
Our -X- _ O
base -X- _ O
model -X- _ O
is -X- _ O
adopted -X- _ O
from -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
predecision -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
of -X- _ O
7 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
simultaneousread -X- _ O
/ -X- _ O
write -X- _ O
decisions -X- _ O
are -X- _ O
made -X- _ O
after -X- _ O
every -X- _ O
seven -X- _ O
encoder -X- _ O
states -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
λorλlatency -X- _ B-HyperparameterName
to -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
hyperparameter -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
weighted -X- _ O
average -X- _ O
( -X- _ O
λavg -X- _ O
) -X- _ O
in -X- _ O
MMA -X- _ O
. -X- _ O

The -X- _ O
values -X- _ O
of -X- _ O
this -X- _ O
hyperparameter -X- _ O
λare -X- _ B-HyperparameterName
chosen -X- _ O
from -X- _ O
the -X- _ O
set -X- _ O
{ -X- _ O
0.01,0.05,0.1 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O

TheΓlayer -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
7 -X- _ O
computes -X- _ O
the -X- _ O
normalized -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
token -X- _ O
representations -X- _ O
. -X- _ O

For -X- _ O
SLM -X- _ O
, -X- _ O
it -X- _ O
simply -X- _ O
finds -X- _ O
the -X- _ O
embedding -X- _ O
since -X- _ O
it -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
vocabulary -X- _ O
set -X- _ O
. -X- _ O

All -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
NVIDIA -X- _ O
v100 -X- _ O
GPU -X- _ O
with -X- _ O
update -X- _ B-HyperparameterName
_ -X- _ I-HyperparameterName
freq -X- _ I-HyperparameterName
set -X- _ O
to -X- _ O
8 -X- _ B-HyperparameterValue
. -X- _ O

Simultaneous -X- _ O
Translation -X- _ O
Models -X- _ O
: -X- _ O
Even -X- _ O
though -X- _ O
future -X- _ O
information -X- _ O
can -X- _ O
be -X- _ O
integrated -X- _ O
explicitly -X- _ O
into -X- _ O
the -X- _ O
fixed -X- _ O
policy -X- _ O
approaches -X- _ O
such -X- _ O
as -X- _ O
Wait -X- _ B-MethodName
- -X- _ I-MethodName
K -X- _ I-MethodName
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
monotonic -X- _ O
attention -X- _ O
as -X- _ O
our -X- _ O
baseline -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
superior -X- _ O
performance -X- _ O
( -X- _ O
Arivazhagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019c -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
a -X- _ O
baseline -X- _ O
based -X- _ O
on -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2020 -X- _ O
) -X- _ O
work -X- _ O
, -X- _ O
called -X- _ O
as -X- _ O
MMA -X- _ B-MethodName
model -X- _ O
. -X- _ O

The -X- _ O
MMA -X- _ B-MethodName
model -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
embedding -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
are -X- _ O
set -X- _ O
to -X- _ O
392 -X- _ B-HyperparameterValue
, -X- _ O
whereas -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
’s -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
embeddings -X- _ B-HyperparameterName
are -X- _ O
set -X- _ O
to -X- _ O
256 -X- _ B-HyperparameterValue
to -X- _ O
have -X- _ O
similar -X- _ O
parameters -X- _ O
( -X- _ O
≈39 -X- _ O
M -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
two -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
1https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
huggingface.co -X- _ O
/ -X- _ O
transformers -X- _ O
/ -X- _ O
40 -X- _ O

Figure -X- _ O
3 -X- _ O
: -X- _ O
LM -X- _ O
prediction -X- _ O
weight -X- _ O
vs -X- _ O
λ -X- _ O
modified -X- _ O
MMA -X- _ B-MethodName
based -X- _ O
on -X- _ O
two -X- _ O
LMs -X- _ O
( -X- _ O
XLM -X- _ O
, -X- _ O
SLM -X- _ O
) -X- _ O
, -X- _ O
referred -X- _ O
as -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
XLM -X- _ I-MethodName
and -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
. -X- _ O

3.2 -X- _ O
Results -X- _ O
We -X- _ O
first -X- _ O
analyze -X- _ O
how -X- _ O
the -X- _ O
LM -X- _ O
predictions -X- _ O
are -X- _ O
being -X- _ O
utilized -X- _ O
by -X- _ O
the -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
relative -X- _ O
weight -X- _ O
given -X- _ O
to -X- _ O
model -X- _ O
’s -X- _ O
internal -X- _ O
states -X- _ O
versus -X- _ O
the -X- _ O
predictions -X- _ O
from -X- _ O
the -X- _ O
LM -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
the -X- _ O
monotonic -X- _ O
energies -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
LM -X- _ O
predictions -X- _ O
epred -X- _ O
( -X- _ O
Eq -X- _ O
. -X- _ O

9 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
output -X- _ O
tokens -X- _ O
eoutput -X- _ O
( -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O

Let -X- _ O
us -X- _ O
define -X- _ O
LM -X- _ O
prediction -X- _ O
weight -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
LMpw= -X- _ O
/ -X- _ O
parenleftbigg∥epred∥ -X- _ O

∥eoutput∥ -X- _ O
/ -X- _ O
parenrightbigg -X- _ O
In -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
plot -X- _ O
the -X- _ O
variation -X- _ O
of -X- _ O
LMpw -X- _ O
( -X- _ O
averaged -X- _ O
) -X- _ O
vs. -X- _ O
λ -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
two -X- _ O
additional -X- _ O
values -X- _ O
of -X- _ O
observe -X- _ O
that -X- _ O
as -X- _ O
the -X- _ O
latency -X- _ O
requirements -X- _ O
become -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
strict -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
starts -X- _ O
to -X- _ O
give -X- _ O
more -X- _ O
weightage -X- _ O
to -X- _ O
the -X- _ O
predictions -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
LM -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
information -X- _ O
coming -X- _ O
from -X- _ O
LM -X- _ O
predictions -X- _ O
based -X- _ O
on -X- _ O
latency -X- _ O
requirements -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
the -X- _ O
performance -X- _ O
improvements -X- _ O
obtained -X- _ O
from -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
. -X- _ O

By -X- _ O
varying -X- _ O
the -X- _ O
λ -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
separate -X- _ O
models -X- _ O
for -X- _ O
different -X- _ O
latency -X- _ O
regimes -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
and -X- _ O
latency -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
model -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
varied -X- _ O
by -X- _ O
controlling -X- _ O
the -X- _ O
speech -X- _ O
segment -X- _ O
size -X- _ O
during -X- _ O
the -X- _ O
inference -X- _ O
. -X- _ O

Speech -X- _ O
segment -X- _ O
size -X- _ O
or -X- _ O
step -X- _ O
size -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
duration -X- _ O
of -X- _ O
speech -X- _ O
( -X- _ O
in -X- _ O
ms -X- _ O
) -X- _ O
processed -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
read -X- _ O
decision -X- _ O
. -X- _ O

We -X- _ O
vary -X- _ O
these -X- _ O
hyperparameters -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
models -X- _ O
, -X- _ O
namely -X- _ O
MMA -X- _ B-MethodName
, -X- _ O
MMAXLM -X- _ B-MethodName
and -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
. -X- _ O

The -X- _ O
BLEU -X- _ B-MetricName
- -X- _ O
AL -X- _ B-MetricName
curves -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
provided -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
and -X- _ O
BLEU -X- _ B-MetricName
- -X- _ O
AL -X- _ B-MetricName
numbers -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
F -X- _ O
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
120 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
200 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
280 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
360 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
440 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
520MMA -X- _ B-HyperparameterValue
MMA- -X- _ B-MethodName
XLM -X- _ I-MethodName
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
( -X- _ O
a -X- _ O
) -X- _ O
EnDe -X- _ O
Task -X- _ O
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
120 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
200 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
280 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
360 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
440 -X- _ B-HyperparameterValue
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
520MMA -X- _ B-HyperparameterValue
MMA- -X- _ B-MethodName
XLM -X- _ I-MethodName
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
( -X- _ O
b -X- _ O
) -X- _ O
EnFr -X- _ O
Task -X- _ O
Figure -X- _ O
4 -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
vs -X- _ O
Average -X- _ B-MetricName
Lagging -X- _ I-MetricName
results -X- _ O
for -X- _ O
MMA -X- _ B-MethodName
, -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
XLM -X- _ I-MethodName
and -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
models -X- _ O
. -X- _ O

for -X- _ O
reference -X- _ O
. -X- _ O

We -X- _ O
vary -X- _ O
the -X- _ O
step -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
in -X- _ O
intervals -X- _ O
of -X- _ O
80ms -X- _ B-HyperparameterValue
from -X- _ O
120 -X- _ B-HyperparameterValue
ms -X- _ O
to -X- _ O
520 -X- _ B-HyperparameterValue
ms -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
get -X- _ O
performances -X- _ O
corresponding -X- _ O
to -X- _ O
different -X- _ O
latency -X- _ O
regimes -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
LM -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
using -X- _ O
both -X- _ O
XLM -X- _ O
and -X- _ O
SLM -X- _ O
provide -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
MMA -X- _ B-MethodName
model -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
improvements -X- _ O
in -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
1 -X- _ O
- -X- _ O
2 -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
consistently -X- _ O
across -X- _ O
all -X- _ O
the -X- _ O
latency -X- _ O
SLM -X- _ O
language -X- _ O
model -X- _ O
performs -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
MMA -X- _ B-MethodName
using -X- _ O
XLM -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
SLM -X- _ O
’s -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
prediction -X- _ O
task -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
XLM -X- _ O
, -X- _ O
30.15 -X- _ B-MetricValue
% -X- _ I-MetricValue
vs. -X- _ O
21.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
German -X- _ O
& -X- _ O
31.65 -X- _ B-MetricValue
% -X- _ I-MetricValue
vs. -X- _ O
18.45 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
French -X- _ O
. -X- _ O

The -X- _ O
high -X- _ O
accuracy -X- _ O
of -X- _ O
SLM -X- _ O
is -X- _ O
attributed -X- _ O
to -X- _ O
its -X- _ O
training -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
. -X- _ O

4 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
generic -X- _ O
framework -X- _ O
to -X- _ O
integrate -X- _ O
the -X- _ O
linguistic -X- _ O
and -X- _ O
extra -X- _ O
- -X- _ O
linguistic -X- _ O
information -X- _ O
into -X- _ O
simultaneous -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
rely -X- _ O
on -X- _ O
lan-41 -X- _ O

guage -X- _ O
models -X- _ O
to -X- _ O
extract -X- _ O
this -X- _ O
plausible -X- _ O
future -X- _ O
information -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
monotonic -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
infuse -X- _ O
this -X- _ O
information -X- _ O
. -X- _ O

Several -X- _ O
experiments -X- _ O
on -X- _ O
speech -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
translation -X- _ O
tasks -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
proposed -X- _ O
approach -X- _ O
on -X- _ O
obtaining -X- _ O
superior -X- _ O
quality -X- _ O
- -X- _ O
latency -X- _ O
trade -X- _ O
- -X- _ O
offs -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
monotonic -X- _ O
multihead -X- _ O
attention -X- _ O
. -X- _ O

A -X- _ O
LM -X- _ O
at -X- _ O
MMA -X- _ B-MethodName
Output -X- _ O
Layer -X- _ O
We -X- _ O
explored -X- _ O
a -X- _ O
naive -X- _ O
approach -X- _ O
of -X- _ O
integrating -X- _ O
LM -X- _ O
information -X- _ O
into -X- _ O
the -X- _ O
MMA -X- _ B-MethodName
. -X- _ O

In -X- _ O
this -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
the -X- _ O
future -X- _ O
information -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
LM -X- _ O
directly -X- _ O
into -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
MMA -X- _ B-MethodName
model -X- _ O
. -X- _ O

We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
experiment -X- _ O
as -X- _ O
‘ -X- _ O
LM -X- _ O
Rescoring -X- _ O
( -X- _ O
LMR -X- _ O
) -X- _ O
’ -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
model -X- _ O
is -X- _ O
called -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
LMR -X- _ I-MethodName
. -X- _ O

As -X- _ O
observed -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
, -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
LMR -X- _ I-MethodName
has -X- _ O
inferior -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
MMA -X- _ B-MethodName
model -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
LM -X- _ O
information -X- _ O
integration -X- _ O
is -X- _ O
only -X- _ O
done -X- _ O
at -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
MMA -X- _ B-MethodName
model -X- _ O
can -X- _ O
not -X- _ O
easily -X- _ O
discard -X- _ O
the -X- _ O
incorrect -X- _ O
information -X- _ O
from -X- _ O
LM -X- _ O
. -X- _ O

This -X- _ O
motivates -X- _ O
us -X- _ O
to -X- _ O
tightly -X- _ O
integrate -X- _ O
the -X- _ O
LM -X- _ O
information -X- _ O
into -X- _ O
the -X- _ O
simultaneous -X- _ O
model -X- _ O
. -X- _ O

B -X- _ O
Language -X- _ O
Models -X- _ O
As -X- _ O
mentioned -X- _ O
earlier -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
different -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LMs -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
anticipation -X- _ O
in -X- _ O
monotonic -X- _ O
attention -X- _ O
based -X- _ O
Simultaneous -X- _ O
models -X- _ O
. -X- _ O

B.1 -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
Roberta -X- _ I-MethodName
( -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
) -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
Large -X- _ O
model2was -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
100 -X- _ O
languages -X- _ O
CommonCrawl -X- _ O
corpora -X- _ O
total -X- _ O
size -X- _ O
of -X- _ O
2.5 -X- _ O
TB -X- _ O
with -X- _ O
550 -X- _ O
M -X- _ O
parameters -X- _ O
from -X- _ O
24 -X- _ O
layers -X- _ O
, -X- _ O
1024 -X- _ O
hidden -X- _ O
states -X- _ O
, -X- _ O
4096 -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
hidden -X- _ O
- -X- _ O
states -X- _ O
, -X- _ O
and -X- _ O
16 -X- _ O
heads -X- _ O
. -X- _ O

Total -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
is -X- _ O
558M -X- _ O
. -X- _ O

We -X- _ O
finetune -X- _ O
the -X- _ O
head -X- _ O
of -X- _ O
the -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
LM -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
objective -X- _ O
which -X- _ O
accounts -X- _ O
for -X- _ O
0.23 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
1.3 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O

B.2 -X- _ O
Smaller -X- _ O
Language -X- _ O
Model -X- _ O
Since -X- _ O
the -X- _ O
LM -X- _ O
predictions -X- _ O
are -X- _ O
computed -X- _ O
serially -X- _ O
during -X- _ O
inference -X- _ O
, -X- _ O
the -X- _ O
time -X- _ O
taken -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
2https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
huggingface.co -X- _ O
/ -X- _ O
xlm-roberta-largeLM -X- _ O
token -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
bottleneck -X- _ O
to -X- _ O
the -X- _ O
latency -X- _ O
requirements -X- _ O
. -X- _ O

To -X- _ O
reduce -X- _ O
the -X- _ O
LM -X- _ O
computation -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
smaller -X- _ O
Language -X- _ O
Model -X- _ O
( -X- _ O
SLM -X- _ O
) -X- _ O
from -X- _ O
scratch -X- _ O
using -X- _ O
the -X- _ O
Causal -X- _ O
Language -X- _ O
Modeling -X- _ O
objective -X- _ O
. -X- _ O

SLM -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
6 -X- _ O
Transformer -X- _ O
decoder -X- _ O
blocks -X- _ O
, -X- _ O
512 -X- _ O
hidden -X- _ O
- -X- _ O
states -X- _ O
, -X- _ O
2048 -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
hidden -X- _ O
- -X- _ O
states -X- _ O
& -X- _ O
8 -X- _ O
attention -X- _ O
heads -X- _ O
. -X- _ O

It -X- _ O
alleviates -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
token -X- _ O
summary -X- _ O
layer -X- _ O
since -X- _ O
it -X- _ O
shares -X- _ O
the -X- _ O
vocabulary -X- _ O
and -X- _ O
tokenization -X- _ O
with -X- _ O
the -X- _ O
MMA -X- _ B-MethodName
models -X- _ O
. -X- _ O

The -X- _ O
train -X- _ O
examples -X- _ O
are -X- _ O
at -X- _ O
the -X- _ O
sentence -X- _ O
level -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
forming -X- _ O
a -X- _ O
block -X- _ O
out -X- _ O
of -X- _ O
multiple -X- _ O
sentences -X- _ O
( -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
usual -X- _ O
case -X- _ O
for -X- _ O
Language -X- _ O
Models -X- _ O
) -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
target -X- _ O
texts -X- _ O
contain -X- _ O
lesser -X- _ O
than -X- _ O
250k -X- _ O
examples -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
additional -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
to -X- _ O
upsample -X- _ O
the -X- _ O
target -X- _ O
data -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
use -X- _ O
additional -X- _ O
data -X- _ O
to -X- _ O
avoid -X- _ O
overfitting -X- _ O
on -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
target -X- _ O
text -X- _ O
. -X- _ O

Details -X- _ O
have -X- _ O
been -X- _ O
provided -X- _ O
in -X- _ O
B.2.1 -X- _ O
. -X- _ O

B.2.1 -X- _ O
Data -X- _ O
Augmentation -X- _ O
Up -X- _ O
- -X- _ O
Sampling -X- _ O
: -X- _ O
To -X- _ O
boost -X- _ O
the -X- _ O
LM -X- _ O
performance -X- _ O
and -X- _ O
mitigate -X- _ O
overfitting -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
contextual -X- _ O
data -X- _ O
augmentation -X- _ O
( -X- _ O
Kobayashi -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
upsample -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
target -X- _ O
text -X- _ O
data -X- _ O
by -X- _ O
substituting -X- _ O
and -X- _ O
inserting -X- _ O
words -X- _ O
based -X- _ O
on -X- _ O
LM -X- _ O
predictions -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
NLPAUG3package -X- _ O
to -X- _ O
get -X- _ O
similar -X- _ O
words -X- _ O
based -X- _ O
on -X- _ O
contextual -X- _ O
embeddings -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
Hugging -X- _ O
Face -X- _ O
Repository -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
two -X- _ O
different -X- _ O
pretrained -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
models -X- _ O
for -X- _ O
German -X- _ O
bert -X- _ O
- -X- _ O
basegerman -X- _ O
- -X- _ O
dbmdz -X- _ O
- -X- _ O
cased -X- _ O
& -X- _ O
bert -X- _ O
- -X- _ O
base -X- _ O
- -X- _ O
german -X- _ O
- -X- _ O
dbmdzuncased -X- _ O
andbert -X- _ O
- -X- _ O
base -X- _ O
- -X- _ O
fr -X- _ O
- -X- _ O
cased -X- _ O
for -X- _ O
French -X- _ O
. -X- _ O

We -X- _ O
upsample -X- _ O
German -X- _ O
to -X- _ O
1.13 -X- _ O
M -X- _ O
examples -X- _ O
and -X- _ O
French -X- _ O
to -X- _ O
1.38 -X- _ O
M -X- _ O
examples -X- _ O
. -X- _ O

Additional -X- _ O
Data -X- _ O
: -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
additional -X- _ O
data -X- _ O
to -X- _ O
avoid -X- _ O
overfitting -X- _ O
. -X- _ O

For -X- _ O
German -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Newscrawl -X- _ O
( -X- _ O
WMT -X- _ O
19 -X- _ O
) -X- _ O
data -X- _ O
which -X- _ O
includes -X- _ O
58 -X- _ O
M -X- _ O
examples -X- _ O
. -X- _ O

For -X- _ O
French -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Common -X- _ O
Crawl -X- _ O
and -X- _ O
Europarl -X- _ O
to -X- _ O
augment -X- _ O
4 -X- _ O
M -X- _ O
extra -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
both -X- _ O
upsampling -X- _ O
and -X- _ O
data -X- _ O
augmentation -X- _ O
help -X- _ O
us -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
overfitting -X- _ O
on -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
dev -X- _ O
set -X- _ O
. -X- _ O

B.3 -X- _ O
Token -X- _ O
Prediction -X- _ O

For -X- _ O
each -X- _ O
output -X- _ O
token -X- _ O
, -X- _ O
the -X- _ O
LM -X- _ O
prediction -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
feeding -X- _ O
the -X- _ O
prefix -X- _ O
upto -X- _ O
that -X- _ O
token -X- _ O
to -X- _ O
the -X- _ O
LM -X- _ O
model -X- _ O
. -X- _ O

These -X- _ O
predictions -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
computed -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
sets -X- _ O
. -X- _ O

This -X- _ O
ensures -X- _ O
parallelization -X- _ O
and -X- _ O
avoids -X- _ O
the -X- _ O
overhead -X- _ O
to -X- _ O
run -X- _ O
the -X- _ O
LM -X- _ O
simultaneously -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O

During -X- _ O
3https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
pypi.org -X- _ O
/ -X- _ O
project -X- _ O
/ -X- _ O
nlpaug -X- _ O
/ -X- _ O
43 -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
EnDe -X- _ O
Task -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
EnFr -X- _ O
Task -X- _ O
Figure -X- _ O
5 -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
vs -X- _ O
Average -X- _ B-MetricName
Lagging -X- _ I-MetricName
results -X- _ O
for -X- _ O
MMA -X- _ B-MethodName
and -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
LMR -X- _ I-MethodName
models -X- _ O
. -X- _ O

Each -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
different -X- _ O
λ= -X- _ O
0.1,0.05,0.01values -X- _ O
. -X- _ O

Each -X- _ O
BLUE -X- _ B-MetricName
- -X- _ O
AL -X- _ B-MetricName
point -X- _ O
obtained -X- _ O
by -X- _ O
varying -X- _ O
step -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
λ -X- _ B-HyperparameterName
. -X- _ O
inference -X- _ O
, -X- _ O
the -X- _ O
LM -X- _ O
model -X- _ O
is -X- _ O
called -X- _ O
every -X- _ O
time -X- _ O
a -X- _ O
new -X- _ O
output -X- _ O
token -X- _ O
is -X- _ O
written -X- _ O
. -X- _ O

C -X- _ O
Dataset -X- _ O

The -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
dataset -X- _ O
comprises -X- _ O
of -X- _ O
English -X- _ O
TED -X- _ O
talks -X- _ O
, -X- _ O
the -X- _ O
translations -X- _ O
and -X- _ O
transcriptions -X- _ O
have -X- _ O
been -X- _ O
aligned -X- _ O
with -X- _ O
the -X- _ O
speech -X- _ O
at -X- _ O
sentence -X- _ O
level -X- _ O
. -X- _ O

Dataset -X- _ O
statistics -X- _ O
have -X- _ O
been -X- _ O
provided -X- _ O
in -X- _ O
the -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

D -X- _ O
Effect -X- _ O
of -X- _ O
LM -X- _ O
Size -X- _ O
on -X- _ O
Latency -X- _ O
- -X- _ O
Quality -X- _ O
We -X- _ O
train -X- _ O
several -X- _ O
SLM -X- _ B-MethodName
models -X- _ O
with -X- _ O
varying -X- _ O
sizes -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
top-1 -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O

As -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
LM -X- _ O
model -X- _ O
from -X- _ O
2 -X- _ B-HyperparameterValue
to -X- _ O
4 -X- _ B-HyperparameterValue
to -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ O
, -X- _ O
the -X- _ O
SLM -X- _ B-MethodName
and -X- _ O
the -X- _ O
proposed -X- _ O
MMA -X- _ B-MethodName
with -X- _ O
future -X- _ O
information -X- _ O
models -X- _ O
have -X- _ O
shown -X- _ O
performance -X- _ O
improvements -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
greater -X- _ O
than -X- _ O
6 -X- _ B-HyperparameterValue
does -X- _ O
not -X- _ O
yield -X- _ O
any -X- _ O
performance -X- _ O
improvements -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
notice -X- _ O
this -X- _ O
degradation -X- _ O
of -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
XLM -X- _ B-MethodName
model -X- _ O
while -X- _ O
varying -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
hidden -X- _ O
layers -X- _ O
in -X- _ O
the -X- _ O
LM -X- _ O
head -X- _ O
. -X- _ O

E -X- _ O
Training -X- _ O
Details -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
similar -X- _ O
to -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2020 -X- _ O
) -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
an -X- _ O
English -X- _ O
ASR -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
source -X- _ O
speech -X- _ O
data -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
simultaneous -X- _ O
model -X- _ O
without -X- _ O
the -X- _ O
latency -X- _ O
loss -X- _ O
( -X- _ O
setting -X- _ O
λlatency -X- _ O
= -X- _ O
0 -X- _ O
) -X- _ O
after -X- _ O
initializing -X- _ O
the -X- _ O
encoder -X- _ O
from -X- _ O
the -X- _ O
English -X- _ O
ASR -X- _ O
model -X- _ O
. -X- _ O

After -X- _ O
this -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
simultaneous -X- _ O
model -X- _ O
for -X- _ O
different -X- _ O
λs -X- _ B-HyperparameterName
. -X- _ O

This -X- _ O
training -X- _ O
process -X- _ O
is -X- _ O
repeated -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
reportedmodels -X- _ O
and -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
details -X- _ O
regarding -X- _ O
the -X- _ O
hyperparameters -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
have -X- _ O
been -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

F -X- _ O
BLEU -X- _ B-MetricName
- -X- _ O
AL -X- _ B-MetricName
Numbers -X- _ O
As -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
results -X- _ O
section -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
latency -X- _ B-HyperparameterName
weight -X- _ I-HyperparameterName
hyperparameter -X- _ I-HyperparameterName
( -X- _ O
λ -X- _ B-HyperparameterName
) -X- _ O
to -X- _ O
train -X- _ O
different -X- _ O
models -X- _ O
to -X- _ O
obtain -X- _ O
different -X- _ O
latency -X- _ O
regimes -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
vary -X- _ O
the -X- _ O
step -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
/ -X- _ O
speech -X- _ B-HyperparameterName
segment -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
during -X- _ O
inference -X- _ O
. -X- _ O

In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
18 -X- _ O
different -X- _ O
data -X- _ O
points -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
using -X- _ O
MMA -X- _ B-MethodName
, -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
XLM -X- _ I-MethodName
and -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
under -X- _ O
similar -X- _ O
hyperparameter -X- _ O
settings -X- _ O
. -X- _ O

It -X- _ O
will -X- _ O
help -X- _ O
the -X- _ O
reader -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
benefits -X- _ O
obtained -X- _ O
from -X- _ O
our -X- _ O
proposed -X- _ O
approach.44 -X- _ O

Task -X- _ O
# -X- _ O
Hours -X- _ O
# -X- _ O
Sentences -X- _ O
# -X- _ O
Talks -X- _ O
# -X- _ O
Words -X- _ O
Train -X- _ O
Dev -X- _ O
Test -X- _ O
Source -X- _ O
Target -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Dataset -X- _ O
Statistics -X- _ O
( -X- _ O
# -X- _ O
- -X- _ O
Number -X- _ O
of -X- _ O
) -X- _ O
MMA -X- _ B-MethodName
MMA -X- _ B-MethodName
- -X- _ I-MethodName
XLM -X- _ I-MethodName
/ -X- _ O
CLMHyperparameter -X- _ O
encoder -X- _ O
layers -X- _ O
12 -X- _ O
12 -X- _ O
encoder -X- _ O
embed -X- _ O
dim -X- _ O
292 -X- _ O
256 -X- _ O
encoder -X- _ O
ffn -X- _ O
embed -X- _ O
dim -X- _ O
2048 -X- _ O
2048 -X- _ O
encoder -X- _ O
attention -X- _ O
heads -X- _ O
4 -X- _ O
4 -X- _ O
decoder -X- _ O
layers -X- _ O
6 -X- _ O
6 -X- _ O
decoder -X- _ O
embed -X- _ O
dim -X- _ O
292 -X- _ O
256 -X- _ O
decoder -X- _ O
ffn -X- _ O
embed -X- _ O
dim -X- _ O
2048 -X- _ O
2048 -X- _ O
monotonic -X- _ O
ffn -X- _ O
embed -X- _ O
dim -X- _ O
– -X- _ O
2048 -X- _ O
decoder -X- _ O
attention -X- _ O
heads -X- _ O
4 -X- _ O
4 -X- _ O
optimizer -X- _ B-HyperparameterName
adam -X- _ O
adam -X- _ O
lr -X- _ B-HyperparameterName
scheduler -X- _ O
inverse -X- _ O
sqrt -X- _ O
inverse -X- _ O
sqrt -X- _ O
warmup -X- _ O
- -X- _ O
updates -X- _ O
4000 -X- _ O
4000 -X- _ O
label -X- _ O
- -X- _ O
smoothing -X- _ O
0.0 -X- _ O
0.0 -X- _ O
conv -X- _ O
layers -X- _ O
2 -X- _ O
2 -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Model -X- _ O
Hyperparameters -X- _ O
λ -X- _ B-HyperparameterName
Modelstep -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
AL -X- _ B-MetricName
( -X- _ O
msec -X- _ O
) -X- _ O
/ -X- _ O
BLEU -X- _ B-MetricName
) -X- _ O

English -X- _ O
- -X- _ O
German -X- _ O
Task -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
Task -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
vs -X- _ O
Average -X- _ B-MetricName
Lagging -X- _ I-MetricName
results -X- _ O
for -X- _ O
MMA -X- _ B-MethodName
, -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
XLM -X- _ I-MethodName
and -X- _ O
MMA -X- _ B-MethodName
- -X- _ I-MethodName
SLM -X- _ I-MethodName
models -X- _ O
on -X- _ O
English -X- _ O
- -X- _ O
German -X- _ O
and -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
using -X- _ O
different -X- _ O
latency -X- _ B-HyperparameterName
loss -X- _ I-HyperparameterName
weights -X- _ I-HyperparameterName
( -X- _ O
λ= -X- _ B-HyperparameterName
0.1,0.05,0.01 -X- _ B-HyperparameterValue
) -X- _ O
.45 -X- _ O

