-DOCSTART- -X- O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
1 -X- _ O
- -X- _ O
15 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O

2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
AdapLeR -X- _ B-MethodName
: -X- _ O
Speeding -X- _ O
up -X- _ O
Inference -X- _ B-TaskName
by -X- _ O
Adaptive -X- _ B-MethodName
Length -X- _ I-MethodName
Reduction -X- _ I-MethodName
Ali -X- _ O
Modarressi⋆ -X- _ O
Hosein -X- _ O
Mohebbi⋆† -X- _ O
Mohammad -X- _ O
Taher -X- _ O
Pilehvar -X- _ O
Iran -X- _ O
University -X- _ O
of -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
, -X- _ O
Iran -X- _ O
Cognitive -X- _ O
Science -X- _ O
and -X- _ O
AI -X- _ O
, -X- _ O
Tilburg -X- _ O
University -X- _ O
, -X- _ O
Netherlands -X- _ O
Tehran -X- _ O
Institute -X- _ O
for -X- _ O
Advanced -X- _ O
Studies -X- _ O
, -X- _ O
Khatam -X- _ O
University -X- _ O
, -X- _ O
Iran -X- _ O
m_modarressi -X- _ O
@ -X- _ O
comp.iust.ac.ir -X- _ O
h.mohebbi -X- _ O
@ -X- _ O
uvt.nl -X- _ O
mp792 -X- _ O
@ -X- _ O
cam.ac.uk -X- _ O
Abstract -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
shown -X- _ O
stellar -X- _ O
performance -X- _ O
in -X- _ O
various -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

But -X- _ O
, -X- _ O
this -X- _ O
usually -X- _ O
comes -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
high -X- _ O
latency -X- _ O
and -X- _ O
computation -X- _ O
, -X- _ O
hindering -X- _ O
their -X- _ O
usage -X- _ O
in -X- _ O
resource -X- _ O
- -X- _ O
limited -X- _ O
settings -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
approach -X- _ O
for -X- _ O
reducing -X- _ O
the -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
BERT -X- _ O
with -X- _ O
minimal -X- _ O
loss -X- _ O
in -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O

Our -X- _ O
method -X- _ O
dynamically -X- _ O
eliminates -X- _ O
less -X- _ O
contributing -X- _ O
tokens -X- _ O
through -X- _ O
layers -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
shorter -X- _ O
lengths -X- _ O
and -X- _ O
consequently -X- _ O
lower -X- _ O
computational -X- _ O
cost -X- _ O
. -X- _ O

To -X- _ O
determine -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
for -X- _ O
each -X- _ O
layer -X- _ O
using -X- _ O
a -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
saliency -X- _ O
method -X- _ O
. -X- _ O

Our -X- _ O
experiments -X- _ O
on -X- _ O
several -X- _ O
diverse -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
show -X- _ O
speedups -X- _ B-MetricName
up -X- _ O
to -X- _ O
22x -X- _ B-MetricValue
during -X- _ O
inference -X- _ O
time -X- _ O
without -X- _ O
much -X- _ O
sacrifice -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
validate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
tokens -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
using -X- _ O
human -X- _ O
annotations -X- _ O
in -X- _ O
the -X- _ O
ERASER -X- _ B-MetricName
benchmark -X- _ O
. -X- _ O

In -X- _ O
comparison -X- _ O
to -X- _ O
other -X- _ O
widely -X- _ O
used -X- _ O
strategies -X- _ O
for -X- _ O
selecting -X- _ O
important -X- _ O
tokens -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
saliency -X- _ B-MethodName
andattention -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
has -X- _ O
a -X- _ O
significantly -X- _ O
lower -X- _ O
false -X- _ O
positive -X- _ O
rate -X- _ O
in -X- _ O
generating -X- _ O
rationales -X- _ O
. -X- _ O

Our -X- _ O
code -X- _ O
is -X- _ O
freely -X- _ O
available -X- _ O
athttps -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
amodaresi -X- _ O
/ -X- _ O
AdapLeR -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
While -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
exhibit -X- _ O
remarkable -X- _ O
performances -X- _ O
on -X- _ O
various -X- _ O
NLP -X- _ O
benchmarks -X- _ O
, -X- _ O
their -X- _ O
excessive -X- _ O
computational -X- _ O
costs -X- _ O
and -X- _ O
high -X- _ O
inference -X- _ O
latency -X- _ O
have -X- _ O
limited -X- _ O
their -X- _ O
usage -X- _ O
in -X- _ O
resource -X- _ O
- -X- _ O
limited -X- _ O
settings -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
regard -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
various -X- _ O
attempts -X- _ O
at -X- _ O
improving -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
knowledge -X- _ O
distilation -X- _ O
( -X- _ O
Hinton -X- _ O
2020 -X- _ O
; -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
quantization -X- _ O
( -X- _ O
Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
⋆Equal -X- _ O
Contribution -X- _ O
. -X- _ O

†Work -X- _ O

done -X- _ O
as -X- _ O
a -X- _ O
Master -X- _ O
’s -X- _ O
student -X- _ O
at -X- _ O
IUST.pruning -X- _ O
( -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Michel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
progressive -X- _ O
module -X- _ O
replacing -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Despite -X- _ O
providing -X- _ O
significant -X- _ O
reduction -X- _ O
in -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
these -X- _ O
techniques -X- _ O
are -X- _ O
generally -X- _ O
static -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
they -X- _ O
dedicate -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
computation -X- _ O
to -X- _ O
all -X- _ O
inputs -X- _ O
, -X- _ O
irrespective -X- _ O
of -X- _ O
their -X- _ O
difficulty -X- _ O
. -X- _ O

A -X- _ O
number -X- _ O
of -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
also -X- _ O
proposed -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
efficiency -X- _ O
enhancement -X- _ O
sensitive -X- _ O
to -X- _ O
inputs -X- _ O
. -X- _ O

Early -X- _ O
exit -X- _ O
mechanism -X- _ O
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
guirre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
commonly -X- _ O
used -X- _ O
method -X- _ O
in -X- _ O
which -X- _ O
each -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
coupled -X- _ O
with -X- _ O
an -X- _ O
intermediate -X- _ O
classifier -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
label -X- _ O
. -X- _ O

At -X- _ O
inference -X- _ O
, -X- _ O
a -X- _ O
halting -X- _ O
condition -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
model -X- _ O
allows -X- _ O
an -X- _ O
example -X- _ O
to -X- _ O
exit -X- _ O
without -X- _ O
passing -X- _ O
through -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O

Various -X- _ O
halting -X- _ O
conditions -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
including -X- _ O
Shannon -X- _ O
’s -X- _ O
entropy -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
softmax -X- _ O
outputs -X- _ O
with -X- _ O
temperature -X- _ O
calibration -X- _ O
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
confidence -X- _ O
predictors -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
agreements -X- _ O
between -X- _ O
predictions -X- _ O
of -X- _ O
intermediate -X- _ O
classifiers -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Most -X- _ O
of -X- _ O
these -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
techniques -X- _ O
compress -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
depth -X- _ O
perspective -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
involved -X- _ O
encoder -X- _ O
layers -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
view -X- _ O
compression -X- _ O
from -X- _ O
the -X- _ O
width -X- _ O
perspective -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
hidden -X- _ O
states -X- _ O
. -X- _ O

( -X- _ O
Ethayarajh -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Klafka -X- _ O
and -X- _ O
Ettinger -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
particularly -X- _ O
promising -X- _ O
as -X- _ O
recent -X- _ O
analytical -X- _ O
studies -X- _ O
showed -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
redundant -X- _ O
encoded -X- _ O
information -X- _ O
in -X- _ O
token -X- _ O
representations -X- _ O
( -X- _ O
Klafka -X- _ O
and -X- _ O
Ettinger -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ethayarajh -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Among -X- _ O
these -X- _ O
redundancies -X- _ O
, -X- _ O
some -X- _ O
tokens -X- _ O
carry -X- _ O
more -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
than -X- _ O
others -X- _ O
( -X- _ O
Mohebbi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
only -X- _ O
these -X- _ O
tokens -X- _ O
could -X- _ O
be -X- _ O
considered -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
pruning -X- _ O
, -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
pruning -X- _ O
does -X- _ O
not1 -X- _ O

come -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
reducing -X- _ O
model -X- _ O
’s -X- _ O
capacity -X- _ O
in -X- _ O
complex -X- _ O
reasoning -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
such -X- _ O
techniques -X- _ O
which -X- _ O
reduces -X- _ O
inference -X- _ O
time -X- _ O
by -X- _ O
eliminating -X- _ O
redundant -X- _ O
token -X- _ O
representations -X- _ O
through -X- _ O
layers -X- _ O
based -X- _ O
on -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O

Several -X- _ O
studies -X- _ O
have -X- _ O
followed -X- _ O
( -X- _ O
Kim -X- _ O
and -X- _ O
Cho -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
usually -X- _ O
optimize -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
elimination -X- _ O
configuration -X- _ O
across -X- _ O
the -X- _ O
entire -X- _ O
dataset -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
static -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
their -X- _ O
token -X- _ O
selection -X- _ O
strategies -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
attention -X- _ O
weights -X- _ O
which -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
suboptimal -X- _ O
solution -X- _ O
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
Adap -X- _ B-MethodName
tiveLength -X- _ I-MethodName
Reduction -X- _ I-MethodName
( -X- _ O
AdapLeR -X- _ B-MethodName
) -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
relying -X- _ O
on -X- _ O
attention -X- _ O
weights -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
trains -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
Contribution -X- _ B-MetricName
Predictors -X- _ I-MetricName
( -X- _ O
CP -X- _ B-MetricName
) -X- _ O
to -X- _ O
estimate -X- _ O
tokens -X- _ O
’ -X- _ O
saliency -X- _ B-MetricName
scores -X- _ O
at -X- _ O
inference -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
choice -X- _ O
results -X- _ O
in -X- _ O
more -X- _ O
reliable -X- _ O
scores -X- _ O
than -X- _ O
attention -X- _ O
weights -X- _ O
in -X- _ O
measuring -X- _ O
tokens -X- _ O
’ -X- _ O
contributions -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
related -X- _ O
study -X- _ O
to -X- _ O
ours -X- _ O
is -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
which -X- _ O
leverages -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
develop -X- _ O
an -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
token -X- _ O
selection -X- _ O
policy -X- _ O
network -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
as -X- _ O
pointed -X- _ O
out -X- _ O
by -X- _ O
the -X- _ O
authors -X- _ O
, -X- _ O
the -X- _ O
problem -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
for -X- _ O
RL -X- _ O
to -X- _ O
solve -X- _ O
. -X- _ O

To -X- _ O
mitigate -X- _ O
this -X- _ O
, -X- _ O
they -X- _ O
resorted -X- _ O
to -X- _ O
extra -X- _ O
heuristics -X- _ O
such -X- _ O
as -X- _ O
imitation -X- _ O
learning -X- _ O
( -X- _ O
Hussein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
for -X- _ O
warming -X- _ O
up -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
network -X- _ O
, -X- _ O
action -X- _ O
sampling -X- _ O
for -X- _ O
limiting -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
and -X- _ O
knowledge -X- _ O
distillation -X- _ O
for -X- _ O
transferring -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
intact -X- _ O
backbone -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
. -X- _ O

All -X- _ O
of -X- _ O
these -X- _ O
steps -X- _ O
significantly -X- _ O
increase -X- _ O
the -X- _ O
training -X- _ O
cost -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
they -X- _ O
only -X- _ O
perform -X- _ O
token -X- _ O
selection -X- _ O
at -X- _ O
two -X- _ O
layers -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
but -X- _ O
effective -X- _ O
method -X- _ O
to -X- _ O
gradually -X- _ O
eliminate -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
throughout -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
using -X- _ O
a -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
which -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
adaptable -X- _ O
to -X- _ O
various -X- _ O
inputs -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
- -X- _ O
wise -X- _ O
mode -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
also -X- _ O
worth -X- _ O
noting -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
our -X- _ O
approach -X- _ O
above -X- _ O
studies -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
operations -X- _ O
for -X- _ O
identifying -X- _ O
the -X- _ O
k -X- _ O
most -X- _ O
important -X- _ O
tokens -X- _ O
during -X- _ O
training -X- _ O
or -X- _ O
inference -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
expensive -X- _ O
without -X- _ O
a -X- _ O
specific -X- _ O
hardware -X- _ O
architecture -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
threefold -X- _ O
: -X- _ O
•We -X- _ O
couple -X- _ O
a -X- _ O
simple -X- _ O
Contribution -X- _ B-MetricName
Predictor -X- _ I-MetricName
( -X- _ O
CP -X- _ B-MetricName
) -X- _ O
with -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
estimate -X- _ O
tokens -X- _ O
’ -X- _ O
contribution -X- _ O
scores -X- _ O
to -X- _ O
eliminate -X- _ O
redundant -X- _ O
representations -X- _ O
. -X- _ O

•Instead -X- _ O
of -X- _ O
an -X- _ O
instant -X- _ O
token -X- _ O
removal -X- _ O
, -X- _ O
we -X- _ O
gradually -X- _ O
mask -X- _ O
out -X- _ O
less -X- _ O
contributing -X- _ O
token -X- _ O
repre -X- _ O
- -X- _ O
sentations -X- _ O
by -X- _ O
employing -X- _ O
a -X- _ O
novel -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
. -X- _ O

•We -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
token -X- _ O
selection -X- _ O
strategy -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
widely -X- _ O
used -X- _ O
strategies -X- _ O
by -X- _ O
using -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O

2 -X- _ O
Background -X- _ O
2.1 -X- _ O
Self -X- _ O
- -X- _ O
attention -X- _ O
Weights -X- _ O
Self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
a -X- _ O
core -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
Transformers -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
which -X- _ O
looks -X- _ O
for -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
different -X- _ O
positions -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
of -X- _ O
token -X- _ O
representations -X- _ O
( -X- _ O
x1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
) -X- _ O
to -X- _ O
build -X- _ O
contextualized -X- _ O
representations -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
each -X- _ O
input -X- _ O
vector -X- _ O
xiis -X- _ O
multiplied -X- _ O
by -X- _ O
the -X- _ O
corresponding -X- _ O
trainable -X- _ O
matrices -X- _ O
Q -X- _ O
, -X- _ O
K -X- _ O
, -X- _ O
andVto -X- _ O
respectively -X- _ O
produce -X- _ O
query -X- _ O
( -X- _ O
qi -X- _ O
) -X- _ O
, -X- _ O
key -X- _ O
( -X- _ O
ki -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
value -X- _ O
( -X- _ O
vi -X- _ O
) -X- _ O
vectors -X- _ O
. -X- _ O

To -X- _ O
construct -X- _ O
the -X- _ O
output -X- _ O
representation -X- _ O
zi -X- _ O
, -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
weights -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
the -X- _ O
dot -X- _ O
product -X- _ O
of -X- _ O
qiwith -X- _ O
every -X- _ O
kjin -X- _ O
all -X- _ O
time -X- _ O
steps -X- _ O
. -X- _ O

Before -X- _ O
applying -X- _ O
a -X- _ O
softmax -X- _ O
function -X- _ O
, -X- _ O
these -X- _ O
values -X- _ O
are -X- _ O
divided -X- _ O
by -X- _ O
a -X- _ O
scaling -X- _ O
factor -X- _ O
and -X- _ O
then -X- _ O
added -X- _ O
to -X- _ O
an -X- _ O
attention -X- _ O
mask -X- _ O
vector -X- _ O
m -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
zero -X- _ O
for -X- _ O
positions -X- _ O
we -X- _ O
wish -X- _ O
to -X- _ O
attend -X- _ O
and -X- _ O
−∞ -X- _ O
( -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
−10000 -X- _ O
) -X- _ O
for -X- _ O
padded -X- _ O
tokens -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Mathematically -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
attention -X- _ O
head -X- _ O
, -X- _ O
the -X- _ O
weight -X- _ O
attention -X- _ O
from -X- _ O
token -X- _ O
xito -X- _ O
token -X- _ O
xjin -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
sequence -X- _ O
can -X- _ O
be -X- _ O
written -X- _ O
as -X- _ O
: -X- _ O
αi -X- _ O
, -X- _ O
j= -X- _ O
softmax -X- _ O
xj∈X -X- _ O
qik⊤ -X- _ O
j√ -X- _ O
d+mi -X- _ O
! -X- _ O

The -X- _ O
time -X- _ O
complexity -X- _ O
for -X- _ O
this -X- _ O
is -X- _ O
O -X- _ O
( -X- _ O
n2 -X- _ O
) -X- _ O
given -X- _ O
the -X- _ O
dot -X- _ O
product -X- _ O
qik⊤ -X- _ O
j -X- _ O
, -X- _ O
where -X- _ O
nis -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O

This -X- _ O
impedes -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
based -X- _ O
models -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
. -X- _ O

While -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
white -X- _ O
- -X- _ O
box -X- _ O
components -X- _ O
in -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
relying -X- _ O
on -X- _ O
raw -X- _ O
attention -X- _ O
weights -X- _ O
as -X- _ O
an -X- _ O
explanation -X- _ O
could -X- _ O
be -X- _ O
misleading -X- _ O
given -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
necessarily -X- _ O
responsible -X- _ O
for -X- _ O
determining -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
classifier -X- _ O
’s -X- _ O
decision -X- _ O
( -X- _ O
Jain -X- _ O
and -X- _ O
Wallace -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Serrano -X- _ O
and -X- _ O
Smith -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Abnar -X- _ O
and -X- _ O
Zuidema -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
raw -X- _ O
attentions -X- _ O
are -X- _ O
being -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
local -X- _ O
mixture -X- _ O
of -X- _ O
information -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
and -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
global -X- _ O
perspective -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
flow -X- _ O
through -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
( -X- _ O
Pascual -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

2.2 -X- _ O
Gradient -X- _ O
- -X- _ O
based -X- _ O
Saliency -X- _ O
Scores -X- _ O
Gradient -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
provide -X- _ O
alternatives -X- _ O
to -X- _ O
attention -X- _ O
weights -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
a2 -X- _ O

Encoder -X- _ O
Layer -X- _ O
ℓ+1 -X- _ O
Encoder -X- _ O
Layer -X- _ O
ℓ -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
thisstockhasrisen -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
thisstockhasrisen -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

Layer -X- _ O
ℓ+1 -X- _ O

Inputs -X- _ O
: -X- _ O
Layer -X- _ O
ℓOutputs -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
thisstockhasrisen -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

𝑛tokensCPℓ -X- _ O
1 -X- _ O
� -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
To -X- _ O
reduce -X- _ O
the -X- _ O
inference -X- _ O
computation -X- _ O
, -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
attribution -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
representation -X- _ O
is -X- _ O
estimated -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
reduced -X- _ O
uniform -X- _ O
- -X- _ O
level -X- _ O
threshold -X- _ O
( -X- _ O
δℓ=ηℓ -X- _ O
/ -X- _ O
n -X- _ O
) -X- _ O
token -X- _ O

representations -X- _ O
with -X- _ O
low -X- _ O
importance -X- _ O
score -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
’s -X- _ O
classifier -X- _ O
is -X- _ O
connected -X- _ O
to -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O

and -X- _ O
it -X- _ O
could -X- _ O
act -X- _ O
as -X- _ O
a -X- _ O
pooler -X- _ O
within -X- _ O
each -X- _ O
layer -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
token -X- _ O
that -X- _ O
would -X- _ O
remain -X- _ O
regardless -X- _ O
of -X- _ O
its -X- _ O
score -X- _ O
. -X- _ O

specific -X- _ O
input -X- _ O
feature -X- _ O
. -X- _ O

Despite -X- _ O
having -X- _ O
been -X- _ O
widely -X- _ O
utilized -X- _ O
in -X- _ O
other -X- _ O
fields -X- _ O
earlier -X- _ O
( -X- _ O
Ancona -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Simonyan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Sundararajan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Smilkov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
only -X- _ O
recently -X- _ O
become -X- _ O
popular -X- _ O
in -X- _ O
NLP -X- _ O
studies -X- _ O
( -X- _ O
Bastings -X- _ O
and -X- _ O
FilThese -X- _ O
methods -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
computing -X- _ O
the -X- _ O
firstorder -X- _ O
derivative -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
logit -X- _ O
ycw.r.t -X- _ O
. -X- _ O

the -X- _ O
input -X- _ O
embedding -X- _ O
h0 -X- _ O
i -X- _ O
( -X- _ O
initial -X- _ O
hidden -X- _ O
states -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
ccould -X- _ O
be -X- _ O
true -X- _ O
class -X- _ O
label -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
input -X- _ O
features -X- _ O
or -X- _ O
the -X- _ O
predicted -X- _ O
class -X- _ O
to -X- _ O
interpret -X- _ O
model -X- _ O
’s -X- _ O
behavior -X- _ O
. -X- _ O

After -X- _ O
taking -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
output -X- _ O
derivatives -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
sensitivity -X- _ B-MetricName
( -X- _ O
Ancona -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
changes -X- _ O
in -X- _ O
model -X- _ O
’s -X- _ O
output -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
changes -X- _ O
in -X- _ O
specific -X- _ O
input -X- _ O
dimensions -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
by -X- _ O
multiplying -X- _ O
gradients -X- _ O
with -X- _ O
input -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
arrive -X- _ O
at -X- _ O
gradient -X- _ O
×input -X- _ O
( -X- _ O
Bastings -X- _ O
and -X- _ O
Filippova -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
saliency -X- _ B-MetricName
, -X- _ O
which -X- _ O
also -X- _ O
considers -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
input -X- _ O
vectors -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
tokens -X- _ O
. -X- _ O

Since -X- _ O
these -X- _ O
scores -X- _ O
are -X- _ O
computed -X- _ O
for -X- _ O
each -X- _ O
dimension -X- _ O
of -X- _ O
embedding -X- _ O
vectors -X- _ O
, -X- _ O
an -X- _ O
aggregation -X- _ O
method -X- _ O
such -X- _ O
as -X- _ O
L2 -X- _ O
norm -X- _ O
or -X- _ O
mean -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
produce -X- _ O
one -X- _ O
score -X- _ O
per -X- _ O
input -X- _ O
token -X- _ O
( -X- _ O
Atanasova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
: -X- _ O
Si=∥∂yc -X- _ O
i⊙h0 -X- _ O
3 -X- _ O
Methodology -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
relies -X- _ O
on -X- _ O
dropping -X- _ O
low -X- _ O
contributing -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
and -X- _ O
passing -X- _ O
only -X- _ O
the -X- _ O
more -X- _ O
important -X- _ O
ones -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
one -X- _ O
important -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
saliency -X- _ B-MetricName
scores -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
recently -X- _ O
shownas -X- _ O
a -X- _ O
reliable -X- _ O
criterion -X- _ O
in -X- _ O
measuring -X- _ O
token -X- _ O
’s -X- _ O
contributions -X- _ O
( -X- _ O
Bastings -X- _ O
and -X- _ O
Filippova -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Pascual -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
Section -X- _ O
5.1 -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
a -X- _ O
series -X- _ O
quantitative -X- _ O
analyses -X- _ O
that -X- _ O
supports -X- _ O
this -X- _ O
choice -X- _ O
. -X- _ O

In -X- _ O
what -X- _ O
follows -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
describe -X- _ O
how -X- _ O
we -X- _ O
estimate -X- _ O
saliency -X- _ B-MetricName
scores -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
using -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
Contribution -X- _ O
Predictors -X- _ O
( -X- _ O
CPs -X- _ O
) -X- _ O
and -X- _ O
then -X- _ O
elaborate -X- _ O
on -X- _ O
how -X- _ O
we -X- _ O
leverage -X- _ O
these -X- _ O
predictors -X- _ O
during -X- _ O
inference -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
training -X- _ O
( -X- _ O
Section -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O

3.1 -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
Computing -X- _ O
gradients -X- _ O
during -X- _ O
inference -X- _ O
is -X- _ O
problematic -X- _ O
as -X- _ O
backpropagation -X- _ O
computation -X- _ O
prolongs -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
contrary -X- _ O
to -X- _ O
our -X- _ O
main -X- _ O
goal -X- _ O
. -X- _ O

To -X- _ O
circumvent -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
add -X- _ O
a -X- _ O
CP -X- _ O
after -X- _ O
each -X- _ O
layer -X- _ O
ℓin -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
estimate -X- _ O
contribution -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
representation -X- _ O
, -X- _ O

i.e. -X- _ O
, -X- _ O
˜Sℓ -X- _ O
i -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
then -X- _ O
decides -X- _ O
on -X- _ O
the -X- _ O
tokens -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
layer -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
values -X- _ O
of˜Sℓ -X- _ O
i. -X- _ O
CP -X- _ O
computes˜Sℓ -X- _ O
ifor -X- _ O
each -X- _ O
token -X- _ O
using -X- _ O
an -X- _ O
MLP -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
, -X- _ O
despite -X- _ O
being -X- _ O
limited -X- _ O
in -X- _ O
learning -X- _ O
capacity -X- _ O
, -X- _ O
the -X- _ O
MLP -X- _ O
is -X- _ O
sufficient -X- _ O
for -X- _ O
estimating -X- _ O
scores -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
generalized -X- _ O
and -X- _ O
relevant -X- _ O
than -X- _ O
vanilla -X- _ O
saliency -X- _ B-MetricName
values -X- _ O
. -X- _ O

We -X- _ O
will -X- _ O
present -X- _ O
a -X- _ O
quantitative -X- _ O
analysis -X- _ O
on -X- _ O
this -X- _ O
topic -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
3.2 -X- _ O
Model -X- _ O
Inference -X- _ O
Most -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
consist -X- _ O
of -X- _ O
Lencoder -X- _ O
layers -X- _ O
. -X- _ O

The -X- _ O
input -X- _ O
sequence -X- _ O
of -X- _ O
ntokens -X- _ O
is -X- _ O
usually -X- _ O
passed -X- _ O
through -X- _ O
an -X- _ O
embedding -X- _ O
layer -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
initial -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
h0 -X- _ O
. -X- _ O

Each -X- _ O
encoder -X- _ O
layer -X- _ O
then -X- _ O
produces -X- _ O
the -X- _ O
next -X- _ O
hidden -X- _ O
states -X- _ O
using -X- _ O
the3 -X- _ O

ones -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
layer -X- _ O
: -X- _ O
In -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
eliminate -X- _ O
less -X- _ O
contributing -X- _ O
token -X- _ O
representations -X- _ O
before -X- _ O
delivering -X- _ O
hidden -X- _ O
states -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
encoder -X- _ O
. -X- _ O

Tokens -X- _ O
are -X- _ O
selected -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
contribution -X- _ B-MetricName
scores -X- _ O
˜Sℓobtained -X- _ O
from -X- _ O
the -X- _ O
CP -X- _ B-MethodName
of -X- _ O
the -X- _ O
corresponding -X- _ O
layer -X- _ O
ℓ. -X- _ O
As -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
these -X- _ O
scores -X- _ O
is -X- _ O
equal -X- _ O
to -X- _ O
one -X- _ O
, -X- _ O
a -X- _ O
uniform -X- _ O
level -X- _ O
indicates -X- _ O
that -X- _ O
all -X- _ O
tokens -X- _ O
contribute -X- _ O
equally -X- _ O
to -X- _ O
the -X- _ O
prediction -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
retained -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
lower -X- _ O
- -X- _ O
scoring -X- _ O
tokens -X- _ O
could -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
unnecessary -X- _ O
tokens -X- _ O
if -X- _ O
the -X- _ O
contribution -X- _ B-MetricName
scores -X- _ O
are -X- _ O
concentrated -X- _ O
only -X- _ O
on -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O

Given -X- _ O
that -X- _ O
the -X- _ O
final -X- _ O
classification -X- _ O
head -X- _ O
uses -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
preserve -X- _ O
this -X- _ O
token -X- _ O
’s -X- _ O
representation -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O

Despite -X- _ O
preserving -X- _ O
this -X- _ O
, -X- _ O
other -X- _ O
tokens -X- _ O
might -X- _ O
be -X- _ O
removed -X- _ O
from -X- _ O
a -X- _ O
layer -X- _ O
when -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
has -X- _ O
a -X- _ O
significantly -X- _ O
high -X- _ O
estimated -X- _ O
contribution -X- _ B-MetricName
score -X- _ O
than -X- _ O
others -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
this -X- _ O
intuition -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
cutoff -X- _ B-HyperparameterName
threshold -X- _ I-HyperparameterName
based -X- _ O
on -X- _ O
the -X- _ O
uniform -X- _ O
level -X- _ O
as -X- _ O
: -X- _ O
δℓ=ηℓ·1 -X- _ O
/ -X- _ O
nwith0 -X- _ O
< -X- _ O
ηℓ≤1to -X- _ O
distinguish -X- _ O
important -X- _ O
tokens -X- _ O
. -X- _ O

Tokens -X- _ O
are -X- _ O
considered -X- _ O
important -X- _ O
if -X- _ O
their -X- _ O
contribution -X- _ B-MetricName
score -X- _ O
exceeds -X- _ O
δ -X- _ O
( -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
value -X- _ O
equal -X- _ O
or -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
uniform -X- _ O
score -X- _ O
) -X- _ O
. -X- _ O

Intuitively -X- _ O
, -X- _ O
a -X- _ O
larger -X- _ O
ηprovides -X- _ O
a -X- _ O
higher -X- _ O
δ -X- _ O
cutoff -X- _ O
level -X- _ O
, -X- _ O
thereby -X- _ O
dropping -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
, -X- _ O
hence -X- _ O
, -X- _ O
yielding -X- _ O
more -X- _ O
speedup -X- _ O
. -X- _ O

The -X- _ O
value -X- _ O
ofηdetermines -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
we -X- _ O
can -X- _ O
rely -X- _ O
on -X- _ O
CP -X- _ B-MetricName
’s -X- _ O
estimations -X- _ O
. -X- _ O

In -X- _ O
case -X- _ O
the -X- _ O
estimations -X- _ O
of -X- _ O
CP -X- _ B-MetricName
are -X- _ O
deemed -X- _ O
to -X- _ O
be -X- _ O
inaccurate -X- _ O
, -X- _ O
its -X- _ O
impact -X- _ O
can -X- _ O
be -X- _ O
reduced -X- _ O
by -X- _ O
lowering -X- _ O
η -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
each -X- _ O
layer -X- _ O
’s -X- _ O
ηℓ -X- _ O
using -X- _ O
an -X- _ O
auxiliary -X- _ O
training -X- _ O
objective -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
cutoff -X- _ O
value -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
speedup -X- _ O
- -X- _ O
performance -X- _ O
tradeoff -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
since -X- _ O
each -X- _ O
input -X- _ O
instance -X- _ O
has -X- _ O
a -X- _ O
different -X- _ O
computational -X- _ O
path -X- _ O
during -X- _ O
token -X- _ O
removal -X- _ O
process -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
should -X- _ O
be -X- _ O
equal -X- _ O
to -X- _ O
one -X- _ O
( -X- _ O
single -X- _ O
instance -X- _ O
usage -X- _ O
) -X- _ O
, -X- _ O
similarly -X- _ O
to -X- _ O
other -X- _ O
dynamic -X- _ O
approaches -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
3.3 -X- _ O
Model -X- _ O
Training -X- _ O
Training -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
phases -X- _ O
: -X- _ O
initial -X- _ O
finetuning -X- _ O
, -X- _ O
saliency -X- _ O
extraction -X- _ O
, -X- _ O
and -X- _ O
adaptive -X- _ O
length -X- _ O
retraining -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
) -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
extract -X- _ O
the -X- _ O
saliencies -X- _ O
of -X- _ O
three -X- _ O
top -X- _ O
- -X- _ O
perfroming -X- _ O
checkpoints -X- _ O
from -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
them -X- _ O
to -X- _ O
mitigate -X- _ O
potential -X- _ O
inconsistencies -X- _ O
in -X- _ O
saliency -X- _ O
scores -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Section -X- _ O
2.2 -X- _ O
) -X- _ O
. -X- _ O

Si -X- _ O
81Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
plotted -X- _ O
with -X- _ O
removal -X- _ O
region -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
gets -X- _ O
steeper -X- _ O
while -X- _ O
the -X- _ O
other -X- _ O
zone -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
almost -X- _ O
horizontal -X- _ O
, -X- _ O
approaches -X- _ O
the -X- _ O
zero -X- _ O
level -X- _ O
. -X- _ O

The -X- _ O
final -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
using -X- _ O
an -X- _ O
adaptive -X- _ O
length -X- _ O
reduction -X- _ O
procedure -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
phase -X- _ O
, -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
function -X- _ O
gradually -X- _ O
fades -X- _ O
out -X- _ O
the -X- _ O
representations -X- _ O
throughout -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O

Each -X- _ O
CP -X- _ O
is -X- _ O
jointly -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
saliencies -X- _ O
extracted -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
phase -X- _ O
alongside -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
labels -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
define -X- _ O
a -X- _ O
speedup -X- _ O
tuning -X- _ O
objective -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
thresholds -X- _ O
( -X- _ O
via -X- _ O
tuning -X- _ O
η -X- _ O
) -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
performance -X- _ O
- -X- _ O
speedup -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
elaborate -X- _ O
on -X- _ O
the -X- _ O
procedure -X- _ O
. -X- _ O

Soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
. -X- _ O

During -X- _ O
training -X- _ O
, -X- _ O
if -X- _ O
tokens -X- _ O
are -X- _ O
immediately -X- _ O
dropped -X- _ O
similarly -X- _ O
to -X- _ O
the -X- _ O
inference -X- _ O
mode -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
dropping -X- _ O
tokens -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
captured -X- _ O
using -X- _ O
a -X- _ O
gradient -X- _ O
backpropagation -X- _ O
procedure -X- _ O
. -X- _ O

Using -X- _ O
batch -X- _ O
- -X- _ O
wise -X- _ O
training -X- _ O
in -X- _ O
this -X- _ O
scenario -X- _ O
will -X- _ O
also -X- _ O
be -X- _ O
problematic -X- _ O
as -X- _ O
the -X- _ O
structure -X- _ O
will -X- _ O
vary -X- _ O
with -X- _ O
each -X- _ O
example -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
padding -X- _ O
mechanism -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
models -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
procedure -X- _ O
that -X- _ O
gradually -X- _ O
masks -X- _ O
out -X- _ O
less -X- _ O
contributing -X- _ O
token -X- _ O
representations -X- _ O
. -X- _ O

In -X- _ O
each -X- _ O
layer -X- _ O
, -X- _ O
after -X- _ O
predicting -X- _ O
contribution -X- _ B-MetricName
scores -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
instantly -X- _ O
removing -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
accumulate -X- _ O
a -X- _ O
negative -X- _ O
mask -X- _ O
to -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
vector -X- _ O
Musing -X- _ O
a -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
: -X- _ O
m− -X- _ O
This -X- _ O
function -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
main -X- _ O
zones -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
term -X- _ O
, -X- _ O
the -X- _ O
less -X- _ O
important -X- _ O
tokens -X- _ O
with -X- _ O
scores -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
threshold -X- _ O
( -X- _ O
δℓ -X- _ O
) -X- _ O
are -X- _ O
assigned -X- _ O
higher -X- _ O
negative -X- _ O
masking -X- _ O
as -X- _ O
they -X- _ O
get -X- _ O
more -X- _ O
distant4 -X- _ O

from -X- _ O
δ -X- _ O
. -X- _ O

The -X- _ O
slope -X- _ O
is -X- _ O
determined -X- _ O
by -X- _ O
λadj -X- _ O
= -X- _ O
λ -X- _ O
/ -X- _ O
δ -X- _ O
, -X- _ O
where -X- _ O
λis -X- _ B-HyperparameterName
a -X- _ O
hyperparameter -X- _ O
that -X- _ O
is -X- _ O
increased -X- _ O
exponentially -X- _ O
after -X- _ O
each -X- _ O
epoch -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
λ←10×λafter -X- _ O
finishing -X- _ O
each -X- _ O
epoch -X- _ O
) -X- _ O
. -X- _ O

Increasing -X- _ O
λmakes -X- _ B-HyperparameterName
the -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
stronger -X- _ O
and -X- _ O
more -X- _ O
decisive -X- _ O
in -X- _ O
masking -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O

To -X- _ O
avoid -X- _ O
undergoing -X- _ O
zero -X- _ O
gradients -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
0 -X- _ O
< -X- _ O
β -X- _ O
< -X- _ O
0.1to -X- _ O
construct -X- _ O
a -X- _ O
small -X- _ O
negative -X- _ O
slope -X- _ O
( -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
well -X- _ O
known -X- _ O
Leaky -X- _ O
- -X- _ O
ReLU -X- _ O
of -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2013 -X- _ O
) -X- _ O
for -X- _ O
those -X- _ O
tokens -X- _ O
with -X- _ O
higher -X- _ O
contributing -X- _ O
scores -X- _ O
than -X- _ O
δℓthreshold -X- _ O
. -X- _ O

Consider -X- _ O
a -X- _ O
scenario -X- _ O
in -X- _ O
which -X- _ O
ηℓsharply -X- _ O
drops -X- _ O
, -X- _ O
causing -X- _ O
most -X- _ O
of˜Sℓ -X- _ O
iget -X- _ O
over -X- _ O
theδℓthreshold -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
zero -X- _ O
value -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O
of -X- _ O
Equation -X- _ O
4 -X- _ O
, -X- _ O
which -X- _ O
facilitates -X- _ O
optimizing -X- _ O
ηℓ. -X- _ O
Training -X- _ O
the -X- _ O
Contribution -X- _ O
Predictors -X- _ O
. -X- _ O

The -X- _ O
CPs -X- _ B-MethodName
are -X- _ O
trained -X- _ O
by -X- _ O
an -X- _ O
additional -X- _ O
term -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
KL -X- _ B-MetricName
- -X- _ I-MetricName
divergence1of -X- _ I-MetricName
each -X- _ O
layer -X- _ O
’s -X- _ O
CP -X- _ B-MethodName
output -X- _ O
with -X- _ O
the -X- _ O
extracted -X- _ O
saliencies -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
a -X- _ O
minimization -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
loss -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
LCE+γLCP -X- _ B-HyperparameterName
( -X- _ O
5 -X- _ O
) -X- _ O
Where -X- _ O
γis -X- _ B-HyperparameterName
a -X- _ O
hyperparameter -X- _ O
which -X- _ O
that -X- _ O
specifies -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
emphasis -X- _ O
on -X- _ O
the -X- _ O
CP -X- _ O
training -X- _ O
loss -X- _ O
: -X- _ O
LCP -X- _ O
= -X- _ O
L−1X -X- _ O
ilog -X- _ O
( -X- _ O
ˆSℓ -X- _ O
i -X- _ O
Since -X- _ O
Sis -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
embeddings -X- _ O
, -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
usually -X- _ O
shows -X- _ O
a -X- _ O
low -X- _ O
amount -X- _ O
of -X- _ O
contribution -X- _ O
due -X- _ O
to -X- _ O
not -X- _ O
having -X- _ O
any -X- _ O
contextualism -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
for -X- _ O
classification -X- _ O
, -X- _ O
this -X- _ O
token -X- _ O
acts -X- _ O
as -X- _ O
a -X- _ O
pooler -X- _ O
and -X- _ O
gathers -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
can -X- _ O
potentially -X- _ O
have -X- _ O
more -X- _ O
contribution -X- _ O
as -X- _ O
it -X- _ O
passes -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
amplify -X- _ O
the -X- _ O
contribution -X- _ B-MetricName
score -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
renormalize -X- _ O
the -X- _ O
distribution -X- _ O
( -X- _ O
ˆSℓ -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
trainable -X- _ O
parameter -X- _ O
θℓ -X- _ O
: -X- _ O
1+Pn -X- _ O
By -X- _ O
this -X- _ O
procedure -X- _ O
, -X- _ O
the -X- _ O
next -X- _ O
objective -X- _ O
( -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
paragraph -X- _ O
) -X- _ O
will -X- _ O
have -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
tuning -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
pooling -X- _ O
, -X- _ O
consequently -X- _ O
controlling -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
speedup -X- _ O
. -X- _ O

Larger -X- _ O
θpush -X- _ O
the -X- _ O
ken -X- _ O
to -X- _ O
gather -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
and -X- _ O
avoids -X- _ O
carrying -X- _ O
redundant -X- _ O
tokens -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Speedup -X- _ O
Tuning -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
speedup -X- _ O
tuning -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
classification -X- _ O
task -X- _ O
with -X- _ O
a -X- _ O
length -X- _ O
loss -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
expected -X- _ O
number -X- _ O
of -X- _ O
unmasked -X- _ O
token -X- _ O
representations -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O

Considering -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
positive -X- _ O
and -X- _ O
continuous -X- _ O
attention -X- _ O
mask -X- _ O
M -X- _ O
, -X- _ O
the -X- _ O
length -X- _ B-MetricName
loss -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
layer -X- _ O
would -X- _ O
be -X- _ O
the -X- _ O
summation -X- _ O
over -X- _ O
the -X- _ O
exponential -X- _ O
of -X- _ O
the -X- _ O
mask -X- _ O
valuesexp -X- _ O
( -X- _ O
mi -X- _ O
) -X- _ O
to -X- _ O
map -X- _ O
the -X- _ O
masking -X- _ O
range -X- _ O

[ -X- _ O
−∞,0 -X- _ O
] -X- _ O
to -X- _ O
a -X- _ O
[ -X- _ O
0 -X- _ O
( -X- _ O
fully -X- _ O
masked -X- _ O
/ -X- _ O
removed -X- _ O
) -X- _ O
, -X- _ O
1 -X- _ O
( -X- _ O
fully -X- _ O
retained -X- _ O
) -X- _ O
] -X- _ O
bound -X- _ O
. -X- _ O

LSPD. -X- _ O
/ -X- _ O
PERF.=LCE+ϕLLENGTH -X- _ O
LLENGTH -X- _ O
= -X- _ O
LX -X- _ O
l=1nX -X- _ O
i=1exp -X- _ O
( -X- _ O
mℓ -X- _ O
Equation -X- _ O
8 -X- _ O
demonstrates -X- _ O
how -X- _ O
the -X- _ O
length -X- _ B-MetricName
loss -X- _ O
is -X- _ O
computed -X- _ O
inside -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
how -X- _ O
it -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
classification -X- _ O
loss -X- _ O
. -X- _ O

During -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
a -X- _ O
separate -X- _ O
optimization -X- _ O
process -X- _ O
which -X- _ O
tunes -X- _ O
ηandθto -X- _ O
adjust -X- _ O
the -X- _ O
thresholds -X- _ O
and -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
pooling2alongside -X- _ O
with -X- _ O
the -X- _ O
CP -X- _ O
training -X- _ O
. -X- _ O

The -X- _ O
reason -X- _ O
that -X- _ O
this -X- _ O
objective -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
separate -X- _ O
problem -X- _ O
instead -X- _ O
of -X- _ O
merging -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
one -X- _ O
, -X- _ O
is -X- _ O
because -X- _ O
in -X- _ O
the -X- _ O
latter -X- _ O
case -X- _ O
the -X- _ O
CPs -X- _ O
could -X- _ O
be -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
length -X- _ B-MetricName
loss -X- _ O
and -X- _ O
try -X- _ O
to -X- _ O
manipulate -X- _ O
the -X- _ O
contribution -X- _ O
scores -X- _ O
for -X- _ O
some -X- _ O
tokens -X- _ O
regardless -X- _ O
of -X- _ O
their -X- _ O
real -X- _ O
influence -X- _ O
. -X- _ O

So -X- _ O
in -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
task -X- _ O
and -X- _ O
make -X- _ O
it -X- _ O
explainable -X- _ O
with -X- _ O
the -X- _ O
CPs -X- _ B-MetricName
, -X- _ O
and -X- _ O
the -X- _ O
secondary -X- _ O
objective -X- _ O
builds -X- _ O
the -X- _ O
speedup -X- _ O
using -X- _ O
tuning -X- _ O
the -X- _ O
threshold -X- _ O
levels -X- _ O
and -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
pooling -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Datasets -X- _ O
To -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
AdapLeR -X- _ B-MethodName
on -X- _ O
inference -X- _ O
speedup -X- _ B-MetricName
, -X- _ O
we -X- _ O
selected -X- _ O
eight -X- _ O
various -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
datasets -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
incorporate -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
utilized -X- _ O
SST-2 -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
IMDB -X- _ B-DatasetName
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
for -X- _ O
sentiment -X- _ B-TaskName
, -X- _ O
MRPC -X- _ B-DatasetName
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
for -X- _ O
paraphrase -X- _ B-TaskName
, -X- _ O
AG -X- _ B-DatasetName
’s -X- _ I-DatasetName
News -X- _ I-DatasetName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
topic -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
DBpedia -X- _ B-DatasetName
( -X- _ O
Lehmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
knowledge -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
NLI -X- _ B-TaskName
, -X- _ O
dummy -X- _ O
variable -X- _ O
inside -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

See -X- _ O
Appendix -X- _ O
B.5 -X- _ O

ModelSST-2 -X- _ O
IMDB -X- _ B-DatasetName
HateXplain -X- _ B-DatasetName
MRPC -X- _ B-DatasetName
MNLI -X- _ B-DatasetName
QNLI -X- _ B-DatasetName
AG -X- _ B-DatasetName
’s -X- _ I-DatasetName
news -X- _ I-DatasetName
DBpedia -X- _ B-DatasetName
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
Speedup -X- _ O
F1 -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ B-MetricName
Table -X- _ O
1 -X- _ O
: -X- _ O
Comparison -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
( -X- _ O
AdapLeR -X- _ B-MethodName
) -X- _ O
with -X- _ O
other -X- _ O
baselines -X- _ O
in -X- _ O
eight -X- _ O
classification -X- _ O
tasks -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
performance -X- _ O
and -X- _ O
speedup -X- _ B-MetricName
. -X- _ O

For -X- _ O
each -X- _ O
dataset -X- _ O
the -X- _ O
corresponding -X- _ O
metric -X- _ O
has -X- _ O
been -X- _ O
reported -X- _ O
( -X- _ O
Accuracy -X- _ O
: -X- _ O
Acc -X- _ O
. -X- _ O
, -X- _ O
F1 -X- _ B-MetricName
: -X- _ O
F-1 -X- _ O
Score -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
MNLI -X- _ B-TaskName
task -X- _ O
, -X- _ O
the -X- _ O
speedup -X- _ B-MetricName
and -X- _ O
performance -X- _ O
values -X- _ O
are -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
evaluations -X- _ O
on -X- _ O
the -X- _ O
matched -X- _ O
and -X- _ O
mismatched -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O

QNLI -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
for -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O
HateXplain -X- _ B-DatasetName
( -X- _ O
Mathew -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
hate -X- _ B-TaskName
speech.3Evaluations -X- _ I-TaskName
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O

For -X- _ O
those -X- _ O
datasets -X- _ O
that -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ O
Benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
test -X- _ O
results -X- _ O
were -X- _ O
acquired -X- _ O
by -X- _ O
submitting -X- _ O
the -X- _ O
test -X- _ O
predictions -X- _ O
to -X- _ O
the -X- _ O
evaluation -X- _ O
server -X- _ O
. -X- _ O

4.2 -X- _ O
Experimental -X- _ O
Setup -X- _ O
As -X- _ O
our -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
AdapLeR -X- _ B-MethodName
. -X- _ O

We -X- _ O
also -X- _ O
compare -X- _ O
against -X- _ O
three -X- _ O
other -X- _ O
approaches -X- _ O
: -X- _ O
DistilBERT -X- _ B-MethodName
( -X- _ O
uncased -X- _ O
) -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
static -X- _ O
compression -X- _ O
method -X- _ O
, -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
as -X- _ O
two -X- _ O
strong -X- _ O
length -X- _ O
reduction -X- _ O
methods -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
provided -X- _ O
implementations -X- _ O
and -X- _ O
suggested -X- _ O
hyperparameters4to -X- _ O
train -X- _ O
these -X- _ O
baselines -X- _ O
. -X- _ O

To -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
same -X- _ O
hyperparameters -X- _ O
over -X- _ O
all -X- _ O
tasks -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
D -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
backbone -X- _ O
model -X- _ O
and -X- _ O
our -X- _ O
model -X- _ O
implementation -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
HuggingFace -X- _ O
’s -X- _ O
Transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Trainings -X- _ O
and -X- _ O
evaluations -X- _ O
were -X- _ O
conducted -X- _ O
on -X- _ O
a -X- _ O
dual -X- _ O
2080Ti -X- _ O
11 -X- _ O
GB -X- _ O
GPU -X- _ O
machine -X- _ O
with -X- _ O
multiple -X- _ O
runs -X- _ O
. -X- _ O

Hyperparameter -X- _ O
Selection -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
four -X- _ O
hyperparameters -X- _ O
( -X- _ O
γ -X- _ B-HyperparameterName
, -X- _ O
ϕ -X- _ B-HyperparameterName
, -X- _ O
λ -X- _ B-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
) -X- _ O
5which -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O

Among -X- _ O
these -X- _ O
, -X- _ O
ϕ -X- _ B-HyperparameterName
andγare -X- _ B-HyperparameterName
the -X- _ O
primary -X- _ O
terms -X- _ O
that -X- _ O
have -X- _ O
considerable -X- _ O
effects -X- _ O
on -X- _ O
AdapLeR -X- _ B-MethodName
’s -X- _ O
downstream -X- _ O
performance -X- _ O
and -X- _ O
speedup -X- _ O
. -X- _ O

This -X- _ O
makes -X- _ O
our -X- _ O
approach -X- _ O
comparable -X- _ O
to -X- _ O
existing -X- _ O
techniques -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
which -X- _ O
usually -X- _ O
have -X- _ O
two -X- _ O
or -X- _ O
three -X- _ O
hyperparameters -X- _ O
adjusted -X- _ O
per -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
grid -X- _ O
search -X- _ O
to -X- _ O
had -X- _ O
to -X- _ O
search -X- _ O
the -X- _ O
hyperparameters -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
given -X- _ O
ranges -X- _ O
. -X- _ O

model -X- _ O
during -X- _ O
training.find -X- _ O
the -X- _ O
optimal -X- _ O
values -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
terms -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
other -X- _ O
hyperparameters -X- _ O
constant -X- _ O
over -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

Hyperparamter -X- _ O
selection -X- _ O
is -X- _ O
further -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
D. -X- _ O
FLOPs -X- _ B-MetricName
Computation -X- _ O
. -X- _ O

We -X- _ O
followed -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
measured -X- _ O
computational -X- _ O
complexity -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
FLOPs -X- _ B-MetricName
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
floating -X- _ O
- -X- _ O
point -X- _ O
operations -X- _ O
( -X- _ O
FLOPs -X- _ B-MetricName
) -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
inference -X- _ O
procedure -X- _ O
. -X- _ O

This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
assess -X- _ O
models -X- _ O
’ -X- _ O
speedups -X- _ O
independently -X- _ O
of -X- _ O
their -X- _ O
operating -X- _ O
environment -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CPU -X- _ O
/ -X- _ O
GPU -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
total -X- _ O
FLOPs -X- _ B-MetricName
of -X- _ O
a -X- _ O
given -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
summation -X- _ O
of -X- _ O
the -X- _ O
measured -X- _ O
FLOPs -X- _ B-MetricName
over -X- _ O
all -X- _ O
test -X- _ O
examples -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
’s -X- _ O
speedup -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
total -X- _ O
FLOPs -X- _ B-MetricName
measured -X- _ O
on -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
our -X- _ O
baseline -X- _ O
) -X- _ O
divided -X- _ O
by -X- _ O
the -X- _ O
corresponding -X- _ O
model -X- _ O
’s -X- _ O
total -X- _ O
FLOPs -X- _ B-MetricName
. -X- _ O

To -X- _ O
have -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
computed -X- _ O
FLOPs -X- _ B-MetricName
for -X- _ O
PoWERBERT -X- _ B-MethodName
in -X- _ O
a -X- _ O
single -X- _ O
instance -X- _ O
mode -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
C. -X- _ O
4.3 -X- _ O
Results -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
performance -X- _ O
and -X- _ O
speedup -X- _ O
for -X- _ O
AdapLeR -X- _ B-MethodName
and -X- _ O
other -X- _ O
comparison -X- _ O
models -X- _ O
across -X- _ O
eight -X- _ O
different -X- _ O
datasets -X- _ O
. -X- _ O

While -X- _ O
preserving -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
performance -X- _ O
, -X- _ O
AdapLeR -X- _ B-MethodName
outperforms -X- _ O
other -X- _ O
techniques -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
speedup -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
( -X- _ O
ranging -X- _ O
from -X- _ O
+0.2x -X- _ B-MetricValue
to -X- _ O
+7.4x -X- _ B-MetricValue
compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
in -X- _ O
each -X- _ O
dataset -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
noteworthy -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
also -X- _ O
reveal -X- _ O
some -X- _ O
form -X- _ O
of -X- _ O
dependency -X- _ O
on -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
. -X- _ O

Some -X- _ O
tasks -X- _ O
may -X- _ O
need -X- _ O
less -X- _ O
amount -X- _ O
of -X- _ O
contextualism -X- _ O
during -X- _ O
inference -X- _ O
and -X- _ O
could -X- _ O
be -X- _ O
classified -X- _ O
by -X- _ O
using -X- _ O
only -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
input -X- _ O
tokens -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
AG -X- _ B-DatasetName
’s -X- _ I-DatasetName
News -X- _ I-DatasetName
, -X- _ O
the -X- _ O
topic -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
might -X- _ O
be -X- _ O
identifiable -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
soccer -X- _ O
→Topic -X- _ O
: -X- _ O
Sports -X- _ O
, -X- _ O
see -X- _ O
Figure -X- _ O
6 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
for -X- _ O
an -X- _ O
example -X- _ O
) -X- _ O
. -X- _ O

PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
adopts -X- _ O
attention -X- _ O
weights -X- _ O
in -X- _ O
its -X- _ O
token -X- _ O
selection -X- _ O
which -X- _ O
requires -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
layer -X- _ O
of -X- _ O
computation -X- _ O
to -X- _ O
be -X- _ O
determined -X- _ O
, -X- _ O
and -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
ap-6 -X- _ O

SST-2 -X- _ O
TR -X- _ O
PoWER -X- _ O
AdapLeR -X- _ O
HateXplain -X- _ O
TR -X- _ O
PoWER -X- _ O
AdapLeRFigure -X- _ O
3 -X- _ O
: -X- _ O
Accuracy -X- _ O
- -X- _ O
Speedup -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
for -X- _ O
AdapLeR -X- _ O
and -X- _ O
two -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
reduction -X- _ O
methods -X- _ O
; -X- _ O
TR -X- _ O
: -X- _ O
TR -X- _ O
- -X- _ O
BERT -X- _ O
, -X- _ O
PoWER -X- _ O
: -X- _ O
PoWER -X- _ O
- -X- _ O
BERT -X- _ O
on -X- _ O
two -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

plies -X- _ O
token -X- _ O
elimination -X- _ O
only -X- _ O
in -X- _ O
two -X- _ O
layers -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
training -X- _ O
search -X- _ O
space -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
procedure -X- _ O
performs -X- _ O
token -X- _ O
elimination -X- _ O
for -X- _ O
all -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
enabling -X- _ O
a -X- _ O
more -X- _ O
effective -X- _ O
removal -X- _ O
of -X- _ O
redundant -X- _ O
tokens -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
lack -X- _ O
any -X- _ O
speedup -X- _ O
gains -X- _ O
for -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
QNLI -X- _ B-TaskName
, -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
and -X- _ O
MRPC -X- _ B-TaskName
which -X- _ O
need -X- _ O
a -X- _ O
higher -X- _ O
degree -X- _ O
of -X- _ O
contextualism -X- _ O
during -X- _ O
inference -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
AdapLeR -X- _ B-MethodName
can -X- _ O
offer -X- _ O
some -X- _ O
speedups -X- _ O
even -X- _ O
for -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O

Speedup -X- _ O
- -X- _ O
Performance -X- _ O
Tradeoff -X- _ O
. -X- _ O

To -X- _ O
provide -X- _ O
a -X- _ O
closer -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
AdapLeR -X- _ B-MethodName
in -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
length -X- _ O
reduction -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
illustrate -X- _ O
speedup -X- _ B-MetricName
- -X- _ O
accuracy -X- _ O
curves -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
these -X- _ O
curves -X- _ O
for -X- _ O
two -X- _ O
tasks -X- _ O
in -X- _ O
which -X- _ O
other -X- _ O
length -X- _ O
reduction -X- _ O
methods -X- _ O
show -X- _ O
comparable -X- _ O
speedups -X- _ O
to -X- _ O
AdapLeR. -X- _ B-MethodName
For -X- _ O
each -X- _ O
curve -X- _ O
, -X- _ O
the -X- _ O
points -X- _ O
were -X- _ O
obtained -X- _ O
by -X- _ O
tuning -X- _ O
the -X- _ O
most -X- _ O
influential -X- _ O
hyperparameters -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
model -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
, -X- _ O
AdapLeR -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
approaches -X- _ O
in -X- _ O
all -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O

An -X- _ O
interesting -X- _ O
observation -X- _ O
here -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
curves -X- _ O
for -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
AdapLeR -X- _ B-MethodName
are -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O

This -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
procedure -X- _ O
employed -X- _ O
by -X- _ O
the -X- _ O
former -X- _ O
two -X- _ O
methods -X- _ O
for -X- _ O
determining -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
reduced -X- _ O
tokens -X- _ O
( -X- _ O
whereas -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
adopts -X- _ O
a -X- _ O
fixed -X- _ O
retention -X- _ O
configuration -X- _ O
in -X- _ O
token -X- _ O
elimination -X- _ O
) -X- _ O
.Movie -X- _ O
Reviews -X- _ O
MultiRC -X- _ O
Strategy -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Acc -X- _ O
. -X- _ O

Speedup -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Accuracy -X- _ O
and -X- _ O
speedup -X- _ O
when -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
input -X- _ O
tokens -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
are -X- _ O
computed -X- _ O
based -X- _ O
on -X- _ O
attention -X- _ O
and -X- _ O
saliency -X- _ O
strategies -X- _ O
and -X- _ O
human -X- _ O
rationale -X- _ O
( -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
bold -X- _ O
values -X- _ O
indicate -X- _ O
the -X- _ O
best -X- _ O
corresponding -X- _ O
strategy -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
( -X- _ O
the -X- _ O
closest -X- _ O
performance -X- _ O
to -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
) -X- _ O
. -X- _ O

5 -X- _ O
Analysis -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
to -X- _ O
support -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
saliency -X- _ O
scores -X- _ O
as -X- _ O
a -X- _ O
supervision -X- _ O
in -X- _ O
measuring -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
token -X- _ O
representations -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
behavior -X- _ O
of -X- _ O
Contribution -X- _ B-MethodName
Predictors -X- _ I-MethodName
in -X- _ O
identifying -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
AdapLeR. -X- _ B-MethodName
5.1 -X- _ O
Rationale -X- _ O
as -X- _ O
an -X- _ O
Upper -X- _ O
Bound -X- _ O
A -X- _ O
natural -X- _ O
question -X- _ O
that -X- _ O
arises -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
token -X- _ O
pruning -X- _ O
is -X- _ O
that -X- _ O
of -X- _ O
importance -X- _ O
measure -X- _ O
: -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
appropriate -X- _ O
criterion -X- _ O
for -X- _ O
assessing -X- _ O
the -X- _ O
relative -X- _ O
importance -X- _ O
of -X- _ O
tokens -X- _ O
within -X- _ O
a -X- _ O
sentence -X- _ O
? -X- _ O

We -X- _ O
resort -X- _ O
to -X- _ O
human -X- _ O
rationale -X- _ O
as -X- _ O
a -X- _ O
reliable -X- _ O
upper -X- _ O
bound -X- _ O
for -X- _ O
measuring -X- _ O
token -X- _ O
importance -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
ERASER -X- _ O
benchmark -X- _ O
( -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
multiple -X- _ O
tasks -X- _ O
for -X- _ O
which -X- _ O
important -X- _ O
spans -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
have -X- _ O
been -X- _ O
highlighted -X- _ O
as -X- _ O
supporting -X- _ O
evidence -X- _ O
( -X- _ O
aka -X- _ O
“ -X- _ O
rationale -X- _ O
” -X- _ O
) -X- _ O
by -X- _ O
human -X- _ O
. -X- _ O

Among -X- _ O
the -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
benchmark -X- _ O
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
two -X- _ O
diverse -X- _ O
classification -X- _ O
tasks -X- _ O
: -X- _ O
Movie -X- _ O
reviews -X- _ O
( -X- _ O
Zaidan -X- _ O
and -X- _ O
Eisner -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
MultiRC -X- _ O
( -X- _ O
Khashabi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
former -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
sentiment -X- _ O
of -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O

Whereas -X- _ O
the -X- _ O
latter -X- _ O
contains -X- _ O
a -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
multiple -X- _ O
candidate -X- _ O
answers -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
cast -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
task -X- _ O
of -X- _ O
passage -X- _ O
/ -X- _ O
question -X- _ O
/ -X- _ O
answer -X- _ O
triplets -X- _ O
in -X- _ O
the -X- _ O
ERASER -X- _ O
benchmark -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
human -X- _ O
rationales -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ B-MethodName
based -X- _ O
on -X- _ O
the -X- _ O
rationales -X- _ O
only -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
by -X- _ O
excluding -X- _ O
those -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
highlighted -X- _ O
as -X- _ O
being -X- _ O
important -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
rows -X- _ O
show -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
with -X- _ O
full -X- _ O
input -X- _ O
and -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
only -X- _ O
. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
merely7 -X- _ O

SST-2 -X- _ O
Label -X- _ O
: -X- _ O
Negative -X- _ O
QNLI -X- _ O
Label -X- _ O
: -X- _ O
EntailmentFigure -X- _ O
4 -X- _ O
: -X- _ O
The -X- _ O
illustration -X- _ O
of -X- _ O
contribution -X- _ O
scores -X- _ O
obtained -X- _ O
by -X- _ O
CPs -X- _ O
in -X- _ O
three -X- _ O
different -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
two -X- _ O
input -X- _ O
examples -X- _ O
from -X- _ O
SST-2 -X- _ O
( -X- _ O
sentiment -X- _ O
) -X- _ O
and -X- _ O
QNLI -X- _ O
( -X- _ O
Question -X- _ O
- -X- _ O
answering -X- _ O
NLI -X- _ O
) -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
contribution -X- _ O
scores -X- _ O
are -X- _ O
shown -X- _ O
by -X- _ O
color -X- _ O
intensity -X- _ O
. -X- _ O

Only -X- _ O
the -X- _ O
highlighted -X- _ O
token -X- _ O
representations -X- _ O
are -X- _ O
processed -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O

See -X- _ O
more -X- _ O
full -X- _ O
- -X- _ O
layer -X- _ O
plots -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
6 -X- _ O
. -X- _ O

on -X- _ O
rationales -X- _ O
not -X- _ O
only -X- _ O
yields -X- _ O
less -X- _ O
computation -X- _ O
cost -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
better -X- _ O
performance -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
full -X- _ O
input -X- _ O
setting -X- _ O
. -X- _ O

Obviously -X- _ O
, -X- _ O
human -X- _ O
annotations -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
for -X- _ O
a -X- _ O
whole -X- _ O
range -X- _ O
of -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
this -X- _ O
criterion -X- _ O
is -X- _ O
infeasible -X- _ O
in -X- _ O
practice -X- _ O
and -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
an -X- _ O
upper -X- _ O
bound -X- _ O
for -X- _ O
evaluating -X- _ O
different -X- _ O
strategies -X- _ O
in -X- _ O
measuring -X- _ O
token -X- _ O
importance -X- _ O
. -X- _ O

5.2 -X- _ O
Saliency -X- _ B-MetricName
vs. -X- _ O
Attention -X- _ O
We -X- _ O
investigated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
saliency -X- _ B-MetricName
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
weights -X- _ O
as -X- _ O
two -X- _ O
commonly -X- _ O
used -X- _ O
strategies -X- _ O
for -X- _ O
measuring -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

To -X- _ O
compute -X- _ O
these -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ B-MetricName
with -X- _ O
all -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
obtained -X- _ O
saliency -X- _ O
scores -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
embedding -X- _ O
layer -X- _ O
. -X- _ O

This -X- _ O
brings -X- _ O
about -X- _ O
two -X- _ O
advantages -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
representations -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
are -X- _ O
non -X- _ O
- -X- _ O
contextualized -X- _ O
, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
independently -X- _ O
from -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
the -X- _ O
backpropagation -X- _ O
of -X- _ O
gradients -X- _ O
through -X- _ O
layers -X- _ O
to -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
provides -X- _ O
us -X- _ O
with -X- _ O
aggregated -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
relative -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
we -X- _ O
aggregated -X- _ O
the -X- _ O
selfattention -X- _ O
weights -X- _ O
across -X- _ O
all -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
processed -X- _ O
variant -X- _ O
of -X- _ O
attentions -X- _ O
called -X- _ O
attention -X- _ O
rollout -X- _ O
( -X- _ O
Abnar -X- _ O
and -X- _ O
Zuidema -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
popular -X- _ O
technique -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
attention -X- _ O
weight -X- _ O
matrix -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
is -X- _ O
multiplied -X- _ O
with -X- _ O
the -X- _ O
preceding -X- _ O
ones -X- _ O
to -X- _ O
form -X- _ O
aggregated -X- _ O
attention -X- _ O
values -X- _ O
. -X- _ O

To -X- _ O
assign -X- _ O
an -X- _ O
importance -X- _ O
score -X- _ O
to -X- _ O
each -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
examined -X- _ O
two -X- _ O
different -X- _ O
interpretation -X- _ O
of -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
strategy -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
adopted -X- _ O
by -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
which -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
we -X- _ O
accumulate -X- _ O
attention -X- _ O
values -X- _ O
fromother -X- _ O
tokens -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
measured -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
attends -X- _ O
to -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
a -X- _ O
strategy -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
interpretability -X- _ O
studies -X- _ O
around -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Abnar -X- _ O
and -X- _ O
Zuidema -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Chrysostomou -X- _ O
and -X- _ O
Aletras -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Jain -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
ksalient -X- _ O
and -X- _ O
attended -X- _ O
words -X- _ O
, -X- _ O
with -X- _ O
kbeing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
annotated -X- _ O
as -X- _ O
rationales -X- _ O
. -X- _ O

Results -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
show -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
salient -X- _ O
tokens -X- _ O
outperforms -X- _ O
that -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
attended -X- _ O
tokens -X- _ O
. -X- _ O

This -X- _ O
denotes -X- _ O
that -X- _ O
saliency -X- _ O
is -X- _ O
a -X- _ O
better -X- _ O
indicator -X- _ O
for -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O

Nonetheless -X- _ O
, -X- _ O
recent -X- _ O
length -X- _ O
reduction -X- _ O
techniques -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kim -X- _ O
and -X- _ O
Cho -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
mostly -X- _ O
adopted -X- _ O
attention -X- _ O
weights -X- _ O
as -X- _ O
their -X- _ O
criterion -X- _ O
for -X- _ O
selecting -X- _ O
important -X- _ O
tokens -X- _ O
. -X- _ O

Computing -X- _ O
these -X- _ O
weights -X- _ O
is -X- _ O
convenient -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
already -X- _ O
computed -X- _ O
during -X- _ O
the -X- _ O
forward -X- _ O
pass -X- _ O
, -X- _ O
whereas -X- _ O
computing -X- _ O
saliency -X- _ O
requires -X- _ O
an -X- _ O
additional -X- _ O
backpropagation -X- _ O
step -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
in -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
saliency -X- _ O
scores -X- _ O
are -X- _ O
easily -X- _ O
estimated -X- _ O
within -X- _ O
inference -X- _ O
time -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
CPs -X- _ B-MethodName
. -X- _ O

5.3 -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
Evaluation -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
validate -X- _ O
our -X- _ O
Contribution -X- _ B-MethodName
Predictors -X- _ I-MethodName
in -X- _ O
selecting -X- _ O
the -X- _ O
most -X- _ O
contributed -X- _ O
tokens -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
illustrates -X- _ O
two -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
QNLI -X- _ B-DatasetName
datasets -X- _ O
in -X- _ O
which -X- _ O
CPs -X- _ B-MethodName
identify -X- _ O
and -X- _ O
gradually -X- _ O
drop -X- _ O
the -X- _ O
irrelevant -X- _ O
tokens -X- _ O
through -X- _ O
layers -X- _ O
, -X- _ O
finally -X- _ O
focusing -X- _ O
mostly -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
token -X- _ O
representations -X- _ O
; -X- _ O
pedestrian -X- _ O
( -X- _ O
adjective -X- _ O
) -X- _ O
in -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
tesla -X- _ O
coil -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
part -X- _ O
of -X- _ O
QNLI -X- _ B-MethodName
( -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
highly -X- _ O
aligned -X- _ O
with -X- _ O
human -X- _ O
rationale -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
AdapLeR -X- _ B-MethodName
’s -X- _ O
CPs -X- _ B-MethodName
can -X- _ O
preserve -X- _ O
rationales -X- _ O
without -X- _ O
requiring -X- _ O
direct -X- _ O
human -X- _ O
annotations -X- _ O
in -X- _ O
an -X- _ O
unsuper-8 -X- _ O

Saliency -X- _ O
AttentionAttention -X- _ O
Rollout -X- _ O
CP -X- _ B-MethodName
Figure -X- _ O
5 -X- _ O
: -X- _ O
Agreement -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
mean -X- _ O
Average -X- _ O
Precision -X- _ O
and -X- _ O
False -X- _ O
Positive -X- _ O
Rate -X- _ O
for -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
( -X- _ O
CP -X- _ B-MethodName
) -X- _ O
and -X- _ O
three -X- _ O
alternative -X- _ O
techniques -X- _ O
. -X- _ O

vised -X- _ O
manner -X- _ O
we -X- _ O
carried -X- _ O
out -X- _ O
the -X- _ O
following -X- _ O
experiment -X- _ O
. -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
trained -X- _ O
CPs -X- _ B-MethodName
in -X- _ O
predicting -X- _ O
human -X- _ O
rationales -X- _ O
we -X- _ O
computed -X- _ O
the -X- _ O
output -X- _ O
scores -X- _ O
of -X- _ O
CPs -X- _ B-MethodName
in -X- _ O
AdapLeR -X- _ B-MethodName
for -X- _ O
each -X- _ O
token -X- _ O
representation -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
Movie -X- _ B-DatasetName
Review -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
computed -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
raw -X- _ O
attention -X- _ O
, -X- _ O
attention -X- _ O
rollout -X- _ O
, -X- _ O
and -X- _ O
saliency -X- _ B-MetricName
scores -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
representation -X- _ O
. -X- _ O

Since -X- _ O
human -X- _ O
rationales -X- _ O
are -X- _ O
annotated -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
the -X- _ O
scores -X- _ O
across -X- _ O
tokens -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
arrive -X- _ O
at -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
importance -X- _ O
scores -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
these -X- _ O
soft -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
uniform -X- _ O
- -X- _ O
level -X- _ O
threshold -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
1 -X- _ O
/ -X- _ O
n -X- _ O
) -X- _ O
to -X- _ O
reach -X- _ O
a -X- _ O
binary -X- _ O
score -X- _ O
indicating -X- _ O
tokens -X- _ O
selected -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O

As -X- _ O
for -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
Average -X- _ B-MetricName
Precision -X- _ I-MetricName
( -X- _ O
AP -X- _ B-MetricName
) -X- _ O
and -X- _ O
False -X- _ B-MetricName
Positive -X- _ I-MetricName
Rate -X- _ I-MetricName
( -X- _ O
FPR -X- _ B-MetricName
) -X- _ O
metrics -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
remaining -X- _ O
tokens -X- _ O
to -X- _ O
the -X- _ O
human -X- _ O
rationale -X- _ O
annotations -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
metric -X- _ O
measures -X- _ O
whether -X- _ O
the -X- _ O
model -X- _ O
assigns -X- _ O
higher -X- _ O
continuous -X- _ O
scores -X- _ O
to -X- _ O
those -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
annotated -X- _ O
by -X- _ O
humans -X- _ O
as -X- _ O
rationales -X- _ O
. -X- _ O

Whereas -X- _ O
, -X- _ O
the -X- _ O
intuition -X- _ O
behind -X- _ O
the -X- _ O
second -X- _ O
metric -X- _ O
is -X- _ O
how -X- _ O
many -X- _ O
irrelevant -X- _ O
tokens -X- _ O
are -X- _ O
selected -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
passed -X- _ O
to -X- _ O
subsequent -X- _ O
layers -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
soft -X- _ O
scores -X- _ O
for -X- _ O
computing -X- _ O
AP -X- _ B-MetricName
and -X- _ O
binary -X- _ O
scores -X- _ O
for -X- _ O
computing -X- _ O
FPR -X- _ B-MetricName
. -X- _ O

Figure -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
agreement -X- _ O
between -X- _ O
human -X- _ O
rationales -X- _ O
and -X- _ O
the -X- _ O
selected -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
metrics -X- _ O
. -X- _ O

In -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
widely -X- _ O
used -X- _ O
strategies -X- _ O
for -X- _ O
selecting -X- _ O
important -X- _ O
tokens -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
salinecy -X- _ O
and -X- _ O
attention -X- _ O
, -X- _ O
our -X- _ O
CPs -X- _ B-MethodName
have -X- _ O
significantly -X- _ O
less -X- _ O
false -X- _ B-MetricName
positive -X- _ I-MetricName
rate -X- _ O
in -X- _ O
preserving -X- _ O
ratio -X- _ O
- -X- _ O
nales -X- _ O
through -X- _ O
layers -X- _ O
. -X- _ O

Despite -X- _ O
having -X- _ O
similar -X- _ O
FPRs -X- _ B-MetricName
at -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
, -X- _ O
CP -X- _ B-MethodName
is -X- _ O
preferable -X- _ O
to -X- _ O
attention -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
better -X- _ O
identify -X- _ O
rationales -X- _ O
at -X- _ O
the -X- _ O
earlier -X- _ O
layers -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
token -X- _ O
representations -X- _ O
when -X- _ O
building -X- _ O
the -X- _ O
final -X- _ O
one -X- _ O
. -X- _ O

This -X- _ O
in -X- _ O
turn -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
performance -X- _ O
, -X- _ O
as -X- _ O
was -X- _ O
also -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
experiment -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
curve -X- _ O
of -X- _ O
mAP -X- _ O
for -X- _ O
saliency -X- _ B-MetricName
is -X- _ O
consistently -X- _ O
higher -X- _ O
than -X- _ O
other -X- _ O
strategies -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
alignment -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
which -X- _ O
supports -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
saliency -X- _ O
as -X- _ O
a -X- _ O
measure -X- _ O
for -X- _ O
token -X- _ O
importance -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
that -X- _ O
attempts -X- _ O
at -X- _ O
guiding -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
humanlike -X- _ O
reasoning -X- _ O
by -X- _ O
training -X- _ O
rationale -X- _ O
generation -X- _ O
simultaneously -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
that -X- _ O
requires -X- _ O
human -X- _ O
annotation -X- _ O
( -X- _ O
Atanasova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
by -X- _ O
- -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
contribution -X- _ O
estimation -X- _ O
process -X- _ O
, -X- _ O
our -X- _ O
trained -X- _ O
CPs -X- _ B-MethodName
are -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
these -X- _ O
rationales -X- _ O
at -X- _ O
inference -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
human -X- _ O
- -X- _ O
generated -X- _ O
annotations -X- _ O
. -X- _ O

6 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
AdapLeR -X- _ B-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
method -X- _ O
that -X- _ O
accelerates -X- _ O
inference -X- _ O
by -X- _ O
dynamically -X- _ O
identifying -X- _ O
and -X- _ O
dropping -X- _ O
less -X- _ O
contributing -X- _ O
token -X- _ O
representations -X- _ O
through -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
AdapLeR -X- _ B-MethodName
accomplishes -X- _ O
this -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
Contribution -X- _ O
Predictors -X- _ O
based -X- _ O
on -X- _ O
saliencies -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
and -X- _ O
applying -X- _ O
a -X- _ O
gradual -X- _ O
masking -X- _ O
technique -X- _ O
to -X- _ O
simulate -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
token -X- _ O
removal -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

Empirical -X- _ O
results -X- _ O
on -X- _ O
eight -X- _ O
diverse -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
show -X- _ O
considerable -X- _ O
improvements -X- _ O
over -X- _ O
existing -X- _ O
methods -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
demonstrated -X- _ O
that -X- _ O
contribution -X- _ O
predictors -X- _ O
generate -X- _ O
rationales -X- _ O
that -X- _ O
are -X- _ O
highly -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
those -X- _ O
manually -X- _ O
specified -X- _ O
by -X- _ O
humans -X- _ O
. -X- _ O

As -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
apply -X- _ O
our -X- _ O
technique -X- _ O
to -X- _ O
more -X- _ O
tasks -X- _ O
and -X- _ O
see -X- _ O
whether -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
those -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
all -X- _ O
token -X- _ O
representations -X- _ O
to -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
) -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
combining -X- _ O
our -X- _ O
width -X- _ O
- -X- _ O
based -X- _ O
strategy -X- _ O
with -X- _ O
a -X- _ O
depthbased -X- _ O
one -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
early -X- _ O
exiting -X- _ O
) -X- _ O
might -X- _ O
potentially -X- _ O
yield -X- _ O
greater -X- _ O
efficiency -X- _ O
, -X- _ O
something -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
pursue -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Broader -X- _ O
Impact -X- _ O
Using -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
use -X- _ O
fewer -X- _ O
FLOPs -X- _ B-MetricName
, -X- _ O
reducing -X- _ O
energy -X- _ O
use -X- _ O
and -X- _ O
carbon -X- _ O
emissions -X- _ O
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
.9 -X- _ O

References -X- _ O
Samira -X- _ O
Abnar -X- _ O
and -X- _ O
Willem -X- _ O
Zuidema -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Quantifying -X- _ O
attention -X- _ O
flow -X- _ O
in -X- _ O
transformers -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
4190–4197 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Marco -X- _ O
Ancona -X- _ O
, -X- _ O
Enea -X- _ O
Ceolini -X- _ O
, -X- _ O
Cengiz -X- _ O
Öztireli -X- _ O
, -X- _ O
and -X- _ O
Markus -X- _ O
Gross -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

Towards -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
attribution -X- _ O
methods -X- _ O
for -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
. -X- _ O

Pepa -X- _ O
Atanasova -X- _ O
, -X- _ O
Jakob -X- _ O
Grue -X- _ O
Simonsen -X- _ O
, -X- _ O
Christina -X- _ O
Lioma -X- _ O
, -X- _ O
and -X- _ O
Isabelle -X- _ O
Augenstein -X- _ O
. -X- _ O
2020a -X- _ O
. -X- _ O

A -X- _ O
diagnostic -X- _ O
study -X- _ O
of -X- _ O
explainability -X- _ O
techniques -X- _ O
for -X- _ O
text -X- _ O
classification -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2020 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
3256–3274 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Pepa -X- _ O
Atanasova -X- _ O
, -X- _ O
Jakob -X- _ O
Grue -X- _ O
Simonsen -X- _ O
, -X- _ O
Christina -X- _ O
Lioma -X- _ O
, -X- _ O
and -X- _ O
Isabelle -X- _ O
Augenstein -X- _ O
. -X- _ O
2020b -X- _ O
. -X- _ O

Generating -X- _ O
fact -X- _ O
checking -X- _ O
explanations -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
7352–7364 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Jasmijn -X- _ O
Bastings -X- _ O
and -X- _ O
Katja -X- _ O
Filippova -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

The -X- _ O
elephant -X- _ O
in -X- _ O
the -X- _ O
interpretability -X- _ O
room -X- _ O
: -X- _ O
Why -X- _ O
use -X- _ O
attention -X- _ O
as -X- _ O
explanation -X- _ O
when -X- _ O
we -X- _ O
have -X- _ O
saliency -X- _ O
methods -X- _ O
? -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Third -X- _ O
BlackboxNLP -X- _ O
Workshop -X- _ O
on -X- _ O
Analyzing -X- _ O
and -X- _ O
Interpreting -X- _ O
Neural -X- _ O
Networks -X- _ O
for -X- _ O
NLP -X- _ O
, -X- _ O
pages -X- _ O
149–155 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

George -X- _ O
Chrysostomou -X- _ O
and -X- _ O
Nikolaos -X- _ O
Aletras -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Enjoy -X- _ O
the -X- _ O
salience -X- _ O
: -X- _ O
Towards -X- _ O
better -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
faithful -X- _ O
explanations -X- _ O
with -X- _ O
word -X- _ O
salience -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2021 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
8189–8200 -X- _ O
, -X- _ O
Online -X- _ O
and -X- _ O
Punta -X- _ O
Cana -X- _ O
, -X- _ O
Dominican -X- _ O
Republic -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Jacob -X- _ O
Devlin -X- _ O
, -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Kristina -X- _ O
Toutanova -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

BERT -X- _ O
: -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
deep -X- _ O
bidirectional -X- _ O
transformers -X- _ O
for -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2019 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
Volume -X- _ O
1 -X- _ O
( -X- _ O
Long -X- _ O
and -X- _ O
Short -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
4171–4186 -X- _ O
, -X- _ O
Minneapolis -X- _ O
, -X- _ O
Minnesota -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Jay -X- _ O
DeYoung -X- _ O
, -X- _ O
Sarthak -X- _ O
Jain -X- _ O
, -X- _ O
Nazneen -X- _ O
Fatema -X- _ O
Rajani -X- _ O
, -X- _ O
Eric -X- _ O
Lehman -X- _ O
, -X- _ O
Caiming -X- _ O
Xiong -X- _ O
, -X- _ O
Richard -X- _ O
Socher -X- _ O
, -X- _ O
and -X- _ O
Byron -X- _ O
C. -X- _ O
Wallace -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

ERASER -X- _ O
: -X- _ O

A -X- _ O
benchmark -X- _ O
to -X- _ O
evaluate -X- _ O
rationalized -X- _ O
NLP -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
4443–4458 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

William -X- _ O
B. -X- _ O
Dolan -X- _ O
and -X- _ O
Chris -X- _ O
Brockett -X- _ O
. -X- _ O

2005 -X- _ O
. -X- _ O

Automatically -X- _ O
constructing -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
sentential -X- _ O
paraphrases -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
Third -X- _ O
International -X- _ O
Workshop -X- _ O
on -X- _ O
Paraphrasing -X- _ O
( -X- _ O
IWP2005 -X- _ O
) -X- _ O
. -X- _ O

Kawin -X- _ O
Ethayarajh -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

How -X- _ O
contextual -X- _ O
are -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
? -X- _ O

Comparing -X- _ O
the -X- _ O
geometry -X- _ O
of -X- _ O
BERT -X- _ O
, -X- _ O
ELMo -X- _ O
, -X- _ O
and -X- _ O
GPT-2 -X- _ O
embeddings -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2019 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
and -X- _ O
the -X- _ O
9th -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
- -X- _ O
IJCNLP -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
55–65 -X- _ O
, -X- _ O
Hong -X- _ O
Kong -X- _ O
, -X- _ O
China -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Cristóbal -X- _ O
Eyzaguirre -X- _ O
, -X- _ O
Felipe -X- _ O
del -X- _ O
Río -X- _ O
, -X- _ O
Vladimir -X- _ O
Araujo -X- _ O
, -X- _ O
and -X- _ O
Álvaro -X- _ O
Soto -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

DACT -X- _ O
- -X- _ O
BERT -X- _ O
: -X- _ O

Differentiable -X- _ O
adaptive -X- _ O
computation -X- _ O
time -X- _ O
for -X- _ O
an -X- _ O
efficient -X- _ O
bert -X- _ O
inference -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:2109.11745 -X- _ O
. -X- _ O

Yunchao -X- _ O
Gong -X- _ O
, -X- _ O
L. -X- _ O
Liu -X- _ O
, -X- _ O
Ming -X- _ O
Yang -X- _ O
, -X- _ O
and -X- _ O
Lubomir -X- _ O
D. -X- _ O
Bourdev -X- _ O
. -X- _ O
2014 -X- _ O
. -X- _ O

Compressing -X- _ O
deep -X- _ O
convolutional -X- _ O
networks -X- _ O
using -X- _ O
vector -X- _ O
quantization -X- _ O
. -X- _ O

ArXiv -X- _ O
, -X- _ O
Saurabh -X- _ O
Goyal -X- _ O
, -X- _ O
Anamitra -X- _ O
Roy -X- _ O
Choudhury -X- _ O
, -X- _ O
Saurabh -X- _ O
Raje -X- _ O
, -X- _ O
Venkatesan -X- _ O
Chakaravarthy -X- _ O
, -X- _ O
Yogish -X- _ O
Sabharwal -X- _ O
, -X- _ O
and -X- _ O
Ashish -X- _ O
Verma -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Power -X- _ O
- -X- _ O
bert -X- _ O
: -X- _ O
Accelerating -X- _ O
bert -X- _ O
inference -X- _ O
via -X- _ O
progressive -X- _ O
word -X- _ O
- -X- _ O
vector -X- _ O
elimination -X- _ O
. -X- _ O

In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
LearnSong -X- _ O
Han -X- _ O
, -X- _ O
Huizi -X- _ O
Mao -X- _ O
, -X- _ O
and -X- _ O
William -X- _ O
J. -X- _ O
Dally -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O

Deep -X- _ O
compression -X- _ O
: -X- _ O
Compressing -X- _ O
deep -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
pruning -X- _ O
, -X- _ O
trained -X- _ O
quantization -X- _ O
and -X- _ O
huffman -X- _ O
coding -X- _ O
. -X- _ O

In -X- _ O
4th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2016 -X- _ O
, -X- _ O
San -X- _ O
Juan -X- _ O
, -X- _ O
Puerto -X- _ O
Rico -X- _ O
, -X- _ O
May -X- _ O
2 -X- _ O
- -X- _ O
4 -X- _ O
, -X- _ O
2016 -X- _ O
, -X- _ O
Conference -X- _ O
Track -X- _ O
Proceedings -X- _ O
. -X- _ O

Yihui -X- _ O
He -X- _ O
, -X- _ O
Xiangyu -X- _ O
Zhang -X- _ O
, -X- _ O
and -X- _ O
Jian -X- _ O
Sun -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Channel -X- _ O
pruning -X- _ O
for -X- _ O
accelerating -X- _ O
very -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

2017 -X- _ O

IEEE -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Computer -X- _ O
Geoffrey -X- _ O
E. -X- _ O
Hinton -X- _ O
, -X- _ O
Oriol -X- _ O
Vinyals -X- _ O
, -X- _ O
and -X- _ O
Jeffrey -X- _ O
Dean -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O

Distilling -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O

Ahmed -X- _ O
Hussein -X- _ O
, -X- _ O
Mohamed -X- _ O
Medhat -X- _ O
Gaber -X- _ O
, -X- _ O
Eyad -X- _ O
Elyan -X- _ O
, -X- _ O
and -X- _ O
Chrisina -X- _ O
Jayne -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Imitation -X- _ O
learning -X- _ O
: -X- _ O
A -X- _ O
survey -X- _ O
of -X- _ O
learning -X- _ O
methods -X- _ O
. -X- _ O

ACM -X- _ O
Computing -X- _ O
Surveys -X- _ O
Sarthak -X- _ O
Jain -X- _ O
and -X- _ O
Byron -X- _ O
C. -X- _ O
Wallace -X- _ O
. -X- _ O

2019 -X- _ O
. -X- _ O

Attention -X- _ O
is -X- _ O
not -X- _ O
Explanation -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2019 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
Volume -X- _ O
1 -X- _ O
( -X- _ O
Long -X- _ O
and -X- _ O
Short -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
3543–3556 -X- _ O
, -X- _ O
Minneapolis -X- _ O
, -X- _ O
Minnesota -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Sarthak -X- _ O
Jain -X- _ O
, -X- _ O
Sarah -X- _ O
Wiegreffe -X- _ O
, -X- _ O
Yuval -X- _ O
Pinter -X- _ O
, -X- _ O
and -X- _ O
Byron -X- _ O
C. -X- _ O
Wallace -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

Learning -X- _ O
to -X- _ O
faithfully -X- _ O
rationalize -X- _ O
by -X- _ O
construction -X- _ O
. -X- _ O

In -X- _ O
ACL -X- _ O
. -X- _ O

Xiaoqi -X- _ O
Jiao -X- _ O
, -X- _ O
Yichun -X- _ O
Yin -X- _ O
, -X- _ O
Lifeng -X- _ O
Shang -X- _ O
, -X- _ O
Xin -X- _ O
Jiang -X- _ O
, -X- _ O
Xiao -X- _ O
Chen -X- _ O
, -X- _ O
Linlin -X- _ O
Li -X- _ O
, -X- _ O
Fang -X- _ O
Wang -X- _ O
, -X- _ O
and -X- _ O
Qun -X- _ O
Liu -X- _ O
. -X- _ O

2020.10 -X- _ O

TinyBERT -X- _ O
: -X- _ O
Distilling -X- _ O
BERT -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Findings -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
EMNLP -X- _ O
2020 -X- _ O
, -X- _ O
pages -X- _ O
4163 -X- _ O
– -X- _ O
4174 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Daniel -X- _ O
Khashabi -X- _ O
, -X- _ O
Snigdha -X- _ O
Chaturvedi -X- _ O
, -X- _ O
Michael -X- _ O
Roth -X- _ O
, -X- _ O
Shyam -X- _ O
Upadhyay -X- _ O
, -X- _ O
and -X- _ O
Dan -X- _ O
Roth -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

Looking -X- _ O
beyond -X- _ O
the -X- _ O
surface -X- _ O
: -X- _ O
A -X- _ O
challenge -X- _ O
set -X- _ O
for -X- _ O
reading -X- _ O
comprehension -X- _ O
over -X- _ O
multiple -X- _ O
sentences -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
Volume -X- _ O
1 -X- _ O
( -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
252–262 -X- _ O
, -X- _ O
New -X- _ O
Orleans -X- _ O
, -X- _ O
Louisiana -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Gyuwan -X- _ O
Kim -X- _ O
and -X- _ O
Kyunghyun -X- _ O
Cho -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Lengthadaptive -X- _ O
transformer -X- _ O
: -X- _ O
Train -X- _ O
once -X- _ O
with -X- _ O
length -X- _ O
drop -X- _ O
, -X- _ O
use -X- _ O
anytime -X- _ O
with -X- _ O
search -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
59th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
and -X- _ O
the -X- _ O
11th -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
6501–6511 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Josef -X- _ O
Klafka -X- _ O
and -X- _ O
Allyson -X- _ O
Ettinger -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Spying -X- _ O
on -X- _ O
your -X- _ O
neighbors -X- _ O
: -X- _ O
Fine -X- _ O
- -X- _ O
grained -X- _ O
probing -X- _ O
of -X- _ O
contextual -X- _ O
embeddings -X- _ O
for -X- _ O
information -X- _ O
about -X- _ O
surrounding -X- _ O
words -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
4801–4811 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Jens -X- _ O
Lehmann -X- _ O
, -X- _ O
Robert -X- _ O
Isele -X- _ O
, -X- _ O
Max -X- _ O
Jakob -X- _ O
, -X- _ O
Anja -X- _ O
Jentzsch -X- _ O
, -X- _ O
Dimitris -X- _ O
Kontokostas -X- _ O
, -X- _ O
Pablo -X- _ O
N -X- _ O
Mendes -X- _ O
, -X- _ O
Sebastian -X- _ O
Hellmann -X- _ O
, -X- _ O
Mohamed -X- _ O
Morsey -X- _ O
, -X- _ O
Patrick -X- _ O
Van -X- _ O
Kleef -X- _ O
, -X- _ O
Sören -X- _ O
Auer -X- _ O
, -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O

Dbpedia -X- _ O
– -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
, -X- _ O
multilingual -X- _ O
knowledge -X- _ O
base -X- _ O
extracted -X- _ O
from -X- _ O
wikipedia -X- _ O
. -X- _ O

Jiwei -X- _ O
Li -X- _ O
, -X- _ O
Xinlei -X- _ O
Chen -X- _ O
, -X- _ O
Eduard -X- _ O
Hovy -X- _ O
, -X- _ O
and -X- _ O
Dan -X- _ O
Jurafsky -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O

Visualizing -X- _ O
and -X- _ O
understanding -X- _ O
neural -X- _ O
models -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2016 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
681–691 -X- _ O
, -X- _ O
San -X- _ O
Diego -X- _ O
, -X- _ O
California -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Sizhen -X- _ O
Li -X- _ O
, -X- _ O
Shuai -X- _ O
Zhao -X- _ O
, -X- _ O
Bo -X- _ O
Cheng -X- _ O
, -X- _ O
and -X- _ O
Hao -X- _ O
Yang -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

An -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
model -X- _ O
for -X- _ O
fact -X- _ O
checking -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
First -X- _ O
Workshop -X- _ O
on -X- _ O
Fact -X- _ O
Extraction -X- _ O
and -X- _ O
VERification -X- _ O
( -X- _ O
FEVER -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
138–144 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Kaiyuan -X- _ O
Liao -X- _ O
, -X- _ O
Yi -X- _ O
Zhang -X- _ O
, -X- _ O
Xuancheng -X- _ O
Ren -X- _ O
, -X- _ O
Qi -X- _ O
Su -X- _ O
, -X- _ O
Xu -X- _ O
Sun -X- _ O
, -X- _ O
and -X- _ O
Bin -X- _ O
He -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

A -X- _ O
global -X- _ O
past -X- _ O
- -X- _ O
future -X- _ O
early -X- _ O
exit -X- _ O
method -X- _ O
for -X- _ O
accelerating -X- _ O
inference -X- _ O
of -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2021 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
2013–2023 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Weijie -X- _ O
Liu -X- _ O
, -X- _ O
Peng -X- _ O
Zhou -X- _ O
, -X- _ O
Zhiruo -X- _ O
Wang -X- _ O
, -X- _ O
Zhe -X- _ O
Zhao -X- _ O
, -X- _ O
Haotang -X- _ O
Deng -X- _ O
, -X- _ O
and -X- _ O
Qi -X- _ O
Ju -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

FastBERT -X- _ O
: -X- _ O
a -X- _ O
selfdistilling -X- _ O
BERT -X- _ O
with -X- _ O
adaptive -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
6035 -X- _ O
– -X- _ O
6044 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Ilya -X- _ O
Loshchilov -X- _ O
and -X- _ O
Frank -X- _ O
Hutter -X- _ O
. -X- _ O

2019 -X- _ O
. -X- _ O

Decoupled -X- _ O
weight -X- _ O
decay -X- _ O
regularization -X- _ O
. -X- _ O

In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
. -X- _ O

Andrew -X- _ O
L. -X- _ O
Maas -X- _ O
, -X- _ O
Raymond -X- _ O
E. -X- _ O
Daly -X- _ O
, -X- _ O
Peter -X- _ O
T. -X- _ O
Pham -X- _ O
, -X- _ O
Dan -X- _ O
Huang -X- _ O
, -X- _ O
Andrew -X- _ O
Y -X- _ O
. -X- _ O

Ng -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
Potts -X- _ O
. -X- _ O
2011 -X- _ O
. -X- _ O

Learning -X- _ O
word -X- _ O
vectors -X- _ O
for -X- _ O
sentiment -X- _ O
analysis -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
49th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
142–150 -X- _ O
, -X- _ O
Portland -X- _ O
, -X- _ O
Oregon -X- _ O
, -X- _ O
USA -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Andrew -X- _ O
L. -X- _ O
Maas -X- _ O
, -X- _ O
Awni -X- _ O
Y -X- _ O
. -X- _ O

Hannun -X- _ O
, -X- _ O
and -X- _ O
Andrew -X- _ O
Y -X- _ O
. -X- _ O

Ng -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O

Rectifier -X- _ O
nonlinearities -X- _ O
improve -X- _ O
neural -X- _ O
network -X- _ O
acoustic -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
in -X- _ O
ICML -X- _ O
Workshop -X- _ O
on -X- _ O
Deep -X- _ O
Learning -X- _ O
for -X- _ O
Audio -X- _ O
, -X- _ O
Speech -X- _ O
and -X- _ O
Language -X- _ O
Processing -X- _ O
. -X- _ O

Binny -X- _ O
Mathew -X- _ O
, -X- _ O
Punyajoy -X- _ O
Saha -X- _ O
, -X- _ O
Seid -X- _ O
Muhie -X- _ O
Yimam -X- _ O
, -X- _ O
Chris -X- _ O
Biemann -X- _ O
, -X- _ O
Pawan -X- _ O
Goyal -X- _ O
, -X- _ O
and -X- _ O
Animesh -X- _ O
Mukherjee -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Hatexplain -X- _ O
: -X- _ O
A -X- _ O
benchmark -X- _ O
dataset -X- _ O
for -X- _ O
explainable -X- _ O
hate -X- _ O
speech -X- _ O
detection -X- _ O
. -X- _ O

In -X- _ O
AAAI -X- _ O
. -X- _ O

Paul -X- _ O
Michel -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
and -X- _ O
Graham -X- _ O
Neubig -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Are -X- _ O
sixteen -X- _ O
heads -X- _ O
really -X- _ O
better -X- _ O
than -X- _ O
one -X- _ O
? -X- _ O

In -X- _ O
NeurIPS -X- _ O
. -X- _ O

Hosein -X- _ O
Mohebbi -X- _ O
, -X- _ O
Ali -X- _ O
Modarressi -X- _ O
, -X- _ O
and -X- _ O
Mohammad -X- _ O
Taher -X- _ O
Pilehvar -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Exploring -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
BERT -X- _ O
token -X- _ O
representations -X- _ O
to -X- _ O
explain -X- _ O
sentence -X- _ O
probing -X- _ O
results -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2021 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
792–806 -X- _ O
, -X- _ O
Online -X- _ O
and -X- _ O
Punta -X- _ O
Cana -X- _ O
, -X- _ O
Dominican -X- _ O
Republic -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Damian -X- _ O
Pascual -X- _ O
, -X- _ O
Gino -X- _ O
Brunner -X- _ O
, -X- _ O
and -X- _ O
Roger -X- _ O
Wattenhofer -X- _ O
. -X- _ O

2021 -X- _ O
. -X- _ O

Telling -X- _ O
BERT -X- _ O
’s -X- _ O
full -X- _ O
story -X- _ O
: -X- _ O
from -X- _ O
local -X- _ O
attention -X- _ O
to -X- _ O
global -X- _ O
aggregation -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
16th -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
European -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Main -X- _ O
Volume -X- _ O
, -X- _ O
pages -X- _ O
105–124 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Pranav -X- _ O
Rajpurkar -X- _ O
, -X- _ O
Jian -X- _ O
Zhang -X- _ O
, -X- _ O
Konstantin -X- _ O
Lopyrev -X- _ O
, -X- _ O
and -X- _ O
Percy -X- _ O
Liang -X- _ O
. -X- _ O

2016 -X- _ O
. -X- _ O

SQuAD -X- _ O
: -X- _ O
100,000 -X- _ O
+ -X- _ O
questions -X- _ O
for -X- _ O
machine -X- _ O
comprehension -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2016 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
2383–2392 -X- _ O
, -X- _ O
Austin -X- _ O
, -X- _ O
Texas -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Victor -X- _ O
Sanh -X- _ O
, -X- _ O
Lysandre -X- _ O
Debut -X- _ O
, -X- _ O
Julien -X- _ O
Chaumond -X- _ O
, -X- _ O
and -X- _ O
Thomas -X- _ O
Wolf -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Distilbert -X- _ O
, -X- _ O
a -X- _ O
distilled -X- _ O
version -X- _ O
of -X- _ O
bert -X- _ O
: -X- _ O
smaller -X- _ O
, -X- _ O
faster -X- _ O
, -X- _ O
cheaper -X- _ O
and -X- _ O
lighter -X- _ O
. -X- _ O

arXiv -X- _ O
Victor -X- _ O
Sanh -X- _ O
, -X- _ O
Thomas -X- _ O
Wolf -X- _ O
, -X- _ O
and -X- _ O
Alexander -X- _ O
Rush -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Movement -X- _ O
pruning -X- _ O
: -X- _ O
Adaptive -X- _ O
sparsity -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
, -X- _ O

Roy -X- _ O
Schwartz -X- _ O
, -X- _ O
Jesse -X- _ O
Dodge -X- _ O
, -X- _ O
Noah -X- _ O
Smith -X- _ O
, -X- _ O
and -X- _ O
Oren -X- _ O
Etzioni -X- _ O
. -X- _ O
2020a -X- _ O
. -X- _ O

Green -X- _ O
ai -X- _ O
. -X- _ O

Communications -X- _ O
of -X- _ O
the -X- _ O
Roy -X- _ O
Schwartz -X- _ O
, -X- _ O
Gabriel -X- _ O
Stanovsky -X- _ O
, -X- _ O
Swabha -X- _ O
Swayamdipta -X- _ O
, -X- _ O
Jesse -X- _ O
Dodge -X- _ O
, -X- _ O
and -X- _ O
Noah -X- _ O
A. -X- _ O
Smith -X- _ O
. -X- _ O
2020b -X- _ O
. -X- _ O

The -X- _ O
right -X- _ O
tool -X- _ O
for -X- _ O
the -X- _ O
job -X- _ O
: -X- _ O
Matching -X- _ O
model -X- _ O
and -X- _ O
instance -X- _ O
complexities -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
6640–6651 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Sofia -X- _ O
Serrano -X- _ O
and -X- _ O
Noah -X- _ O
A. -X- _ O
Smith -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Is -X- _ O
attention -X- _ O
interpretable -X- _ O
? -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
57th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
2931–2951 -X- _ O
, -X- _ O
Florence -X- _ O
, -X- _ O
Italy -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Sheng -X- _ O
Shen -X- _ O
, -X- _ O
Zhen -X- _ O
Dong -X- _ O
, -X- _ O
Jiayu -X- _ O
Ye -X- _ O
, -X- _ O
Linjian -X- _ O
Ma -X- _ O
, -X- _ O
Zhewei -X- _ O
Yao -X- _ O
, -X- _ O
Amir -X- _ O
Gholami -X- _ O
, -X- _ O
Michael -X- _ O
W. -X- _ O
Mahoney -X- _ O
, -X- _ O
and -X- _ O
Kurt -X- _ O
Keutzer -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

Q -X- _ O
- -X- _ O
bert -X- _ O
: -X- _ O
Hessian -X- _ O
based -X- _ O
ultra -X- _ O
low -X- _ O
precision -X- _ O
quantization -X- _ O
of -X- _ O
bert -X- _ O
. -X- _ O

In -X- _ O
AAAI -X- _ O
. -X- _ O

Karen -X- _ O
Simonyan -X- _ O
, -X- _ O
Andrea -X- _ O
Vedaldi -X- _ O
, -X- _ O
and -X- _ O
Andrew -X- _ O
Zisserman -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O

Deep -X- _ O
inside -X- _ O
convolutional -X- _ O
networks -X- _ O
: -X- _ O
Visualising -X- _ O
image -X- _ O
classification -X- _ O
models -X- _ O
and -X- _ O
saliency -X- _ O
maps -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:1312.6034 -X- _ O
. -X- _ O

D -X- _ O
Smilkov -X- _ O
, -X- _ O
N -X- _ O
Thorat -X- _ O
, -X- _ O
B -X- _ O
Kim -X- _ O
, -X- _ O
F -X- _ O
Viégas -X- _ O
, -X- _ O
and -X- _ O
M -X- _ O
Wattenberg -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Smoothgrad -X- _ O
: -X- _ O
removing -X- _ O
noise -X- _ O
by -X- _ O
adding -X- _ O
noise -X- _ O
. -X- _ O

arxiv -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arxiv:1706.03825 -X- _ O
. -X- _ O

Richard -X- _ O
Socher -X- _ O
, -X- _ O
Alex -X- _ O
Perelygin -X- _ O
, -X- _ O
Jean -X- _ O
Wu -X- _ O
, -X- _ O
Jason -X- _ O
Chuang -X- _ O
, -X- _ O
Christopher -X- _ O
D. -X- _ O
Manning -X- _ O
, -X- _ O
Andrew -X- _ O
Ng -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
Potts -X- _ O
. -X- _ O

2013 -X- _ O
. -X- _ O

Recursive -X- _ O
deep -X- _ O
models -X- _ O
for -X- _ O
semantic -X- _ O
compositionality -X- _ O
over -X- _ O
a -X- _ O
sentiment -X- _ O
treebank -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
2013 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
1631–1642 -X- _ O
, -X- _ O
Seattle -X- _ O
, -X- _ O
Washington -X- _ O
, -X- _ O
USA -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Siqi -X- _ O
Sun -X- _ O
, -X- _ O
Yu -X- _ O
Cheng -X- _ O
, -X- _ O
Zhe -X- _ O
Gan -X- _ O
, -X- _ O
and -X- _ O
Jingjing -X- _ O
Liu -X- _ O
. -X- _ O

2019 -X- _ O
. -X- _ O

Patient -X- _ O
knowledge -X- _ O
distillation -X- _ O
for -X- _ O
BERT -X- _ O
model -X- _ O
compression -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2019 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
and -X- _ O
the -X- _ O
9th -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
- -X- _ O
IJCNLP -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
4323–4332 -X- _ O
, -X- _ O
Hong -X- _ O
Kong -X- _ O
, -X- _ O
China -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Tianxiang -X- _ O
Sun -X- _ O
, -X- _ O
Yunhua -X- _ O
Zhou -X- _ O
, -X- _ O
Xiangyang -X- _ O
Liu -X- _ O
, -X- _ O
Xinyu -X- _ O
Zhang -X- _ O
, -X- _ O
Hao -X- _ O
Jiang -X- _ O
, -X- _ O
Zhao -X- _ O
Cao -X- _ O
, -X- _ O
Xuanjing -X- _ O
Huang -X- _ O
, -X- _ O
and -X- _ O
Xipeng -X- _ O
Qiu -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Early -X- _ O
exiting -X- _ O
with -X- _ O
ensemble -X- _ O
internal -X- _ O
classifiers -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:2105.13792 -X- _ O
. -X- _ O

Zhiqing -X- _ O
Sun -X- _ O
, -X- _ O
Hongkun -X- _ O
Yu -X- _ O
, -X- _ O
Xiaodan -X- _ O
Song -X- _ O
, -X- _ O
Renjie -X- _ O
Liu -X- _ O
, -X- _ O
Yiming -X- _ O
Yang -X- _ O
, -X- _ O
and -X- _ O
Denny -X- _ O
Zhou -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

MobileBERT -X- _ O
: -X- _ O
a -X- _ O
compact -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
BERT -X- _ O
for -X- _ O
resource -X- _ O
- -X- _ O
limited -X- _ O
devices -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
2158–2170 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Mukund -X- _ O
Sundararajan -X- _ O
, -X- _ O
Ankur -X- _ O
Taly -X- _ O
, -X- _ O
and -X- _ O
Qiqi -X- _ O
Yan -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Axiomatic -X- _ O
attribution -X- _ O
for -X- _ O
deep -X- _ O
networks -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
34th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
- -X- _ O
Volume -X- _ O
70 -X- _ O
, -X- _ O
pages -X- _ O
3319–3328.Thierry -X- _ O
Tambe -X- _ O
, -X- _ O
Coleman -X- _ O
Hooper -X- _ O
, -X- _ O
Lillian -X- _ O
Pentecost -X- _ O
, -X- _ O
Tianyu -X- _ O
Jia -X- _ O
, -X- _ O
En -X- _ O
- -X- _ O
Yu -X- _ O
Yang -X- _ O
, -X- _ O
Marco -X- _ O
Donato -X- _ O
, -X- _ O
Victor -X- _ O
Sanh -X- _ O
, -X- _ O
Paul -X- _ O
N. -X- _ O
Whatmough -X- _ O
, -X- _ O
Alexander -X- _ O
M. -X- _ O
Rush -X- _ O
, -X- _ O
David -X- _ O
Brooks -X- _ O
, -X- _ O
and -X- _ O
Gu -X- _ O
- -X- _ O
Yeon -X- _ O
Wei -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Edgebert -X- _ O
: -X- _ O
Sentence -X- _ O
- -X- _ O
level -X- _ O
energy -X- _ O
optimizations -X- _ O
for -X- _ O
latencyaware -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
nlp -X- _ O
inference -X- _ O
. -X- _ O

MICRO-54 -X- _ O
: -X- _ O
54th -X- _ O
Annual -X- _ O
IEEE -X- _ O
/ -X- _ O
ACM -X- _ O
International -X- _ O
Symposium -X- _ O
on -X- _ O
Microarchitecture -X- _ O
. -X- _ O

Ashish -X- _ O
Vaswani -X- _ O
, -X- _ O
Noam -X- _ O
Shazeer -X- _ O
, -X- _ O
Niki -X- _ O
Parmar -X- _ O
, -X- _ O
Jakob -X- _ O
Uszkoreit -X- _ O
, -X- _ O
Llion -X- _ O
Jones -X- _ O
, -X- _ O
Aidan -X- _ O
N -X- _ O
Gomez -X- _ O
, -X- _ O
Ł -X- _ O
ukasz -X- _ O
Kaiser -X- _ O
, -X- _ O
and -X- _ O
Illia -X- _ O
Polosukhin -X- _ O
. -X- _ O

2017 -X- _ O
. -X- _ O

Attention -X- _ O
is -X- _ O
all -X- _ O
you -X- _ O
need -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
, -X- _ O
volume -X- _ O
30 -X- _ O
. -X- _ O

Curran -X- _ O
Associates -X- _ O
, -X- _ O
Inc -X- _ O
. -X- _ O

Alex -X- _ O
Wang -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
Julian -X- _ O
Michael -X- _ O
, -X- _ O
Felix -X- _ O
Hill -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
Bowman -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

GLUE -X- _ O
: -X- _ O

A -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
benchmark -X- _ O
and -X- _ O
analysis -X- _ O
platform -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
EMNLP -X- _ O
Workshop -X- _ O
BlackboxNLP -X- _ O
: -X- _ O
Analyzing -X- _ O
and -X- _ O
Interpreting -X- _ O
Neural -X- _ O
Networks -X- _ O
for -X- _ O
NLP -X- _ O
, -X- _ O
pages -X- _ O
353–355 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Hanrui -X- _ O
Wang -X- _ O
, -X- _ O
Zhekai -X- _ O
Zhang -X- _ O
, -X- _ O
and -X- _ O
Song -X- _ O
Han -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Spatten -X- _ O
: -X- _ O

Efficient -X- _ O
sparse -X- _ O
attention -X- _ O
architecture -X- _ O
with -X- _ O
cascade -X- _ O
token -X- _ O
and -X- _ O
head -X- _ O
pruning -X- _ O
. -X- _ O

2021 -X- _ O
IEEE -X- _ O
International -X- _ O
Symposium -X- _ O
on -X- _ O
High -X- _ O
- -X- _ O
Performance -X- _ O
Computer -X- _ O
Architecture -X- _ O
( -X- _ O
HPCA -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
97–110 -X- _ O
. -X- _ O

Adina -X- _ O
Williams -X- _ O
, -X- _ O
Nikita -X- _ O
Nangia -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
Bowman -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

A -X- _ O
broad -X- _ O
- -X- _ O
coverage -X- _ O
challenge -X- _ O
corpus -X- _ O
for -X- _ O
sentence -X- _ O
understanding -X- _ O
through -X- _ O
inference -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
Volume -X- _ O
1 -X- _ O
( -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
1112–1122 -X- _ O
, -X- _ O
New -X- _ O
Orleans -X- _ O
, -X- _ O
Louisiana -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Thomas -X- _ O
Wolf -X- _ O
, -X- _ O
Lysandre -X- _ O
Debut -X- _ O
, -X- _ O
Victor -X- _ O
Sanh -X- _ O
, -X- _ O
Julien -X- _ O
Chaumond -X- _ O
, -X- _ O
Clement -X- _ O
Delangue -X- _ O
, -X- _ O
Anthony -X- _ O
Moi -X- _ O
, -X- _ O
Pierric -X- _ O
Cistac -X- _ O
, -X- _ O
Tim -X- _ O
Rault -X- _ O
, -X- _ O
Remi -X- _ O
Louf -X- _ O
, -X- _ O
Morgan -X- _ O
Funtowicz -X- _ O
, -X- _ O
Joe -X- _ O
Davison -X- _ O
, -X- _ O
Sam -X- _ O
Shleifer -X- _ O
, -X- _ O
Patrick -X- _ O
von -X- _ O
Platen -X- _ O
, -X- _ O
Clara -X- _ O
Ma -X- _ O
, -X- _ O
Yacine -X- _ O
Jernite -X- _ O
, -X- _ O
Julien -X- _ O
Plu -X- _ O
, -X- _ O
Canwen -X- _ O
Xu -X- _ O
, -X- _ O
Teven -X- _ O
Le -X- _ O
Scao -X- _ O
, -X- _ O
Sylvain -X- _ O
Gugger -X- _ O
, -X- _ O
Mariama -X- _ O
Drame -X- _ O
, -X- _ O
Quentin -X- _ O
Lhoest -X- _ O
, -X- _ O
and -X- _ O
Alexander -X- _ O
Rush -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Transformers -X- _ O
: -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
2020 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
: -X- _ O
System -X- _ O
Demonstrations -X- _ O
, -X- _ O
pages -X- _ O
38–45 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Ji -X- _ O
Xin -X- _ O
, -X- _ O
Raphael -X- _ O
Tang -X- _ O
, -X- _ O
Jaejun -X- _ O
Lee -X- _ O
, -X- _ O
Yaoliang -X- _ O
Yu -X- _ O
, -X- _ O
and -X- _ O
Jimmy -X- _ O
Lin -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

DeeBERT -X- _ O
: -X- _ O

Dynamic -X- _ O
early -X- _ O
exiting -X- _ O
for -X- _ O
accelerating -X- _ O
BERT -X- _ O
inference -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
2246–2251 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Ji -X- _ O
Xin -X- _ O
, -X- _ O
Raphael -X- _ O
Tang -X- _ O
, -X- _ O
Yaoliang -X- _ O
Yu -X- _ O
, -X- _ O
and -X- _ O
Jimmy -X- _ O
Lin -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

BERxiT -X- _ O
: -X- _ O

Early -X- _ O
exiting -X- _ O
for -X- _ O
BERT -X- _ O
with -X- _ O
better -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
extension -X- _ O
to -X- _ O
regression -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
16th -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
European -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics:12 -X- _ O

Main -X- _ O
Volume -X- _ O
, -X- _ O
pages -X- _ O
91–104 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Canwen -X- _ O
Xu -X- _ O
, -X- _ O
Wangchunshu -X- _ O
Zhou -X- _ O
, -X- _ O
Tao -X- _ O
Ge -X- _ O
, -X- _ O
Furu -X- _ O
Wei -X- _ O
, -X- _ O
and -X- _ O
Ming -X- _ O
Zhou -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

BERT -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theseus -X- _ O
: -X- _ O
Compressing -X- _ O
BERT -X- _ O
by -X- _ O
progressive -X- _ O
module -X- _ O
replacing -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2020 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
7859–7869 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Deming -X- _ O
Ye -X- _ O
, -X- _ O
Yankai -X- _ O
Lin -X- _ O
, -X- _ O
Yufei -X- _ O
Huang -X- _ O
, -X- _ O
and -X- _ O
Maosong -X- _ O
Sun -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

TR -X- _ O
- -X- _ O
BERT -X- _ O
: -X- _ O

Dynamic -X- _ O
token -X- _ O
reduction -X- _ O
for -X- _ O
accelerating -X- _ O
BERT -X- _ O
inference -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2021 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
5798–5809 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Hao -X- _ O
Yuan -X- _ O
, -X- _ O
Yongjun -X- _ O
Chen -X- _ O
, -X- _ O
Xia -X- _ O
Hu -X- _ O
, -X- _ O
and -X- _ O
Shuiwang -X- _ O
Ji -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Interpreting -X- _ O
deep -X- _ O
models -X- _ O
for -X- _ O
text -X- _ O
analysis -X- _ O
via -X- _ O
optimization -X- _ O
and -X- _ O
regularization -X- _ O
methods -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
AAAI -X- _ O
Conference -X- _ O
on -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
, -X- _ O
Omar -X- _ O
Zaidan -X- _ O
and -X- _ O
Jason -X- _ O
Eisner -X- _ O
. -X- _ O
2008 -X- _ O
. -X- _ O

Modeling -X- _ O
annotators -X- _ O
: -X- _ O
A -X- _ O
generative -X- _ O
approach -X- _ O
to -X- _ O
learning -X- _ O
from -X- _ O
annotator -X- _ O
rationales -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2008 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
31–40 -X- _ O
, -X- _ O
Honolulu -X- _ O
, -X- _ O
Hawaii -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Xiang -X- _ O
Zhang -X- _ O
, -X- _ O
Junbo -X- _ O
Jake -X- _ O
Zhao -X- _ O
, -X- _ O
and -X- _ O
Yann -X- _ O
LeCun -X- _ O
. -X- _ O

2015 -X- _ O
. -X- _ O

Character -X- _ O
- -X- _ O
level -X- _ O
convolutional -X- _ O
networks -X- _ O
for -X- _ O
text -X- _ O
classification -X- _ O
. -X- _ O

In -X- _ O
NIPS -X- _ O
. -X- _ O

Chen -X- _ O
Zhao -X- _ O
, -X- _ O
Chenyan -X- _ O
Xiong -X- _ O
, -X- _ O
Corby -X- _ O
Rosset -X- _ O
, -X- _ O
Xia -X- _ O
Song -X- _ O
, -X- _ O
Paul -X- _ O
Bennett -X- _ O
, -X- _ O
and -X- _ O
Saurabh -X- _ O
Tiwary -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Transformer -X- _ O
- -X- _ O
xh -X- _ O
: -X- _ O
Multi -X- _ O
- -X- _ O
evidence -X- _ O
reasoning -X- _ O
with -X- _ O
extra -X- _ O
hop -X- _ O
attention -X- _ O
. -X- _ O

In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
. -X- _ O

Wangchunshu -X- _ O
Zhou -X- _ O
, -X- _ O
Canwen -X- _ O
Xu -X- _ O
, -X- _ O
Tao -X- _ O
Ge -X- _ O
, -X- _ O
Julian -X- _ O
McAuley -X- _ O
, -X- _ O
Ke -X- _ O
Xu -X- _ O
, -X- _ O
and -X- _ O
Furu -X- _ O
Wei -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Bert -X- _ O
loses -X- _ O
patience -X- _ O
: -X- _ O
Fast -X- _ O
and -X- _ O
robust -X- _ O
inference -X- _ O
with -X- _ O
early -X- _ O
exit -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
, -X- _ O
volume -X- _ O
33 -X- _ O
, -X- _ O
pages -X- _ O
18330–18341 -X- _ O
. -X- _ O

Curran -X- _ O
Associates -X- _ O
, -X- _ O
Inc -X- _ O
. -X- _ O

A -X- _ O
Inclusive -X- _ O
KL -X- _ O
Loss -X- _ O
Consideration -X- _ O
We -X- _ O
opted -X- _ O
for -X- _ O
an -X- _ O
inclusive -X- _ O
KL -X- _ B-MetricName
loss -X- _ O
since -X- _ O
CPs -X- _ B-MethodName
should -X- _ O
be -X- _ O
trained -X- _ O
to -X- _ O
cover -X- _ O
all -X- _ O
tokens -X- _ O
considered -X- _ O
important -X- _ O
by -X- _ O
saliency -X- _ O
and -X- _ O
not -X- _ O
to -X- _ O
be -X- _ O
mode -X- _ O
seeking -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
covering -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
high -X- _ O
contributing -X- _ O
tokens -X- _ O
considered -X- _ O
by -X- _ O
the -X- _ O
saliency -X- _ O
scores -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Suppose -X- _ O
an -X- _ O
exclusive -X- _ O
KL -X- _ O
is -X- _ O
selected -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
limited -X- _ O
learning -X- _ O
capacity -X- _ O
of -X- _ O
the -X- _ O
CP -X- _ B-MethodName
and -X- _ O
miscalculation -X- _ O
possibility -X- _ O
from -X- _ O
the -X- _ O
saliency -X- _ O
, -X- _ O
the -X- _ O
CP -X- _ B-MethodName
may -X- _ O
be -X- _ O
trained -X- _ O
to -X- _ O
maximize -X- _ O
its -X- _ O
contribution -X- _ O
on -X- _ O
noninformative -X- _ O
tokens -X- _ O
. -X- _ O

While -X- _ O
in -X- _ O
an -X- _ O
inclusive -X- _ O
setting -X- _ O
, -X- _ O
it -X- _ O
trains -X- _ O
to -X- _ O
extend -X- _ O
its -X- _ O
coverage -X- _ O
over -X- _ O
all -X- _ O
high -X- _ O
- -X- _ O
saliency -X- _ B-MetricName
tokens -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
our -X- _ O
initial -X- _ O
research -X- _ O
indicated -X- _ O
that -X- _ O
using -X- _ O
a -X- _ O
symmetric -X- _ O
loss -X- _ O
( -X- _ O
e.g. -X- _ O
Jensen -X- _ O
- -X- _ O
Shannon -X- _ O
divergence -X- _ O
) -X- _ O
would -X- _ O
produce -X- _ O
similar -X- _ O
results -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
significantly -X- _ O
longer -X- _ O
convergence -X- _ O
time -X- _ O
. -X- _ O

B -X- _ O
Optimization -X- _ O
of -X- _ O
θ -X- _ O

In -X- _ O
Section -X- _ O
3.3 -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
θℓas -X- _ O
a -X- _ O
trainable -X- _ O
parameter -X- _ O
that -X- _ O
increases -X- _ O
the -X- _ O
saliency -X- _ O
score -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
deduce -X- _ O
from -X- _ O
Equations -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
that -X- _ O
this -X- _ O
parameter -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
computational -X- _ O
DAG -X- _ O
and -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
derivative -X- _ O
of -X- _ O
˜Sℓ -X- _ O
w.r.t -X- _ O
. -X- _ O
θℓto -X- _ O
train -X- _ O
this -X- _ O
parameter -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
first -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
˜Sℓis -X- _ O
a -X- _ O
close -X- _ O
estimate -X- _ O
of -X- _ O
ˆSℓ -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
CPs -X- _ O
’ -X- _ O
training -X- _ O
objective -X- _ O
) -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
dummy -X- _ O
variable -X- _ O
θℓ -X- _ O
d -X- _ O
— -X- _ O
that -X- _ O
is -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
computational -X- _ O
graph -X- _ O
and -X- _ O
is -X- _ O
always -X- _ O
equal -X- _ O
to -X- _ O
1 -X- _ O
— -X- _ O
we -X- _ O
reformulate -X- _ O
d˜Sℓ -X- _ O
d˜Sℓ -X- _ O
1+Pn -X- _ O

This -X- _ O
reformulation -X- _ O
is -X- _ O
valid -X- _ O
due -X- _ O
to -X- _ O
θℓ -X- _ O
d= -X- _ O
1 -X- _ O
andPn -X- _ O
i= -X- _ O
1 -X- _ O
. -X- _ O

Now -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
partial -X- _ O
derivative -X- _ O
w.r.t -X- _ O
. -X- _ O

θℓ -X- _ O
dwhich -X- _ O
is -X- _ O
the -X- _ O
gradient -X- _ O
that -X- _ O
is -X- _ O
computed -X- _ O
in -X- _ O
the -X- _ O
backpropagation -X- _ O
: -X- _ O
i -X- _ O
1 -X- _ O
( -X- _ O
Pn -X- _ O
d˜Sℓ -X- _ O
1+Pn -X- _ O
By -X- _ O
knowing -X- _ O
that -X- _ O

θℓ -X- _ O
i -X- _ O
Now -X- _ O
using -X- _ O
our -X- _ O
initial -X- _ O
assumption -X- _ O
( -X- _ O
ˆSℓ -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
substitute -X- _ O
˜Sℓ -X- _ O
iwith -X- _ O
ˆSℓ -X- _ O
ibased -X- _ O
on -X- _ O
Equation -X- _ O
7 -X- _ O
: -X- _ O
i -X- _ O
1 -X- _ O
( -X- _ O
Pn -X- _ O
1+Pn -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
ˆSℓ -X- _ O
iw.r.t -X- _ O
. -X- _ O

θℓis -X- _ O
as -X- _ O
follows -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O

Equation -X- _ O
7 -X- _ O
) -X- _ O
: -X- _ O
i -X- _ O
1 -X- _ O
( -X- _ O
Pn -X- _ O
1+Pn -X- _ O
By -X- _ O
comparing -X- _ O
Equations -X- _ O
12 -X- _ O
and -X- _ O
13 -X- _ O
, -X- _ O
these -X- _ O
derivatives -X- _ O
are -X- _ O
related -X- _ O
with -X- _ O
a -X- _ O
term -X- _ O
of -X- _ O
θℓ -X- _ O
: -X- _ O
i -X- _ O
i -X- _ O
i -X- _ O

Therefore -X- _ O
, -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
compute -X- _ O
the -X- _ O
gradient -X- _ O
w.r.t -X- _ O
. -X- _ O

the -X- _ O
dummy -X- _ O
variable -X- _ O
θℓ -X- _ O
dand -X- _ O
then -X- _ O
divide -X- _ O
it -X- _ O
by -X- _ O
θℓ. -X- _ O
C -X- _ O
Evaluating -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
in -X- _ O
Single -X- _ O
Instance -X- _ O
Mode -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
static -X- _ O
structure -X- _ O
of -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
the -X- _ O
speedup -X- _ O
ratios -X- _ O
reported -X- _ O
in -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
wall -X- _ O
time -X- _ O
acceleration -X- _ O
with -X- _ O
batch -X- _ O
- -X- _ O
wise -X- _ O
inference -X- _ O
procedure -X- _ O
. -X- _ O

This -X- _ O
means -X- _ O
that -X- _ O
some -X- _ O
inputs -X- _ O
might -X- _ O
need -X- _ O
extra -X- _ O
padding -X- _ O
to -X- _ O
make -X- _ O
all -X- _ O
inputs -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
token -X- _ O
length -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
since -X- _ O
our -X- _ O
approach -X- _ O
and -X- _ O
other -X- _ O
dynamic -X- _ O
approaches -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
single -X- _ O
instance -X- _ O
inference -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
procedure -X- _ O
inputs -X- _ O
are -X- _ O
fed -X- _ O
without -X- _ O
being -X- _ O
padded -X- _ O
. -X- _ O

To -X- _ O
even -X- _ O
out -X- _ O
this -X- _ O
discrepancy -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
single -X- _ O
instance -X- _ O
flops -X- _ O
computation -X- _ O
on -X- _ O
the -X- _ O
PoWER -X- _ O
- -X- _ O
BERT -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
computational -X- _ O
cost -X- _ O
for -X- _ O
all -X- _ O
input -X- _ O
lengths -X- _ O
that -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
dataset -X- _ O
. -X- _ O

Some -X- _ O
instnaces -X- _ O
may -X- _ O
have -X- _ O
shorter -X- _ O
input -X- _ O
length -X- _ O
than -X- _ O
some -X- _ O
values -X- _ O
in -X- _ O
the -X- _ O
resulting -X- _ O
retention -X- _ O
configuration -X- _ O
( -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
retained -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
overcome -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
update -X- _ O
the -X- _ O
retention -X- _ O
configuration -X- _ O
by -X- _ O
selecting -X- _ O
the -X- _ O
minimum -X- _ O
between -X- _ O
the -X- _ O
input -X- _ O
length -X- _ O
and -X- _ O
each -X- _ O
layers -X- _ O
’ -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
retained -X- _ O
, -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
new -X- _ O
retention -X- _ O
configuration -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
length -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
retention -X- _ O
configuration -X- _ O
trained -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
task -X- _ O
be -X- _ O
( -X- _ O
153 -X- _ O
, -X- _ O
input -X- _ O
with -X- _ O
75 -X- _ O
tokens -X- _ O
length -X- _ O
, -X- _ O
the -X- _ O
new -X- _ O
configuration -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
speedup -X- _ O
computation -X- _ O
will -X- _ O
be -X- _ O
: -X- _ O
( -X- _ O
75 -X- _ O
, -X- _ O
D -X- _ O
AdapLeR -X- _ B-MethodName
Training -X- _ O
Hyperparameters -X- _ O
For -X- _ O
the -X- _ O
initial -X- _ O
step -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
hyperparameters -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

For -X- _ O
both -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
training -X- _ O
with -X- _ O
length -X- _ O
reduction -X- _ O
, -X- _ O
we -X- _ O
employed -X- _ O
an -X- _ O
AdamW -X- _ O
optimizer -X- _ O
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
weight -X- _ O
decay -X- _ O
rate -X- _ O
of -X- _ O
0.1 -X- _ O
, -X- _ O
warmup -X- _ O
proportion -X- _ O
6 -X- _ O
% -X- _ O
of -X- _ O
total -X- _ O
training -X- _ O
steps -X- _ O
and -X- _ O
a -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
decay -X- _ O
which -X- _ O
reaches -X- _ O
to -X- _ O
zero -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
training -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
adaptive -X- _ O
length -X- _ O
reduction -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
with -X- _ O
two -X- _ O
differences -X- _ O
: -X- _ O
Since -X- _ O
MRPC -X- _ O
and -X- _ O
CoLA -X- _ O
have -X- _ O
small -X- _ O
training -X- _ O
sets -X- _ O
, -X- _ O
to -X- _ O
prolong -X- _ O
the -X- _ O
gradual -X- _ O
softremoval -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
increased -X- _ O
the -X- _ O
training -X- _ O
duration -X- _ O
to -X- _ O
10 -X- _ O
epochs -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
3e-5 -X- _ B-HyperparameterValue
. -X- _ O

Other -X- _ O
hyperparameters -X- _ O
are -X- _ O
stated -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

To -X- _ O
set -X- _ O
a -X- _ O
trend -X- _ O
for -X- _ O
λ -X- _ B-HyperparameterName
, -X- _ O
it -X- _ O
needs -X- _ O
to -X- _ O
start -X- _ O
from -X- _ O
a -X- _ O
small -X- _ O
but -X- _ O
effective -X- _ O
value -X- _ O
( -X- _ O
10 -X- _ B-HyperparameterValue
< -X- _ O
λ -X- _ B-HyperparameterName
< -X- _ O
100 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
grow -X- _ O
exponentially -X- _ O
per -X- _ O
each -X- _ O
epoch -X- _ O
to -X- _ O
reach -X- _ O
an -X- _ O
ex -X- _ O
- -X- _ O
Dataset -X- _ O
Epoch -X- _ O
LR -X- _ O
MaxLen -X- _ O
. -X- _ O

BSZ -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Hyperparameters -X- _ O
in -X- _ O
each -X- _ O
dataset -X- _ O
; -X- _ O
LR -X- _ B-HyperparameterName
: -X- _ O
Learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
; -X- _ O
BSZ -X- _ B-HyperparameterName
: -X- _ O
Batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
; -X- _ O
MaxLen -X- _ B-HyperparameterName
: -X- _ O

Maximum -X- _ O
Token -X- _ O
Length -X- _ O
tremely -X- _ O
high -X- _ O
amount -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
to -X- _ O
mimic -X- _ O
a -X- _ O
hard -X- _ O
removal -X- _ O
function -X- _ O
( -X- _ O
1e+5 -X- _ O
< -X- _ O
λ -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
datasets -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
epochs -X- _ O
have -X- _ O
similar -X- _ O
λtrends -X- _ B-HyperparameterName
. -X- _ O

Dataset -X- _ O
γ -X- _ O
ϕ -X- _ O
λ -X- _ B-HyperparameterName

IMDB -X- _ O

5e-3 -X- _ B-HyperparameterValue
5e-4 -X- _ B-HyperparameterValue
10Epoch -X- _ B-HyperparameterValue
HateXplain -X- _ O
5e-2 -X- _ B-HyperparameterValue
2e-2 -X- _ B-HyperparameterValue
50Epoch -X- _ B-HyperparameterValue
MNLI -X- _ O

5e-3 -X- _ B-HyperparameterValue
5e-4 -X- _ B-HyperparameterValue
50Epoch -X- _ O
QNLI -X- _ O

5e-3 -X- _ O
1e-4 -X- _ O
10Epoch -X- _ O
AG -X- _ O
’s -X- _ O
News -X- _ O
1e-1 -X- _ O
1e-1 -X- _ O
10Epoch -X- _ O
DBPedia -X- _ O
1e-1 -X- _ O
1e-1 -X- _ O
50Epoch -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
AdapLeR -X- _ O
hyperparameters -X- _ O
in -X- _ O
each -X- _ O
dataset -X- _ O
; -X- _ O
Since -X- _ O
λincreases -X- _ O
exponentially -X- _ O
on -X- _ O
each -X- _ O
epoch -X- _ O
the -X- _ O
coorresponding -X- _ O
formula -X- _ O
is -X- _ O
written -X- _ O
. -X- _ O

E -X- _ O
Statistics -X- _ O
of -X- _ O
Datasets -X- _ O
F -X- _ O
Additional -X- _ O
Qualitative -X- _ O
Examples14 -X- _ O

SST-2 -X- _ O
Label -X- _ O
: -X- _ O
Negative -X- _ O
AG -X- _ O
's -X- _ O
news -X- _ O
( -X- _ O
test -X- _ O
) -X- _ O
- -X- _ O
Label -X- _ O
: -X- _ O
Sports -X- _ O
Layer -X- _ O
1 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
2 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
3 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
4 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
5 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
6 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
7 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
8 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
9 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
10 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
11 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Layer -X- _ O
12 -X- _ O
: -X- _ O

[ -X- _ O
CLS -X- _ O
] -X- _ O
league -X- _ O
of -X- _ O
development -X- _ O
major -X- _ O
league -X- _ O
soccer -X- _ O
plans -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
new -X- _ O
league -X- _ O
to -X- _ O
develop -X- _ O
young -X- _ O
players -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
its -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
sponsorship -X- _ O
deal -X- _ O
with -X- _ O
adi -X- _ O
# -X- _ O
# -X- _ O
das -X- _ O
. -X- _ O

[ -X- _ O
SEP -X- _ O
] -X- _ O
Figure -X- _ O
6 -X- _ O
: -X- _ O
The -X- _ O
illustration -X- _ O
of -X- _ O
contribution -X- _ O
scores -X- _ O
obtained -X- _ O
by -X- _ O
CPs -X- _ O
in -X- _ O
each -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
different -X- _ O
input -X- _ O
examples -X- _ O
from -X- _ O
QNLI -X- _ O
( -X- _ O
Question -X- _ O
- -X- _ O
answering -X- _ O
NLI -X- _ O
) -X- _ O
, -X- _ O
SST-2 -X- _ O
( -X- _ O
sentiment -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
AG -X- _ O
’s -X- _ O
news -X- _ O
( -X- _ O
topic -X- _ O
classification -X- _ O
) -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
color -X- _ O
intensity -X- _ O
indicates -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
contribution -X- _ O
scores -X- _ O
. -X- _ O

Only -X- _ O
the -X- _ O
highlighted -X- _ O
token -X- _ O
representations -X- _ O
are -X- _ O
processed -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
Number -X- _ O
of -X- _ O
Examples -X- _ O
Number -X- _ O
of -X- _ O
Tokens -X- _ O
Task -X- _ O
Train -X- _ O
Test -X- _ O
Mean -X- _ O
/ -X- _ O
Median -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
datasets -X- _ O
: -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
examples -X- _ O
and -X- _ O
average -X- _ O
and -X- _ O
median -X- _ O
of -X- _ O
sequence -X- _ O
length -X- _ O
( -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
) -X- _ O
of -X- _ O
test -X- _ O
examples -X- _ O
based -X- _ O
on -X- _ O
BERT -X- _ O
’s -X- _ O
tokenizer.†and‡indicate -X- _ O
matched -X- _ O
andmismatched -X- _ O
versions -X- _ O
of -X- _ O
MNLI -X- _ O
test -X- _ O
split -X- _ O
, -X- _ O
respectively.15 -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
16 -X- _ O
- -X- _ O
28 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O

2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Quantified -X- _ B-TaskName
Reproducibility -X- _ I-TaskName
Assessment -X- _ I-TaskName
of -X- _ O
NLP -X- _ O
Results -X- _ O
Anya -X- _ O
Belz -X- _ O
and -X- _ O
Maja -X- _ O
Popovi -X- _ O
´ -X- _ O
c -X- _ O
ADAPT -X- _ O
Research -X- _ O
Centre -X- _ O
Dublin -X- _ O
City -X- _ O
University -X- _ O
, -X- _ O
Ireland -X- _ O
{ -X- _ O
anya.belz -X- _ O
, -X- _ O
maja.popovic -X- _ O
} -X- _ O
@ -X- _ O
adaptcentre.ieSimon -X- _ O
Mille -X- _ O
Universitat -X- _ O
Pompeu -X- _ O
Fabra -X- _ O
Barcelona -X- _ O
, -X- _ O

Spain -X- _ O
simon.mille -X- _ O
@ -X- _ O
upf.edu -X- _ O
Abstract -X- _ O
This -X- _ O
paper -X- _ O
describes -X- _ O
and -X- _ O
tests -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
carrying -X- _ O
out -X- _ O
quantified -X- _ B-TaskName
reproducibility -X- _ I-TaskName
assessment -X- _ I-TaskName
( -X- _ O
QRA -X- _ B-TaskName
) -X- _ O
that -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
from -X- _ O
metrology -X- _ O
. -X- _ O

QRA -X- _ B-TaskName
produces -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
estimating -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
scores -X- _ O
from -X- _ O
, -X- _ O
and -X- _ O
differences -X- _ O
between -X- _ O
, -X- _ O
different -X- _ O
reproductions -X- _ O
. -X- _ O

We -X- _ O
test -X- _ O
QRA -X- _ B-TaskName
on -X- _ O
18 -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
combinations -X- _ O
( -X- _ O
involving -X- _ O
diverse -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
types -X- _ O
of -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
original -X- _ O
results -X- _ O
and -X- _ O
one -X- _ O
to -X- _ O
seven -X- _ O
reproduction -X- _ O
results -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
QRA -X- _ B-TaskName
method -X- _ O
produces -X- _ O
degree -X- _ B-MetricName
- -X- _ I-MetricName
of -X- _ I-MetricName
- -X- _ I-MetricName
reproducibility -X- _ I-MetricName
scores -X- _ I-MetricName
that -X- _ O
are -X- _ O
comparable -X- _ O
across -X- _ O
multiple -X- _ O
reproductions -X- _ O
not -X- _ O
only -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
but -X- _ O
of -X- _ O
different -X- _ O
original -X- _ O
studies -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
facilitates -X- _ O
insights -X- _ O
into -X- _ O
causes -X- _ O
of -X- _ O
variation -X- _ O
between -X- _ O
reproductions -X- _ O
, -X- _ O
and -X- _ O
allows -X- _ O
conclusions -X- _ O
to -X- _ O
be -X- _ O
drawn -X- _ O
about -X- _ O
what -X- _ O
changes -X- _ O
to -X- _ O
system -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
evaluation -X- _ O
design -X- _ O
might -X- _ O
lead -X- _ O
to -X- _ O
improved -X- _ O
reproducibility -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Reproduction -X- _ O
studies -X- _ O
are -X- _ O
becoming -X- _ O
more -X- _ O
common -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
first -X- _ O
shared -X- _ O
tasks -X- _ O
being -X- _ O
organised -X- _ O
, -X- _ O
including -X- _ O
REPROLANG -X- _ O
( -X- _ O
Branco -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
ReproGen -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
NLP -X- _ O
, -X- _ O
reproduction -X- _ O
studies -X- _ O
generally -X- _ O
address -X- _ O
the -X- _ O
following -X- _ O
question -X- _ O
: -X- _ O
if -X- _ O
we -X- _ O
create -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
evaluate -X- _ O
this -X- _ O
system -X- _ O
multiple -X- _ O
times -X- _ O
, -X- _ O
will -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
? -X- _ O

To -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
specific -X- _ O
system -X- _ O
, -X- _ O
typically -X- _ O
( -X- _ O
Wieling -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Popovi -X- _ O
´ -X- _ O
c -X- _ O
and -X- _ O
Belz -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
an -X- _ O
original -X- _ O
study -X- _ O
is -X- _ O
selected -X- _ O
and -X- _ O
repeated -X- _ O
more -X- _ O
or -X- _ O
less -X- _ O
closely -X- _ O
, -X- _ O
before -X- _ O
comparing -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
with -X- _ O
those -X- _ O
obtained -X- _ O
in -X- _ O
the -X- _ O
repeat -X- _ O
, -X- _ O
and -X- _ O
deciding -X- _ O
whether -X- _ O
the -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
results -X- _ O
are -X- _ O
similar -X- _ O
enough -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
same -X- _ O
conclusions -X- _ O
. -X- _ O

This -X- _ O
framing -X- _ O
, -X- _ O
whether -X- _ O
the -X- _ O
same -X- _ O
conclusions -X- _ O
can -X- _ O
be -X- _ O
drawn -X- _ O
, -X- _ O
involves -X- _ O
subjective -X- _ O
judgments -X- _ O
and -X- _ O
different -X- _ O
researchers -X- _ O
can -X- _ O
come -X- _ O
to -X- _ O
contradictory -X- _ O
con -X- _ O
- -X- _ O
clusions -X- _ O
: -X- _ O
e.g. -X- _ O
the -X- _ O
four -X- _ O
papers -X- _ O
( -X- _ O
Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bestgen -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Caines -X- _ O
and -X- _ O
Buttery -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Huber -X- _ O
and -X- _ O
Çöltekin -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
reproducing -X- _ O
Vajjala -X- _ O
and -X- _ O
Rama -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
in -X- _ O
REPROLANG -X- _ O
all -X- _ O
report -X- _ O
similarly -X- _ O
large -X- _ O
differences -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
conclude -X- _ O
that -X- _ O
reproduction -X- _ O
was -X- _ O
unsuccessful -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
no -X- _ O
standard -X- _ O
way -X- _ O
of -X- _ O
going -X- _ O
about -X- _ O
a -X- _ O
reproduction -X- _ O
study -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
and -X- _ O
different -X- _ O
reproduction -X- _ O
studies -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
original -X- _ O
set -X- _ O
of -X- _ O
results -X- _ O
can -X- _ O
differ -X- _ O
substantially -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
their -X- _ O
similarity -X- _ O
in -X- _ O
system -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
evaluation -X- _ O
design -X- _ O
( -X- _ O
as -X- _ O
is -X- _ O
the -X- _ O
case -X- _ O
with -X- _ O
the -X- _ O
Vajjala -X- _ O
and -X- _ O
Rama -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
reproductions -X- _ O
, -X- _ O
see -X- _ O
Section -X- _ O
4 -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

Other -X- _ O
things -X- _ O
being -X- _ O
equal -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
similar -X- _ O
reproduction -X- _ O
can -X- _ O
be -X- _ O
expected -X- _ O
to -X- _ O
produce -X- _ O
more -X- _ O
similar -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
such -X- _ O
( -X- _ O
dis -X- _ O
) -X- _ O
similarities -X- _ O
should -X- _ O
be -X- _ O
factored -X- _ O
into -X- _ O
reproduction -X- _ O
analysis -X- _ O
and -X- _ O
conclusions -X- _ O
, -X- _ O
but -X- _ O
NLP -X- _ O
lacks -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
doing -X- _ O
so -X- _ O
. -X- _ O

Being -X- _ O
able -X- _ O
to -X- _ O
assess -X- _ O
reproducibility -X- _ O
of -X- _ O
results -X- _ O
objectively -X- _ O
and -X- _ O
comparably -X- _ O
is -X- _ O
important -X- _ O
not -X- _ O
only -X- _ O
to -X- _ O
establish -X- _ O
that -X- _ O
results -X- _ O
are -X- _ O
valid -X- _ O
, -X- _ O
but -X- _ O
to -X- _ O
provide -X- _ O
evidence -X- _ O
about -X- _ O
which -X- _ O
methods -X- _ O
have -X- _ O
better -X- _ O
/ -X- _ O
worse -X- _ O
reproducibility -X- _ O
and -X- _ O
what -X- _ O
may -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
changed -X- _ O
to -X- _ O
improve -X- _ O
reproducibility -X- _ O
. -X- _ O

To -X- _ O
do -X- _ O
this -X- _ O
, -X- _ O
assessment -X- _ O
has -X- _ O
to -X- _ O
be -X- _ O
done -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
also -X- _ O
comparable -X- _ O
across -X- _ O
reproduction -X- _ O
studies -X- _ O
of -X- _ O
different -X- _ O
original -X- _ O
studies -X- _ O
, -X- _ O
e.g. -X- _ O
to -X- _ O
develop -X- _ O
common -X- _ O
expectations -X- _ O
of -X- _ O
how -X- _ O
similar -X- _ O
original -X- _ O
and -X- _ O
reproduction -X- _ O
results -X- _ O
should -X- _ O
be -X- _ O
for -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
system -X- _ O
, -X- _ O
task -X- _ O
and -X- _ O
evaluation -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
describe -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
quantified -X- _ B-MethodName
reproducibility -X- _ I-MethodName
assessment -X- _ I-MethodName
( -X- _ O
QRA -X- _ B-MethodName
) -X- _ O
directly -X- _ O
derived -X- _ O
from -X- _ O
standard -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
from -X- _ O
metrology -X- _ O
which -X- _ O
addresses -X- _ O
the -X- _ O
above -X- _ O
issues -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
test -X- _ O
it -X- _ O
on -X- _ O
diverse -X- _ O
sets -X- _ O
of -X- _ O
NLP -X- _ O
results -X- _ O
. -X- _ O

Following -X- _ O
a -X- _ O
review -X- _ O
of -X- _ O
related -X- _ O
research -X- _ O
( -X- _ O
Section -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
method -X- _ O
( -X- _ O
Section -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
tests -X- _ O
and -X- _ O
results -X- _ O
( -X- _ O
Section -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
discuss -X- _ O
method -X- _ O
and -X- _ O
results -X- _ O
( -X- _ O
Section -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
finish -X- _ O
with -X- _ O
some -X- _ O
conclusions -X- _ O
( -X- _ O
Section -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Research -X- _ O

The -X- _ O
situation -X- _ O
memorably -X- _ O
caricatured -X- _ O
by -X- _ O
Pedersen -X- _ O
( -X- _ O
2008 -X- _ O
) -X- _ O
still -X- _ O
happens -X- _ O
all -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
you -X- _ O
download16 -X- _ O

some -X- _ O
code -X- _ O
you -X- _ O
read -X- _ O
about -X- _ O
in -X- _ O
a -X- _ O
paper -X- _ O
and -X- _ O
liked -X- _ O
the -X- _ O
sound -X- _ O
of -X- _ O
, -X- _ O
you -X- _ O
run -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
provided -X- _ O
, -X- _ O
only -X- _ O
to -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
in -X- _ O
fact -X- _ O
they -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
worse -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O

When -X- _ O
both -X- _ O
data -X- _ O
and -X- _ O
code -X- _ O
are -X- _ O
provided -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
potential -X- _ O
causes -X- _ O
of -X- _ O
such -X- _ O
differences -X- _ O
is -X- _ O
limited -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NLP -X- _ O
field -X- _ O
has -X- _ O
shared -X- _ O
increasingly -X- _ O
detailed -X- _ O
information -X- _ O
about -X- _ O
system -X- _ O
, -X- _ O
dependencies -X- _ O
and -X- _ O
evaluation -X- _ O
to -X- _ O
chase -X- _ O
down -X- _ O
sources -X- _ O
of -X- _ O
differences -X- _ O
. -X- _ O

Sharing -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
together -X- _ O
with -X- _ O
detailed -X- _ O
information -X- _ O
about -X- _ O
them -X- _ O
is -X- _ O
now -X- _ O
expected -X- _ O
as -X- _ O
standard -X- _ O
, -X- _ O
and -X- _ O
checklists -X- _ O
and -X- _ O
datasheets -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
standardise -X- _ O
information -X- _ O
sharing -X- _ O
( -X- _ O
Pineau -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Shimorina -X- _ O
and -X- _ O
Belz -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Reproducibility -X- _ O
more -X- _ O
generally -X- _ O
is -X- _ O
becoming -X- _ O
more -X- _ O
of -X- _ O
a -X- _ O
research -X- _ O
focus -X- _ O
. -X- _ O

There -X- _ O
have -X- _ O
been -X- _ O
several -X- _ O
workshops -X- _ O
and -X- _ O
initiatives -X- _ O
on -X- _ O
reproducibility -X- _ O
, -X- _ O
including -X- _ O
workshops -X- _ O
at -X- _ O
ICML -X- _ O
2017 -X- _ O
and -X- _ O
2018 -X- _ O
, -X- _ O
the -X- _ O
reproducibility -X- _ O
challenge -X- _ O
at -X- _ O
ICLR -X- _ O
2018 -X- _ O
and -X- _ O
PROLANG -X- _ O
( -X- _ O
Branco -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
initiative -X- _ O
at -X- _ O
LREC -X- _ O
2020 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
ReproGen -X- _ O
shared -X- _ O
task -X- _ O
on -X- _ O
reproducibility -X- _ O
in -X- _ O
NLG -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

Despite -X- _ O
this -X- _ O
growing -X- _ O
body -X- _ O
of -X- _ O
research -X- _ O
, -X- _ O
no -X- _ O
consensus -X- _ O
has -X- _ O
emerged -X- _ O
about -X- _ O
standards -X- _ O
, -X- _ O
terminology -X- _ O
and -X- _ O
definitions -X- _ O
. -X- _ O

Particularly -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
most -X- _ O
frequently -X- _ O
used -X- _ O
terms -X- _ O
, -X- _ O
reproducibility -X- _ O
andreplicability -X- _ O
, -X- _ O
multiple -X- _ O
divergent -X- _ O
definitions -X- _ O
are -X- _ O
in -X- _ O
use -X- _ O
, -X- _ O
variously -X- _ O
conditioned -X- _ O
on -X- _ O
same -X- _ O
vs. -X- _ O
different -X- _ O
teams -X- _ O
, -X- _ O
methods -X- _ O
, -X- _ O
artifacts -X- _ O
, -X- _ O
code -X- _ O
, -X- _ O
and -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
for -X- _ O
Rougier -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
reproducing -X- _ O
a -X- _ O
result -X- _ O
means -X- _ O
running -X- _ O
the -X- _ O
same -X- _ O
code -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
obtaining -X- _ O
the -X- _ O
same -X- _ O
result -X- _ O
, -X- _ O
while -X- _ O
replicating -X- _ O
the -X- _ O
result -X- _ O
is -X- _ O
writing -X- _ O
and -X- _ O
running -X- _ O
new -X- _ O
code -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
information -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
publication -X- _ O
. -X- _ O

For -X- _ O
Wieling -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
reproducibility -X- _ O
is -X- _ O
achieving -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
methods -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
ACM -X- _ O
’s -X- _ O
definitions -X- _ O
( -X- _ O
Association -X- _ O
for -X- _ O
Computing -X- _ O
Machinery -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
results -X- _ O
have -X- _ O
been -X- _ O
reproduced -X- _ O
if -X- _ O
obtained -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
study -X- _ O
by -X- _ O
a -X- _ O
different -X- _ O
team -X- _ O
using -X- _ O
artifacts -X- _ O
supplied -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
, -X- _ O
and -X- _ O
replicated -X- _ O
if -X- _ O
obtained -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
study -X- _ O
by -X- _ O
a -X- _ O
different -X- _ O
team -X- _ O
using -X- _ O
artifacts -X- _ O
notsupplied -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
. -X- _ O

The -X- _ O
ACM -X- _ O
originally -X- _ O
had -X- _ O
these -X- _ O
definitions -X- _ O
the -X- _ O
other -X- _ O
way -X- _ O
around -X- _ O
until -X- _ O
asked -X- _ O
by -X- _ O
ISO -X- _ O
to -X- _ O
bring -X- _ O
them -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
scientific -X- _ O
standard -X- _ O
( -X- _ O
ibid -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Conversely -X- _ O
, -X- _ O
in -X- _ O
Drummond -X- _ O
’s -X- _ O
view -X- _ O
2009 -X- _ O
obtaining -X- _ O
the -X- _ O
same -X- _ O
result -X- _ O
by -X- _ O
re -X- _ O
- -X- _ O
running -X- _ O
an -X- _ O
experiment -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
is -X- _ O
replicability -X- _ O
, -X- _ O
while -X- _ O
reproducibility -X- _ O
is -X- _ O
obtaining -X- _ O
it -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
way -X- _ O
. -X- _ O

Whitaker -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
Schloss -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
defines -X- _ O
four -X- _ O
concepts -X- _ O
rather -X- _ O
than -X- _ O
two -X- _ O
, -X- _ O
basing -X- _ O
definitions -X- _ O
of -X- _ O
reproducibility -X- _ O
, -X- _ O
replicability -X- _ O
, -X- _ O
robustness -X- _ O
andgeneralisability -X- _ O
on -X- _ O
the -X- _ O
different -X- _ O
possible -X- _ O
combinations -X- _ O
of -X- _ O
same -X- _ O
vs. -X- _ O
different -X- _ O
data -X- _ O
and -X- _ O
code -X- _ O
. -X- _ O

None -X- _ O
of -X- _ O
these -X- _ O
definitions -X- _ O
adopt -X- _ O
the -X- _ O
general -X- _ O
scientific -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
pertaining -X- _ O
to -X- _ O
reproducibility -X- _ O
, -X- _ O
codified -X- _ O
in -X- _ O
the -X- _ O
International -X- _ O
V -X- _ O
ocabulary -X- _ O
of -X- _ O
Metrology -X- _ O
, -X- _ O
VIM -X- _ O
( -X- _ O
JCGM -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

One -X- _ O
issue -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
all -X- _ O
reduce -X- _ O
the -X- _ O
in -X- _ O
principle -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
number -X- _ O
of -X- _ O
dimensions -X- _ O
of -X- _ O
variation -X- _ O
between -X- _ O
measurements -X- _ O
accounted -X- _ O
for -X- _ O
by -X- _ O
VIM -X- _ O
to -X- _ O
just -X- _ O
two -X- _ O
or -X- _ O
three -X- _ O
( -X- _ O
code -X- _ O
, -X- _ O
data -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
team -X- _ O
) -X- _ O
. -X- _ O

Another -X- _ O
, -X- _ O
that -X- _ O
unlike -X- _ O
VIM -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
n’t -X- _ O
produce -X- _ O
comparable -X- _ O
results -X- _ O
. -X- _ O

NLP -X- _ O
does -X- _ O
not -X- _ O
currently -X- _ O
have -X- _ O
a -X- _ O
shared -X- _ O
approach -X- _ O
to -X- _ O
deciding -X- _ O
reproducibility -X- _ O
, -X- _ O
and -X- _ O
results -X- _ O
from -X- _ O
reproductions -X- _ O
as -X- _ O
currently -X- _ O
reported -X- _ O
are -X- _ O
not -X- _ O
comparable -X- _ O
across -X- _ O
studies -X- _ O
and -X- _ O
can -X- _ O
, -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
introduction -X- _ O
, -X- _ O
lead -X- _ O
to -X- _ O
contradictory -X- _ O
conclusions -X- _ O
about -X- _ O
an -X- _ O
original -X- _ O
study -X- _ O
’s -X- _ O
reproducibility -X- _ O
. -X- _ O

There -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
no -X- _ O
work -X- _ O
at -X- _ O
all -X- _ O
in -X- _ O
NLP -X- _ O
that -X- _ O
aims -X- _ O
to -X- _ O
estimate -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
which -X- _ O
would -X- _ O
allow -X- _ O
crossstudy -X- _ O
comparisons -X- _ O
and -X- _ O
conclusions -X- _ O
. -X- _ O

3 -X- _ O
Metrology -X- _ O
- -X- _ O
based -X- _ O
Reproducibility -X- _ B-MethodName
Assessment -X- _ I-MethodName
Metrology -X- _ O
is -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
science -X- _ O
: -X- _ O
its -X- _ O
subject -X- _ O
is -X- _ O
the -X- _ O
standardisation -X- _ O
of -X- _ O
measurements -X- _ O
across -X- _ O
all -X- _ O
of -X- _ O
science -X- _ O
to -X- _ O
ensure -X- _ O
comparability -X- _ O
. -X- _ O

Computer -X- _ O
science -X- _ O
has -X- _ O
long -X- _ O
borrowed -X- _ O
terms -X- _ O
, -X- _ O
most -X- _ O
notably -X- _ O
reproducibility -X- _ O
, -X- _ O
from -X- _ O
metrology -X- _ O
, -X- _ O
albeit -X- _ O
not -X- _ O
adopting -X- _ O
the -X- _ O
same -X- _ O
definitions -X- _ O
( -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
above -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
quantified -X- _ B-MethodName
reproducibility -X- _ I-MethodName
assessment -X- _ I-MethodName
( -X- _ O
QRA -X- _ B-MethodName
) -X- _ O
, -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
is -X- _ O
directly -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
of -X- _ O
metrology -X- _ O
, -X- _ O
adopting -X- _ O
the -X- _ O
latter -X- _ O
exactly -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
, -X- _ O
and -X- _ O
yields -X- _ O
assessments -X- _ O
of -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
similarity -X- _ O
between -X- _ O
numerical -X- _ O
results -X- _ O
and -X- _ O
between -X- _ O
the -X- _ O
studies -X- _ O
that -X- _ O
produced -X- _ O
them -X- _ O
. -X- _ O

We -X- _ O
start -X- _ O
below -X- _ O
with -X- _ O
the -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
that -X- _ O
QRA -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
framework -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
steps -X- _ O
in -X- _ O
applying -X- _ O
it -X- _ O
in -X- _ O
practice -X- _ O
( -X- _ O
Section -X- _ O
3.1 -X- _ O
VIM -X- _ O
Definitions -X- _ O
of -X- _ O
Repeatability -X- _ O
and -X- _ O
Reproducibility -X- _ O
The -X- _ O
International -X- _ O
V -X- _ O
ocabulary -X- _ O
of -X- _ O
Metrology -X- _ O
( -X- _ O
VIM -X- _ O
) -X- _ O
( -X- _ O
JCGM -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
defines -X- _ O
repeatability -X- _ O
and -X- _ O
reproducibility -X- _ O
as -X- _ O
follows -X- _ O
( -X- _ O
defined -X- _ O
terms -X- _ O
in -X- _ O
bold -X- _ O
, -X- _ O
see -X- _ O
VIM -X- _ O
for -X- _ O
subsidiary -X- _ O
defined -X- _ O
terms -X- _ O
) -X- _ O
: -X- _ O
2.21 -X- _ O
measurement -X- _ O
repeatability -X- _ O
( -X- _ O
or -X- _ O
repeatability,17 -X- _ O

for -X- _ O
short -X- _ O
) -X- _ O
is -X- _ O
measurement -X- _ O
precision -X- _ O
under -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
repeatability -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
. -X- _ O

2.20 -X- _ O
arepeatability -X- _ O
condition -X- _ O
of -X- _ O
measurement -X- _ O
( -X- _ O
repeatability -X- _ O
condition -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
condition -X- _ O
of -X- _ O
measurement -X- _ O
, -X- _ O
out -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
conditions -X- _ O
that -X- _ O
includes -X- _ O
the -X- _ O
same -X- _ O
measurement -X- _ O
procedure -X- _ O
, -X- _ O
same -X- _ O
operators -X- _ O
, -X- _ O
same -X- _ O
measuring -X- _ O
system -X- _ O
, -X- _ O
same -X- _ O
operating -X- _ O
conditions -X- _ O
and -X- _ O
same -X- _ O
location -X- _ O
, -X- _ O
and -X- _ O
replicate -X- _ O
measurements -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
or -X- _ O
similar -X- _ O
objects -X- _ O
over -X- _ O
a -X- _ O
short -X- _ O
period -X- _ O
of -X- _ O
time -X- _ O
. -X- _ O

2.25 -X- _ O
measurement -X- _ B-MetricName
reproducibility -X- _ I-MetricName
( -X- _ O
reproducibility -X- _ B-MetricName
) -X- _ O
is -X- _ O
measurement -X- _ O
precision -X- _ O
under -X- _ O
reproducibility -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
. -X- _ O

2.24 -X- _ O
areproducibility -X- _ O
condition -X- _ O
of -X- _ O
measurement -X- _ O
( -X- _ O
reproducibility -X- _ O
condition -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
condition -X- _ O
of -X- _ O
measurement -X- _ O
, -X- _ O
out -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
conditions -X- _ O
that -X- _ O
includes -X- _ O
different -X- _ O
locations -X- _ O
, -X- _ O
operators -X- _ O
, -X- _ O
measuring -X- _ O
systems -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O

A -X- _ O
specification -X- _ O
should -X- _ O
give -X- _ O
the -X- _ O
conditions -X- _ O
changed -X- _ O
and -X- _ O
unchanged -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
extent -X- _ O
practical -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
VIM -X- _ O
considers -X- _ O
repeatability -X- _ O
and -X- _ O
reproducibility -X- _ O
to -X- _ O
be -X- _ O
properties -X- _ O
of -X- _ O
measurements -X- _ O
( -X- _ O
not -X- _ O
objects -X- _ O
, -X- _ O
scores -X- _ O
, -X- _ O
results -X- _ O
or -X- _ O
conclusions -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
defines -X- _ O
them -X- _ O
as -X- _ O
measurement -X- _ O
precision -X- _ O
, -X- _ O
i.e. -X- _ O
both -X- _ O
are -X- _ O
quantified -X- _ O
by -X- _ O
calculating -X- _ O
the -X- _ O
precision -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
. -X- _ O

Both -X- _ O
concepts -X- _ O
are -X- _ O
defined -X- _ O
relative -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
: -X- _ O
the -X- _ O
conditions -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
known -X- _ O
and -X- _ O
specified -X- _ O
for -X- _ O
assessment -X- _ O
of -X- _ O
repeatability -X- _ O
and -X- _ O
reproducibility -X- _ O
to -X- _ O
be -X- _ O
meaningful -X- _ O
. -X- _ O

In -X- _ O
repeatability -X- _ O
, -X- _ O
conditions -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
whereas -X- _ O
in -X- _ O
reproducibility -X- _ O
, -X- _ O
they -X- _ O
differ -X- _ O
. -X- _ O

In -X- _ O
an -X- _ O
NLP -X- _ O
context -X- _ O
, -X- _ O
objects -X- _ O
are -X- _ O
systems -X- _ O
, -X- _ O
and -X- _ O
measurements -X- _ O
involve -X- _ O
applying -X- _ O
an -X- _ O
evaluation -X- _ O
method -X- _ O
to -X- _ O
a -X- _ O
system -X- _ O
usually -X- _ O
via -X- _ O
obtaining -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
its -X- _ O
outputs -X- _ O
and -X- _ O
applying -X- _ O
the -X- _ O
method -X- _ O
to -X- _ O
the -X- _ O
sample -X- _ O
( -X- _ O
further -X- _ O
details -X- _ O
of -X- _ O
how -X- _ O
concepts -X- _ O
map -X- _ O
to -X- _ O
NLP -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Section -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O

3.2 -X- _ O
Assessment -X- _ O
framework -X- _ O
The -X- _ O
VIM -X- _ O
definitions -X- _ O
translate -X- _ O
directly -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
definition -X- _ O
of -X- _ O
repeatability -X- _ O
R0 -X- _ O
( -X- _ O
where -X- _ O
all -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
Care -X- _ O
the -X- _ O
same -X- _ O
across -X- _ O
measurements -X- _ O
) -X- _ O
: -X- _ O
and -X- _ O
the -X- _ O
Miare -X- _ O
repeat -X- _ O
measurements -X- _ O
for -X- _ O
measurandmperformed -X- _ O
on -X- _ O
object -X- _ O
Oat -X- _ O
different -X- _ O
times -X- _ O
ti -X- _ O
under -X- _ O
( -X- _ O
the -X- _ O
same -X- _ O
) -X- _ O
set -X- _ O
of -X- _ O
conditions -X- _ O
C -X- _ O
, -X- _ O
producing -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
vi -X- _ O
. -X- _ O

Below -X- _ O
, -X- _ O
the -X- _ O
coefficientof -X- _ O
variation -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
precision -X- _ O
measure -X- _ O
, -X- _ O
but -X- _ O
other -X- _ O
measures -X- _ O
are -X- _ O
possible -X- _ O
. -X- _ O

Conditions -X- _ O
of -X- _ O
measurement -X- _ O
are -X- _ O
attribute -X- _ O
/ -X- _ O
value -X- _ O
pairs -X- _ O
each -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
name -X- _ O
and -X- _ O
a -X- _ O
value -X- _ O
( -X- _ O
for -X- _ O
examples -X- _ O
, -X- _ O
see -X- _ O
following -X- _ O
section -X- _ O
) -X- _ O
. -X- _ O

Reproducibility -X- _ B-MetricName
Ris -X- _ B-MetricName
defined -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
R0except -X- _ O
that -X- _ O
condition -X- _ O
values -X- _ O
( -X- _ O
but -X- _ O
not -X- _ O
names -X- _ O
) -X- _ O
differ -X- _ O
for -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
of -X- _ O
the -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
Ci -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
is -X- _ O
typically -X- _ O
reported -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
some -X- _ O
or -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
mean -X- _ O
, -X- _ O
standard -X- _ O
deviation -X- _ O
with -X- _ O
95 -X- _ O
% -X- _ O
confidence -X- _ O
intervals -X- _ O
, -X- _ O
coefficient -X- _ O
of -X- _ O
variation -X- _ O
, -X- _ O
and -X- _ O
percentage -X- _ O
of -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
within -X- _ O
nstandard -X- _ O
deviations -X- _ O
. -X- _ O

We -X- _ O
opt -X- _ O
for -X- _ O
the -X- _ O
coefficient -X- _ B-MetricName
of -X- _ I-MetricName
variation -X- _ I-MetricName
( -X- _ O
CV -X- _ B-MetricName
) -X- _ O
,1because -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
general -X- _ O
measure -X- _ O
, -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
unit -X- _ O
of -X- _ O
the -X- _ O
measurements -X- _ O
( -X- _ O
unlike -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
) -X- _ O
, -X- _ O
providing -X- _ O
a -X- _ O
quantification -X- _ O
of -X- _ O
precision -X- _ O
( -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
) -X- _ O
that -X- _ O
is -X- _ O
comparable -X- _ O
across -X- _ O
studies -X- _ O
( -X- _ O
Ahmed -X- _ O
, -X- _ O
1995 -X- _ O
, -X- _ O
p. -X- _ O
57 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
also -X- _ O
holds -X- _ O
for -X- _ O
percentage -X- _ O
within -X- _ O
nstandard -X- _ O
deviations -X- _ O
but -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
a -X- _ O
less -X- _ O
recognised -X- _ O
measure -X- _ O
, -X- _ O
and -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
less -X- _ O
intuitive -X- _ O
for -X- _ O
many -X- _ O
. -X- _ O

In -X- _ O
reproduction -X- _ O
studies -X- _ O
in -X- _ O
NLP -X- _ O
/ -X- _ O
ML -X- _ O
, -X- _ O
sample -X- _ O
sizes -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
very -X- _ O
small -X- _ O
( -X- _ O
a -X- _ O
sample -X- _ O
size -X- _ O
of -X- _ O
8 -X- _ O
, -X- _ O
one -X- _ O
original -X- _ O
study -X- _ O
plus -X- _ O
7 -X- _ O
reproductions -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
is -X- _ O
currently -X- _ O
unique -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
therefore -X- _ O
need -X- _ O
to -X- _ O
use -X- _ O
de -X- _ O
- -X- _ O
biased -X- _ O
sample -X- _ O
estimators -X- _ O
: -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
unbiased -X- _ O
sample -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
denoted -X- _ O
s∗ -X- _ O
, -X- _ O
with -X- _ O
confidence -X- _ O
intervals -X- _ O
calculated -X- _ O
using -X- _ O
a -X- _ O
t -X- _ O
- -X- _ O
distribution -X- _ O
, -X- _ O
and -X- _ O
standard -X- _ O
error -X- _ O
( -X- _ O
of -X- _ O
the -X- _ O
unbiased -X- _ O
sample -X- _ O
standard -X- _ O
deviation -X- _ O
) -X- _ O
approximated -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
standard -X- _ O
error -X- _ O
of -X- _ O
the -X- _ O
unbiased -X- _ O
sample -X- _ O
variance -X- _ O
se -X- _ O
( -X- _ O
s2 -X- _ O
) -X- _ O
as -X- _ O
2σse -X- _ O
( -X- _ O
s2 -X- _ O
) -X- _ O
( -X- _ O
Rao -X- _ O
, -X- _ O
1973 -X- _ O
) -X- _ O
. -X- _ O

Assuming -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
are -X- _ O
normally -X- _ O
distributed -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
standard -X- _ O
error -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
variance -X- _ O
in -X- _ O
the -X- _ O
usual -X- _ O
way -X- _ O
: -X- _ O
se -X- _ O
( -X- _ O
s2 -X- _ O
) -X- _ O
= -X- _ O
q -X- _ O
n−1 -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
small -X- _ O
sample -X- _ O
correction -X- _ O
( -X- _ O
indicated -X- _ O
by -X- _ O
the -X- _ O
star -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
coefficient -X- _ O
of -X- _ O
variation -X- _ O
: -X- _ O
CV∗= -X- _ O
( -X- _ O
1 -X- _ O
+ -X- _ O
1 -X- _ O
4n -X- _ O
) -X- _ O
CV -X- _ O
( -X- _ O
Sokal -X- _ O
and -X- _ O
Rohlf -X- _ O
, -X- _ O
1971 -X- _ O
) -X- _ O
.2 -X- _ O
Before -X- _ O
applying -X- _ O
CV∗to -X- _ O
values -X- _ O
on -X- _ O
scales -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
start -X- _ O
at -X- _ O
0 -X- _ O
( -X- _ O
mostly -X- _ O
in -X- _ O
human -X- _ O
evaluations -X- _ O
) -X- _ O
we -X- _ O
shift -X- _ O
values -X- _ O
to -X- _ O
start -X- _ O
at -X- _ O
0 -X- _ O
to -X- _ O
ensure -X- _ O
comparability.3 -X- _ O

This -X- _ O
means -X- _ O
that -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
CV∗scores -X- _ O
in -X- _ O
the -X- _ O
tables -X- _ O
below -X- _ O
, -X- _ O
measurements -X- _ O
are -X- _ O
first -X- _ O
shifted -X- _ O
. -X- _ O

standard -X- _ O
deviation -X- _ O
( -X- _ O
RSD -X- _ O
) -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
standard -X- _ O
deviation -X- _ O
over -X- _ O
the -X- _ O
mean -X- _ O
, -X- _ O
often -X- _ O
expressed -X- _ O
as -X- _ O
a -X- _ O
percentage -X- _ O
. -X- _ O

com -X- _ O
/ -X- _ O
asbelz -X- _ O
/ -X- _ O
coeff -X- _ O
- -X- _ O
var -X- _ O
. -X- _ O

lower -X- _ O
ends -X- _ O
of -X- _ O
scales.18 -X- _ O

3.3 -X- _ O
Application -X- _ O
of -X- _ O
the -X- _ O
framework -X- _ O
Using -X- _ O
the -X- _ O
defined -X- _ O
VIM -X- _ O
terms -X- _ O
and -X- _ O
the -X- _ O
notations -X- _ O
from -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
refine -X- _ O
the -X- _ O
question -X- _ O
from -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
if -X- _ O
we -X- _ O
perform -X- _ O
multiple -X- _ O
measurements -X- _ O
of -X- _ O
object -X- _ O
Oand -X- _ O
measurand -X- _ O
munder -X- _ O
reproducibility -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
Ci -X- _ O
, -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
precision -X- _ B-MetricName
of -X- _ O
the -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
we -X- _ O
obtain -X- _ O
? -X- _ O

For -X- _ O
NLP -X- _ O
, -X- _ O
this -X- _ O
means -X- _ O
calculating -X- _ O
the -X- _ O
precision -X- _ B-MetricName
of -X- _ O
multiple -X- _ O
evaluation -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
. -X- _ O

Focusing -X- _ O
here -X- _ O
on -X- _ O
reproducibility -X- _ B-MethodName
assessment -X- _ I-MethodName
where -X- _ O
we -X- _ O
start -X- _ O
from -X- _ O
an -X- _ O
existing -X- _ O
set -X- _ O
of -X- _ O
results -X- _ O
( -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
specifically -X- _ O
designed -X- _ O
to -X- _ O
test -X- _ O
reproducibility -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
steps -X- _ O
in -X- _ O
performing -X- _ O
QRA -X- _ B-MethodName
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

1.For -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
nmeasurements -X- _ O
to -X- _ O
be -X- _ O
assessed -X- _ O
, -X- _ O
identify -X- _ O
the -X- _ O
shared -X- _ O
object -X- _ O
and -X- _ O
measurand -X- _ O
. -X- _ O

2.Identify -X- _ O
all -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
Cifor -X- _ O
which -X- _ O
information -X- _ O
is -X- _ O
available -X- _ O
for -X- _ O
all -X- _ O
measurements -X- _ O
, -X- _ O
and -X- _ O
specify -X- _ O
values -X- _ O
for -X- _ O
each -X- _ O
condition -X- _ O
, -X- _ O
including -X- _ O
measurement -X- _ O
method -X- _ O
and -X- _ O
procedure -X- _ O
. -X- _ O

3.Gather -X- _ O
the -X- _ O
nmeasured -X- _ O
quantity -X- _ O
values -X- _ O
4.Compute -X- _ O
precision -X- _ B-MetricName
for -X- _ O
v1 -X- _ O
, -X- _ O
v2 -X- _ O
, -X- _ O
... -X- _ O
v -X- _ O
n -X- _ O
, -X- _ O
giving -X- _ O
reproducibility -X- _ B-MetricName
score -X- _ I-MetricName
R. -X- _ O
5.Report -X- _ O
resulting -X- _ O
Rscore -X- _ B-MetricName
and -X- _ O
associated -X- _ O
confidence -X- _ O
statistics -X- _ O
, -X- _ O
alongside -X- _ O
the -X- _ O
Ci -X- _ O
. -X- _ O

In -X- _ O
NLP -X- _ O
terms -X- _ O
, -X- _ O
the -X- _ O
object -X- _ O
is -X- _ O
the -X- _ O
ready -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
use -X- _ O
system -X- _ O
( -X- _ O
binaries -X- _ O
if -X- _ O
available -X- _ O
; -X- _ O
otherwise -X- _ O
code -X- _ O
, -X- _ O
dependencies -X- _ O
, -X- _ O
parameter -X- _ O
values -X- _ O
, -X- _ O
how -X- _ O
the -X- _ O
system -X- _ O
was -X- _ O
compiled -X- _ O
and -X- _ O
trained -X- _ O
) -X- _ O
being -X- _ O
evaluated -X- _ O
( -X- _ O
e.g. -X- _ O
the -X- _ O
NTSdefault -X- _ O
system -X- _ O
variant -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
measurand -X- _ O
is -X- _ O
the -X- _ O
quantity -X- _ O
intended -X- _ O
to -X- _ O
be -X- _ O
measured -X- _ O
( -X- _ O
e.g. -X- _ O
BLEUstyle -X- _ O
modified -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
precision -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
measurement -X- _ O
method -X- _ O
and -X- _ O
procedure -X- _ O
capture -X- _ O
how -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
system -X- _ O
( -X- _ O
e.g. -X- _ O
obtaining -X- _ O
system -X- _ O
outputs -X- _ O
for -X- _ O
a -X- _ O
specified -X- _ O
set -X- _ O
of -X- _ O
inputs -X- _ O
, -X- _ O
and -X- _ O
applying -X- _ O
preprocessing -X- _ O
and -X- _ O
a -X- _ O
given -X- _ O
BLEU -X- _ O
implementation -X- _ O
to -X- _ O
the -X- _ O
latter -X- _ O
) -X- _ O
. -X- _ O

VIM -X- _ O
holds -X- _ O
that -X- _ O
reproducibility -X- _ O
assessment -X- _ O
is -X- _ O
only -X- _ O
meaningful -X- _ O
if -X- _ O
the -X- _ O
reproducibility -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
are -X- _ O
specified -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
test -X- _ O
. -X- _ O

Conditions -X- _ O
of -X- _ O
measurement -X- _ O
cover -X- _ O
every -X- _ O
aspect -X- _ O
and -X- _ O
detail -X- _ O
of -X- _ O
how -X- _ O
a -X- _ O
measurement -X- _ O
was -X- _ O
performed -X- _ O
and -X- _ O
how -X- _ O
the -X- _ O
measured -X- _ O
quantity -X- _ O
value -X- _ O
was -X- _ O
obtained -X- _ O
. -X- _ O

The -X- _ O
key -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
capture -X- _ O
all -X- _ O
respects -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
measurements -X- _ O
to -X- _ O
be -X- _ O
assessed -X- _ O
are -X- _ O
known -X- _ O
to -X- _ O
be -X- _ O
either -X- _ O
the -X- _ O
same -X- _ O
or -X- _ O
different -X- _ O
. -X- _ O

If -X- _ O
QRA -X- _ B-MethodName
is -X- _ O
performed -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
existing -X- _ O
results -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
not -X- _ O
possible -X- _ O
todiscover -X- _ O
every -X- _ O
aspect -X- _ O
and -X- _ O
detail -X- _ O
of -X- _ O
how -X- _ O
a -X- _ O
measurement -X- _ O
was -X- _ O
performed -X- _ O
, -X- _ O
so -X- _ O
a -X- _ O
reduced -X- _ O
set -X- _ O
may -X- _ O
have -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
( -X- _ O
unlike -X- _ O
in -X- _ O
experiments -X- _ O
designed -X- _ O
to -X- _ O
test -X- _ O
reproducibility -X- _ O
where -X- _ O
such -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
gathered -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
experimental -X- _ O
design -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
reproducibility -X- _ O
and -X- _ O
evaluation -X- _ O
checklists -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
( -X- _ O
Pineau -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Shimorina -X- _ O
and -X- _ O
Belz -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
capture -X- _ O
properties -X- _ O
that -X- _ O
are -X- _ O
in -X- _ O
effect -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
combination -X- _ O
with -X- _ O
code -X- _ O
, -X- _ O
data -X- _ O
and -X- _ O
other -X- _ O
resources -X- _ O
serve -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
specifying -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
, -X- _ O
if -X- _ O
they -X- _ O
have -X- _ O
been -X- _ O
completed -X- _ O
by -X- _ O
authors -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
present -X- _ O
time -X- _ O
, -X- _ O
completed -X- _ O
checklists -X- _ O
are -X- _ O
not -X- _ O
normally -X- _ O
available -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
set -X- _ O
of -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
the -X- _ O
information -X- _ O
required -X- _ O
for -X- _ O
which -X- _ O
istypically -X- _ O
available -X- _ O
for -X- _ O
existing -X- _ O
work -X- _ O
( -X- _ O
we -X- _ O
include -X- _ O
object -X- _ O
and -X- _ O
measurand -X- _ O
for -X- _ O
completeness -X- _ O
although -X- _ O
strictly -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
conditions -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
must -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
in -X- _ O
each -X- _ O
measurement -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
QRA -X- _ B-MethodName
test -X- _ O
) -X- _ O
: -X- _ O

1.Object -X- _ O
: -X- _ O
the -X- _ O
system -X- _ O
( -X- _ O
variant -X- _ O
) -X- _ O
being -X- _ O
evaluated.4 -X- _ O
E.g. -X- _ O
a -X- _ O
given -X- _ O
MT -X- _ O
system -X- _ O
. -X- _ O

2.Measurand -X- _ O
: -X- _ O
the -X- _ O
quantity -X- _ O
intended -X- _ O
to -X- _ O
be -X- _ O
evaluated.5E.g -X- _ O
. -X- _ O

BLEU -X- _ B-MetricName
- -X- _ O
style -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
precision -X- _ O
or -X- _ O
human -X- _ O
- -X- _ O
assessed -X- _ O
Fluency -X- _ O
. -X- _ O

3 -X- _ O
. -X- _ O
Object -X- _ O
conditions -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
System -X- _ O
code -X- _ O
: -X- _ O
source -X- _ O
code -X- _ O
including -X- _ O
any -X- _ O
parameters -X- _ O
. -X- _ O

E.g. -X- _ O
the -X- _ O
complete -X- _ O
code -X- _ O
implementing -X- _ O
an -X- _ O
MT -X- _ O
system -X- _ O
. -X- _ O

( -X- _ O
b -X- _ O
) -X- _ O
Compile -X- _ O
/ -X- _ O
training -X- _ O
information -X- _ O
: -X- _ O
steps -X- _ O
from -X- _ O
code -X- _ O
plus -X- _ O
parameters -X- _ O
to -X- _ O
fully -X- _ O
compiled -X- _ O
and -X- _ O
trained -X- _ O
system -X- _ O
, -X- _ O
including -X- _ O
dependencies -X- _ O
and -X- _ O
environment -X- _ O
. -X- _ O

E.g. -X- _ O
complete -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
the -X- _ O
MT -X- _ O
system -X- _ O
code -X- _ O
was -X- _ O
compiled -X- _ O
and -X- _ O
the -X- _ O
system -X- _ O
trained -X- _ O
. -X- _ O

4 -X- _ O
. -X- _ O
Measurement -X- _ O
method -X- _ O
conditions:6 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
Method -X- _ O
specification -X- _ O
: -X- _ O
full -X- _ O
description -X- _ O
of -X- _ O
method -X- _ O
used -X- _ O
for -X- _ O
obtaining -X- _ O
values -X- _ O
quantifying -X- _ O
the -X- _ O
measurand -X- _ O
. -X- _ O

E.g. -X- _ O
a -X- _ O
formal -X- _ O
definition -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O

( -X- _ O
b -X- _ O
) -X- _ O
Implementation -X- _ O
: -X- _ O
the -X- _ O
method -X- _ O
implemented -X- _ O
in -X- _ O
a -X- _ O
form -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
object -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
. -X- _ O

E.g. -X- _ O
a -X- _ O
full -X- _ O
implementation -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O

is -X- _ O
being -X- _ O
measured -X- _ O
. -X- _ O

System -X- _ O
( -X- _ O
Object -X- _ O
) -X- _ O
Evaluation -X- _ O
measure -X- _ O
NPapers -X- _ O
reporting -X- _ O
results -X- _ O
NLP -X- _ O
task -X- _ O
Evaluation -X- _ O
type -X- _ O
( -X- _ O
Measurand -X- _ O
) -X- _ O
scores -X- _ O
PASSClarity -X- _ O
2 -X- _ O
Fluency -X- _ O
2 -X- _ O
van -X- _ O
der -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
data -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
human -X- _ O
, -X- _ O
intrinsicIdentifiability2Mille -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
of -X- _ O
stance -X- _ O
mult -X- _ O
- -X- _ O
base -X- _ O
wf1 -X- _ O
8 -X- _ O
mult -X- _ O
- -X- _ O
word−wF1 -X- _ O
8 -X- _ O
mult -X- _ O
- -X- _ O
word+wF1 -X- _ O
8 -X- _ O
mult -X- _ O
- -X- _ O
POS−wF1 -X- _ O
8 -X- _ O
Vajjala -X- _ O
and -X- _ O
Rama -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
mult -X- _ O
- -X- _ O
POS+wF1 -X- _ O
8 -X- _ O
Huber -X- _ O
and -X- _ O
Çöltekin -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
multilingual -X- _ O
essay -X- _ O
metric -X- _ O
: -X- _ O
intrinsic -X- _ O
, -X- _ O
mult -X- _ O
- -X- _ O
dep−wF1 -X- _ O
8 -X- _ O
Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
scoring -X- _ O
as -X- _ O
text -X- _ O
evaluated -X- _ O
against -X- _ O
mult -X- _ O
- -X- _ O
dep+wF1 -X- _ O
8 -X- _ O
Bestgen -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
classification -X- _ O
single -X- _ O
reference -X- _ O
mult -X- _ O
- -X- _ O
dom−wF1 -X- _ O
8 -X- _ O
Caines -X- _ O
and -X- _ O
Buttery -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
mult -X- _ O
- -X- _ O
dom+wF1 -X- _ O
8 -X- _ O
mult -X- _ O
- -X- _ O
emb−wF1 -X- _ O
8 -X- _ O
mult -X- _ O
- -X- _ O
emb+wF1 -X- _ O
8 -X- _ O
NTS_defaultBLEU -X- _ O
7 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
metric -X- _ O
: -X- _ O
intrinsic -X- _ O
, -X- _ O
SARI -X- _ O
5 -X- _ O
Cooper -X- _ O
& -X- _ O
Shardlow -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ O
simplificationeval -X- _ O
. -X- _ O

against -X- _ O
input -X- _ O
NTS -X- _ O
- -X- _ O
w2v_defaultBLEU -X- _ O
6 -X- _ O
additional -X- _ O
reproduction -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
multiple -X- _ O
SARI -X- _ O
4 -X- _ O
study -X- _ O
for -X- _ O
this -X- _ O
paper -X- _ O
references -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Summary -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
18 -X- _ O
object -X- _ O
/ -X- _ O
measurand -X- _ O
combinations -X- _ O
taht -X- _ O
were -X- _ O
QRA -X- _ B-MethodName
- -X- _ O
tested -X- _ O
for -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

5 -X- _ O
. -X- _ O
Measurement -X- _ O
procedure -X- _ O
conditions:7 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
Procedure -X- _ O
: -X- _ O
specification -X- _ O
of -X- _ O
how -X- _ O
system -X- _ O
outputs -X- _ O
( -X- _ O
or -X- _ O
other -X- _ O
system -X- _ O
characteristics -X- _ O
) -X- _ O
are -X- _ O
obtained -X- _ O
and -X- _ O
the -X- _ O
measurement -X- _ O
method -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
them -X- _ O
. -X- _ O

E.g. -X- _ O
running -X- _ O
a -X- _ O
BLEU -X- _ B-MetricName
tool -X- _ O
on -X- _ O
system -X- _ O
outputs -X- _ O
and -X- _ O
reference -X- _ O
outputs -X- _ O
. -X- _ O

( -X- _ O
b -X- _ O
) -X- _ O
Test -X- _ O
set -X- _ O
: -X- _ O
the -X- _ O
data -X- _ O
used -X- _ O
in -X- _ O
obtaining -X- _ O
and -X- _ O
evaluating -X- _ O
system -X- _ O
outputs -X- _ O
( -X- _ O
or -X- _ O
other -X- _ O
system -X- _ O
characteristics -X- _ O
) -X- _ O
. -X- _ O

E.g. -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
source -X- _ O
- -X- _ O
language -X- _ O
texts -X- _ O
and -X- _ O
reference -X- _ O
translations -X- _ O
. -X- _ O

( -X- _ O
c -X- _ O
) -X- _ O
Performed -X- _ O
by -X- _ O
: -X- _ O
who -X- _ O
performed -X- _ O
the -X- _ O
measurement -X- _ O
procedure -X- _ O
and -X- _ O
any -X- _ O
additional -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
they -X- _ O
did -X- _ O
it -X- _ O
. -X- _ O

E.g. -X- _ O
the -X- _ O
team -X- _ O
applying -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
tool -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
run -X- _ O
- -X- _ O
time -X- _ O
environment -X- _ O
they -X- _ O
used -X- _ O
. -X- _ O

Thenames -X- _ O
of -X- _ O
the -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
boldfaced -X- _ O
above -X- _ O
. -X- _ O

The -X- _ O
values -X- _ O
for -X- _ O
each -X- _ O
condition -X- _ O
characterise -X- _ O
how -X- _ O
measurements -X- _ O
differ -X- _ O
in -X- _ O
respect -X- _ O
of -X- _ O
the -X- _ O
condition -X- _ O
. -X- _ O

In -X- _ O
reporting -X- _ O
results -X- _ O
from -X- _ O
QRA -X- _ B-MethodName
tests -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
paper -X- _ O
identifiers -X- _ O
as -X- _ O
shorthand -X- _ O
for -X- _ O
each -X- _ O
distinct -X- _ O
condition -X- _ O
value -X- _ O
( -X- _ O
full -X- _ O
details -X- _ O
in -X- _ O
each -X- _ O
case -X- _ O
being -X- _ O
available -X- _ O
from -X- _ O
the -X- _ O
referenced -X- _ O
papers -X- _ O
) -X- _ O
. -X- _ O

4 -X- _ O
QRA -X- _ B-MethodName
Tests -X- _ O
Table -X- _ O
1 -X- _ O
provides -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
18 -X- _ O
object -X- _ O
/ -X- _ O
measurand -X- _ O
pairs -X- _ O
( -X- _ O
corresponding -X- _ O
to -X- _ O
116 -X- _ O
individual -X- _ O
meathis -X- _ O
study -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
object -X- _ O
/ -X- _ O
measurand -X- _ O
pair -X- _ O
, -X- _ O
the -X- _ O
columns -X- _ O
show -X- _ O
, -X- _ O
from -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
, -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
system -X- _ O
evaluated -X- _ O
( -X- _ O
object -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
evaluation -X- _ O
measure -X- _ O
applied -X- _ O
( -X- _ O
measurand -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
scores -X- _ O
( -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
) -X- _ O
obtained -X- _ O
, -X- _ O
the -X- _ O
papers -X- _ O
in -X- _ O
which -X- _ O
systems -X- _ O
and -X- _ O
scores -X- _ O
were -X- _ O
first -X- _ O
reported -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NLP -X- _ O
task -X- _ O
and -X- _ O
type -X- _ O
of -X- _ O
evaluation -X- _ O
involved -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
three -X- _ O
sets -X- _ O
of -X- _ O
related -X- _ O
systems -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
the -X- _ O
( -X- _ O
single -X- _ O
) -X- _ O
PASS -X- _ O
football -X- _ O
report -X- _ O
generator -X- _ O
( -X- _ O
van -X- _ O
der -X- _ O
11 -X- _ O
multilingual -X- _ O
essay -X- _ O
scoring -X- _ O
system -X- _ O
variants -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
two -X- _ O
variants -X- _ O
of -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2017 -X- _ O
) -X- _ O
’s -X- _ O
neural -X- _ O
text -X- _ O
simplifier -X- _ O
( -X- _ O
NTS -X- _ O
) -X- _ O
. -X- _ O

PASS -X- _ O
is -X- _ O
evaluated -X- _ O
with -X- _ O
three -X- _ O
evaluation -X- _ O
measures -X- _ O
( -X- _ O
human -X- _ B-MetricName
- -X- _ I-MetricName
assessed -X- _ I-MetricName
Clarity -X- _ I-MetricName
, -X- _ O
Fluency -X- _ B-MetricName
and -X- _ I-MetricName
Stance -X- _ I-MetricName
Identifiability -X- _ I-MetricName
) -X- _ O
, -X- _ O
the -X- _ O
essay -X- _ O
scoring -X- _ O
systems -X- _ O
with -X- _ O
one -X- _ O
( -X- _ O
weighted -X- _ B-MetricName
F1 -X- _ I-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NTS -X- _ O
systems -X- _ O
with -X- _ O
two -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
SARI -X- _ B-MetricName
) -X- _ O
. -X- _ O

For -X- _ O
PASS -X- _ O
we -X- _ O
have -X- _ O
one -X- _ O
reproduction -X- _ O
study -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
essay -X- _ O
scorers -X- _ O
seven -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
NTS -X- _ O
systems -X- _ O
, -X- _ O
from -X- _ O
three -X- _ O
to -X- _ O
six -X- _ O
. -X- _ O

The -X- _ O
PASS -X- _ O
reproduction -X- _ O
was -X- _ O
carried -X- _ O
out -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
ReproGen -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
reproductions -X- _ O
of -X- _ O
the -X- _ O
essay -X- _ O
- -X- _ O
scoring -X- _ O
systems -X- _ O
and -X- _ O
of -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
NTS -X- _ O
systems -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
REPROLANG -X- _ O
( -X- _ O
Branco -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
carried -X- _ O
out -X- _ O
an -X- _ O
additional -X- _ O
reproduction -X- _ O
study -X- _ O
of -X- _ O
the -X- _ O
NTS -X- _ O
systems -X- _ O
for -X- _ O
this -X- _ O
paper.8 -X- _ O

The -X- _ O
PASS -X- _ O
text -X- _ O
generation -X- _ O
system -X- _ O
is -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
the -X- _ O
essay -X- _ O
classifiers -X- _ O
are -X- _ O
‘ -X- _ O
theory -X- _ O
- -X- _ O
guided -X- _ O
and -X- _ O
datadriven -X- _ O
’ -X- _ O
hybrids -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
simplifiers -X- _ O
are -X- _ O
end -X- _ O
- -X- _ O
toend -X- _ O
neural -X- _ O
systems -X- _ O
. -X- _ O

This -X- _ O
gives -X- _ O
us -X- _ O
a -X- _ O
good -X- _ O
breadth -X- _ O
to -X- _ O
be -X- _ O
reproduced -X- _ O
( -X- _ O
Branco -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
.20 -X- _ O

Measured -X- _ O
quantity -X- _ O
value -X- _ O
Sample -X- _ O
Object -X- _ O
Measurand -X- _ O
van -X- _ O
der -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Mille -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
size -X- _ O
mean -X- _ O
stdev -X- _ O
stdev -X- _ O
95 -X- _ O
% -X- _ O
CI -X- _ O
CV∗↓ -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
CV∗ -X- _ B-MetricName
) -X- _ O
and -X- _ O
component -X- _ O
measures -X- _ O
( -X- _ O
mean -X- _ B-MetricName
, -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
, -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
, -X- _ O
confidence -X- _ B-MetricName
intervals -X- _ I-MetricName
) -X- _ O
for -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
obtained -X- _ O
in -X- _ O
two -X- _ O
measurements -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
human -X- _ O
- -X- _ O
assessed -X- _ O
evaluation -X- _ O
measures -X- _ O
for -X- _ O
the -X- _ O
PASS -X- _ O
system -X- _ O
. -X- _ O

Columns -X- _ O
6–9 -X- _ O
calculated -X- _ O
on -X- _ O
shifted -X- _ O
scores -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O

Object -X- _ O
conditionsMeasurement -X- _ O
method -X- _ O
Measurement -X- _ O
procedure -X- _ O
Measured -X- _ O
Object -X- _ O
Measurand -X- _ O
conditions -X- _ O
conditions -X- _ O
quantity -X- _ O
CV∗ -X- _ O
Code -X- _ O
by -X- _ O
Comp. -X- _ O
/ -X- _ O
trained -X- _ O
by -X- _ O
Method -X- _ O
Implem -X- _ O
. -X- _ O

by -X- _ O
Procedure -X- _ O
Test -X- _ O
set -X- _ O
Performed -X- _ O
by -X- _ O
value -X- _ O
PASSClarityvdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

5.6413.193 -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O

6.30 -X- _ O
FluencyvdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

5.3616.372 -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O

6.14 -X- _ O
Stance -X- _ O
id.vdL -X- _ O
& -X- _ O
al -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
91 -X- _ O
% -X- _ O
6.107 -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
vdL -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O
96.75 -X- _ O
% -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Conditions -X- _ O
of -X- _ O
measurement -X- _ O
for -X- _ O
two -X- _ O
measurements -X- _ O
each -X- _ O
for -X- _ O
three -X- _ O
evaluation -X- _ O
measures -X- _ O
( -X- _ O
measurands -X- _ O
) -X- _ O
and -X- _ O
thePASS -X- _ O
system -X- _ O
. -X- _ O

vdL -X- _ O
& -X- _ O
al -X- _ O

= -X- _ O
van -X- _ O
der -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
M -X- _ O
& -X- _ O
al -X- _ O
= -X- _ O
Mille -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

of -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
system -X- _ O
types -X- _ O
, -X- _ O
and -X- _ O
evaluation -X- _ O
types -X- _ O
and -X- _ O
measures -X- _ O

to -X- _ O
test -X- _ O
QRA -X- _ B-MethodName
on -X- _ O

. -X- _ O

4.1 -X- _ O
QRA -X- _ B-MethodName
for -X- _ O
NTS -X- _ O
systems -X- _ O
The -X- _ O
neural -X- _ O
text -X- _ O
simplification -X- _ O
systems -X- _ O
reported -X- _ O
by -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
were -X- _ O
evaluated -X- _ O
with -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
similarity -X- _ O
between -X- _ O
outputs -X- _ O
and -X- _ O
multiple -X- _ O
reference -X- _ O
texts -X- _ O
) -X- _ O
and -X- _ O
SARI -X- _ B-MetricName
( -X- _ O
based -X- _ O
on -X- _ O
word -X- _ O
added -X- _ O
/ -X- _ O
retained -X- _ O
/ -X- _ O
deleted -X- _ O
in -X- _ O
outputs -X- _ O
compared -X- _ O
to -X- _ O
both -X- _ O
inputs -X- _ O
and -X- _ O
reference -X- _ O
texts -X- _ O
, -X- _ O
summing -X- _ O
over -X- _ O
addition -X- _ O
and -X- _ O
retention -X- _ O
F -X- _ B-MetricName
- -X- _ I-MetricName
scores -X- _ I-MetricName
and -X- _ O
deletion -X- _ B-MetricName
Precisions -X- _ I-MetricName
) -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
shows -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
SARI -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
system -X- _ O
variants -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
reproduction -X- _ O
studies -X- _ O
, -X- _ O
alongside -X- _ O
the -X- _ O
four -X- _ O
corresponding -X- _ O
CV∗values -X- _ O
. -X- _ O

In -X- _ O
their -X- _ O
reproduction -X- _ O
, -X- _ O
Cooper -X- _ O
and -X- _ O
Shardlow -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
regenerated -X- _ O
test -X- _ O
outputs -X- _ O
for -X- _ O
NTS -X- _ O
- -X- _ O
w2v_def -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
for -X- _ O
NTS_def -X- _ O
, -X- _ O
which -X- _ O
explains -X- _ O
the -X- _ O
missing -X- _ O
scores -X- _ O
in -X- _ O
Column -X- _ O
4 -X- _ O
. -X- _ O

The -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
scores -X- _ O
in -X- _ O
different -X- _ O
rows -X- _ O
in -X- _ O
Columns -X- _ O
6–9 -X- _ O
are -X- _ O
due -X- _ O
to -X- _ O
our -X- _ O
own -X- _ O
reproduction -X- _ O
using -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
’s -X- _ O
SARI -X- _ B-MetricName
script -X- _ O
, -X- _ O
but -X- _ O
two -X- _ O
different -X- _ O
BLEU -X- _ B-MetricName
scripts -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
’s -X- _ O
script -X- _ O
albeit -X- _ O
with -X- _ O
the -X- _ O
tokeniser -X- _ O
replaced -X- _ O
by -X- _ O
our -X- _ O
own -X- _ O
because -X- _ O
the -X- _ O
former -X- _ O
did -X- _ O
not -X- _ O
work -X- _ O
due -X- _ O
to -X- _ O
changes -X- _ O
in -X- _ O
the -X- _ O
NLTK -X- _ O
library -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
SacreBLEU -X- _ B-MetricName
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
22 -X- _ O
individual -X- _ O
measurements -X- _ O
. -X- _ O

The -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
for -X- _ O
those -X- _ O
measurements -X- _ O
where -X- _ O
Comp. -X- _ O
/ -X- _ O
trained -X- _ O
by -X- _ O
= -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
are -X- _ O
identical -X- _ O
for -X- _ O
the -X- _ O
SARI -X- _ B-MetricName
metric -X- _ O
( -X- _ O
scores -X- _ O
highlighted -X- _ O
bygreen -X- _ O
/ -X- _ O
lighter -X- _ O
shading -X- _ O
and -X- _ O
italics -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
differ -X- _ O
by -X- _ O
up -X- _ O
to -X- _ O
1.4 -X- _ O
points -X- _ O
for -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
scores -X- _ O
highlighted -X- _ O
by -X- _ O
blue -X- _ O
/ -X- _ O
darker -X- _ O
shading -X- _ O
) -X- _ O
. -X- _ O

Because -X- _ O
Test -X- _ O
set -X- _ O
= -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

in -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
these -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
caused -X- _ O
by -X- _ O
differences -X- _ O
in -X- _ O
BLEU -X- _ B-MetricName
scripts -X- _ O
and -X- _ O
how -X- _ O
they -X- _ O
were -X- _ O
run -X- _ O
. -X- _ O

The -X- _ O
corresponding -X- _ O
CV∗is -X- _ O
as -X- _ O
big -X- _ O
as -X- _ O
0.838 -X- _ O
for -X- _ O
( -X- _ O
just -X- _ O
) -X- _ O
the -X- _ O
four -X- _ O
NTS_def -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
, -X- _ O
and -X- _ O
1.314 -X- _ O
for -X- _ O
( -X- _ O
just -X- _ O
) -X- _ O
the -X- _ O
three -X- _ O
NTS -X- _ O
- -X- _ O
w2v_def -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
, -X- _ O
reflecting -X- _ O
known -X- _ O
problems -X- _ O
with -X- _ O
nonstandardised -X- _ O
BLEU -X- _ B-MetricName
scripts -X- _ O
( -X- _ O
Post -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

If -X- _ O
we -X- _ O
conversely -X- _ O
look -X- _ O
just -X- _ O
at -X- _ O
those -X- _ O
measurements -X- _ O
( -X- _ O
identifiable -X- _ O
by -X- _ O
boldfaced -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
reproducing -X- _ O
team -X- _ O
regenerated -X- _ O
outputs -X- _ O
( -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
system -X- _ O
code -X- _ O
) -X- _ O
and -X- _ O
evaluation -X- _ O
scripts -X- _ O
were -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
SARI -X- _ B-MetricName
CV∗is -X- _ O
3.11 -X- _ O
for -X- _ O
the -X- _ O
NTS_def -X- _ O
variants -X- _ O
, -X- _ O
and -X- _ O
4.05 -X- _ O
for -X- _ O
the -X- _ O
NTS -X- _ B-MetricName
- -X- _ O
w2v_def -X- _ O
variants -X- _ O
( -X- _ O
compared -X- _ O
in -X- _ O
both -X- _ O
cases -X- _ O
to -X- _ O
0 -X- _ O
( -X- _ O
perfect -X- _ O
) -X- _ O
when -X- _ O
the -X- _ O
same -X- _ O
outputs -X- _ O
are -X- _ O
used -X- _ O
) -X- _ O
. -X- _ O

BLEU -X- _ B-MetricName
CV∗is -X- _ B-MetricName
2.154 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
NTS_def -X- _ O
variants -X- _ O
( -X- _ O
compared -X- _ O
to -X- _ O
0.838 -X- _ B-MetricValue
for -X- _ O
same -X- _ O
outputs -X- _ O
but -X- _ O
different -X- _ O
evaluation -X- _ O
scripts -X- _ O
, -X- _ O
as -X- _ O
above -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
6.598 -X- _ B-MetricValue
for -X- _ O
the -X- _ O
NTS -X- _ O
- -X- _ O
w2v_def -X- _ O
variants -X- _ O
( -X- _ O
compared -X- _ O
to -X- _ O
1.314 -X- _ B-MetricValue
for -X- _ O
same -X- _ O
outputs -X- _ O
but -X- _ O
different -X- _ O
evaluation -X- _ O
scripts -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
differences -X- _ O
arise -X- _ O
simply -X- _ O
from -X- _ O
running -X- _ O
the -X- _ O
system -X- _ O
in -X- _ O
different -X- _ O
environments -X- _ O
. -X- _ O

The -X- _ O
overall -X- _ O
higher -X- _ O
( -X- _ O
worse -X- _ O
) -X- _ O
CV∗values -X- _ O
for -X- _ O
NTSw2v_def -X- _ O
variants -X- _ O
( -X- _ O
compared -X- _ O
to -X- _ O
NTS_def -X- _ O
) -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
partly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
NTS -X- _ O
models -X- _ O
using -X- _ O
one -X- _ O
third -X- _ O
party -X- _ O
tool -X- _ O
( -X- _ O
openNMT -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NTS -X- _ O
- -X- _ O
w2v -X- _ O
models -X- _ O
using -X- _ O
two -X- _ O
( -X- _ O
openNMT -X- _ O
and -X- _ O
word2vec -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
latter -X- _ O
are -X- _ O
more -X- _ O
susceptible -X- _ O
to -X- _ O
changes -X- _ O
in -X- _ O
dependencies.21 -X- _ O

Measured -X- _ O
quantity -X- _ O
value -X- _ O
Object -X- _ O
Measurand -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Cooper -X- _ O
& -X- _ O
Shardlow -X- _ O
this -X- _ O
paper -X- _ O
Sample -X- _ O
mean -X- _ O
stdev -X- _ O
stdev -X- _ O
95 -X- _ O
% -X- _ O
CI -X- _ O
CV∗↓ -X- _ O
outputs -X- _ O
1 -X- _ O
outputs -X- _ O
1 -X- _ O
outputs -X- _ O
2 -X- _ O
outputs -X- _ O
1 -X- _ O
outputs -X- _ O
3 -X- _ O
size -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Precision -X- _ O
( -X- _ O
CV∗ -X- _ O
) -X- _ O
and -X- _ O
component -X- _ O
measures -X- _ O
( -X- _ O
mean -X- _ O
, -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
standard -X- _ O
deviation -X- _ O
confidence -X- _ O
intervals -X- _ O
) -X- _ O
for -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
obtained -X- _ O
in -X- _ O
multiple -X- _ O
measurements -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
NTS -X- _ O
systems -X- _ O
. -X- _ O

Outputs -X- _ O
1 -X- _ O
= -X- _ O
test -X- _ O
set -X- _ O
outputs -X- _ O
as -X- _ O
generated -X- _ O
by -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
outputs -X- _ O
2 -X- _ O
= -X- _ O
test -X- _ O
set -X- _ O
outputs -X- _ O
regenerated -X- _ O
by -X- _ O
Cooper -X- _ O
and -X- _ O
Shardlow -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
outputs -X- _ O
3 -X- _ O
= -X- _ O
test -X- _ O
set -X- _ O
outputs -X- _ O
regenerated -X- _ O
by -X- _ O
the -X- _ O
present -X- _ O
authors -X- _ O
. -X- _ O

s1 -X- _ O
= -X- _ O
SARI -X- _ O
script -X- _ O
( -X- _ O
always -X- _ O
the -X- _ O
same -X- _ O
) -X- _ O
; -X- _ O

b1 -X- _ O
= -X- _ O

Nisioi -X- _ O

et -X- _ O

al -X- _ O
. -X- _ O
’s -X- _ O
BLEU -X- _ O
script -X- _ O
, -X- _ O
run -X- _ O
by -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
; -X- _ O
b2 -X- _ O
= -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
’s -X- _ O
BLEU -X- _ O
script -X- _ O
, -X- _ O
run -X- _ O
by -X- _ O
Cooper -X- _ O
& -X- _ O
Shardlow -X- _ O
; -X- _ O
b3 -X- _ O
= -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
’s -X- _ O
BLEU -X- _ B-MetricName
script -X- _ O
with -X- _ O
different -X- _ O
version -X- _ O
of -X- _ O
NLTK -X- _ O
tokeniser -X- _ O
( -X- _ O
see -X- _ O
in -X- _ O
text -X- _ O
) -X- _ O
, -X- _ O
run -X- _ O
by -X- _ O
the -X- _ O
present -X- _ O
authors -X- _ O
; -X- _ O
b4 -X- _ O
= -X- _ O
SacreBLEU -X- _ B-MetricName
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
run -X- _ O
by -X- _ O
the -X- _ O
present -X- _ O
authors -X- _ O
. -X- _ O

Object -X- _ O
conditionsMeasurement -X- _ O
method -X- _ O
Measurement -X- _ O
procedure -X- _ O
Measured -X- _ O
Object -X- _ O
Measurand -X- _ O
conditions -X- _ O
conditions -X- _ O
quantity -X- _ O
CV∗ -X- _ O
Code -X- _ O
by -X- _ O
Comp. -X- _ O
/ -X- _ O
trained -X- _ O
by -X- _ O
Method -X- _ O
Implem -X- _ O
. -X- _ O

by -X- _ O
Procedure -X- _ O
Test -X- _ O
set -X- _ O
Performed -X- _ O
by -X- _ O
value -X- _ O
NTS_defBLEUNisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
84.51 -X- _ O
1.562Nisioi -X- _ O

et -X- _ O

al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

84.50 -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
≈Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
85.60 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
SacreBLEU -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
84.20 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

87.46 -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

≈Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
86.61 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
SacreBLEU -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
86.20 -X- _ O
SARINisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
30.65 -X- _ O
2.487Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

30.65 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
30.65 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

29.13 -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
29.96 -X- _ O
NTS -X- _ O
- -X- _ O
w2v_defBLEUNisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
87.50 -X- _ O
4.176Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
≈Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
89.36 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
SacreBLEU -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
88.10 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

80.75 -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

≈Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
89.64 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
bleu -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
SacreBLEU -X- _ O

OTE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
88.80 -X- _ O
SARINisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
31.11 -X- _ O
3.572Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
31.11 -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
Coop -X- _ O
. -X- _ O
& -X- _ O
Shard -X- _ O
. -X- _ O

30.28 -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
sari -X- _ O
( -X- _ O
o -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O

Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

OITE -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

this -X- _ O
paper -X- _ O
29.12 -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
Conditions -X- _ O
of -X- _ O
measurement -X- _ O
for -X- _ O
each -X- _ O
measurement -X- _ O
carried -X- _ O
out -X- _ O
for -X- _ O
the -X- _ O
NTS -X- _ O
systems -X- _ O
. -X- _ O

OTE -X- _ O
= -X- _ O
outputs -X- _ O
vs. -X- _ O
targets -X- _ O
evaluation -X- _ O
, -X- _ O
OITE -X- _ O
= -X- _ O
outputs -X- _ O
vs. -X- _ O
inputs -X- _ O
and -X- _ O
targets -X- _ O
evaluation -X- _ O
. -X- _ O

Shaded -X- _ O
cells -X- _ O
: -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
system -X- _ O
outputs -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
reproductions -X- _ O
did -X- _ O
not -X- _ O
regenerate -X- _ O
outputs -X- _ O
. -X- _ O

Bold -X- _ O
: -X- _ O
evaluation -X- _ O
of -X- _ O
( -X- _ O
potentially -X- _ O
) -X- _ O
different -X- _ O
system -X- _ O
outputs -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
reproductions -X- _ O
did -X- _ O
regenerate -X- _ O
outputs -X- _ O
. -X- _ O

4.2 -X- _ O
QRA -X- _ O
for -X- _ O
PASS -X- _ O
system -X- _ O
The -X- _ O
PASS -X- _ O
system -X- _ O
, -X- _ O
developed -X- _ O
by -X- _ O
van -X- _ O
der -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
generates -X- _ O
football -X- _ O
match -X- _ O
reports -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
competing -X- _ O
teams -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
study -X- _ O
evaluated -X- _ O
the -X- _ O
system -X- _ O
for -X- _ O
Clarity -X- _ O
, -X- _ O
Fluency -X- _ O
and -X- _ O
Stance -X- _ O
Identifiability -X- _ O
in -X- _ O
an -X- _ O
evaluation -X- _ O
with -X- _ O
20 -X- _ O
evaluators -X- _ O
and -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
10 -X- _ O
output -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
evaluation -X- _ O
was -X- _ O
repeated -X- _ O
with -X- _ O
a -X- _ O
slightly -X- _ O
different -X- _ O
evaluation -X- _ O
interface -X- _ O
and -X- _ O
a -X- _ O
different -X- _ O
cohort -X- _ O
of -X- _ O
evaluators -X- _ O
by -X- _ O
Mille -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
and -X- _ O
reproduction -X- _ O
evaluations -X- _ O
( -X- _ O
columns -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
Clarity -X- _ O
and -X- _ O
Fluency -X- _ O
results -X- _ O
are -X- _ O
the -X- _ O
mean -X- _ O
scores -X- _ O
from -X- _ O
7 -X- _ O
- -X- _ O
point -X- _ O
agreementscales -X- _ O
, -X- _ O
and -X- _ O
Identifiability -X- _ O
results -X- _ O
are -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
times -X- _ O
the -X- _ O
evaluators -X- _ O
correctly -X- _ O
guessed -X- _ O
the -X- _ O
team -X- _ O
whose -X- _ O
supporters -X- _ O
a -X- _ O
report -X- _ O
was -X- _ O
written -X- _ O
for -X- _ O
. -X- _ O

Columns -X- _ O
6–9 -X- _ O
show -X- _ O
the -X- _ O
corresponding -X- _ O
sample -X- _ O
size -X- _ O
( -X- _ O
number -X- _ O
of -X- _ O
reproductions -X- _ O
plus -X- _ O
original -X- _ O
study -X- _ O
) -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
standard -X- _ O
deviation -X- _ O
( -X- _ O
stdev -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
confidence -X- _ O
interval -X- _ O
( -X- _ O
CI -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
and -X- _ O
CV∗ -X- _ O
, -X- _ O
all -X- _ O
calculated -X- _ O
on -X- _ O
the -X- _ O
shifted -X- _ O
scores -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
values -X- _ O
( -X- _ O
here -X- _ O
, -X- _ O
paper -X- _ O
identifiers -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
nine -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
3.3 -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
six -X- _ O
individual -X- _ O
measurements -X- _ O
( -X- _ O
three -X- _ O
evaluation -X- _ O
measures -X- _ O
times -X- _ O
two -X- _ O
studies -X- _ O
) -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
both -X- _ O
object -X- _ O
conditions -X- _ O
and -X- _ O
the22 -X- _ O

test -X- _ O
set -X- _ O
condition -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
because -X- _ O
Mille -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
used -X- _ O
the -X- _ O
system -X- _ O
outputs -X- _ O
shared -X- _ O
by -X- _ O
van -X- _ O
der -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

The -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
Implemented -X- _ O
by -X- _ O
, -X- _ O
Procedure -X- _ O
and -X- _ O
Performed -X- _ O
by -X- _ O
conditions -X- _ O
reflect -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
evaluations -X- _ O
in -X- _ O
design -X- _ O
, -X- _ O
evaluator -X- _ O
cohorts -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
teams -X- _ O
that -X- _ O
performed -X- _ O
them -X- _ O
. -X- _ O

The -X- _ O
scores -X- _ O
vary -X- _ O
to -X- _ O
different -X- _ O
degrees -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
measurands -X- _ O
, -X- _ O
with -X- _ O
CV∗lowest -X- _ O
( -X- _ O
reproducibility -X- _ O
best -X- _ O
) -X- _ O
for -X- _ O
Stance -X- _ O
Identifiability -X- _ O
, -X- _ O
and -X- _ O
highest -X- _ O
( -X- _ O
worst -X- _ O
) -X- _ O
for -X- _ O
Fluency -X- _ O
. -X- _ O

These -X- _ O
CV∗results -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
reflect -X- _ O
that -X- _ O
evaluators -X- _ O
agreed -X- _ O
more -X- _ O
on -X- _ O
Clarity -X- _ O
than -X- _ O
Fluency -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
binary -X- _ O
stance -X- _ O
identification -X- _ O
assessment -X- _ O
has -X- _ O
better -X- _ O
reproducibility -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
criteria -X- _ O
which -X- _ O
are -X- _ O
assessed -X- _ O
on -X- _ O
7 -X- _ O
- -X- _ O
point -X- _ O
rating -X- _ O
scales -X- _ O
. -X- _ O

4.3 -X- _ O
QRA -X- _ B-MethodName
for -X- _ O
essay -X- _ O
scoring -X- _ O
system -X- _ O
variants -X- _ O
The -X- _ O
11 -X- _ O
multilingual -X- _ O
essay -X- _ O
scoring -X- _ O
system -X- _ O
variants -X- _ O
reported -X- _ O
by -X- _ O
Vajjala -X- _ O
and -X- _ O
Rama -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
were -X- _ O
evaluated -X- _ O
by -X- _ O
weighted -X- _ O
F1 -X- _ B-MetricName
( -X- _ O
wF1 -X- _ B-MetricName
) -X- _ O
score -X- _ O
. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
wF1 -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
11 -X- _ O
multilingual -X- _ O
system -X- _ O
variants -X- _ O
from -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
five -X- _ O
papers -X- _ O
, -X- _ O
alongside -X- _ O
the -X- _ O
11 -X- _ O
corresponding -X- _ O
CV∗values -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
shows -X- _ O
the -X- _ O
corresponding -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
. -X- _ O

The -X- _ O
baseline -X- _ O
classifier -X- _ O
( -X- _ O
mult -X- _ O
- -X- _ O
base -X- _ O
) -X- _ O
uses -X- _ O
document -X- _ O
length -X- _ O
( -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
) -X- _ O
as -X- _ O
its -X- _ O
only -X- _ O
feature -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
other -X- _ O
variants -X- _ O
, -X- _ O
+ -X- _ O
/ -X- _ O
- -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
multilingual -X- _ O
classifier -X- _ O
was -X- _ O
/ -X- _ O
was -X- _ O
not -X- _ O
given -X- _ O
information -X- _ O
about -X- _ O
which -X- _ O
language -X- _ O
the -X- _ O
input -X- _ O
was -X- _ O
in -X- _ O
; -X- _ O
the -X- _ O
multword -X- _ O
variants -X- _ O
use -X- _ O
word -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
only -X- _ O
; -X- _ O
mult -X- _ O
- -X- _ O
word -X- _ O
uses -X- _ O
POS -X- _ O
( -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
) -X- _ O
tag -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
only -X- _ O
; -X- _ O
multdep -X- _ O
uses -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
over -X- _ O
dependency -X- _ O
relation -X- _ O
, -X- _ O
dependent -X- _ O
POS -X- _ O
, -X- _ O
and -X- _ O
head -X- _ O
POS -X- _ O
triples -X- _ O
; -X- _ O
mult -X- _ O
- -X- _ O
dom -X- _ O
uses -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
linguistic -X- _ O
features -X- _ O
including -X- _ O
document -X- _ O
length -X- _ O
, -X- _ O
lexical -X- _ O
richness -X- _ O
and -X- _ O
errors -X- _ O
; -X- _ O
mult -X- _ O
- -X- _ O
emb -X- _ O
uses -X- _ O
word -X- _ O
and -X- _ O
character -X- _ O
embeddings -X- _ O
. -X- _ O

The -X- _ O
multbase -X- _ O
and -X- _ O
mult -X- _ O
- -X- _ O
dom -X- _ O
models -X- _ O
are -X- _ O
logistic -X- _ O
regressors -X- _ O
, -X- _ O
the -X- _ O
others -X- _ O
are -X- _ O
random -X- _ O
forests -X- _ O
. -X- _ O

A -X- _ O
very -X- _ O
clear -X- _ O
picture -X- _ O
emerges -X- _ O
: -X- _ O
system -X- _ O
variant -X- _ O
pairs -X- _ O
that -X- _ O
differ -X- _ O
only -X- _ O
in -X- _ O
whether -X- _ O
they -X- _ O
do -X- _ O
or -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
language -X- _ O
information -X- _ O
have -X- _ O
very -X- _ O
similar -X- _ O
CV -X- _ O
scores -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
mult -X- _ O
- -X- _ O
POS− -X- _ O
( -X- _ O
POS -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
without -X- _ O
language -X- _ O
information -X- _ O
) -X- _ O
and -X- _ O
mult -X- _ O
- -X- _ O
POS+ -X- _ O
( -X- _ O
POS -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
with -X- _ O
language -X- _ O
information -X- _ O
) -X- _ O
both -X- _ O
have -X- _ O
a -X- _ O
very -X- _ O
good -X- _ O
degree -X- _ O
of -X- _ O
wF1 -X- _ B-MetricName
- -X- _ O
reproducibility -X- _ B-MetricName
, -X- _ O
their -X- _ O
CV∗being -X- _ B-MetricName
3.818 -X- _ B-MetricValue
and -X- _ O
3.808 -X- _ B-MetricValue
respectively -X- _ O
; -X- _ O
multword− -X- _ O
( -X- _ O
word -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
without -X- _ O
language -X- _ O
information -X- _ O
) -X- _ O
and -X- _ O
mult -X- _ O
- -X- _ O
word+ -X- _ O
( -X- _ O
word -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
with -X- _ O
language -X- _ O
information -X- _ O
) -X- _ O
have -X- _ O
notably -X- _ O
higher -X- _ O
CV∗ -X- _ B-MetricName
, -X- _ O
around -X- _ O
10 -X- _ O
. -X- _ O

This -X- _ O
tendency -X- _ O
holds -X- _ O
for -X- _ O
all -X- _ O
such -X- _ O
pairs -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
using -X- _ O
language -X- _ O
information -X- _ O
makes -X- _ O
next -X- _ O
to -X- _ O
no -X- _ O
difference -X- _ O
to -X- _ O
reproducibility -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
mult -X- _ O
- -X- _ O
dom -X- _ O
and -X- _ O
mult -X- _ O
- -X- _ O
emb -X- _ O
variants -X- _ O
all -X- _ O
have -X- _ O
similar -X- _ O
CV∗.9 -X- _ O

The -X- _ O
indication -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
syntactic -X- _ O
information -X- _ O
is -X- _ O
obtained -X- _ O
/ -X- _ O
used -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
particularly -X- _ O
reproducible -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
and -X- _ O
the -X- _ O
embeddings -X- _ O
are -X- _ O
obtained -X- _ O
/ -X- _ O
used -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
particularly -X- _ O
hard -X- _ O
to -X- _ O
reproduce -X- _ O
. -X- _ O

Overall -X- _ O
, -X- _ O
the -X- _ O
random -X- _ O
forest -X- _ O
models -X- _ O
using -X- _ O
syntactic -X- _ O
features -X- _ O
have -X- _ O
the -X- _ O
best -X- _ O
reproducibility -X- _ O
; -X- _ O
the -X- _ O
logistic -X- _ O
regressors -X- _ O
using -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
features -X- _ O
have -X- _ O
the -X- _ O
worst -X- _ O
. -X- _ O

5 -X- _ O
Discussion -X- _ O
Quantified -X- _ B-MethodName
reproducibility -X- _ I-MethodName
assessment -X- _ I-MethodName
( -X- _ O
QRA -X- _ B-MethodName
) -X- _ O
enables -X- _ O
assessment -X- _ O
of -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
of -X- _ O
evaluation -X- _ O
results -X- _ O
for -X- _ O
any -X- _ O
given -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
scale -X- _ O
- -X- _ O
invariant10 -X- _ O
and -X- _ O
comparable -X- _ O
across -X- _ O
different -X- _ O
QRAs -X- _ B-MethodName
, -X- _ O
for -X- _ O
reproductions -X- _ O
involving -X- _ O
either -X- _ O
the -X- _ O
same -X- _ O
or -X- _ O
different -X- _ O
original -X- _ O
studies -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
formally -X- _ O
capturing -X- _ O
( -X- _ O
dis -X- _ O
) -X- _ O
similarities -X- _ O
between -X- _ O
systems -X- _ O
and -X- _ O
evaluation -X- _ O
designs -X- _ O
enables -X- _ O
reproducibility -X- _ O
to -X- _ O
be -X- _ O
assessed -X- _ O
relative -X- _ O
to -X- _ O
such -X- _ O
( -X- _ O
dis -X- _ O
) -X- _ O
similarities -X- _ O
. -X- _ O

In -X- _ O
combination -X- _ O
, -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
results -X- _ O
from -X- _ O
QRA -X- _ B-MethodName
tests -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
can -X- _ O
provide -X- _ O
pointers -X- _ O
to -X- _ O
which -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
might -X- _ O
be -X- _ O
associated -X- _ O
with -X- _ O
low -X- _ O
reproducibility -X- _ O
. -X- _ O

E.g. -X- _ O
for -X- _ O
the -X- _ O
wF1 -X- _ B-MethodName
evaluations -X- _ O
of -X- _ O
the -X- _ O
essay -X- _ O
scoring -X- _ O
systems -X- _ O
above -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
clear -X- _ O
that -X- _ O
variations -X- _ O
in -X- _ O
reproducibility -X- _ O
are -X- _ O
associated -X- _ O
at -X- _ O
least -X- _ O
in -X- _ O
part -X- _ O
with -X- _ O
the -X- _ O
different -X- _ O
features -X- _ O
used -X- _ O
by -X- _ O
systems -X- _ O
. -X- _ O

It -X- _ O
might -X- _ O
be -X- _ O
expected -X- _ O
that -X- _ O
the -X- _ O
reproducibility -X- _ O
of -X- _ O
human -X- _ O
- -X- _ O
assessed -X- _ O
evaluations -X- _ O
is -X- _ O
generally -X- _ O
worse -X- _ O
than -X- _ O
metric -X- _ O
- -X- _ O
assessed -X- _ O
. -X- _ O

Our -X- _ O
study -X- _ O
revealed -X- _ O
a -X- _ O
more -X- _ O
mixed -X- _ O
picture -X- _ O
. -X- _ O

As -X- _ O
expected -X- _ O
, -X- _ O
the -X- _ O
Fluency -X- _ O
and -X- _ O
Clarity -X- _ O
evaluations -X- _ O
of -X- _ O
the -X- _ O
PASS -X- _ O
system -X- _ O
were -X- _ O
among -X- _ O
those -X- _ O
with -X- _ O
highest -X- _ O
CV∗ -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
SARI -X- _ B-MetricName
evaluation -X- _ O
of -X- _ O
the -X- _ O
NTS -X- _ O
systems -X- _ O
and -X- _ O
wF1 -X- _ B-MetricName
evaluation -X- _ O
of -X- _ O
the -X- _ O
mult -X- _ O
- -X- _ O
POS -X- _ O
and -X- _ O
mult -X- _ O
- -X- _ O
dep -X- _ O
systems -X- _ O
were -X- _ O
among -X- _ O
those -X- _ O
with -X- _ O
lowest -X- _ O
CV∗ -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
human -X- _ O
- -X- _ O
assessed -X- _ O
Stance -X- _ O
Identifiability -X- _ O
of -X- _ O
PASS -X- _ O
was -X- _ O
among -X- _ O
the -X- _ O
most -X- _ O
reproducible -X- _ O
, -X- _ O
and -X- _ O
metric -X- _ O
- -X- _ O
assessed -X- _ O
wF1 -X- _ B-MetricName
of -X- _ O
mult -X- _ O
- -X- _ O
base -X- _ O
, -X- _ O
mult -X- _ O
- -X- _ O
dom -X- _ O
and -X- _ O
mult -X- _ O
- -X- _ O
emb -X- _ O
were -X- _ O
among -X- _ O
the -X- _ O
worst -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
our -X- _ O
focus -X- _ O
has -X- _ O
been -X- _ O
QRA -X- _ B-MethodName
testing -X- _ O
of -X- _ O
existing -X- _ O
research -X- _ O
results -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
ideally -X- _ O
, -X- _ O
QRA -X- _ B-MethodName
would -X- _ O
be -X- _ O
built -X- _ O
into -X- _ O
new -X- _ O
method -X- _ O
development -X- _ O
from -X- _ O
the -X- _ O
outset -X- _ O
, -X- _ O
where -X- _ O
at -X- _ O
first -X- _ O
reporting -X- _ O
, -X- _ O
a -X- _ O
detailed -X- _ O
stanissue -X- _ O
wiith -X- _ O
the -X- _ O
evaluation -X- _ O
code -X- _ O
( -X- _ O
macro -X- _ O
- -X- _ O
F1 -X- _ O
instead -X- _ O
of -X- _ O
weightedF1 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
reported -X- _ O
by -X- _ O
Bestgen -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
first -X- _ O
paragraph -X- _ O
) -X- _ O
, -X- _ O
Caines -X- _ O
and -X- _ O
Buttery -X- _ O
( -X- _ O
Section -X- _ O
2.5 -X- _ O
, -X- _ O
one -X- _ O
before -X- _ O
last -X- _ O
paragraph -X- _ O
) -X- _ O
and -X- _ O
Huber -X- _ O
and -X- _ O
Çöltekin -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
second -X- _ O
paragraph -X- _ O
) -X- _ O
. -X- _ O

10If -X- _ O
evaluation -X- _ O
scores -X- _ O
are -X- _ O
multiplied -X- _ O
by -X- _ O
a -X- _ O
common -X- _ O
factor -X- _ O
, -X- _ O
CV∗does -X- _ O
not -X- _ O
change.23 -X- _ O

Measured -X- _ O
quantity -X- _ O
value -X- _ O
Vajjala -X- _ O
Huber -X- _ O
& -X- _ O
Arhiliuc -X- _ O
Object -X- _ O
Meas- -X- _ O
& -X- _ O
Rama -X- _ O
Coltekin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Bestgen -X- _ O
Caines -X- _ O
& -X- _ O
Buttery -X- _ O
Sample -X- _ O
mean -X- _ O
stdev -X- _ O
stdev -X- _ O
95 -X- _ O
% -X- _ O
CI -X- _ O
CV∗↓ -X- _ O
urand -X- _ O
seed -X- _ O
1 -X- _ O
seed -X- _ O
2 -X- _ O
seed -X- _ O
? -X- _ O

seed -X- _ O
1 -X- _ O
seed -X- _ O
2 -X- _ O
seed -X- _ O
1 -X- _ O
seed -X- _ O
? -X- _ O

size -X- _ O
Table -X- _ O
6 -X- _ O
: -X- _ O
Precision -X- _ B-MetricName
( -X- _ O
CV∗ -X- _ O
) -X- _ O
and -X- _ O
component -X- _ O
measures -X- _ O
( -X- _ O
mean -X- _ B-MetricName
, -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
, -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
confidence -X- _ O
intervals -X- _ O
) -X- _ O
for -X- _ O
measured -X- _ O
quantity -X- _ O
values -X- _ O
obtained -X- _ O
in -X- _ O
multiple -X- _ O
measurements -X- _ O
of -X- _ O
the -X- _ O
essay -X- _ O
scoring -X- _ O
systems -X- _ O
. -X- _ O

Seed -X- _ O
i= -X- _ O
different -X- _ O
approaches -X- _ O
to -X- _ O
random -X- _ O
seeding -X- _ O
and -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
; -X- _ O
e -X- _ O
i= -X- _ O
different -X- _ O
compile -X- _ O
/ -X- _ O
run -X- _ O
- -X- _ O
time -X- _ O
environments -X- _ O
; -X- _ O
i -X- _ O
i= -X- _ O
different -X- _ O
test -X- _ O
data -X- _ O
sets -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
folds -X- _ O
. -X- _ O

dardised -X- _ O
set -X- _ O
of -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
is -X- _ O
specified -X- _ O
, -X- _ O
and -X- _ O
repeatability -X- _ O
tests -X- _ O
( -X- _ O
where -X- _ O
all -X- _ O
conditions -X- _ O
are -X- _ O
identical -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
team -X- _ O
conducting -X- _ O
the -X- _ O
tests -X- _ O
, -X- _ O
see -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
are -X- _ O
performed -X- _ O
to -X- _ O
determine -X- _ O
baseline -X- _ O
reproducibility -X- _ O
. -X- _ O

Such -X- _ O
repeatability -X- _ O
QRA -X- _ O
would -X- _ O
provide -X- _ O
quality -X- _ O
assurance -X- _ O
for -X- _ O
new -X- _ O
methods -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
important -X- _ O
pointers -X- _ O
for -X- _ O
future -X- _ O
reproductions -X- _ O
regarding -X- _ O
what -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
to -X- _ O
expect -X- _ O
for -X- _ O
given -X- _ O
( -X- _ O
types -X- _ O
of -X- _ O
) -X- _ O
methods -X- _ O
. -X- _ O

If -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
, -X- _ O
post -X- _ O
- -X- _ O
hoc -X- _ O
reproducibility -X- _ O
QRA -X- _ O
( -X- _ O
where -X- _ O
there -X- _ O
are -X- _ O
differences -X- _ O
in -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
values -X- _ O
) -X- _ O
is -X- _ O
performed -X- _ O
instead -X- _ O
. -X- _ O

If -X- _ O
this -X- _ O
yields -X- _ O
high -X- _ O
( -X- _ O
poor -X- _ O
) -X- _ O
CV∗ -X- _ B-MetricName
, -X- _ O
one -X- _ O
way -X- _ O
to -X- _ O
proceed -X- _ O
is -X- _ O
to -X- _ O
minimise -X- _ O
differences -X- _ O
in -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
between -X- _ O
the -X- _ O
studies -X- _ O
and -X- _ O
observe -X- _ O
the -X- _ O
effect -X- _ O
on -X- _ O
CV∗ -X- _ B-MetricName
, -X- _ O
changing -X- _ O
aspects -X- _ O
of -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
design -X- _ O
and -X- _ O
adding -X- _ O
further -X- _ O
conditions -X- _ O
of -X- _ O
measurement -X- _ O
if -X- _ O
need -X- _ O
be -X- _ O
. -X- _ O

For -X- _ O
human -X- _ O
evaluation -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
persistently -X- _ O
high -X- _ O
CV∗would -X- _ B-MetricName
indicate -X- _ O
a -X- _ O
problem -X- _ O
with -X- _ O
the -X- _ O
method -X- _ O
itself -X- _ O
. -X- _ O

6 -X- _ O
Conclusion -X- _ O
We -X- _ O
have -X- _ O
described -X- _ O
an -X- _ O
approach -X- _ O
to -X- _ O
quantified -X- _ O
reproducibility -X- _ O
assessment -X- _ O
( -X- _ O
QRA -X- _ B-MethodName
) -X- _ O
based -X- _ O
on -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
from -X- _ O
metrology -X- _ O
, -X- _ O
and -X- _ O
tested -X- _ O
it -X- _ O
on -X- _ O
18 -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
combinations -X- _ O
involving -X- _ O
diverse -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
types -X- _ O
of -X- _ O
evaluation -X- _ O
. -X- _ O

QRA -X- _ B-MethodName
produces -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
that -X- _ O
quantifies -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
scores -X- _ O
from -X- _ O
, -X- _ O
and -X- _ O
differences -X- _ O
between -X- _ O
, -X- _ O
multiple -X- _ O
reproductions -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
original -X- _ O
study -X- _ O
. -X- _ O

We -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
approach -X- _ O
facilitates -X- _ O
insights -X- _ O
into -X- _ O
sources -X- _ O
of -X- _ O
variationbetween -X- _ O
reproductions -X- _ O
, -X- _ O
produces -X- _ O
results -X- _ O
that -X- _ O
are -X- _ O
comparable -X- _ O
across -X- _ O
different -X- _ O
reproducibility -X- _ O
assessments -X- _ O
, -X- _ O
and -X- _ O
provides -X- _ O
pointers -X- _ O
about -X- _ O
what -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
changed -X- _ O
in -X- _ O
system -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
evaluation -X- _ O
design -X- _ O
to -X- _ O
improve -X- _ O
reproducibility -X- _ O
. -X- _ O

A -X- _ O
recent -X- _ O
survey -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
found -X- _ O
that -X- _ O
just -X- _ O
14 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
513 -X- _ O
original -X- _ O
/ -X- _ O
reproduction -X- _ O
score -X- _ O
pairs -X- _ O
analysed -X- _ O
were -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O

Judging -X- _ O
the -X- _ O
remainder -X- _ O
simply -X- _ O
‘ -X- _ O
not -X- _ O
reproduced -X- _ O
’ -X- _ O
is -X- _ O
of -X- _ O
limited -X- _ O
usefulness -X- _ O
, -X- _ O
as -X- _ O
some -X- _ O
are -X- _ O
much -X- _ O
closer -X- _ O
to -X- _ O
being -X- _ O
the -X- _ O
same -X- _ O
than -X- _ O
others -X- _ O
. -X- _ O

At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
assessments -X- _ O
of -X- _ O
whether -X- _ O
the -X- _ O
same -X- _ O
conclusions -X- _ O
can -X- _ O
be -X- _ O
drawn -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
different -X- _ O
scores -X- _ O
involve -X- _ O
subjective -X- _ O
judgments -X- _ O
and -X- _ O
are -X- _ O
prone -X- _ O
to -X- _ O
disagreement -X- _ O
among -X- _ O
assessors -X- _ O
. -X- _ O

Quantifying -X- _ O
the -X- _ O
closeness -X- _ O
of -X- _ O
results -X- _ O
as -X- _ O
in -X- _ O
QRA -X- _ B-MethodName
, -X- _ O
and -X- _ O
, -X- _ O
over -X- _ O
time -X- _ O
, -X- _ O
establishing -X- _ O
expected -X- _ O
levels -X- _ O
of -X- _ O
closeness -X- _ O
, -X- _ O
seems -X- _ O
a -X- _ O
better -X- _ O
way -X- _ O
forward -X- _ O
. -X- _ O

Acknowledgements -X- _ O
We -X- _ O
are -X- _ O
grateful -X- _ O
to -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
and -X- _ O
area -X- _ O
chairs -X- _ O
for -X- _ O
their -X- _ O
exceptionally -X- _ O
detailed -X- _ O
and -X- _ O
helpful -X- _ O
feedback -X- _ O
. -X- _ O

Popovi -X- _ O
´ -X- _ O
c -X- _ O
’s -X- _ O
work -X- _ O
on -X- _ O
this -X- _ O
s -X- _ O
study -X- _ O
was -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
ADAPT -X- _ O
SFI -X- _ O
Centre -X- _ O
for -X- _ O
Digital -X- _ O
Media -X- _ O
Technology -X- _ O
which -X- _ O
is -X- _ O
funded -X- _ O
by -X- _ O
Science -X- _ O
Foundation -X- _ O
Ireland -X- _ O
through -X- _ O
the -X- _ O
SFI -X- _ O
Research -X- _ O
Centres -X- _ O
Programme -X- _ O
, -X- _ O
and -X- _ O
co -X- _ O
- -X- _ O
funded -X- _ O
under -X- _ O
the -X- _ O
European -X- _ O
Regional -X- _ O
Development -X- _ O
Fund -X- _ O
( -X- _ O
ERDF -X- _ O
) -X- _ O
through -X- _ O
Grant -X- _ O
13 -X- _ O
/ -X- _ O
RC -X- _ O
/ -X- _ O
2106 -X- _ O
. -X- _ O

Mille -X- _ O
’s -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
European -X- _ O
Commission -X- _ O
under -X- _ O
the -X- _ O
H2020 -X- _ O
program -X- _ O
contract -X- _ O
num- -X- _ O

References -X- _ O
SE -X- _ O
Ahmed -X- _ O
. -X- _ O

1995 -X- _ O
. -X- _ O

A -X- _ O
pooling -X- _ O
methodology -X- _ O
for -X- _ O
coefficient -X- _ O
of -X- _ O
variation -X- _ O
. -X- _ O

Sankhy -X- _ O
¯a -X- _ O
: -X- _ O
The -X- _ O
Indian -X- _ O
Journal -X- _ O
of -X- _ O
Statistics -X- _ O
, -X- _ O
Series -X- _ O
B -X- _ O
, -X- _ O
pages -X- _ O
57–75 -X- _ O
. -X- _ O

Cristina -X- _ O
Arhiliuc -X- _ O
, -X- _ O
Jelena -X- _ O
Mitrovi -X- _ O
´ -X- _ O
c -X- _ O
, -X- _ O
and -X- _ O
Michael -X- _ O
Granitzer -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Language -X- _ O
proficiency -X- _ O
scoring -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
The -X- _ O
12th -X- _ O
Language -X- _ O
Resources -X- _ O
and -X- _ O
Evaluation -X- _ O
Conference -X- _ O
, -X- _ O
pages -X- _ O
5624–5630 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resources -X- _ O
Association -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computing -X- _ O
Machinery -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

Artifact -X- _ O
review -X- _ O
and -X- _ O
badging -X- _ O
Version -X- _ O
1.1 -X- _ O
. -X- _ O

Accessed -X- _ O
August -X- _ O
Anya -X- _ O
Belz -X- _ O
, -X- _ O
Shubham -X- _ O
Agarwal -X- _ O
, -X- _ O
Anastasia -X- _ O
Shimorina -X- _ O
, -X- _ O
and -X- _ O
Ehud -X- _ O
Reiter -X- _ O
. -X- _ O
2021a -X- _ O
. -X- _ O

A -X- _ O
systematic -X- _ O
review -X- _ O
of -X- _ O
reproducibility -X- _ O
research -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
16th -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
European -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Main -X- _ O
Volume -X- _ O
, -X- _ O
pages -X- _ O
381–393 -X- _ O
. -X- _ O

Anya -X- _ O
Belz -X- _ O
, -X- _ O
Anastasia -X- _ O
Shimorina -X- _ O
, -X- _ O
Shubham -X- _ O
Agarwal -X- _ O
, -X- _ O
and -X- _ O
Ehud -X- _ O
Reiter -X- _ O
. -X- _ O

2021b -X- _ O
. -X- _ O

The -X- _ O
reprogen -X- _ O
shared -X- _ O
task -X- _ O
on -X- _ O
reproducibility -X- _ O
of -X- _ O
human -X- _ O
evaluations -X- _ O
in -X- _ O
NLG -X- _ O
: -X- _ O
Overview -X- _ O
and -X- _ O
results -X- _ O
. -X- _ O

In -X- _ O
The -X- _ O
14th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Generation -X- _ O
. -X- _ O

Yves -X- _ O
Bestgen -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Reproducing -X- _ O
monolingual -X- _ O
, -X- _ O
multilingual -X- _ O
and -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
CEFR -X- _ O
predictions -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
The -X- _ O
12th -X- _ O
Language -X- _ O
Resources -X- _ O
and -X- _ O
Evaluation -X- _ O
Conference -X- _ O
, -X- _ O
pages -X- _ O
5595–5602 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resources -X- _ O
Association -X- _ O
. -X- _ O

António -X- _ O
Branco -X- _ O
, -X- _ O
Nicoletta -X- _ O
Calzolari -X- _ O
, -X- _ O
Piek -X- _ O
V -X- _ O
ossen -X- _ O
, -X- _ O
Gertjan -X- _ O
Van -X- _ O
Noord -X- _ O
, -X- _ O
Dieter -X- _ O
van -X- _ O
Uytvanck -X- _ O
, -X- _ O
João -X- _ O
Silva -X- _ O
, -X- _ O
Luís -X- _ O
Gomes -X- _ O
, -X- _ O
André -X- _ O
Moreira -X- _ O
, -X- _ O
and -X- _ O
Willem -X- _ O
Elbers -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

A -X- _ O
shared -X- _ O
task -X- _ O
of -X- _ O
a -X- _ O
new -X- _ O
, -X- _ O
collaborative -X- _ O
type -X- _ O
to -X- _ O
foster -X- _ O
reproducibility -X- _ O
: -X- _ O

A -X- _ O
first -X- _ O
exercise -X- _ O
in -X- _ O
the -X- _ O
area -X- _ O
of -X- _ O
language -X- _ O
science -X- _ O
and -X- _ O
technology -X- _ O
with -X- _ O
REPROLANG2020 -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
The -X- _ O
12th -X- _ O
Language -X- _ O
Resources -X- _ O
and -X- _ O
Evaluation -X- _ O
Conference -X- _ O
, -X- _ O
pages -X- _ O
5539–5545 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resources -X- _ O
Association -X- _ O
. -X- _ O

Andrew -X- _ O
Caines -X- _ O
and -X- _ O
Paula -X- _ O
Buttery -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

REPROLANG -X- _ O
2020 -X- _ O
: -X- _ O

Automatic -X- _ O
proficiency -X- _ O
scoring -X- _ O
of -X- _ O
Czech -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
Italian -X- _ O
, -X- _ O
and -X- _ O
Spanish -X- _ O
learner -X- _ O
essays -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
The -X- _ O
12th -X- _ O
Language -X- _ O
Resources -X- _ O
and -X- _ O
Evaluation -X- _ O
Conference -X- _ O
, -X- _ O
pages -X- _ O
5614–5623 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resources -X- _ O
Association -X- _ O
. -X- _ O

Michael -X- _ O
Cooper -X- _ O
and -X- _ O
Matthew -X- _ O
Shardlow -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

CombiNMT -X- _ O
: -X- _ O

An -X- _ O
exploration -X- _ O
into -X- _ O
neural -X- _ O
text -X- _ O
simplification -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
The -X- _ O
12th -X- _ O
Language -X- _ O
Resources -X- _ O
and -X- _ O
Evaluation -X- _ O
Conference -X- _ O
, -X- _ O
pages -X- _ O
5588 -X- _ O
– -X- _ O
5594 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resources -X- _ O
Association -X- _ O
. -X- _ O

Chris -X- _ O
Drummond -X- _ O
. -X- _ O
2009 -X- _ O
. -X- _ O

Replicability -X- _ O
is -X- _ O
not -X- _ O
reproducibility -X- _ O
: -X- _ O
nor -X- _ O
is -X- _ O
it -X- _ O
good -X- _ O
science -X- _ O
. -X- _ O

Presented -X- _ O
at -X- _ O
4th -X- _ O
Workshop -X- _ O
on -X- _ O
Evaluation -X- _ O
Methods -X- _ O
for -X- _ O
Machine -X- _ O
Learning -X- _ O
held -X- _ O
at -X- _ O
ICML’09.Eva -X- _ O
Huber -X- _ O
and -X- _ O
Ça -X- _ O
˘grı -X- _ O
Çöltekin -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Reproduction -X- _ O
and -X- _ O
replication -X- _ O
: -X- _ O

A -X- _ O
case -X- _ O
study -X- _ O
with -X- _ O
automatic -X- _ O
essay -X- _ O
scoring -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
The -X- _ O
12th -X- _ O
Language -X- _ O
Resources -X- _ O
and -X- _ O
Evaluation -X- _ O
Conference -X- _ O
, -X- _ O
pages -X- _ O
5603–5613 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resources -X- _ O
Association -X- _ O
. -X- _ O

JCGM -X- _ O
. -X- _ O

2012 -X- _ O
. -X- _ O

International -X- _ O
vocabulary -X- _ O
of -X- _ O
metrology -X- _ O
: -X- _ O
Basic -X- _ O
and -X- _ O
general -X- _ O
concepts -X- _ O
and -X- _ O
associated -X- _ O
terms -X- _ O
( -X- _ O
VIM -X- _ O
) -X- _ O
. -X- _ O

Joint -X- _ O
Committee -X- _ O
for -X- _ O
Guides -X- _ O
in -X- _ O
Metrology -X- _ O
, -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.bipm.org -X- _ O
/ -X- _ O
utils -X- _ O
/ -X- _ O
common -X- _ O
/ -X- _ O
documents -X- _ O
/ -X- _ O
jcgm -X- _ O
/ -X- _ O
JCGM_200_2012.pdf -X- _ O
. -X- _ O

Simon -X- _ O
Mille -X- _ O
, -X- _ O
Thiago -X- _ O
Castro -X- _ O
Ferreira -X- _ O
, -X- _ O
Anya -X- _ O
Belz -X- _ O
, -X- _ O
and -X- _ O
Brian -X- _ O
Davis -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Another -X- _ O
PASS -X- _ O
: -X- _ O
A -X- _ O
reproduction -X- _ O
study -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
of -X- _ O
a -X- _ O
football -X- _ O
report -X- _ O
generation -X- _ O
system -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
14th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
GeneraSergiu -X- _ O
Nisioi -X- _ O
, -X- _ O
Sanja -X- _ O
Štajner -X- _ O
, -X- _ O
Simone -X- _ O
Paolo -X- _ O
Ponzetto -X- _ O
, -X- _ O
and -X- _ O
Liviu -X- _ O
P. -X- _ O
Dinu -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Exploring -X- _ O
neural -X- _ O
text -X- _ O
simplification -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
55th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
Volume -X- _ O
2 -X- _ O
: -X- _ O
Short -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
85–91 -X- _ O
, -X- _ O
Vancouver -X- _ O
, -X- _ O
Canada -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Ted -X- _ O
Pedersen -X- _ O
. -X- _ O
2008 -X- _ O
. -X- _ O

Empiricism -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
matter -X- _ O
of -X- _ O
faith -X- _ O
. -X- _ O

Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
34 -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
:465–470 -X- _ O
. -X- _ O

Joelle -X- _ O
Pineau -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

The -X- _ O
machine -X- _ O
learning -X- _ O
reproducibility -X- _ O
checklist -X- _ O
v2.0 -X- _ O
. -X- _ O

Maja -X- _ O
Popovi -X- _ O
´ -X- _ O
c -X- _ O
and -X- _ O
Anya -X- _ O
Belz -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

A -X- _ O
reproduction -X- _ O
study -X- _ O
of -X- _ O
an -X- _ O
annotation -X- _ O
- -X- _ O
based -X- _ O
human -X- _ O
evaluation -X- _ O
of -X- _ O
MT -X- _ O
outputs -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
14th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Generation -X- _ O
, -X- _ O
pages -X- _ O
293–300 -X- _ O
, -X- _ O
Aberdeen -X- _ O
, -X- _ O
Scotland -X- _ O
, -X- _ O
UK -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Matt -X- _ O
Post -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

A -X- _ O
call -X- _ O
for -X- _ O
clarity -X- _ O
in -X- _ O
reporting -X- _ O
bleu -X- _ O
Calyampudi -X- _ O
Radhakrishna -X- _ O
Rao -X- _ O
. -X- _ O
1973 -X- _ O
. -X- _ O

Linear -X- _ O
statistical -X- _ O
inference -X- _ O
and -X- _ O
its -X- _ O
applications -X- _ O
. -X- _ O

Wiley -X- _ O
. -X- _ O

Nicolas -X- _ O
P. -X- _ O
Rougier -X- _ O
, -X- _ O
Konrad -X- _ O
Hinsen -X- _ O
, -X- _ O
Frédéric -X- _ O
Alexandre -X- _ O
, -X- _ O
Thomas -X- _ O
Arildsen -X- _ O
, -X- _ O
Lorena -X- _ O
A -X- _ O
Barba -X- _ O
, -X- _ O
Fabien -X- _ O
CY -X- _ O
Benureau -X- _ O
, -X- _ O
C -X- _ O
Titus -X- _ O
Brown -X- _ O
, -X- _ O
Pierre -X- _ O
De -X- _ O
Buyl -X- _ O
, -X- _ O
Ozan -X- _ O
Caglayan -X- _ O
, -X- _ O
Andrew -X- _ O
P -X- _ O
Davison -X- _ O
, -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Sustainable -X- _ O
computational -X- _ O
science -X- _ O
: -X- _ O
The -X- _ O
ReScience -X- _ O
initiative -X- _ O
. -X- _ O

PeerJ -X- _ O
Computer -X- _ O
Science -X- _ O
, -X- _ O
3 -X- _ O
: -X- _ O
e142 -X- _ O
. -X- _ O

Patrick -X- _ O
D. -X- _ O
Schloss -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

Identifying -X- _ O
and -X- _ O
overcoming -X- _ O
threats -X- _ O
to -X- _ O
reproducibility -X- _ O
, -X- _ O
replicability -X- _ O
, -X- _ O
robustness -X- _ O
, -X- _ O
and -X- _ O
generalizability -X- _ O
in -X- _ O
microbiome -X- _ O
research -X- _ O
. -X- _ O

MBio -X- _ O
, -X- _ O
Anastasia -X- _ O
Shimorina -X- _ O
and -X- _ O
Anya -X- _ O
Belz -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

The -X- _ O
human -X- _ O
evaluation -X- _ O
datasheet -X- _ O
1.0 -X- _ O
: -X- _ O
A -X- _ O
template -X- _ O
for -X- _ O
recording -X- _ O
details -X- _ O
of -X- _ O
human -X- _ O
evaluation -X- _ O
experiments -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

arXiv -X- _ O
preprint -X- _ O
arXiv:3910940 -X- _ O
. -X- _ O

R.R. -X- _ O
Sokal -X- _ O
and -X- _ O
F.J. -X- _ O
Rohlf -X- _ O
. -X- _ O
1971 -X- _ O
. -X- _ O

Biometry -X- _ O
: -X- _ O

The -X- _ O
Principles -X- _ O
and -X- _ O
Practice -X- _ O
of -X- _ O
Statistics -X- _ O
in -X- _ O
Biological -X- _ O
Research -X- _ O
. -X- _ O

WH -X- _ O
Freeman.25 -X- _ O

Sowmya -X- _ O
Vajjala -X- _ O
and -X- _ O
Taraka -X- _ O
Rama -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

Experiments -X- _ O
with -X- _ O
universal -X- _ O
CEFR -X- _ O
classification -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Thirteenth -X- _ O
Workshop -X- _ O
on -X- _ O
Innovative -X- _ O
Use -X- _ O
of -X- _ O
NLP -X- _ O
for -X- _ O
Building -X- _ O
Educational -X- _ O
Applications -X- _ O
, -X- _ O
pages -X- _ O
147–153 -X- _ O
, -X- _ O
New -X- _ O
Orleans -X- _ O
, -X- _ O
Louisiana -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Chris -X- _ O
van -X- _ O
der -X- _ O
Lee -X- _ O
, -X- _ O
Emiel -X- _ O
Krahmer -X- _ O
, -X- _ O
and -X- _ O
Sander -X- _ O
Wubben -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
29 -X- _ O
- -X- _ O
45 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O

2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Rare -X- _ O
Tokens -X- _ O
Degenerate -X- _ O
All -X- _ O
Tokens -X- _ O
: -X- _ O
Improving -X- _ O
Neural -X- _ B-TaskName
Text -X- _ I-TaskName
Generation -X- _ I-TaskName
via -X- _ O
Adaptive -X- _ B-MethodName
Gradient -X- _ I-MethodName
Gating -X- _ I-MethodName
for -X- _ O
Rare -X- _ O
Token -X- _ O
Embeddings -X- _ O
Sangwon -X- _ O
Yu1Jongyoon -X- _ O
Song1Heeseung -X- _ O
Kim1Seong -X- _ O
- -X- _ O
min -X- _ O
Lee3 -X- _ O
Woo -X- _ O
- -X- _ O
Jong -X- _ O
Ryu3Sungroh -X- _ O
Yoon1,2 -X- _ O
, -X- _ O
∗ -X- _ O
{ -X- _ O
dbtkddnjs96 -X- _ O
, -X- _ O
coms1580 -X- _ O
, -X- _ O
gmltmds789 -X- _ O
, -X- _ O
sryoon -X- _ O
} -X- _ O
@ -X- _ O
snu.ac.kr -X- _ O
{ -X- _ O
blueworm7 -X- _ O
, -X- _ O
woojong.ryu -X- _ O
} -X- _ O
@ -X- _ O
hyundai.com -X- _ O

Abstract -X- _ O
Recent -X- _ O
studies -X- _ O
have -X- _ O
determined -X- _ O
that -X- _ O
the -X- _ O
learned -X- _ O
token -X- _ O
embeddings -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
neural -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
degenerated -X- _ O
to -X- _ O
be -X- _ O
anisotropic -X- _ O
with -X- _ O
a -X- _ O
narrow -X- _ O
- -X- _ O
cone -X- _ O
shape -X- _ O
. -X- _ O

This -X- _ O
phenomenon -X- _ O
, -X- _ O
called -X- _ O
the -X- _ O
representation -X- _ O
degeneration -X- _ O
problem -X- _ O
, -X- _ O
facilitates -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
overall -X- _ O
similarity -X- _ O
between -X- _ O
token -X- _ O
embeddings -X- _ O
that -X- _ O
negatively -X- _ O
affect -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
existing -X- _ O
methods -X- _ O
that -X- _ O
address -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
based -X- _ O
on -X- _ O
observations -X- _ O
of -X- _ O
the -X- _ O
phenomenon -X- _ O
triggered -X- _ O
by -X- _ O
the -X- _ O
problem -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
generation -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
behind -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
are -X- _ O
still -X- _ O
not -X- _ O
explored -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
focusing -X- _ O
on -X- _ O
rare -X- _ O
token -X- _ O
embedding -X- _ O
. -X- _ O

We -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
is -X- _ O
the -X- _ O
key -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
for -X- _ O
all -X- _ O
tokens -X- _ O
during -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
method -X- _ O
called -X- _ O
, -X- _ O
adaptive -X- _ B-MethodName
gradient -X- _ I-MethodName
gating -X- _ I-MethodName
( -X- _ O
AGG -X- _ B-MethodName
) -X- _ O
. -X- _ O

AGG -X- _ B-MethodName
addresses -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
by -X- _ O
gating -X- _ O
the -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Experimental -X- _ O
results -X- _ O
from -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
word -X- _ O
similarity -X- _ O
, -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
tasks -X- _ O
quantitatively -X- _ O
and -X- _ O
qualitatively -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Neural -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
with -X- _ O
various -X- _ O
architectures -X- _ O
during -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
Graves -X- _ O
, -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Despite -X- _ O
the -X- _ O
improvement -X- _ O
in -X- _ O
model -X- _ O
architectures -X- _ O
, -X- _ O
models -X- _ O
usually -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
process -X- _ O
for -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
. -X- _ O

They -X- _ O
process -X- _ O
token -X- _ O
embeddings -X- _ O
as -X- _ O
inputs -X- _ O
to -X- _ O
compute -X- _ O
contextualized -X- _ O
features -X- _ O
and -X- _ O
subsequently -X- _ O
project -X- _ O
the -X- _ O
features -X- _ O
into -X- _ O
a -X- _ O
categorical -X- _ O
distribution -X- _ O
of -X- _ O
tokens -X- _ O
at -X- _ O
the -X- _ O
output -X- _ O
softmax -X- _ O
layer -X- _ O
whose -X- _ O
weight -X- _ O
is -X- _ O
token -X- _ O
embedding -X- _ O
∗Corresponding -X- _ O
author.matrix -X- _ O
( -X- _ O
Merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Press -X- _ O
and -X- _ O
Wolf -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
studies -X- _ O
have -X- _ O
determined -X- _ O
that -X- _ O
the -X- _ O
learned -X- _ O
embedding -X- _ O
distribution -X- _ O
is -X- _ O
biased -X- _ O
in -X- _ O
a -X- _ O
common -X- _ O
direction -X- _ O
, -X- _ O
thereby -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
narrow -X- _ O
cone -X- _ O
- -X- _ O
shaped -X- _ O
anisotropy -X- _ O
( -X- _ O
Mu -X- _ O
and -X- _ O
Viswanath -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
This -X- _ O
phenomenon -X- _ O
, -X- _ O
named -X- _ O
the -X- _ O
representation -X- _ O
degeneration -X- _ O
problem -X- _ O
by -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
increases -X- _ O
the -X- _ O
overall -X- _ O
similarity -X- _ O
between -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
problem -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
expressiveness -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
decreases -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
semantic -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
tokens -X- _ O
and -X- _ O
to -X- _ O
generate -X- _ O
high -X- _ O
quality -X- _ O
texts -X- _ O
. -X- _ O

Existing -X- _ O
studies -X- _ O
addressing -X- _ O
this -X- _ O
problem -X- _ O
suggest -X- _ O
methods -X- _ O
that -X- _ O
apply -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
or -X- _ O
regularization -X- _ O
techniques -X- _ O
to -X- _ O
all -X- _ O
token -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
observed -X- _ O
phenomena -X- _ O
owing -X- _ O
to -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
( -X- _ O
Mu -X- _ O
and -X- _ O
Viswanath -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Although -X- _ O
these -X- _ O
works -X- _ O
improve -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
and -X- _ O
generated -X- _ O
texts -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
not -X- _ O
clear -X- _ O
how -X- _ O
token -X- _ O
embeddings -X- _ O
become -X- _ O
degenerate -X- _ O
during -X- _ O
training -X- _ O
procedure -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
over -X- _ O
regularization -X- _ O
for -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
whose -X- _ O
semantic -X- _ O
relationships -X- _ O
are -X- _ O
trained -X- _ O
well -X- _ O
because -X- _ O
the -X- _ O
above -X- _ O
methods -X- _ O
are -X- _ O
applied -X- _ O
for -X- _ O
all -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
empirical -X- _ O
studies -X- _ O
about -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

By -X- _ O
observing -X- _ O
the -X- _ O
initial -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
grouped -X- _ O
based -X- _ O
on -X- _ O
appearance -X- _ O
frequency -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
triggers -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
remaining -X- _ O
tokens -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
entire -X- _ O
degeneration -X- _ O
problem -X- _ O
is -X- _ O
mitigated -X- _ O
by -X- _ O
only -X- _ O
freezing -X- _ O
rare -X- _ O
tokens -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
main -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
degeneration -X- _ O
problem -X- _ O
is -X- _ O
the -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
token -X- _ O
em-29 -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
Training -X- _ O
step -X- _ O
100 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Training -X- _ O
step -X- _ O
500 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
Training -X- _ O
step -X- _ O
1500 -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
Training -X- _ O
step -X- _ O
3500 -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Visualization -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
of -X- _ O
language -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
WikiText-103 -X- _ O
. -X- _ O

Red -X- _ O
, -X- _ O
green -X- _ O
, -X- _ O
and -X- _ O
blue -X- _ O
points -X- _ O
represent -X- _ O
rare -X- _ O
, -X- _ O
medium -X- _ O
, -X- _ O
and -X- _ O
frequent -X- _ O
groups -X- _ O
respecively -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
present -X- _ O
a -X- _ O
visualization -X- _ O
of -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
. -X- _ O

beddings -X- _ O
. -X- _ O

This -X- _ O
gradient -X- _ O
part -X- _ O
pushes -X- _ O
away -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
from -X- _ O
the -X- _ O
feature -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
targets -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
sample -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
method -X- _ O
, -X- _ O
adaptive -X- _ B-MethodName
gradient -X- _ I-MethodName
gating -X- _ I-MethodName
( -X- _ O
AGG -X- _ B-MethodName
) -X- _ O
. -X- _ O

With -X- _ O
a -X- _ O
dynamic -X- _ O
grouping -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
at -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
AGG -X- _ B-MethodName
solves -X- _ O
the -X- _ O
entire -X- _ O
degeneration -X- _ O
problem -X- _ O
by -X- _ O
gating -X- _ O
a -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
that -X- _ O
is -X- _ O
solely -X- _ O
about -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

Because -X- _ O
AGG -X- _ B-MethodName
is -X- _ O
optimized -X- _ O
to -X- _ O
target -X- _ O
the -X- _ O
main -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
, -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
prevent -X- _ O
the -X- _ O
over -X- _ O
regularization -X- _ O
problem -X- _ O
about -X- _ O
frequent -X- _ O
token -X- _ O
embeddings -X- _ O
which -X- _ O
occurs -X- _ O
in -X- _ O
other -X- _ O
methods -X- _ O
addressing -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
evaluated -X- _ O
in -X- _ O
three -X- _ O
tasks -X- _ O
: -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
, -X- _ O
word -X- _ B-TaskName
similarity -X- _ I-TaskName
, -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

The -X- _ O
AGG -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
and -X- _ O
other -X- _ O
existing -X- _ O
methods -X- _ O
in -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
it -X- _ O
shows -X- _ O
compatibility -X- _ O
with -X- _ O
other -X- _ O
method -X- _ O
that -X- _ O
addresses -X- _ O
the -X- _ O
neural -X- _ O
text -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

Via -X- _ O
qualitative -X- _ O
studies -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
a -X- _ O
correlation -X- _ O
between -X- _ O
our -X- _ O
method -X- _ O
and -X- _ O
the -X- _ O
frequency -X- _ O
bias -X- _ O
problem -X- _ O
of -X- _ O
learned -X- _ O
embeddings -X- _ O
( -X- _ O
Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2 -X- _ O
Background -X- _ O
2.1 -X- _ O
Text -X- _ O
Generation -X- _ O
of -X- _ O
Neural -X- _ O
Language -X- _ O
Models -X- _ O
Neural -X- _ O
language -X- _ O
generative -X- _ O
models -X- _ O
process -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
as -X- _ O
conditional -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
typically -X- _ O
trained -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
negative -X- _ O
log -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

With -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
tokens -X- _ O
V= -X- _ O
{ -X- _ O
v1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
v -X- _ O
N -X- _ O
} -X- _ O
and -X- _ O
embedding -X- _ O
vectors -X- _ O
{ -X- _ O
w1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
wN -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
wicorresponds -X- _ O
to -X- _ O
token -X- _ O
vi -X- _ O
, -X- _ O
at -X- _ O
every -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
obtains -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
input -X- _ O
and -X- _ O
target -X- _ O
text -X- _ O
corpus -X- _ O
pair -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
xi -X- _ O
, -X- _ O
yi∈V -X- _ O
, -X- _ O
and -X- _ O
y∈VT -X- _ O
. -X- _ O

The -X- _ O
conditional -X- _ O
probability -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
yt -X- _ O
, -X- _ O
Pθ -X- _ O
( -X- _ O
yt|ht -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
htis -X- _ O
a -X- _ O
context -X- _ O
feature -X- _ O
vector -X- _ O
of -X- _ O
thet -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
text -X- _ O
conditionedby -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
< -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
θdenotes -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Pθ -X- _ O
( -X- _ O
yt|ht -X- _ O
) -X- _ O

= -X- _ O
exp -X- _ O
( -X- _ O
htwT -X- _ O
I -X- _ O
( -X- _ O
yt -X- _ O
) -X- _ O
) -X- _ O

PN -X- _ O
l=1exp -X- _ O

( -X- _ O

htwT -X- _ O
where -X- _ O
wis -X- _ O
the -X- _ O
output -X- _ O
token -X- _ O
embedding -X- _ O
which -X- _ O
roles -X- _ O
the -X- _ O
weight -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
softmax -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
I -X- _ O
( -X- _ O
yt -X- _ O
) -X- _ O
represents -X- _ O
the -X- _ O
index -X- _ O
of -X- _ O
token -X- _ O
yt -X- _ O
. -X- _ O

The -X- _ O
negative -X- _ B-MetricName
log -X- _ I-MetricName
likelihood -X- _ I-MetricName
loss -X- _ I-MetricName
for -X- _ O
an -X- _ O
input -X- _ O
and -X- _ O
target -X- _ O
pair -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
LNLL -X- _ O
is -X- _ O
expressed -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

LNLL=−TX -X- _ O
2.2 -X- _ O

Embedding -X- _ O
Problems -X- _ O
in -X- _ O
Neural -X- _ O
Language -X- _ O
Models -X- _ O

Recent -X- _ O
studies -X- _ O
on -X- _ O
the -X- _ O
geometric -X- _ O
properties -X- _ O
of -X- _ O
contextual -X- _ O
embedding -X- _ O
space -X- _ O
have -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
embedding -X- _ O
vectors -X- _ O
is -X- _ O
far -X- _ O
from -X- _ O
isotropic -X- _ O
and -X- _ O
occupies -X- _ O
a -X- _ O
relatively -X- _ O
narrow -X- _ O
cone -X- _ O
space -X- _ O
( -X- _ O
Mu -X- _ O
and -X- _ O
Viswanath -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
this -X- _ O
phenomenon -X- _ O
the -X- _ O
representation -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

This -X- _ O
degeneration -X- _ O
problem -X- _ O
results -X- _ O
in -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
overall -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
semantic -X- _ O
relationships -X- _ O
between -X- _ O
tokens -X- _ O
. -X- _ O

Demeter -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
demonstrated -X- _ O
that -X- _ O
the -X- _ O
norm -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
is -X- _ O
so -X- _ O
dominant -X- _ O
that -X- _ O
angle -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
feature -X- _ O
vector -X- _ O
is -X- _ O
ignored -X- _ O
when -X- _ O
calculating -X- _ O
the -X- _ O
logits -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
. -X- _ O

Owing -X- _ O
to -X- _ O
this -X- _ O
structural -X- _ O
weakness -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
, -X- _ O
embeddings -X- _ O
with -X- _ O
small -X- _ O
norms -X- _ O
are -X- _ O
always -X- _ O
assigned -X- _ O
with -X- _ O
a -X- _ O
low -X- _ O
probability -X- _ O
, -X- _ O
which -X- _ O
reduces -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Anisotropy -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
is -X- _ O
a -X- _ O
still -X- _ O
problem -X- _ O
for -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
improved -X- _ O
isotropic30 -X- _ O

MethodsPPL↓ -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑ -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Perplexity -X- _ O
and -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
groups -X- _ O
. -X- _ O

Lower -X- _ O
is -X- _ O
better -X- _ O
for -X- _ O
PPL -X- _ O
and -X- _ O
higher -X- _ O
is -X- _ O
better -X- _ O
for -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
freeze -X- _ O
until -X- _ O
step -X- _ O
7k -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
freeze -X- _ O
until -X- _ O
step -X- _ O
18k -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
freeze -X- _ O
until -X- _ O
step -X- _ O
29k -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Plot -X- _ O
of -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
rare -X- _ O
and -X- _ O
frequent -X- _ O
groups -X- _ O
and -X- _ O
average -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
rare -X- _ O
and -X- _ O
frequent -X- _ O
embeddings -X- _ O
when -X- _ O
freezing -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
until -X- _ O
specific -X- _ O
training -X- _ O
steps -X- _ O
. -X- _ O

embedding -X- _ O
space -X- _ O
performs -X- _ O
well -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
Bi -X- _ O
´ -X- _ O
s -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Rajaee -X- _ O
and -X- _ O
Pilehvar -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
problem -X- _ O
has -X- _ O
been -X- _ O
theoretically -X- _ O
analyzed -X- _ O
in -X- _ O
several -X- _ O
studies -X- _ O
, -X- _ O
existing -X- _ O
methods -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
observed -X- _ O
phenomena -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
problem -X- _ O
. -X- _ O

To -X- _ O
mitigate -X- _ O
the -X- _ O
phenomena -X- _ O
observed -X- _ O
from -X- _ O
the -X- _ O
problem -X- _ O
, -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
( -X- _ O
Mu -X- _ O
and -X- _ O
Viswanath -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Bi -X- _ O
´ -X- _ O
s -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
or -X- _ O
regularization -X- _ O
terms -X- _ O
about -X- _ O
the -X- _ O
phenomena -X- _ O
( -X- _ O
Gao -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
were -X- _ O
introduced -X- _ O
. -X- _ O

These -X- _ O
methods -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
all -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
so -X- _ O
there -X- _ O
is -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
over -X- _ O
regularization -X- _ O
for -X- _ O
the -X- _ O
embeddings -X- _ O
whose -X- _ O
semantic -X- _ O
relationship -X- _ O
is -X- _ O
trained -X- _ O
well -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
methodologies -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
concerning -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
remain -X- _ O
subject -X- _ O
to -X- _ O
study -X- _ O
. -X- _ O

Frequency -X- _ O
bias -X- _ O
in -X- _ O
embedding -X- _ O
space -X- _ O
is -X- _ O
another -X- _ O
problem -X- _ O
. -X- _ O

Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
conducted -X- _ O
a -X- _ O
comprehensive -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
under -X- _ O
- -X- _ O
estimation -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
in -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O

Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
observed -X- _ O
that -X- _ O
embeddings -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
were -X- _ O
biased -X- _ O
towards -X- _ O
frequency -X- _ O
and -X- _ O
proposed -X- _ O
an -X- _ O
adversarial -X- _ O
training -X- _ O
scheme -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O

3 -X- _ O
Empirical -X- _ O
Study -X- _ O
: -X- _ O
Token -X- _ O
Embedding -X- _ O
Training -X- _ O
Dynamics -X- _ O
led -X- _ O
by -X- _ O
Rare -X- _ O
Tokens -X- _ O
3.1 -X- _ O
Initial -X- _ O
Training -X- _ O
Dynamics -X- _ O
of -X- _ O
Embeddings -X- _ O
To -X- _ O
analyze -X- _ O
the -X- _ O
training -X- _ O
procedure -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
Transformer -X- _ O
language -X- _ O
model -X- _ O
at -X- _ O
the -X- _ O
WikiText-103 -X- _ B-DatasetName
dataset -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O

Wholevocabulary -X- _ O
tokens -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
three -X- _ O
groups -X- _ O
: -X- _ O
frequent -X- _ O
, -X- _ O
medium -X- _ O
, -X- _ O
and -X- _ O
rare -X- _ O
groups -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
appearance -X- _ O
frequency -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
the -X- _ O
30 -X- _ O
% -X- _ O
, -X- _ O
50 -X- _ O
% -X- _ O
, -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
tokens -X- _ O
are -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
frequent -X- _ O
, -X- _ O
medium -X- _ O
, -X- _ O
and -X- _ O
rare -X- _ O
group -X- _ O
. -X- _ O

We -X- _ O
visualize -X- _ O
the -X- _ O
initial -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
these -X- _ O
groups -X- _ O
via -X- _ O
the -X- _ O
projection -X- _ O
of -X- _ O
the -X- _ O
embeddings -X- _ O
into -X- _ O
2D -X- _ O
, -X- _ O
using -X- _ O
singular -X- _ O
value -X- _ O
decomposition -X- _ O
( -X- _ O
SVD -X- _ O
) -X- _ O
projection -X- _ O
. -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
rare -X- _ O
groups -X- _ O
degenerate -X- _ O
first -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
emerge -X- _ O
from -X- _ O
the -X- _ O
entire -X- _ O
embedding -X- _ O
distribution -X- _ O
. -X- _ O

Subsequently -X- _ O
, -X- _ O
other -X- _ O
groups -X- _ O
also -X- _ O
start -X- _ O
to -X- _ O
degenerate -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
the -X- _ O
rare -X- _ O
group -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
this -X- _ O
observation -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
induces -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

3.2 -X- _ O
Rare -X- _ O
Tokens -X- _ O
Degenerate -X- _ O
Non -X- _ O
- -X- _ O
Rare -X- _ O
Tokens -X- _ O
Because -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
6 -X- _ O
- -X- _ O
layer -X- _ O
Transformer -X- _ O
decoder -X- _ O
model -X- _ O
architecture -X- _ O
for -X- _ O
an -X- _ O
empirical -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
embedding -X- _ O
vectors -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
using -X- _ O
WikiText-103 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Experimental -X- _ O
details -X- _ O
regarding -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
training -X- _ O
hyperparameter -X- _ O
configurations -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
B. -X- _ O
To -X- _ O
verify -X- _ O
the -X- _ O
hypothesis -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
while -X- _ O
freezing -X- _ O
the -X- _ O
rare -X- _ O
group -X- _ O
token -X- _ O
embeddings -X- _ O
in -X- _ O
their -X- _ O
initial -X- _ O
states -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
, -X- _ O
where -X- _ O
all -X- _ O
embeddings -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
negative -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
loss -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
of -X- _ O
various -X- _ O
set-31 -X- _ O

MethodsPPL↓ -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑ -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Perplexity -X- _ O
and -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
at -X- _ O
gradient -X- _ O
partial -X- _ O
freezing -X- _ O
experiment -X- _ O
. -X- _ O

tings -X- _ O
relative -X- _ O
to -X- _ O
freezing -X- _ O
steps -X- _ O
and -X- _ O
examine -X- _ O
whether -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
depends -X- _ O
on -X- _ O
when -X- _ O
training -X- _ O
of -X- _ O
rare -X- _ O
embeddings -X- _ O
begins -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
is -X- _ O
evaluated -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
; -X- _ O
the -X- _ O
likelihood -X- _ O
and -X- _ O
isotropy -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Perplexity -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
is -X- _ O
adopted -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

To -X- _ O
measure -X- _ O
the -X- _ O
isotropy -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
distribution -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
partition -X- _ O
function -X- _ O
Z -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O

= -X- _ O
PN -X- _ O
i=1exp -X- _ O
( -X- _ O
wiaT -X- _ O
) -X- _ O
defined -X- _ O
in -X- _ O
Arora -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
widenotes -X- _ O
the -X- _ O
embedding -X- _ O
vector -X- _ O
of -X- _ O
token -X- _ O
vi -X- _ O
, -X- _ O
and -X- _ O
arepresents -X- _ O
a -X- _ O
unit -X- _ O
vector -X- _ O
. -X- _ O

Lemma -X- _ O
2.1 -X- _ O
. -X- _ O

in -X- _ O
Arora -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2016 -X- _ O
) -X- _ O
demonstrate -X- _ O
that -X- _ O
if -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
are -X- _ O
isotropic -X- _ O
, -X- _ O
Z -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
is -X- _ O
approximately -X- _ O
constant -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
this -X- _ O
property -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
isotropy -X- _ O
of -X- _ O
an -X- _ O
embedding -X- _ O
matrix -X- _ O
W -X- _ O
using -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O

= -X- _ O
min -X- _ O
a∈XZ -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
where -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
∈ -X- _ O
[ -X- _ O
0,1 -X- _ O
] -X- _ O
andXrepresents -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
eigenvectors -X- _ O
of -X- _ O
WTW -X- _ O
( -X- _ O
Mu -X- _ O
and -X- _ O
Viswanath -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bi -X- _ O
´ -X- _ O
s -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
relatedness -X- _ O
between -X- _ O
the -X- _ O
rare -X- _ O
and -X- _ O
frequent -X- _ O
group -X- _ O
token -X- _ O
embeddings -X- _ O
to -X- _ O
verify -X- _ O
that -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
the -X- _ O
frequent -X- _ O
group -X- _ O
follows -X- _ O
the -X- _ O
degeneration -X- _ O
of -X- _ O
the -X- _ O
rare -X- _ O
group -X- _ O
. -X- _ O

We -X- _ O
calculate -X- _ O
the -X- _ O
average -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
rare -X- _ O
and -X- _ O
frequent -X- _ O
group -X- _ O
embeddings -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
relatedness -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
frozen -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
baseline -X- _ O
as -X- _ O
" -X- _ O
MLE -X- _ O
" -X- _ O
and -X- _ O
the -X- _ O
freezing -X- _ O
method -X- _ O
as -X- _ O
" -X- _ O
Freeze -X- _ O
" -X- _ O
. -X- _ O

Surprisingly -X- _ O
, -X- _ O
the -X- _ O
PPL -X- _ O
of -X- _ O
frequent -X- _ O
group -X- _ O
tokens -X- _ O
and -X- _ O
overall -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
improved -X- _ O
by -X- _ O
simply -X- _ O
not -X- _ O
training -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
change -X- _ O
in -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
frequent -X- _ O
and -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
frequent -X- _ O
and -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
at -X- _ O
various -X- _ O
freezing -X- _ O
step -X- _ O
settings -X- _ O
. -X- _ O

Whenever -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
start -X- _ O
to -X- _ O
be -X- _ O
trained -X- _ O
, -X- _ O
their -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
decreases -X- _ O
steeply -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
decreasing -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
of -X- _ O
frequent -X- _ O
embeddings -X- _ O
and -X- _ O
increasing -X- _ O
similaritiesbetween -X- _ O
the -X- _ O
frequent -X- _ O
and -X- _ O
rare -X- _ O
embeddings -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
analysis -X- _ O
in -X- _ O
this -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
entire -X- _ O
degeneration -X- _ O
problem -X- _ O
can -X- _ O
be -X- _ O
solved -X- _ O
by -X- _ O
solely -X- _ O
handling -X- _ O
just -X- _ O
rare -X- _ O
embeddings -X- _ O
during -X- _ O
the -X- _ O
entire -X- _ O
training -X- _ O
procedure -X- _ O
. -X- _ O

3.3 -X- _ O
Finding -X- _ O
the -X- _ O
Primary -X- _ O
Cause -X- _ O
of -X- _ O
the -X- _ O
Degeneration -X- _ O
Problem -X- _ O
: -X- _ O
From -X- _ O
the -X- _ O
Gradient -X- _ O
WithTcontext -X- _ O
feature -X- _ O
vectors -X- _ O
hi -X- _ O
( -X- _ O
i∈ -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
T -X- _ O
] -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
sample -X- _ O
, -X- _ O
the -X- _ O
negative -X- _ B-MetricName
log -X- _ I-MetricName
- -X- _ I-MetricName
likelihood -X- _ I-MetricName
loss -X- _ O
gradient -X- _ O
for -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embedding -X- _ O
wris -X- _ O
calculated -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLNLL -X- _ O
= -X- _ O
X -X- _ O
yi -X- _ O
= -X- _ O
vr -X- _ O
( -X- _ O
pr|i−1 -X- _ O
) -X- _ O
hi -X- _ O
+ -X- _ O
X -X- _ O
yj -X- _ O
/ -X- _ O
∈Vrpr|jhj -X- _ O
yk∈Vrpr|khk -X- _ O
where -X- _ O
yidenotes -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
for -X- _ O
hi -X- _ O
, -X- _ O
Vris -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
vocabulary -X- _ O
group -X- _ O
, -X- _ O
and -X- _ O
pr|irepresents -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
of -X- _ O
token -X- _ O
vrgiven -X- _ O
hi -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
calculated -X- _ O
as -X- _ O
[ -X- _ O
softmax -X- _ O
( -X- _ O
hiWT -X- _ O
) -X- _ O
] -X- _ O
r -X- _ O
. -X- _ O

We -X- _ O
divide -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
wrto -X- _ O
3 -X- _ O
parts -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O

Part -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
pulls -X- _ O
wrclose -X- _ O
to -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
target -X- _ O
tokens -X- _ O
arevr -X- _ O
. -X- _ O

Part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
pushes -X- _ O
away -X- _ O
wrfrom -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
target -X- _ O
tokens -X- _ O
are -X- _ O
not -X- _ O
rare -X- _ O
. -X- _ O

Part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
pushes -X- _ O
away -X- _ O
wrfrom -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
target -X- _ O
tokens -X- _ O
are -X- _ O
rare -X- _ O
. -X- _ O

As -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
the -X- _ O
analysis -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
these -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
with -X- _ O
various -X- _ O
settings -X- _ O
during -X- _ O
training -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
key -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
settings -X- _ O
, -X- _ O
the -X- _ O
specific -X- _ O
gradient -X- _ O
parts -X- _ O
that -X- _ O
will -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
embedding -X- _ O
training -X- _ O
is -X- _ O
detached -X- _ O
from -X- _ O
the -X- _ O
computation -X- _ O
graph -X- _ O
during -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O

This -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
implemented -X- _ O
by -X- _ O
detach -X- _ O
( -X- _ O
) -X- _ O
function -X- _ O
of -X- _ O
Pytorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

All -X- _ O
model -X- _ O
and -X- _ O
training -X- _ O
configurations -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
sections -X- _ O
, -X- _ O
except -X- _ O
those -X- _ O
to -X- _ O
be -X- _ O
frozen.32 -X- _ O

Table -X- _ O
2 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
subsection -X- _ O
. -X- _ O

We -X- _ O
freeze -X- _ O
the -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
the -X- _ O
rare -X- _ O
tokens -X- _ O
with -X- _ O
three -X- _ O
settings -X- _ O
. -X- _ O

Because -X- _ O
part -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
component -X- _ O
required -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
to -X- _ O
be -X- _ O
aligned -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
, -X- _ O
all -X- _ O
settings -X- _ O
activate -X- _ O
part -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
notice -X- _ O
that -X- _ O
when -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
is -X- _ O
activated -X- _ O
( -X- _ O
solely -X- _ O
freezing -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
decreases -X- _ O
and -X- _ O
PPL -X- _ O
for -X- _ O
rare -X- _ O
tokens -X- _ O
increases -X- _ O
almost -X- _ O
10 -X- _ O
times -X- _ O
compared -X- _ O
to -X- _ O
when -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
is -X- _ O
frozen -X- _ O
. -X- _ O

Because -X- _ O
activating -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
is -X- _ O
not -X- _ O
seen -X- _ O
to -X- _ O
be -X- _ O
negative -X- _ O
for -X- _ O
PPL -X- _ O
andI -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
is -X- _ O
the -X- _ O
bedrock -X- _ O
cause -X- _ O
for -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
analysis -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
could -X- _ O
be -X- _ O
solved -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
extent -X- _ O
by -X- _ O
mainly -X- _ O
addressing -X- _ O
the -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
embeddings -X- _ O
that -X- _ O
pushes -X- _ O
away -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
from -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
feature -X- _ O
vectors -X- _ O
. -X- _ O

4 -X- _ O
Method -X- _ O
4.1 -X- _ O
Dynamic -X- _ O
Rare -X- _ O
Token -X- _ O
Grouping -X- _ O

To -X- _ O
handle -X- _ O
the -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
studied -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
properly -X- _ O
group -X- _ O
the -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

A -X- _ O
naive -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
group -X- _ O
rare -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
appearance -X- _ O
frequency -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
static -X- _ O
grouping -X- _ O
method -X- _ O
is -X- _ O
suboptimal -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
typically -X- _ O
trained -X- _ O
via -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
training -X- _ O
. -X- _ O

The -X- _ O
group -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
that -X- _ O
appeared -X- _ O
less -X- _ O
frequently -X- _ O
in -X- _ O
recent -X- _ O
batch -X- _ O
samples -X- _ O
is -X- _ O
variable -X- _ O
in -X- _ O
the -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
training -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
dynamically -X- _ O
group -X- _ O
rare -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
token -X- _ O
appearances -X- _ O
in -X- _ O
recent -X- _ O
batch -X- _ O
samples -X- _ O
. -X- _ O

To -X- _ O
consider -X- _ O
the -X- _ O
token -X- _ O
appearances -X- _ O
in -X- _ O
recent -X- _ O
batch -X- _ O
samples -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
token -X- _ O
counter -X- _ O
memory -X- _ O
that -X- _ O
remembers -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
the -X- _ O
appearances -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
during -X- _ O
the -X- _ O
previous -X- _ O
Ktraining -X- _ O
steps -X- _ O
. -X- _ O

For -X- _ O
Kmemories -X- _ O
, -X- _ O
[ -X- _ O
m1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
mK -X- _ O
] -X- _ O
, -X- _ O
mt∈RN -X- _ O
represents -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
appearances -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
ofN -X- _ O
- -X- _ O
size -X- _ O
vocabulary -X- _ O
at -X- _ O
the -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
previous -X- _ O
training -X- _ O
step -X- _ O
. -X- _ O

Memories -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
zero -X- _ O
vectors -X- _ O
at -X- _ O
the -X- _ O
initial -X- _ O
stage -X- _ O
. -X- _ O

At -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
appearance -X- _ O
, -X- _ O
a∈RN -X- _ O
, -X- _ O
is -X- _ O
calculated -X- _ O
as -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
all -X- _ O
Kmemories -X- _ O
: -X- _ O
a -X- _ O
= -X- _ O
PK -X- _ O
t=1mt -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
a -X- _ O
, -X- _ O
we -X- _ O
determine -X- _ O
whether -X- _ O
token -X- _ O
viis -X- _ O
in -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
Vras -X- _ O
follows.ai -X- _ O
K -X- _ O
< -X- _ O
α⇒vi∈Vr -X- _ O
ai -X- _ O
where -X- _ O
aiis -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
component -X- _ O
of -X- _ O
a -X- _ O
, -X- _ O
and -X- _ O
αis -X- _ O
a -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
that -X- _ O
controls -X- _ O
theproportion -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
entire -X- _ O
vocabulary -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
Kto -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
iteration -X- _ O
steps -X- _ O
during -X- _ O
one -X- _ O
epoch -X- _ O
of -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O

4.2 -X- _ O
Adaptive -X- _ B-MethodName
Gradient -X- _ I-MethodName
Gating -X- _ I-MethodName
for -X- _ O
Rare -X- _ O
Tokens -X- _ O
After -X- _ O
dynamically -X- _ O
grouping -X- _ O
the -X- _ O
rare -X- _ O
tokens -X- _ O
at -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
handle -X- _ O
a -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
of -X- _ O
all -X- _ O
embeddings -X- _ O
. -X- _ O

To -X- _ O
solely -X- _ O
control -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
gradient -X- _ O
gating -X- _ O
method -X- _ O
for -X- _ O
a -X- _ O
parameter -X- _ O
x -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
˜xas -X- _ O
a -X- _ O
tensor -X- _ O
whose -X- _ O
value -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
x -X- _ O
, -X- _ O
but -X- _ O
detached -X- _ O
from -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
graph -X- _ O
. -X- _ O

This -X- _ O
implies -X- _ O
that -X- _ O
˜xis -X- _ O
considered -X- _ O
a -X- _ O
constant -X- _ O
, -X- _ O
hence -X- _ O
, -X- _ O
gradient -X- _ O
about -X- _ O
˜xdoes -X- _ O
not -X- _ O
exist -X- _ O
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
˜xcan -X- _ O
be -X- _ O
easily -X- _ O
obtained -X- _ O
from -X- _ O
xusing -X- _ O
the -X- _ O
detach -X- _ O
( -X- _ O
) -X- _ O
function -X- _ O
of -X- _ O
Pytorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

With -X- _ O
˜x -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
gate -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
xas -X- _ O
follows -X- _ O
. -X- _ O

where -X- _ O
xgated -X- _ O
is -X- _ O
a -X- _ O
new -X- _ O
parameter -X- _ O
whose -X- _ O
value -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
x -X- _ O
, -X- _ O
and -X- _ O
g∈ -X- _ O
[ -X- _ O
0,1 -X- _ O
] -X- _ O
is -X- _ O
a -X- _ O
gate -X- _ O
tensor -X- _ O
. -X- _ O

When -X- _ O
thexgated -X- _ O
is -X- _ O
fed -X- _ O
to -X- _ O
the -X- _ O
function -X- _ O
f -X- _ O
( -X- _ O
· -X- _ O
) -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
xis -X- _ O
gated -X- _ O
by -X- _ O
g -X- _ O
. -X- _ O

As -X- _ O
we -X- _ O
described -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
, -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
should -X- _ O
mainly -X- _ O
be -X- _ O
handled -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
context -X- _ O
feature -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
hi -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
gate -X- _ O
vector -X- _ O
g1∈RNas -X- _ O
follows -X- _ O
. -X- _ O

ak -X- _ O
/ -X- _ O
K -X- _ O
ifvk∈Vr -X- _ O
, -X- _ O
vk̸=yi -X- _ O
where -X- _ O
g1kdenotes -X- _ O
a -X- _ O
k -X- _ O
- -X- _ O
th -X- _ O
component -X- _ O
of -X- _ O
g1.g1controls -X- _ O
the -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
move -X- _ O
away -X- _ O
from -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
targets -X- _ O
differ -X- _ O
from -X- _ O
each -X- _ O
rare -X- _ O
token -X- _ O
embedding -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
g1is -X- _ O
calculated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
rarity -X- _ O
of -X- _ O
each -X- _ O
rare -X- _ O
token -X- _ O
, -X- _ O
ak -X- _ O
, -X- _ O
so -X- _ O
gradient -X- _ O
gating -X- _ O
for -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
is -X- _ O
adaptive -X- _ O
for -X- _ O
each -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

Although -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
, -X- _ O
which -X- _ O
pushes -X- _ O
embeddings -X- _ O
away -X- _ O
from -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
targets -X- _ O
are -X- _ O
other -X- _ O
rare -X- _ O
tokens -X- _ O
, -X- _ O
is -X- _ O
not -X- _ O
to -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
the -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
, -X- _ O
this -X- _ O
part -X- _ O
also -X- _ O
induces -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
for -X- _ O
the -X- _ O
certain -X- _ O
situation -X- _ O
when -X- _ O
rare -X- _ O
tokens -X- _ O
degenerate -X- _ O
other -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
approximate -X- _ O
the -X- _ O
multiple -X- _ O
levels -X- _ O
of -X- _ O
rarity -X- _ O
in -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
to -X- _ O
two -X- _ O
levels -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
: -X- _ O
‘ -X- _ O
less -X- _ O
rare -X- _ O
’ -X- _ O
and -X- _ O
‘ -X- _ O
very -X- _ O
rare’.33 -X- _ O

MethodsPPL↓ -X- _ O
Uniq↑I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Experimental -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
in -X- _ O
WikiText-103 -X- _ B-DatasetName
language -X- _ O
modeling -X- _ O
task -X- _ O
comparing -X- _ O
MLE -X- _ O
baseline -X- _ O
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

MethodsPPL↓ -X- _ O
Uniq↑I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Total -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Experimental -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
in -X- _ O
WikiText-103 -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
comparing -X- _ O
UL -X- _ O
and -X- _ O
UL+AGG -X- _ O
. -X- _ O

We -X- _ O
define -X- _ O
the -X- _ O
two -X- _ O
rarity -X- _ O
levels -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
appearances -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
rare -X- _ O
tokens -X- _ O
: -X- _ O
if -X- _ O
the -X- _ O
token -X- _ O
appearance -X- _ O
akis -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
mean -X- _ O
ofarwhere -X- _ O
r∈Vr -X- _ O
, -X- _ O
corresponding -X- _ O
token -X- _ O
is -X- _ O
a -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
about -X- _ O
embeddings -X- _ O
pushes -X- _ O
them -X- _ O
away -X- _ O
from -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
targets -X- _ O
are -X- _ O
less -X- _ O
rare -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
relatively -X- _ O
frequent -X- _ O
compared -X- _ O
to -X- _ O
them -X- _ O
. -X- _ O

This -X- _ O
means -X- _ O
that -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
roles -X- _ O
like -X- _ O
part -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
above -X- _ O
situation -X- _ O
, -X- _ O
which -X- _ O
becomes -X- _ O
the -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
handle -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
for -X- _ O
very -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
for -X- _ O
the -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
another -X- _ O
gate -X- _ O
vector -X- _ O
g2∈RNas -X- _ O
follows -X- _ O
. -X- _ O

min -X- _ O
( -X- _ O
ak -X- _ O
¯ar,1 -X- _ O
) -X- _ O

ifvk∈Vr -X- _ O
, -X- _ O
vk̸=yi -X- _ O
where -X- _ O
g2kis -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
th -X- _ O
component -X- _ O
of -X- _ O
g2and¯aris -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
arwhere -X- _ O
r∈Vr.g2controls -X- _ O
the -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
move -X- _ O
away -X- _ O
from -X- _ O
less -X- _ O
rare -X- _ O
feature -X- _ O
vectors -X- _ O
whose -X- _ O
targets -X- _ O
differ -X- _ O
from -X- _ O
each -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
embedding -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
g2is -X- _ O
calculated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
rarity -X- _ O
of -X- _ O
each -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
, -X- _ O
ak -X- _ O
, -X- _ O
so -X- _ O
gradient -X- _ O
gating -X- _ O
for -X- _ O
part -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
is -X- _ O
adaptive -X- _ O
for -X- _ O
each -X- _ O
very -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

To -X- _ O
calculate -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
hi -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
three -X- _ O
logits -X- _ O
, -X- _ O
z0 -X- _ O
i -X- _ O
, -X- _ O
z1 -X- _ O
i -X- _ O
, -X- _ O
andz2 -X- _ O

i -X- _ O
, -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

z0 -X- _ O
i -X- _ O
= -X- _ O
hi˜WT -X- _ O
zl -X- _ O
where -X- _ O
Wdenotes -X- _ O
an -X- _ O
embedding -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
l=1,2 -X- _ O
. -X- _ O

Because -X- _ O
our -X- _ O
method -X- _ O
solely -X- _ O
handles -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
z0 -X- _ O
ifor -X- _ O
a -X- _ O
gradient -X- _ O
about -X- _ O
hi -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
gated -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
the -X- _ O
negative -X- _ O
log -X- _ B-MetricName
- -X- _ I-MetricName
likelihood -X- _ I-MetricName
loss -X- _ O
for -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
Li -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

Li=−logp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O
− -X- _ O
1 -X- _ O
( -X- _ O
yi∈Vr -X- _ O
) -X- _ O
logp2 -X- _ O
where -X- _ O
pm -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i= -X- _ O
[ -X- _ O
softmax -X- _ O
( -X- _ O
zm -X- _ O
and -X- _ O
1 -X- _ O
( -X- _ O
· -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
Indicator -X- _ O
function -X- _ O
. -X- _ O

Derivation -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
∇wrLi -X- _ O
, -X- _ O
is -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
5 -X- _ O
Experiments -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
including -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
, -X- _ O
word -X- _ B-TaskName
similarity -X- _ I-TaskName
, -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

In -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
verifying -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
texts -X- _ O
. -X- _ O

We -X- _ O
test -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
the -X- _ O
semantic -X- _ O
relationships -X- _ O
between -X- _ O
tokens -X- _ O
on -X- _ O
the -X- _ O
word -X- _ B-TaskName
similarity -X- _ I-TaskName
task -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
texts -X- _ O
on -X- _ O
the -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
task -X- _ O
. -X- _ O

For -X- _ O
all -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
below -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
architecture -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
to -X- _ O
properly -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

Every -X- _ O
detail -X- _ O
on -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
model -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
and -X- _ O
training -X- _ O
configurations -X- _ O
, -X- _ O
regard -X- _ O
the -X- _ O
reproducibility -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
B.34 -X- _ O

Method -X- _ O
Texts -X- _ O
Uniq -X- _ O
↑ -X- _ O
Prefix -X- _ O
No -X- _ O
. -X- _ O
20 -X- _ O
Squadron -X- _ O
is -X- _ O
a -X- _ O
Royal -X- _ O
Australian -X- _ O
Air -X- _ O
Force -X- _ O
( -X- _ O
RAAF -X- _ O
) -X- _ O
support -X- _ O
squadron -X- _ O
. -X- _ O

Coming -X- _ O
under -X- _ O
the -X- _ O
control -X- _ O
of -X- _ O
No -X- _ O
. -X- _ O
96 -X- _ O
Wing -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
management -X- _ O
of -X- _ O
the -X- _ O
airfield -X- _ O
at -X- _ O
RAAF -X- _ O
Base -X- _ O
Woomera -X- _ O
, -X- _ O
South -X- _ O
Australia -X- _ O
. -X- _ O

The -X- _ O
squadron -X- _ O
MLE -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
and -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
aerial -X- _ O
reconnaissance -X- _ O
, -X- _ O
and -X- _ O
air -X- _ O
defence -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
also -X- _ O
responsible -X- _ O
for -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
and -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
air -X- _ O
defence -X- _ O
, -X- _ O
aerial -X- _ O
reconnaissance -X- _ O
, -X- _ O
and -X- _ O
air -X- _ O
defence -X- _ O
.15 -X- _ O

AGG -X- _ O
was -X- _ O
established -X- _ O
in -X- _ O
October -X- _ O
1943 -X- _ O
at -X- _ O
Townsville -X- _ O
, -X- _ O
Queensland -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
command -X- _ O
of -X- _ O
Group -X- _ O
Captain -X- _ O
Paddy -X- _ O
Heffernan -X- _ O
. -X- _ O

It -X- _ O
was -X- _ O
initially -X- _ O
based -X- _ O
at -X- _ O
Townsville -X- _ O
, -X- _ O
Queensland -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
control -X- _ O
of -X- _ O
No -X- _ O
. -X- _ O
9 -X- _ O
Operational -X- _ O
Group -X- _ O
, -X- _ O
which -X- _ O
controlled -X- _ O
all -X- _ O
air -X- _ O
bases -X- _ O
in -X- _ O
New -X- _ O
South -X- _ O
Wales -X- _ O
. -X- _ O

It -X- _ O
was -X- _ O
renamed -X- _ O
No -X- _ O
. -X- _ O
1 -X- _ O
Mobile -X- _ O
Fighter -X- _ O
Sector -X- _ O
in -X- _ O
April -X- _ O
1944 -X- _ O
.48 -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Generated -X- _ O
texts -X- _ O
on -X- _ O
the -X- _ O
Wikitext-103 -X- _ O
test -X- _ O
set -X- _ O
and -X- _ O
uniq -X- _ O
tokens -X- _ O
for -X- _ O
each -X- _ O
texts -X- _ O
. -X- _ O

50 -X- _ O
BPE -X- _ O
tokens -X- _ O
are -X- _ O
given -X- _ O
as -X- _ O
prefix -X- _ O
and -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
continuation -X- _ O
of -X- _ O
100 -X- _ O
next -X- _ O
BPE -X- _ O
tokens -X- _ O
. -X- _ O

5.1 -X- _ O
Language -X- _ O
Modeling -X- _ O
Setting -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
using -X- _ O
WikiText103 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
significantly -X- _ O
large -X- _ O
dataset -X- _ O
for -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
with -X- _ O
approximately -X- _ O
103 -X- _ O
M -X- _ O
words -X- _ O
and -X- _ O
260 -X- _ O
K -X- _ O
vocabulary -X- _ O
size -X- _ O
( -X- _ O
Merity -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Texts -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
are -X- _ O
preprocessed -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
byte -X- _ O
- -X- _ O
pair -X- _ O
encoding -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
GPT-2 -X- _ O
medium -X- _ O
architecture -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
comprises -X- _ O
24 -X- _ O
Transformer -X- _ O
decoder -X- _ O
layers -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
model -X- _ O
. -X- _ O

Because -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
about -X- _ O
learning -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
from -X- _ O
scratch -X- _ O
for -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
50k -X- _ B-HyperparameterValue
iterations -X- _ B-HyperparameterName
and -X- _ O
evaluate -X- _ O
them -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
perplexity -X- _ O
of -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

For -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
searching -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
α∈ -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
sensitivity -X- _ O
for -X- _ O
the -X- _ O
AGG -X- _ B-MethodName
are -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
D. -X- _ O
We -X- _ O
use -X- _ O
three -X- _ O
quantitative -X- _ O
metrics -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
: -X- _ O
Perplexity -X- _ B-MetricName
, -X- _ O
Uniq -X- _ B-MetricName
, -X- _ O
and -X- _ O
I -X- _ B-MetricName
( -X- _ I-MetricName
W -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O

Related -X- _ O
to -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
generated -X- _ O
texts -X- _ O
, -X- _ O
Perplexity -X- _ B-MetricName
quantifies -X- _ O
the -X- _ O
prediction -X- _ O
difficulty -X- _ O
over -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
. -X- _ O

Uniq -X- _ O
( -X- _ O
Welleck -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
quantify -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
next -X- _ O
- -X- _ O
token -X- _ O
predictions -X- _ O
, -X- _ O
measuring -X- _ O
the -X- _ O
token -X- _ O
diversity -X- _ O
. -X- _ O

As -X- _ O
described -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
, -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
measures -X- _ O
the -X- _ O
isotropy -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O

Results -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
testset -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
baseline -X- _ O
method -X- _ O
as -X- _ O
‘ -X- _ O
MLE -X- _ B-MethodName
’ -X- _ O
and -X- _ O
our -X- _ O
method -X- _ O
as -X- _ O
‘ -X- _ O
AGG -X- _ B-MethodName
’ -X- _ O
. -X- _ O

We -X- _ O
measure -X- _ O
Perplexity -X- _ B-MetricName
and -X- _ O
Uniq -X- _ B-MetricName
for -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
defined -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
. -X- _ O

As -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
AGG -X- _ B-MethodName
improves -X- _ O
the -X- _ O
overall -X- _ O
metrics -X- _ O
for -X- _ O
the -X- _ O
medium -X- _ O
and -X- _ O
rare -X- _ O
groups -X- _ O
while -X- _ O
maintaining -X- _ O
performance -X- _ O
for -X- _ O
the -X- _ O
frequent -X- _ O
token -X- _ O
group -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
not -X- _ O
only -X- _ O
improves -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
rare -X- _ O
group -X- _ O
, -X- _ O
the -X- _ O
Perplexity -X- _ B-MetricName
score -X- _ O
decrease -X- _ O
significantly -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
uniquepredictions -X- _ O
surpasses -X- _ O
the -X- _ O
human -X- _ O
distribution -X- _ O
. -X- _ O

The -X- _ O
I -X- _ B-MetricName
( -X- _ I-MetricName
W -X- _ I-MetricName
) -X- _ I-MetricName
for -X- _ O
all -X- _ O
token -X- _ O
embeddings -X- _ O
increased -X- _ O
over -X- _ O
2 -X- _ O
times -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O

Experimental -X- _ O
results -X- _ O
of -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
each -X- _ O
frequency -X- _ O
groups -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
examples -X- _ O
of -X- _ O
generated -X- _ O
texts -X- _ O
from -X- _ O
MLE -X- _ B-MethodName
baseline -X- _ O
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
additional -X- _ O
examples -X- _ O
of -X- _ O
generated -X- _ O
texts -X- _ O
in -X- _ O
Appendix -X- _ O
F. -X- _ O
Compatibility -X- _ O
Neural -X- _ O
text -X- _ O
degeneration -X- _ O
problem -X- _ O
is -X- _ O
another -X- _ O
problem -X- _ O
in -X- _ O
neural -X- _ O
text -X- _ O
generative -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
generates -X- _ O
texts -X- _ O
that -X- _ O
are -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
match -X- _ O
human -X- _ O
word -X- _ O
distributions -X- _ O
. -X- _ O

Existing -X- _ O
methods -X- _ O
for -X- _ O
this -X- _ O
problem -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
texts -X- _ O
by -X- _ O
adding -X- _ O
an -X- _ O
auxiliary -X- _ O
loss -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
negative -X- _ B-MethodName
log -X- _ I-MethodName
- -X- _ I-MethodName
likelihood -X- _ I-MethodName
loss -X- _ O
( -X- _ O
Welleck -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Although -X- _ O
Welleck -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
AGG -X- _ O
attempts -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
same -X- _ O
problem -X- _ O
about -X- _ O
diversity -X- _ O
, -X- _ O
AGG -X- _ B-MethodName
can -X- _ O
be -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
existing -X- _ O
method -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
degeneration -X- _ O
problem -X- _ O
because -X- _ O
AGG -X- _ O
does -X- _ O
not -X- _ O
alter -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
in -X- _ O
MLE -X- _ B-MethodName
training -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
experiments -X- _ O
about -X- _ O
fusion -X- _ O
of -X- _ O
unlikelihood -X- _ O
training -X- _ O
( -X- _ O
Welleck -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
unlikelihood -X- _ B-MethodName
training -X- _ I-MethodName
as -X- _ O
UL -X- _ B-MethodName
. -X- _ O

From -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
when -X- _ O
UL -X- _ B-MethodName
and -X- _ O
AGG -X- _ B-MethodName
are -X- _ O
fused -X- _ O
, -X- _ O
it -X- _ O
produces -X- _ O
a -X- _ O
synergistic -X- _ O
effect -X- _ O
that -X- _ O
exceeds -X- _ O
the -X- _ O
gain -X- _ O
of -X- _ O
each -X- _ O
for -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
AGG -X- _ B-MethodName
is -X- _ O
compatible -X- _ O
with -X- _ O
methods -X- _ O
that -X- _ O
address -X- _ O
other -X- _ O
problems -X- _ O
in -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O

5.2 -X- _ O
Word -X- _ O
Similarity -X- _ O
Setting -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
semantic -X- _ O
relationship -X- _ O
between -X- _ O
tokens -X- _ O
for -X- _ O
AGG -X- _ B-MethodName
and -X- _ O
the -X- _ O
baseline -X- _ B-MethodName
with -X- _ O
four -X- _ O
word -X- _ O
similarity -X- _ O
datasets -X- _ O
: -X- _ O
MEN -X- _ B-DatasetName
, -X- _ O
WS353 -X- _ B-DatasetName
, -X- _ O
RG65 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
RW -X- _ B-DatasetName
( -X- _ O
Bruni -X- _ O
et -X- _ O

al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Agirre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Rubenstein -X- _ O
and -X- _ O
Goodenough -X- _ O
, -X- _ O
1965 -X- _ O
; -X- _ O
Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Methods -X- _ O
are -X- _ O
tested -X- _ O
whether -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
given -X- _ O
two -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
Spear-35 -X- _ B-MetricName

Datasets -X- _ O
MLE -X- _ B-MethodName
AGG -X- _ B-MethodName
Table -X- _ O
6 -X- _ O
: -X- _ O
Performance -X- _ O
( -X- _ O
Spearman -X- _ O
’s -X- _ O
γ×100 -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
four -X- _ O
word -X- _ O
similarity -X- _ O
datasets -X- _ O
. -X- _ O

MethodsBLEU -X- _ B-MetricName
↑ -X- _ O
Base -X- _ O
Big -X- _ O
Table -X- _ O
7 -X- _ O
: -X- _ O
Comparison -X- _ O
of -X- _ O
different -X- _ O
methods -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
. -X- _ O

man -X- _ O
’s -X- _ O
rank -X- _ O
correlation -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
cosine -X- _ O
distance -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
embeddings -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
language -X- _ O
modeling -X- _ O
tasks -X- _ O
with -X- _ O
the -X- _ O
WikiText-103 -X- _ B-DatasetName
dataset -X- _ O
for -X- _ O
the -X- _ O
word -X- _ O
similarity -X- _ O
task -X- _ O
. -X- _ O

Results -X- _ O
Table -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
result -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
similarity -X- _ O
task -X- _ O
. -X- _ O

From -X- _ O
this -X- _ O
table -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
on -X- _ O
overall -X- _ O
datasets -X- _ O
. -X- _ O

Although -X- _ O
AGG -X- _ B-MethodName
handles -X- _ O
only -X- _ O
training -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
, -X- _ O
the -X- _ O
semantic -X- _ O
relationships -X- _ O
between -X- _ O
all -X- _ O
tokens -X- _ O
are -X- _ O
also -X- _ O
well -X- _ O
learned -X- _ O
. -X- _ O

Qualitative -X- _ O
studies -X- _ O
on -X- _ O
semantic -X- _ O
alignment -X- _ O
between -X- _ O
tokens -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
E. -X- _ O
5.3 -X- _ O
Machine -X- _ O
Translation -X- _ O
Setting -X- _ O
We -X- _ O
utilize -X- _ O
a -X- _ O
dataset -X- _ O
from -X- _ O
standard -X- _ O
WMT -X- _ B-DatasetName
2014 -X- _ I-DatasetName
containing -X- _ O
4.5 -X- _ O
M -X- _ O
English -X- _ O
→German -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
are -X- _ O
encoded -X- _ O
by -X- _ O
37 -X- _ O
K -X- _ O
shared -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
byte -X- _ O
- -X- _ O
pair -X- _ O
encoding -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
two -X- _ O
version -X- _ O
of -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
for -X- _ O
applying -X- _ O
our -X- _ O
method -X- _ O
: -X- _ O
base -X- _ O
and -X- _ O
big -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
configuration -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
proposed -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
texts -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
standard -X- _ O
metric -X- _ O
for -X- _ O
machine -X- _ O
translation -X- _ O
task -X- _ O
. -X- _ O

Results -X- _ O
Table -X- _ O
7 -X- _ O
presents -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
and -X- _ O
other -X- _ O
methods -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O

Our -X- _ O
method -X- _ O
achieves -X- _ O
1.4 -X- _ O
and -X- _ O
1.41 -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
improvements -X- _ O
on -X- _ O
the -X- _ O
machine -X- _ O
translation -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
base -X- _ O
andbig -X- _ O
baseline -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
addi -X- _ O
- -X- _ O
Method -X- _ O
PPL↓Uniq↑I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑ -X- _ O
Table -X- _ O
8 -X- _ O
: -X- _ O
Ablation -X- _ O
study -X- _ O
on -X- _ O
gating -X- _ O
vector -X- _ O
of -X- _ O
AGG -X- _ O
. -X- _ O

Method -X- _ O
PPL↓Uniq↑I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑ -X- _ O
Table -X- _ O
9 -X- _ O
: -X- _ O

Ablation -X- _ O
study -X- _ O
about -X- _ O
dynamic -X- _ O
grouping -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
. -X- _ O
tion -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
all -X- _ O
other -X- _ O
previous -X- _ O
works -X- _ O
in -X- _ O
handling -X- _ O
the -X- _ O
representation -X- _ O
degeneration -X- _ O
problem -X- _ O
that -X- _ O
reported -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
tasks -X- _ O
. -X- _ O

These -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
in -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
texts -X- _ O
. -X- _ O

While -X- _ O
other -X- _ O
methods -X- _ O
addressing -X- _ O
the -X- _ O
degeneration -X- _ O
problem -X- _ O
targets -X- _ O
all -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
target -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
, -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
are -X- _ O
optimized -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
analysis -X- _ O
about -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
this -X- _ O
difference -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
can -X- _ O
prevent -X- _ O
the -X- _ O
over -X- _ O
regularization -X- _ O
problem -X- _ O
for -X- _ O
frequent -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
main -X- _ O
advantage -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
compared -X- _ O
to -X- _ O
other -X- _ O
works -X- _ O
. -X- _ O

Qualitative -X- _ O
study -X- _ O
about -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
semantic -X- _ O
alignment -X- _ O
between -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
is -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
E. -X- _ O
6 -X- _ O
Analysis -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
6.1 -X- _ O
Ablation -X- _ O
Study -X- _ O
In -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
AGG -X- _ B-MethodName
, -X- _ O
we -X- _ O
introduce -X- _ O
two -X- _ O
gate -X- _ O
vectors -X- _ O
, -X- _ O
g1 -X- _ O
, -X- _ O
and -X- _ O
g2 -X- _ O
, -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
gradient -X- _ O
for -X- _ O
rare -X- _ O
and -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
these -X- _ O
gate -X- _ O
vectors -X- _ O
. -X- _ O

Table -X- _ O
8 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
ablation -X- _ O
studies -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
MLE -X- _ B-MethodName
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

When -X- _ O
g1is -X- _ O
excluded -X- _ O
from -X- _ O
AGG -X- _ B-MethodName
( -X- _ O
denoted -X- _ O
as -X- _ O
‘ -X- _ O
no -X- _ O
g1 -X- _ O
’ -X- _ O
) -X- _ O
, -X- _ O
Uniq -X- _ B-MetricName
and -X- _ O
I -X- _ B-MetricName
( -X- _ I-MetricName
W -X- _ I-MetricName
) -X- _ I-MetricName
decreased -X- _ O
significantly -X- _ O
, -X- _ O
because -X- _ O
g1is -X- _ O
the -X- _ O
key -X- _ O
component -X- _ O
for -X- _ O
the -X- _ O
gradient -X- _ O
gating -X- _ O
. -X- _ O

When -X- _ O
g2is -X- _ O
excluded -X- _ O
from -X- _ O
AGG -X- _ B-MethodName
( -X- _ O
denoted -X- _ O
as -X- _ O
‘ -X- _ O
no -X- _ O
g2 -X- _ O
’ -X- _ O
) -X- _ O
, -X- _ O
Uniq -X- _ B-MetricName
and -X- _ O
I -X- _ B-MetricName
( -X- _ I-MetricName
W -X- _ I-MetricName
) -X- _ I-MetricName
slightly -X- _ O
decrease -X- _ O
. -X- _ O

Accordingly -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
g2is -X- _ O
important -X- _ O
for -X- _ O
the -X- _ O
gating -X- _ O
of -X- _ O
gradients -X- _ O
fort -X- _ O
the -X- _ O
very -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Also -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
analysis -X- _ O
about -X- _ O
rare -X- _ O
token -X- _ O
grouping -X- _ O
method -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

Figure -X- _ O
4 -X- _ O
presents -X- _ O
the36 -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
MLE -X- _ B-MethodName
( -X- _ O
b -X- _ O
) -X- _ O
AGG -X- _ B-MethodName
( -X- _ O
c -X- _ O
) -X- _ O
Singular -X- _ O
value -X- _ O
decay -X- _ O
Figure -X- _ O
3 -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Token -X- _ O
embedding -X- _ O
visualization -X- _ O
for -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
and -X- _ O
AGG -X- _ B-MethodName
on -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
with -X- _ O
WikiText-103 -X- _ B-DatasetName
. -X- _ O

Red -X- _ O
, -X- _ O
green -X- _ O
, -X- _ O
and -X- _ O
blue -X- _ O
points -X- _ O
represent -X- _ O
rare -X- _ O
, -X- _ O
medium -X- _ O
, -X- _ O
and -X- _ O
frequent -X- _ O
groups -X- _ O
respecively -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
Normalized -X- _ O
singular -X- _ O
value -X- _ O
for -X- _ O
MLE -X- _ B-MethodName
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

Figure -X- _ O
4 -X- _ O
: -X- _ O
Size -X- _ O
of -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
during -X- _ O
initial -X- _ O
1k -X- _ O
steps -X- _ O
of -X- _ O
training -X- _ O
with -X- _ O
WikiText-103 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

size -X- _ O
of -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
during -X- _ O
initial -X- _ O
1k -X- _ O
training -X- _ O
steps -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
WikiText103 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

As -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
rare -X- _ O
group -X- _ O
size -X- _ O
fluctuate -X- _ O
wildly -X- _ O
at -X- _ O
the -X- _ O
initial -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O

We -X- _ O
expect -X- _ O
for -X- _ O
this -X- _ O
grouping -X- _ O
method -X- _ O
to -X- _ O
determine -X- _ O
an -X- _ O
optimal -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
step -X- _ O
. -X- _ O

Table -X- _ O
9 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ablation -X- _ O
study -X- _ O
about -X- _ O
dynamic -X- _ O
grouping -X- _ O
. -X- _ O

To -X- _ O
except -X- _ O
dynamic -X- _ O
grouping -X- _ O
from -X- _ O
AGG -X- _ B-MethodName
, -X- _ O
we -X- _ O
fixed -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
after -X- _ O
1 -X- _ O
epoch -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
static -X- _ O
grouping -X- _ O
AGG -X- _ B-MethodName
method -X- _ O
, -X- _ O
Next -X- _ O
- -X- _ O
token -X- _ O
diversity -X- _ O
( -X- _ O
Uniq -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
isotropy -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
space -X- _ O
( -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
) -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
dynamic -X- _ O
grouping -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

6.2 -X- _ O
Visualization -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
present -X- _ O
the -X- _ O
visualizations -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
of -X- _ O
baseline -X- _ O
MLE -X- _ B-MethodName
and -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
applying -X- _ O
the -X- _ O
AGG -X- _ B-MethodName
method -X- _ O
restores -X- _ O
the -X- _ O
isotropy -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
regions -X- _ O
occupied -X- _ O
by -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
are -X- _ O
not -X- _ O
disjoint -X- _ O
when -X- _ O
applying -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

For -X- _ O
baseline -X- _ O
, -X- _ O
the -X- _ O
regions -X- _ O
occupied -X- _ O
by -X- _ O
rare -X- _ O
group -X- _ O
andthe -X- _ O
frequent -X- _ O
group -X- _ O
are -X- _ O
disjoint -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
refered -X- _ O
as -X- _ O
the -X- _ O
frequency -X- _ O
bias -X- _ O
problem -X- _ O
of -X- _ O
embeddings -X- _ O
( -X- _ O
Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
the -X- _ O
manipulating -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
can -X- _ O
alleviate -X- _ O
the -X- _ O
frequency -X- _ O
bias -X- _ O
problem -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
presents -X- _ O
the -X- _ O
plot -X- _ O
of -X- _ O
the -X- _ O
normalized -X- _ O
singular -X- _ O
value -X- _ O
of -X- _ O
embedding -X- _ O
matrix -X- _ O
for -X- _ O
MLE -X- _ B-MethodName
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

Slowly -X- _ O
decaying -X- _ O
singular -X- _ O
values -X- _ O
of -X- _ O
AGG -X- _ O
demonstrate -X- _ O
an -X- _ O
isotropic -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O

7 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
analyzed -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
concerning -X- _ O
the -X- _ O
representation -X- _ O
degeneration -X- _ O
problem -X- _ O
of -X- _ O
the -X- _ O
learned -X- _ O
embeddings -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
adaptive -X- _ O
gradient -X- _ O
gating -X- _ O
method -X- _ O
that -X- _ O
solves -X- _ O
the -X- _ O
problem -X- _ O
by -X- _ O
solely -X- _ O
handling -X- _ O
the -X- _ O
training -X- _ O
for -X- _ O
rare -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Experiments -X- _ O
and -X- _ O
qualitative -X- _ O
studies -X- _ O
in -X- _ O
various -X- _ O
tasks -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

Beyond -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
level -X- _ O
approximation -X- _ O
of -X- _ O
rarity -X- _ O
of -X- _ O
rare -X- _ O
tokens -X- _ O
which -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
addressing -X- _ O
multiple -X- _ O
levels -X- _ O
of -X- _ O
rarity -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
interesting -X- _ O
region -X- _ O
to -X- _ O
study -X- _ O
for -X- _ O
the -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Acknowledgements -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
Institute -X- _ O
of -X- _ O
Information -X- _ O
& -X- _ O
communications -X- _ O
Technology -X- _ O
Planning -X- _ O
& -X- _ O
Evaluation -X- _ O
( -X- _ O
IITP -X- _ O
) -X- _ O
grant -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
Korea -X- _ O
government -X- _ O
( -X- _ O
MSIT -X- _ O
) -X- _ O

[ -X- _ O
NO.2021 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
01343 -X- _ O
, -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
Graduate -X- _ O
School -X- _ O
Program -X- _ O
( -X- _ O
Seoul -X- _ O
National -X- _ O
University -X- _ O
) -X- _ O
] -X- _ O
, -X- _ O
the -X- _ O
BK21 -X- _ O
FOUR -X- _ O
program -X- _ O
of -X- _ O
the -X- _ O
Education -X- _ O
and -X- _ O
Research -X- _ O
Program -X- _ O
for -X- _ O
Future -X- _ O
ICT -X- _ O
Pioneers -X- _ O
, -X- _ O
Seoul -X- _ O
National -X- _ O
University -X- _ O
in -X- _ O
2022 -X- _ O
, -X- _ O
AIRS -X- _ O
Company -X- _ O
in -X- _ O
Hyundai -X- _ O
Motor -X- _ O
Company -X- _ O
& -X- _ O
Kia37 -X- _ O

Corporation -X- _ O
through -X- _ O
HMC -X- _ O
/ -X- _ O
KIA -X- _ O
- -X- _ O
SNU -X- _ O
AI -X- _ O
Consortium -X- _ O
Fund -X- _ O
, -X- _ O
and -X- _ O
SNU -X- _ O
- -X- _ O
Naver -X- _ O
Hyperscale -X- _ O
AI -X- _ O
Center -X- _ O
. -X- _ O

References -X- _ O
Eneko -X- _ O
Agirre -X- _ O
, -X- _ O
Enrique -X- _ O
Alfonseca -X- _ O
, -X- _ O
Keith -X- _ O
Hall -X- _ O
, -X- _ O
Jana -X- _ O
Kravalova -X- _ O
, -X- _ O
Marius -X- _ O
Pa¸ -X- _ O
sca -X- _ O
, -X- _ O
and -X- _ O
Aitor -X- _ O
Soroa -X- _ O
. -X- _ O
2009 -X- _ O
. -X- _ O

A -X- _ O
study -X- _ O
on -X- _ O
similarity -X- _ O
and -X- _ O
relatedness -X- _ O
using -X- _ O
distributional -X- _ O
and -X- _ O
WordNet -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
: -X- _ O
The -X- _ O
2009 -X- _ O
Annual -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
19–27 -X- _ O
, -X- _ O
Boulder -X- _ O
, -X- _ O
Colorado -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Sanjeev -X- _ O
Arora -X- _ O
, -X- _ O
Yuanzhi -X- _ O
Li -X- _ O
, -X- _ O
Yingyu -X- _ O
Liang -X- _ O
, -X- _ O
Tengyu -X- _ O
Ma -X- _ O
, -X- _ O
and -X- _ O
Andrej -X- _ O
Risteski -X- _ O
. -X- _ O

2016 -X- _ O
. -X- _ O

A -X- _ O
latent -X- _ O
variable -X- _ O
model -X- _ O
approach -X- _ O
to -X- _ O
PMI -X- _ O
- -X- _ O
based -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

Transactions -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
LinguisDzmitry -X- _ O
Bahdanau -X- _ O
, -X- _ O
Kyunghyun -X- _ O
Cho -X- _ O
, -X- _ O
and -X- _ O
Yoshua -X- _ O
Bengio -X- _ O
. -X- _ O

2015 -X- _ O
. -X- _ O

In -X- _ O
3rd -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2015 -X- _ O
, -X- _ O
San -X- _ O
Diego -X- _ O
, -X- _ O
CA -X- _ O
, -X- _ O
USA -X- _ O
, -X- _ O
May -X- _ O
7 -X- _ O
- -X- _ O
9 -X- _ O
, -X- _ O
2015 -X- _ O
, -X- _ O
Conference -X- _ O
Track -X- _ O
Proceedings -X- _ O
. -X- _ O

Yoshua -X- _ O
Bengio -X- _ O
, -X- _ O
Réjean -X- _ O
Ducharme -X- _ O
, -X- _ O
and -X- _ O
Pascal -X- _ O
Vincent -X- _ O
. -X- _ O
2000 -X- _ O
. -X- _ O

A -X- _ O
neural -X- _ O
probabilistic -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
13 -X- _ O
, -X- _ O
Papers -X- _ O
from -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
Press -X- _ O
. -X- _ O

Daniel -X- _ O
Bi -X- _ O
´ -X- _ O
s -X- _ O
, -X- _ O
Maksim -X- _ O
Podkorytov -X- _ O
, -X- _ O
and -X- _ O
Xiuwen -X- _ O
Liu -X- _ O
. -X- _ O

2021 -X- _ O
. -X- _ O

Too -X- _ O
much -X- _ O
in -X- _ O
common -X- _ O
: -X- _ O
Shifting -X- _ O
of -X- _ O
embeddings -X- _ O
in -X- _ O
transformer -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
its -X- _ O
implications -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
2021 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
pages -X- _ O
5117–5130 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Elia -X- _ O
Bruni -X- _ O
, -X- _ O
Nam -X- _ O
Khanh -X- _ O
Tran -X- _ O
, -X- _ O
and -X- _ O
Marco -X- _ O
Baroni -X- _ O
. -X- _ O

2014 -X- _ O
. -X- _ O

Multimodal -X- _ O
distributional -X- _ O
semantics -X- _ O
. -X- _ O

Journal -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
Research -X- _ O
. -X- _ O

David -X- _ O
Demeter -X- _ O
, -X- _ O
Gregory -X- _ O
Kimmel -X- _ O
, -X- _ O
and -X- _ O
Doug -X- _ O
Downey -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Stolen -X- _ O
probability -X- _ O
: -X- _ O
A -X- _ O
structural -X- _ O
weakness -X- _ O
of -X- _ O
neural -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
2191–2197 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Kawin -X- _ O
Ethayarajh -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

How -X- _ O
contextual -X- _ O
are -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
? -X- _ O

Comparing -X- _ O
the -X- _ O
geometry -X- _ O
of -X- _ O
BERT -X- _ O
, -X- _ O
ELMo -X- _ O
, -X- _ O
and -X- _ O
GPT-2 -X- _ O
embeddings -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2019 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
and -X- _ O
the -X- _ O
9th -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
- -X- _ O
IJCNLP -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
55–65 -X- _ O
, -X- _ O
Hong -X- _ O
Kong -X- _ O
, -X- _ O
China -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Jun -X- _ O
Gao -X- _ O
, -X- _ O
Di -X- _ O
He -X- _ O
, -X- _ O
Xu -X- _ O
Tan -X- _ O
, -X- _ O
Tao -X- _ O
Qin -X- _ O
, -X- _ O
Liwei -X- _ O
Wang -X- _ O
, -X- _ O
and -X- _ O
TieYan -X- _ O
Liu -X- _ O
. -X- _ O

2019 -X- _ O
. -X- _ O

Representation -X- _ O
degeneration -X- _ O
problem -X- _ O
in -X- _ O
training -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
7th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2019 -X- _ O
, -X- _ O
New -X- _ O
Orleans -X- _ O
, -X- _ O
LA -X- _ O
, -X- _ O
USA -X- _ O
, -X- _ O
May -X- _ O
6 -X- _ O
- -X- _ O
9 -X- _ O
, -X- _ O
2019 -X- _ O
. -X- _ O

OpenReview.net -X- _ O
. -X- _ O

Jonas -X- _ O
Gehring -X- _ O
, -X- _ O
Michael -X- _ O
Auli -X- _ O
, -X- _ O
David -X- _ O
Grangier -X- _ O
, -X- _ O
Denis -X- _ O
Yarats -X- _ O
, -X- _ O
and -X- _ O
Yann -X- _ O
N. -X- _ O
Dauphin -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Convolutional -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
learning -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
34th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
, -X- _ O
ICML -X- _ O
2017 -X- _ O
, -X- _ O
Sydney -X- _ O
, -X- _ O
NSW -X- _ O
, -X- _ O
Australia -X- _ O
, -X- _ O
6 -X- _ O
- -X- _ O
11 -X- _ O
August -X- _ O
2017 -X- _ O
, -X- _ O
volume -X- _ O
70 -X- _ O
of -X- _ O
Proceedings -X- _ O
of -X- _ O
Machine -X- _ O
Learning -X- _ O
Research -X- _ O
, -X- _ O
pages -X- _ O
1243–1252 -X- _ O
. -X- _ O

PMLR -X- _ O
. -X- _ O

ChengYue -X- _ O
Gong -X- _ O
, -X- _ O
Di -X- _ O
He -X- _ O
, -X- _ O
Xu -X- _ O
Tan -X- _ O
, -X- _ O
Tao -X- _ O
Qin -X- _ O
, -X- _ O
Liwei -X- _ O
Wang -X- _ O
, -X- _ O
and -X- _ O
Tie -X- _ O
- -X- _ O
Yan -X- _ O
Liu -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

FRAGE -X- _ O
: -X- _ O
frequencyagnostic -X- _ O
word -X- _ O
representation -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
31 -X- _ O
: -X- _ O
Annual -X- _ O
Conference -X- _ O
on -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
A. -X- _ O
Graves -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O

Generating -X- _ O
sequences -X- _ O
with -X- _ O
recurrent -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O

ArXiv -X- _ O
, -X- _ O
abs -X- _ O
/ -X- _ O
1308.0850 -X- _ O
. -X- _ O

Tianlin -X- _ O
Liu -X- _ O
, -X- _ O
Lyle -X- _ O
Ungar -X- _ O
, -X- _ O
and -X- _ O
João -X- _ O
Sedoc -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Unsupervised -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
of -X- _ O
word -X- _ O
vectors -X- _ O
via -X- _ O
conceptor -X- _ O
negation -X- _ O
. -X- _ O

In -X- _ O
The -X- _ O
Thirty -X- _ O
- -X- _ O
Third -X- _ O
AAAI -X- _ O
Conference -X- _ O
on -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
, -X- _ O
AAAI -X- _ O
2019 -X- _ O
, -X- _ O
The -X- _ O
ThirtyFirst -X- _ O
Innovative -X- _ O
Applications -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
Conference -X- _ O
, -X- _ O
IAAI -X- _ O
2019 -X- _ O
, -X- _ O
The -X- _ O
Ninth -X- _ O
AAAI -X- _ O
Symposium -X- _ O
on -X- _ O
Educational -X- _ O
Advances -X- _ O
in -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
, -X- _ O
EAAI -X- _ O
2019 -X- _ O
, -X- _ O
Honolulu -X- _ O
, -X- _ O
Hawaii -X- _ O
, -X- _ O
USA -X- _ O
, -X- _ O
January -X- _ O
27 -X- _ O
Thang -X- _ O
Luong -X- _ O
, -X- _ O
Richard -X- _ O
Socher -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
Manning -X- _ O
. -X- _ O

2013 -X- _ O
. -X- _ O

Better -X- _ O
word -X- _ O
representations -X- _ O
with -X- _ O
recursive -X- _ O
neural -X- _ O
networks -X- _ O
for -X- _ O
morphology -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Seventeenth -X- _ O
Conference -X- _ O
on -X- _ O
Computational -X- _ O
Natural -X- _ O
Language -X- _ O
Learning -X- _ O
, -X- _ O
pages -X- _ O
104–113 -X- _ O
, -X- _ O
Sofia -X- _ O
, -X- _ O
Bulgaria -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Stephen -X- _ O
Merity -X- _ O
, -X- _ O
Nitish -X- _ O
Shirish -X- _ O
Keskar -X- _ O
, -X- _ O
and -X- _ O
Richard -X- _ O
Socher -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

Regularizing -X- _ O
and -X- _ O
optimizing -X- _ O
LSTM -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
6th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2018 -X- _ O
, -X- _ O
Vancouver -X- _ O
, -X- _ O
BC -X- _ O
, -X- _ O
Canada -X- _ O
, -X- _ O
April -X- _ O
30 -X- _ O
- -X- _ O
May -X- _ O
3 -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
Conference -X- _ O
Track -X- _ O
Proceedings -X- _ O
. -X- _ O

OpenReview.net -X- _ O
. -X- _ O

Stephen -X- _ O
Merity -X- _ O
, -X- _ O
Caiming -X- _ O
Xiong -X- _ O
, -X- _ O
James -X- _ O
Bradbury -X- _ O
, -X- _ O
and -X- _ O
Richard -X- _ O
Socher -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Pointer -X- _ O
sentinel -X- _ O
mixture -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
5th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2017 -X- _ O
, -X- _ O
Toulon -X- _ O
, -X- _ O
France -X- _ O
, -X- _ O
April -X- _ O
24 -X- _ O
- -X- _ O
26 -X- _ O
, -X- _ O
2017 -X- _ O
, -X- _ O
Conference -X- _ O
Track -X- _ O
Proceedings -X- _ O
. -X- _ O

OpenReview.net -X- _ O
. -X- _ O

Jiaqi -X- _ O
Mu -X- _ O
and -X- _ O
Pramod -X- _ O
Viswanath -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

All -X- _ O
- -X- _ O
but -X- _ O
- -X- _ O
thetop -X- _ O
: -X- _ O
Simple -X- _ O
and -X- _ O
effective -X- _ O
postprocessing -X- _ O
for -X- _ O
word -X- _ O
representations -X- _ O
. -X- _ O

In -X- _ O
6th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2018 -X- _ O
, -X- _ O
Vancouver -X- _ O
, -X- _ O
BC -X- _ O
, -X- _ O
Canada -X- _ O
, -X- _ O
April -X- _ O
30 -X- _ O
- -X- _ O
May -X- _ O
3 -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
Conference -X- _ O
Track -X- _ O
Proceedings -X- _ O
. -X- _ O

OpenReview.net.38 -X- _ O

Myle -X- _ O
Ott -X- _ O
, -X- _ O
Michael -X- _ O
Auli -X- _ O
, -X- _ O
David -X- _ O
Grangier -X- _ O
, -X- _ O
and -X- _ O
Marc’Aurelio -X- _ O
Ranzato -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

Analyzing -X- _ O
uncertainty -X- _ O
in -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
35th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
, -X- _ O
ICML -X- _ O
2018 -X- _ O
, -X- _ O
Stockholmsmässan -X- _ O
, -X- _ O
Stockholm -X- _ O
, -X- _ O
Sweden -X- _ O
, -X- _ O
July -X- _ O
10 -X- _ O
- -X- _ O
15 -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
volume -X- _ O
80 -X- _ O
of -X- _ O
Proceedings -X- _ O
of -X- _ O
Machine -X- _ O
Learning -X- _ O
Research -X- _ O
, -X- _ O
pages -X- _ O
3953–3962 -X- _ O
. -X- _ O

PMLR -X- _ O
. -X- _ O

Kishore -X- _ O
Papineni -X- _ O
, -X- _ O
Salim -X- _ O
Roukos -X- _ O
, -X- _ O
Todd -X- _ O
Ward -X- _ O
, -X- _ O
and -X- _ O
WeiJing -X- _ O
Zhu -X- _ O
. -X- _ O
2002 -X- _ O
. -X- _ O

Bleu -X- _ O
: -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
automatic -X- _ O
evaluation -X- _ O
of -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
40th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
311–318 -X- _ O
, -X- _ O
Philadelphia -X- _ O
, -X- _ O
Pennsylvania -X- _ O
, -X- _ O
USA -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Adam -X- _ O
Paszke -X- _ O
, -X- _ O
Sam -X- _ O
Gross -X- _ O
, -X- _ O
Francisco -X- _ O
Massa -X- _ O
, -X- _ O
Adam -X- _ O
Lerer -X- _ O
, -X- _ O
James -X- _ O
Bradbury -X- _ O
, -X- _ O
Gregory -X- _ O
Chanan -X- _ O
, -X- _ O
Trevor -X- _ O
Killeen -X- _ O
, -X- _ O
Zeming -X- _ O
Lin -X- _ O
, -X- _ O
Natalia -X- _ O
Gimelshein -X- _ O
, -X- _ O
Luca -X- _ O
Antiga -X- _ O
, -X- _ O
Alban -X- _ O
Desmaison -X- _ O
, -X- _ O
Andreas -X- _ O
Köpf -X- _ O
, -X- _ O
Edward -X- _ O
Yang -X- _ O
, -X- _ O
Zachary -X- _ O
DeVito -X- _ O
, -X- _ O
Martin -X- _ O
Raison -X- _ O
, -X- _ O
Alykhan -X- _ O
Tejani -X- _ O
, -X- _ O
Sasank -X- _ O
Chilamkurthy -X- _ O
, -X- _ O
Benoit -X- _ O
Steiner -X- _ O
, -X- _ O
Lu -X- _ O
Fang -X- _ O
, -X- _ O
Junjie -X- _ O
Bai -X- _ O
, -X- _ O
and -X- _ O
Soumith -X- _ O
Chintala -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Pytorch -X- _ O
: -X- _ O

An -X- _ O
imperative -X- _ O
style -X- _ O
, -X- _ O
high -X- _ O
- -X- _ O
performance -X- _ O
deep -X- _ O
learning -X- _ O
library -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
32 -X- _ O
: -X- _ O
Annual -X- _ O
Conference -X- _ O
on -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
2019 -X- _ O
, -X- _ O
NeurIPS -X- _ O
2019 -X- _ O
, -X- _ O
December -X- _ O
8 -X- _ O
- -X- _ O
14 -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
Vancouver -X- _ O
, -X- _ O
BC -X- _ O
, -X- _ O
Canada -X- _ O
, -X- _ O
pages -X- _ O
Ofir -X- _ O
Press -X- _ O
and -X- _ O
Lior -X- _ O
Wolf -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O

Using -X- _ O
the -X- _ O
output -X- _ O
embedding -X- _ O
to -X- _ O
improve -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
15th -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
European -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Volume -X- _ O
2 -X- _ O
, -X- _ O
Short -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
157–163 -X- _ O
, -X- _ O
Valencia -X- _ O
, -X- _ O
Spain -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Alec -X- _ O
Radford -X- _ O
, -X- _ O
Jeff -X- _ O
Wu -X- _ O
, -X- _ O
Rewon -X- _ O
Child -X- _ O
, -X- _ O
David -X- _ O
Luan -X- _ O
, -X- _ O
Dario -X- _ O
Amodei -X- _ O
, -X- _ O
and -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Language -X- _ O
models -X- _ O
are -X- _ O
unsupervised -X- _ O
multitask -X- _ O
learners -X- _ O
. -X- _ O

Sara -X- _ O
Rajaee -X- _ O
and -X- _ O
Mohammad -X- _ O
Taher -X- _ O
Pilehvar -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

A -X- _ O
cluster -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
for -X- _ O
improving -X- _ O
isotropy -X- _ O
in -X- _ O
contextual -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
59th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
and -X- _ O
the -X- _ O
11th -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
Volume -X- _ O
2 -X- _ O
: -X- _ O
Short -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
575–584 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Herbert -X- _ O
Rubenstein -X- _ O
and -X- _ O
John -X- _ O
Goodenough -X- _ O
. -X- _ O
1965 -X- _ O
. -X- _ O

Contextual -X- _ O
correlates -X- _ O
of -X- _ O
synonymy -X- _ O
. -X- _ O

Commun -X- _ O
. -X- _ O

ACM -X- _ O
, -X- _ O
Rico -X- _ O
Sennrich -X- _ O
, -X- _ O
Barry -X- _ O
Haddow -X- _ O
, -X- _ O
and -X- _ O
Alexandra -X- _ O
Birch -X- _ O
. -X- _ O

2016 -X- _ O
. -X- _ O

Neural -X- _ O
machine -X- _ O
translation -X- _ O
of -X- _ O
rare -X- _ O
words -X- _ O
with -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
54th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
1715–1725 -X- _ O
, -X- _ O
Berlin -X- _ O
, -X- _ O
Germany -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Ashish -X- _ O
Vaswani -X- _ O
, -X- _ O
Noam -X- _ O
Shazeer -X- _ O
, -X- _ O
Niki -X- _ O
Parmar -X- _ O
, -X- _ O
Jakob -X- _ O
Uszkoreit -X- _ O
, -X- _ O
Llion -X- _ O
Jones -X- _ O
, -X- _ O
Aidan -X- _ O
N. -X- _ O
Gomez -X- _ O
, -X- _ O
Lukasz -X- _ O
Kaiser -X- _ O
, -X- _ O
and -X- _ O
Illia -X- _ O
Polosukhin -X- _ O
. -X- _ O

2017 -X- _ O
. -X- _ O

Attention -X- _ O
is -X- _ O
allyou -X- _ O
need -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
30 -X- _ O
: -X- _ O
Annual -X- _ O
Conference -X- _ O
on -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
2017 -X- _ O
, -X- _ O
December -X- _ O
4 -X- _ O
- -X- _ O
9 -X- _ O
, -X- _ O
Dilin -X- _ O
Wang -X- _ O
, -X- _ O
Chengyue -X- _ O
Gong -X- _ O
, -X- _ O
and -X- _ O
Qiang -X- _ O
Liu -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Improving -X- _ O
neural -X- _ O
language -X- _ O
modeling -X- _ O
via -X- _ O
adversarial -X- _ O
training -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
36th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
, -X- _ O
volume -X- _ O
97 -X- _ O
of -X- _ O
Proceedings -X- _ O
of -X- _ O
Machine -X- _ O
Learning -X- _ O
Research -X- _ O
, -X- _ O
pages -X- _ O
6555 -X- _ O
– -X- _ O
Lingxiao -X- _ O
Wang -X- _ O
, -X- _ O
Jing -X- _ O
Huang -X- _ O
, -X- _ O
Kevin -X- _ O
Huang -X- _ O
, -X- _ O
Ziniu -X- _ O
Hu -X- _ O
, -X- _ O
Guangtao -X- _ O
Wang -X- _ O
, -X- _ O
and -X- _ O
Quanquan -X- _ O
Gu -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Improving -X- _ O
neural -X- _ O
language -X- _ O
generation -X- _ O
with -X- _ O
spectrum -X- _ O
control -X- _ O
. -X- _ O

In8th -X- _ O

International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2020 -X- _ O
, -X- _ O
Addis -X- _ O
Ababa -X- _ O
, -X- _ O
Ethiopia -X- _ O
, -X- _ O
April -X- _ O
Sean -X- _ O
Welleck -X- _ O
, -X- _ O
Ilia -X- _ O
Kulikov -X- _ O
, -X- _ O
Stephen -X- _ O
Roller -X- _ O
, -X- _ O
Emily -X- _ O
Dinan -X- _ O
, -X- _ O
Kyunghyun -X- _ O
Cho -X- _ O
, -X- _ O
and -X- _ O
Jason -X- _ O
Weston -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

Neural -X- _ O
text -X- _ O
generation -X- _ O
with -X- _ O
unlikelihood -X- _ O
training -X- _ O
. -X- _ O

In -X- _ O
8th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2020 -X- _ O
, -X- _ O
Addis -X- _ O
Ababa -X- _ O
, -X- _ O
Ethiopia -X- _ O
, -X- _ O
April -X- _ O
Zhilin -X- _ O
Yang -X- _ O
, -X- _ O
Zihang -X- _ O
Dai -X- _ O
, -X- _ O
Ruslan -X- _ O
Salakhutdinov -X- _ O
, -X- _ O
and -X- _ O
William -X- _ O
W. -X- _ O
Cohen -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

Breaking -X- _ O
the -X- _ O
softmax -X- _ O
bottleneck -X- _ O
: -X- _ O
A -X- _ O
high -X- _ O
- -X- _ O
rank -X- _ O
RNN -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
6th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
, -X- _ O
ICLR -X- _ O
2018 -X- _ O
, -X- _ O
Vancouver -X- _ O
, -X- _ O
BC -X- _ O
, -X- _ O
Canada -X- _ O
, -X- _ O
April -X- _ O
30 -X- _ O
May -X- _ O
3 -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
Conference -X- _ O
Track -X- _ O
Proceedings -X- _ O
. -X- _ O

OpenReview.net -X- _ O
. -X- _ O

Zhong -X- _ O
Zhang -X- _ O
, -X- _ O
Chongming -X- _ O
Gao -X- _ O
, -X- _ O
Cong -X- _ O
Xu -X- _ O
, -X- _ O
Rui -X- _ O
Miao -X- _ O
, -X- _ O
Qinli -X- _ O
Yang -X- _ O
, -X- _ O
and -X- _ O
Junming -X- _ O
Shao -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Revisiting -X- _ O
representation -X- _ O
degeneration -X- _ O
problem -X- _ O
in -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O

In -X- _ O
Findings -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
EMNLP -X- _ O
2020 -X- _ O
, -X- _ O
pages -X- _ O
518–527 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Tianyuan -X- _ O
Zhou -X- _ O
, -X- _ O
João -X- _ O
Sedoc -X- _ O
, -X- _ O
and -X- _ O
Jordan -X- _ O
Rodu -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Getting -X- _ O
in -X- _ O
shape -X- _ O
: -X- _ O
Word -X- _ O
embedding -X- _ O
subspaces -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Twenty -X- _ O
- -X- _ O
Eighth -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
, -X- _ O
IJCAI -X- _ O
2019 -X- _ O
, -X- _ O

A -X- _ O
Derivation -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
AGG -X- _ O
loss -X- _ O
w.r.t -X- _ O
. -X- _ O

rare -X- _ O
token -X- _ O
embedding -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
notation -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
. -X- _ O

Before -X- _ O
we -X- _ O
write -X- _ O
the -X- _ O
derivation -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
about -X- _ O
rare -X- _ O
token -X- _ O
embedding -X- _ O
wr -X- _ O
, -X- _ O
we -X- _ O
write -X- _ O
the -X- _ O
gradient -X- _ O
off -X- _ O
( -X- _ O
˜wj -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
zl -X- _ O
i -X- _ O
) -X- _ O
jabout -X- _ O
wr -X- _ O
, -X- _ O
where -X- _ O
f -X- _ O
( -X- _ O
˜wj -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
function -X- _ O
of -X- _ O
˜wjwithj= -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
N -X- _ O
and -X- _ O
( -X- _ O
zl -X- _ O
i -X- _ O
) -X- _ O
jis -X- _ O
aj -X- _ O
- -X- _ O
th -X- _ O
component -X- _ O
of -X- _ O
zl -X- _ O
iwithl= -X- _ O
0,1,2as -X- _ O
follows -X- _ O
. -X- _ O

= -X- _ O
0for -X- _ O
all -X- _ O
j -X- _ O
( -X- _ O
∵˜wjis -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
constant -X- _ O
. -X- _ O
) -X- _ O

( -X- _ O
11 -X- _ O
) -X- _ O
∇wr -X- _ O
( -X- _ O
zl -X- _ O
i -X- _ O
) -X- _ O
j=∇wr -X- _ O
[ -X- _ O
glj·˜hiwT -X- _ O
j+ -X- _ O
( -X- _ O
1−glj·˜hi˜wT -X- _ O
= -X- _ O
glj∇wr˜hiwT -X- _ O
glj˜hiifj -X- _ O
= -X- _ O
r -X- _ O
0 -X- _ O
else -X- _ O
gljhiifj -X- _ O
= -X- _ O
r -X- _ O
0 -X- _ O
else -X- _ O
( -X- _ O
∵hi=˜hiin -X- _ O
terms -X- _ O
of -X- _ O
value -X- _ O
. -X- _ O
) -X- _ O

Considering -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
yi -X- _ O
/ -X- _ O
∈Vr -X- _ O
, -X- _ O
AGG -X- _ O
negative -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
of -X- _ O
token -X- _ O
generation -X- _ O
, -X- _ O
LAGG -X- _ O
i -X- _ O
is -X- _ O
written -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

LAGG -X- _ O
i -X- _ O
= -X- _ O
−logp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i−logp1 -X- _ O

Then -X- _ O
gradient -X- _ O
of -X- _ O
LAGG -X- _ O
i -X- _ O
about -X- _ O
wris -X- _ O
written -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLAGG -X- _ O
i -X- _ O
= -X- _ O
−∇ -X- _ O
wrlogp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i− -X- _ O
∇ -X- _ O
wrlogp1 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O

= -X- _ O
−∇ -X- _ O
wrlogp1 -X- _ O
( -X- _ O
∵logp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|iis -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
˜wr -X- _ O
. -X- _ O
) -X- _ O

p1 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i∇wrp1 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O
p1 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|iNX -X- _ O
i -X- _ O
) -X- _ O
jp1 -X- _ O
i -X- _ O
) -X- _ O
j -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|iis -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
( -X- _ O
z1 -X- _ O
p1 -X- _ O
i -X- _ O
) -X- _ O
rp1 -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i= -X- _ O
[ -X- _ O
softmax -X- _ O
( -X- _ O
z1 -X- _ O
i -X- _ O
) -X- _ O
rp1 -X- _ O

I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|ip1 -X- _ O
Thus -X- _ O
, -X- _ O
∇wrLAGG -X- _ O

i -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLAGG -X- _ O
i -X- _ O
p1 -X- _ O
i -X- _ O
) -X- _ O
rp1 -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
= -X- _ O
g1rp1 -X- _ O
r|ihi -X- _ O
Considering -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
yi∈Vrbutyi̸=vr -X- _ O
, -X- _ O
LAGG -X- _ O
i -X- _ O
is -X- _ O
written -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

LAGG -X- _ O
i -X- _ O
= -X- _ O
−logp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i−logp2 -X- _ O

Then∇wrLAGG -X- _ O
i -X- _ O
is -X- _ O
written -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLAGG -X- _ O
i -X- _ O
= -X- _ O
−∇ -X- _ O
wrlogp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i− -X- _ O
∇ -X- _ O
wrlogp2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O

= -X- _ O
−∇ -X- _ O
wrlogp2 -X- _ O
( -X- _ O
∵logp0 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|iis -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
˜wr -X- _ O
. -X- _ O
) -X- _ O

p2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i∇wrp2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O
p2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|iNX -X- _ O

i -X- _ O
) -X- _ O
jp2 -X- _ O
i -X- _ O
) -X- _ O
j -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|iis -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
( -X- _ O
z2 -X- _ O
p2 -X- _ O
i -X- _ O
) -X- _ O
rp2 -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
Asp2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i= -X- _ O
[ -X- _ O
softmax -X- _ O
( -X- _ O
z2 -X- _ O
i -X- _ O
) -X- _ O
rp2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|ip2 -X- _ O

Thus -X- _ O
, -X- _ O
∇wrLAGG -X- _ O
i -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLAGG -X- _ O
i -X- _ O
p2 -X- _ O
i -X- _ O
) -X- _ O
rp2 -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
= -X- _ O
g2rp2 -X- _ O
r|ihi -X- _ O

Considering -X- _ O
the -X- _ O
remained -X- _ O
case -X- _ O
of -X- _ O
yi -X- _ O
= -X- _ O
vr -X- _ O
, -X- _ O
since -X- _ O
yi∈Vr -X- _ O
, -X- _ O
LAGG -X- _ O
i -X- _ O
is -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
second -X- _ O
case -X- _ O
, -X- _ O
and -X- _ O
derivation -X- _ O
process -X- _ O
of -X- _ O
∇wrLAGG -X- _ O
i -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
process -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
18 -X- _ O
. -X- _ O

As -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
= -X- _ O
r -X- _ O
, -X- _ O
i -X- _ O
) -X- _ O
rp2 -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O
= -X- _ O
p2 -X- _ O
Thus -X- _ O
, -X- _ O
∇wrLAGG -X- _ O

i -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLAGG -X- _ O
i -X- _ O
p2 -X- _ O
i -X- _ O
) -X- _ O
rp2 -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
i -X- _ O
) -X- _ O
r -X- _ O
I -X- _ O
( -X- _ O
yi -X- _ O
) -X- _ O
|i -X- _ O
) -X- _ O
hi -X- _ O
r|i−1 -X- _ O
) -X- _ O
hi -X- _ O
Aspr|i -X- _ O
= -X- _ O
pm -X- _ O
r|iwithm= -X- _ O
0,1,2 -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
value -X- _ O
, -X- _ O
we -X- _ O
finally -X- _ O
write -X- _ O
∇wrLAGG -X- _ O
i -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O

∇wrLi= -X- _ O
 -X- _ O
( -X- _ O
pr|i−1 -X- _ O
) -X- _ O
hiifyi -X- _ O
= -X- _ O
vr -X- _ O
g1rpr|ihi -X- _ O
ifyi -X- _ O
/ -X- _ O
∈Vr -X- _ O
g2rpr|ihi -X- _ O
else -X- _ O
, -X- _ O
( -X- _ O
23 -X- _ O
) -X- _ O

B -X- _ O
Experimental -X- _ O
Details -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
experiments -X- _ O
in -X- _ O
main -X- _ O
page -X- _ O
. -X- _ O

All -X- _ O
the -X- _ O
experiments -X- _ O
were -X- _ O
conducted -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
on -X- _ O
our -X- _ O
machine -X- _ O
( -X- _ O
GPU -X- _ O
: -X- _ O
NVIDIA -X- _ O
A40 -X- _ O
) -X- _ O
and -X- _ O
from -X- _ O
single -X- _ O
run -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
train -X- _ O
it -X- _ O
with -X- _ O
different -X- _ O
objectives -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
MLE -X- _ O
, -X- _ O
AGG -X- _ O
, -X- _ O
UL -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
used -X- _ O
for -X- _ O
different -X- _ O
training -X- _ O
methods -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
task -X- _ O
are -X- _ O
exactly -X- _ O
same -X- _ O
. -X- _ O

The -X- _ O
detailed -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
Table -X- _ O
12 -X- _ O
. -X- _ O

C -X- _ O
Experimental -X- _ O
Results -X- _ O
of -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
frequency -X- _ O
groups -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
about -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
each -X- _ O
frequency -X- _ O
groups -X- _ O
. -X- _ O

Table -X- _ O
10 -X- _ O
shows -X- _ O
the -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
comparing -X- _ O
MLE -X- _ B-MethodName
baseline -X- _ O
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

Table -X- _ O
11 -X- _ O
shows -X- _ O
the -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
comparing -X- _ O
UL -X- _ B-MethodName
baseline -X- _ O
and -X- _ O
the -X- _ O
fusion -X- _ O
of -X- _ O
UL -X- _ B-MethodName
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

As -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
and -X- _ O
11 -X- _ O
, -X- _ O
AGG -X- _ B-MethodName
improves -X- _ O
isotropy -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
for -X- _ O
all -X- _ O
frequency -X- _ O
groups -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
solves -X- _ O
the -X- _ O
whole -X- _ O
degeneration -X- _ O
problem -X- _ O
. -X- _ O

MethodsI -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑ -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Table -X- _ O
10 -X- _ O
: -X- _ O
Experimental -X- _ O
results -X- _ O
about -X- _ O
I -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
in -X- _ O
WikiText-103 -X- _ B-DatasetName
language -X- _ O
modeling -X- _ O
task -X- _ O
comparing -X- _ O
MLE -X- _ B-MethodName
baseline -X- _ O
and -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

MethodsI -X- _ O
( -X- _ O
W -X- _ O
) -X- _ O
↑ -X- _ O
Freq -X- _ O
Med -X- _ O
Rare -X- _ O
Table -X- _ O
11 -X- _ O
: -X- _ O
Experimental -X- _ O
results -X- _ O
about -X- _ O
I -X- _ B-DatasetName
( -X- _ I-DatasetName
W -X- _ I-DatasetName
) -X- _ I-DatasetName
for -X- _ O
each -X- _ O
token -X- _ O
group -X- _ O
in -X- _ O
WikiText-103 -X- _ B-DatasetName
language -X- _ O
modeling -X- _ O
task -X- _ O
comparing -X- _ O
UL -X- _ B-MethodName
baseline -X- _ O
and -X- _ O
UL -X- _ B-MethodName
+ -X- _ O
AGG -X- _ B-MethodName
. -X- _ O

D -X- _ O
Hyperparameter -X- _ O
Sensitivity -X- _ O
In -X- _ O
this -X- _ O
sections -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
metrics -X- _ O
used -X- _ O
on -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
change -X- _ O
with -X- _ O
the -X- _ O
hyperparameter -X- _ O
αin -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O

We -X- _ O
observed -X- _ O
an -X- _ O
interesting -X- _ O
phenomenon -X- _ O
about -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
when -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
size -X- _ O
increases -X- _ O
over -X- _ O
a -X- _ O
specific -X- _ O
threshold -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
, -X- _ O
Uniq -X- _ B-MetricName
and -X- _ O
I -X- _ B-MetricName
( -X- _ I-MetricName
W -X- _ I-MetricName
) -X- _ I-MetricName
metrics -X- _ O
have -X- _ O
a -X- _ O
positive -X- _ O
correlation -X- _ O
. -X- _ O

They -X- _ O
increase -X- _ O
together -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
alpha -X- _ O
value -X- _ O
and -X- _ O
decrease -X- _ O
together -X- _ O
as -X- _ O
alpha -X- _ O
increases -X- _ O
over -X- _ O
that -X- _ O
value -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
, -X- _ O
Uniq -X- _ O
increases -X- _ O
as -X- _ O
alpha -X- _ O
increases -X- _ O
over -X- _ O
that -X- _ O
certain -X- _ O
value -X- _ O
while -X- _ O
there -X- _ O
are -X- _ O
negative -X- _ O
effects -X- _ O
where -X- _ O
I -X- _ B-MetricName
( -X- _ I-MetricName
W -X- _ I-MetricName
) -X- _ I-MetricName
decreases -X- _ O
and -X- _ O
Ppl -X- _ O
increases -X- _ O
. -X- _ O

Because -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
tokens -X- _ O
are -X- _ O
a -X- _ O
major -X- _ O
group -X- _ O
, -X- _ O
Figure -X- _ O
5 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
present -X- _ O
the -X- _ O
above -X- _ O
phenomenon -X- _ O
about -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
although -X- _ O
they -X- _ O
present -X- _ O
metrics -X- _ O
for -X- _ O
overall -X- _ O
tokens -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
this -X- _ O
phenomenon -X- _ O
to -X- _ O
be -X- _ O
another -X- _ O
degeneration -X- _ O
problem -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
increase -X- _ O
of -X- _ O
Uniq -X- _ O
with -X- _ O
negative -X- _ O
impacts -X- _ O
on -X- _ O
isotropy -X- _ O
and -X- _ O
likelihood -X- _ O
does -X- _ O
not -X- _ O
imply -X- _ O
improvement -X- _ O
of -X- _ O
text -X- _ O
quality -X- _ O
, -X- _ O
implying -X- _ O
just -X- _ O
generation -X- _ O
of -X- _ O
unproper -X- _ O
tokens -X- _ O
. -X- _ O

This -X- _ O
problem -X- _ O
which -X- _ O
occurs -X- _ O
when -X- _ O
rare -X- _ O
token -X- _ O
group -X- _ O
size -X- _ O
increases -X- _ O
over -X- _ O
a -X- _ O
certain -X- _ O
threshold -X- _ O
can -X- _ O
be -X- _ O
handled -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

E -X- _ O
Qualitative -X- _ O
Study -X- _ O
about -X- _ O
Semantic -X- _ O
Alignments -X- _ O
between -X- _ O
Tokens -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
qualitative -X- _ O
studies -X- _ O
about -X- _ O
semantic -X- _ O
alignments -X- _ O
between -X- _ O
tokens -X- _ O
for -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
select -X- _ O
three -X- _ O
rare -X- _ O
token -X- _ O
from -X- _ O
each -X- _ O
datasets -X- _ O
: -X- _ O
" -X- _ O
homepage -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
Werewolf -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
policymakers -X- _ O
" -X- _ O
for -X- _ O
WikiText-10341 -X- _ B-DatasetName

dataset -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
optimum -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
criminal -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
" -X- _ O
happiness -X- _ O
" -X- _ O
for -X- _ O
WMT14 -X- _ O
En -X- _ O
→De -X- _ O
dataset -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
rare -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
top-5 -X- _ O
nearest -X- _ O
neighbor -X- _ O
token -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
cosine -X- _ O
distance -X- _ O
between -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Compared -X- _ O
with -X- _ O
baseline -X- _ O
MLE -X- _ B-MethodName
method -X- _ O
, -X- _ O
AGG -X- _ B-MethodName
shows -X- _ O
significant -X- _ O
improvement -X- _ O
to -X- _ O
train -X- _ O
semantic -X- _ O
alignments -X- _ O
for -X- _ O
rare -X- _ O
tokens -X- _ O
. -X- _ O

From -X- _ O
Table -X- _ O
13 -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
the -X- _ O
rare -X- _ O
tokens -X- _ O
trained -X- _ O
with -X- _ O
AGG -X- _ B-MethodName
are -X- _ O
semantically -X- _ O
well -X- _ O
aligned -X- _ O
and -X- _ O
not -X- _ O
biased -X- _ O
about -X- _ O
token -X- _ O
frequency -X- _ O
. -X- _ O

Table -X- _ O
14 -X- _ O
demonstrates -X- _ O
that -X- _ O
token -X- _ O
embeddings -X- _ O
trained -X- _ O
with -X- _ O
AGG -X- _ B-MethodName
also -X- _ O
learn -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
semantic -X- _ O
alignments -X- _ O
between -X- _ O
target -X- _ O
language -X- _ O
tokens -X- _ O
. -X- _ O

F -X- _ O
Examples -X- _ O
We -X- _ O
present -X- _ O
additional -X- _ O
generated -X- _ O
text -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
in -X- _ O
Table -X- _ O
15 -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
AGG -X- _ B-MethodName
generates -X- _ O
more -X- _ O
diverse -X- _ O
and -X- _ O
high -X- _ O
quality -X- _ O
text -X- _ O
than -X- _ O
the -X- _ O
baseline.42 -X- _ O

Hyperparameter -X- _ O
Empirical -X- _ O
Study -X- _ O
Language -X- _ O
ModelingMachine -X- _ O
Translation -X- _ O
Base -X- _ O
Big -X- _ O
Max -X- _ O
tokens -X- _ O
per -X- _ O
batch -X- _ O
32k -X- _ O
32k -X- _ O
64k -X- _ O
64k -X- _ O
Maximum -X- _ O
training -X- _ O
steps -X- _ O
40k -X- _ O
50k -X- _ O
190k -X- _ O
190k -X- _ O
Warmup -X- _ O
steps -X- _ O
4k -X- _ O
4k -X- _ O
4k -X- _ O
4k -X- _ O
Optimizer -X- _ O
Adam -X- _ O
Adam -X- _ O
Adam -X- _ O
Adam -X- _ O
Table -X- _ O
12 -X- _ O
: -X- _ O
Model -X- _ O
configurations -X- _ O
and -X- _ O
training -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
for -X- _ O
all -X- _ O
experiments -X- _ O
conducted -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
page -X- _ O
. -X- _ O

For -X- _ O
word -X- _ O
similarity -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
are -X- _ O
evaluated -X- _ O
for -X- _ O
word -X- _ O
similarity -X- _ O
datasets -X- _ O
. -X- _ O

( -X- _ O
a -X- _ O
) -X- _ O
Perplexity -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
Uniq -X- _ O
Figure -X- _ O
5 -X- _ O
: -X- _ O
Hyper -X- _ O
- -X- _ O
parameter -X- _ O
( -X- _ O
α -X- _ O
) -X- _ O
sensitivity -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
in -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
on -X- _ O
Wikitext-103 -X- _ B-DatasetName
dataset.43 -X- _ O

homepage -X- _ O
Werewolf -X- _ O
policymakers -X- _ O
MLE -X- _ O
AGG -X- _ O
MLE -X- _ O
AGG -X- _ O
MLE -X- _ O
AGG -X- _ O
BOX -X- _ O
website -X- _ O
ASUS -X- _ O
Creature -X- _ O
Steam -X- _ O
politicians -X- _ O
inbox -X- _ O
webpage -X- _ O
riet -X- _ O
Nightmare -X- _ O
death -X- _ O
environmentalists -X- _ O
livestream -X- _ O
blog -X- _ O
480 -X- _ O
Bride -X- _ O
Venezuel -X- _ O
activists -X- _ O
namespace -X- _ O
Tumblr -X- _ O
nuclear -X- _ O
Sneak -X- _ O
includ -X- _ O
planners -X- _ O
hashes -X- _ O
websites -X- _ O

ATCH -X- _ O
Sniper -X- _ O
reason -X- _ O
economists -X- _ O
Table -X- _ O
13 -X- _ O
: -X- _ O
Top-5 -X- _ O
nearest -X- _ O
neighbors -X- _ O
of -X- _ O
each -X- _ O
rare -X- _ O
tokens -X- _ O
in -X- _ O
WikiText-103 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Performance -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
method -X- _ O
is -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
baseline -X- _ O
MLE -X- _ B-MethodName
method -X- _ O
. -X- _ O

Red -X- _ O
color -X- _ O
denotes -X- _ O
the -X- _ O
rare -X- _ O
tokens -X- _ O
among -X- _ O
neighbors -X- _ O
. -X- _ O

optimum -X- _ O
criminal -X- _ O
happiness -X- _ O
MLE -X- _ B-MethodName
AGG -X- _ B-MethodName
MLE -X- _ B-MethodName
AGG -X- _ B-MethodName
MLE -X- _ B-MethodName
AGG -X- _ B-MethodName
therto -X- _ O
optimal -X- _ O
Criminal -X- _ O
criminals -X- _ O
juries -X- _ O
happy -X- _ O
ratory -X- _ O
optimale∗criminals -X- _ O
Criminal -X- _ O
enness -X- _ O
joy -X- _ O
consultan -X- _ O
@ -X- _ O
@ -X- _ O

optimalen∗perpetr -X- _ O
@ -X- _ O
@ -X- _ O
krimi -X- _ O
@ -X- _ O
@ -X- _ O
∗ocopying -X- _ O
happ -X- _ O
@ -X- _ O
@ -X- _ O
sofar -X- _ O
maximum -X- _ O
secution -X- _ O
kriminellen∗ratory -X- _ O
Glück∗ -X- _ O
protection -X- _ O
@ -X- _ O
@ -X- _ O
Optim -X- _ O
@ -X- _ O
@ -X- _ O
xious -X- _ O
crime -X- _ O
sacri -X- _ O
@ -X- _ O
@ -X- _ O
pleasure -X- _ O
Table -X- _ O
14 -X- _ O
: -X- _ O

Top-5 -X- _ O
nearest -X- _ O
neighbors -X- _ O
of -X- _ O
each -X- _ O
rare -X- _ O
source -X- _ O
tokens -X- _ O
in -X- _ O
WMT14 -X- _ O

En -X- _ O
→De -X- _ O
dataset -X- _ O
. -X- _ O

Performance -X- _ O
of -X- _ O
AGG -X- _ B-MethodName
method -X- _ O
is -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
baseline -X- _ O
MLE -X- _ B-MethodName
method -X- _ O
. -X- _ O

The -X- _ O
symbol -X- _ O
@ -X- _ O
@ -X- _ O
stands -X- _ O
for -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
tokenization -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O

The -X- _ O
symbol -X- _ O
* -X- _ O
denotes -X- _ O
the -X- _ O
synonym -X- _ O
token -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language.44 -X- _ O

Method -X- _ O
Texts -X- _ O
Uniq -X- _ O
↑ -X- _ O
Prefix -X- _ O
A -X- _ O
Company -X- _ O
, -X- _ O

2nd -X- _ O
Engineer -X- _ O
Combat -X- _ O
Battalion -X- _ O
, -X- _ O
moved -X- _ O
to -X- _ O
the -X- _ O
south -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
Yongsan -X- _ O
- -X- _ O
Naktong -X- _ O
River -X- _ O
road -X- _ O
; -X- _ O
D -X- _ O
Company -X- _ O
of -X- _ O
the -X- _ O
2nd -X- _ O
Engineer -X- _ O
Battalion -X- _ O
was -X- _ O
on -X- _ O
the -X- _ O
north -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
road -X- _ O
. -X- _ O

Approximately -X- _ O
2 -X- _ O
miles -X- _ O
( -X- _ O
3 -X- _ O
MLE -X- _ O
. -X- _ O

2 -X- _ O
km -X- _ O
) -X- _ O
north -X- _ O
of -X- _ O
the -X- _ O
river -X- _ O
, -X- _ O
the -X- _ O
2nd -X- _ O
Engineer -X- _ O
Combat -X- _ O
Battalion -X- _ O
was -X- _ O
on -X- _ O
the -X- _ O
south -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
road -X- _ O
. -X- _ O

The -X- _ O
2nd -X- _ O
Engineer -X- _ O
Combat -X- _ O
Battalion -X- _ O
was -X- _ O
on -X- _ O
the -X- _ O
south -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
road -X- _ O
.22 -X- _ O

AGG -X- _ O
. -X- _ O

2 -X- _ O
km -X- _ O
) -X- _ O
north -X- _ O
of -X- _ O
the -X- _ O
river -X- _ O
, -X- _ O
the -X- _ O
2nd -X- _ O
Engineer -X- _ O
Combat -X- _ O
Battalion -X- _ O
was -X- _ O
attacked -X- _ O
by -X- _ O
a -X- _ O
small -X- _ O
force -X- _ O
of -X- _ O
North -X- _ O
Korean -X- _ O
People -X- _ O
’s -X- _ O
V -X- _ O
olunteer -X- _ O
Army -X- _ O
( -X- _ O
NK -X- _ O
) -X- _ O
troops -X- _ O
. -X- _ O

The -X- _ O
North -X- _ O
Koreans -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
penetrate -X- _ O
the -X- _ O
UN -X- _ O
lines -X- _ O
and -X- _ O
capture -X- _ O
the -X- _ O
town -X- _ O
.43 -X- _ O
Method -X- _ O
Texts -X- _ O
Uniq -X- _ O
↑ -X- _ O

Prefix -X- _ O
The -X- _ O
twelve -X- _ O
45 -X- _ O
- -X- _ O
calibre -X- _ O
35 -X- _ O
. -X- _ O

6 -X- _ O
cm -X- _ O
( -X- _ O
14 -X- _ O
. -X- _ O
0 -X- _ O

in -X- _ O
) -X- _ O

Type -X- _ O
41 -X- _ O
guns -X- _ O
of -X- _ O
the -X- _ O
Ise -X- _ O
class -X- _ O
were -X- _ O
mounted -X- _ O
in -X- _ O
three -X- _ O
pairs -X- _ O
of -X- _ O
twin -X- _ O
- -X- _ O
gun -X- _ O
, -X- _ O
superfiring -X- _ O
turrets -X- _ O
. -X- _ O

Numbered -X- _ O
one -X- _ O
through -X- _ O
MLE -X- _ O
two -X- _ O
, -X- _ O
the -X- _ O
turrets -X- _ O
were -X- _ O
placed -X- _ O
in -X- _ O
superfiring -X- _ O
pairs -X- _ O
, -X- _ O
one -X- _ O
ahead -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O

The -X- _ O
turrets -X- _ O
were -X- _ O
placed -X- _ O
in -X- _ O
superfiring -X- _ O
pairs -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
turrets -X- _ O
superfiring -X- _ O
over -X- _ O
the -X- _ O
wing -X- _ O
turrets -X- _ O
. -X- _ O

The -X- _ O
turrets -X- _ O
were -X- _ O
placed -X- _ O
in -X- _ O
superfiring -X- _ O
pairs -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
turrets -X- _ O
superfiring -X- _ O
over -X- _ O
the -X- _ O
wing -X- _ O
turrets -X- _ O
. -X- _ O

The -X- _ O
turrets -X- _ O
were -X- _ O
placed -X- _ O
in -X- _ O
superfiring -X- _ O
pairs -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
turrets -X- _ O
superfiring -X- _ O
over -X- _ O
the -X- _ O
wing -X- _ O
turrets -X- _ O
. -X- _ O

The -X- _ O
turrets -X- _ O
were -X- _ O
placed -X- _ O
in -X- _ O
superfiring -X- _ O
pairs -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
turrets -X- _ O
superfiring -X- _ O
over -X- _ O
the -X- _ O
wing -X- _ O
turrets -X- _ O
. -X- _ O

The -X- _ O
turrets -X- _ O
were -X- _ O
placed -X- _ O
in -X- _ O
superfiring19 -X- _ O
AGG -X- _ O
five -X- _ O
from -X- _ O
front -X- _ O
to -X- _ O
rear -X- _ O
, -X- _ O
the -X- _ O
guns -X- _ O
had -X- _ O
a -X- _ O
firing -X- _ O
arc -X- _ O
of -X- _ O
260 -X- _ O
° -X- _ O
. -X- _ O

They -X- _ O
fired -X- _ O
a -X- _ O
45 -X- _ O
. -X- _ O

3 -X- _ O
kg -X- _ O
( -X- _ O
99 -X- _ O
lb -X- _ O
) -X- _ O
projectile -X- _ O
had -X- _ O
a -X- _ O
maximum -X- _ O
elevation -X- _ O
of -X- _ O
30 -X- _ O
degrees -X- _ O
and -X- _ O
fired -X- _ O
a -X- _ O
36 -X- _ O
. -X- _ O

3 -X- _ O
kg -X- _ O
( -X- _ O
77 -X- _ O
lb -X- _ O
) -X- _ O
projectile -X- _ O
at -X- _ O
a -X- _ O
muzzle -X- _ O
velocity -X- _ O
of -X- _ O
83555 -X- _ O
Method -X- _ O
Texts -X- _ O
Uniq -X- _ O
↑ -X- _ O

Prefix -X- _ O
Despite -X- _ O
the -X- _ O
expensive -X- _ O
reconstructions -X- _ O
, -X- _ O
both -X- _ O
vessels -X- _ O
were -X- _ O
considered -X- _ O
obsolete -X- _ O
by -X- _ O
the -X- _ O
eve -X- _ O
of -X- _ O
the -X- _ O
Pacific -X- _ O
War -X- _ O
, -X- _ O
and -X- _ O
neither -X- _ O
saw -X- _ O
significant -X- _ O
action -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
years -X- _ O
of -X- _ O
the -X- _ O
war -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
IJN -X- _ O
’s -X- _ O
large -X- _ O
aircraft -X- _ O
carriers -X- _ O
during -X- _ O
the -X- _ O
Battle -X- _ O
MLE -X- _ O
of -X- _ O
Midway -X- _ O
, -X- _ O
the -X- _ O
IJN -X- _ O
was -X- _ O
forced -X- _ O
to -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
United -X- _ O
States -X- _ O
Navy -X- _ O
for -X- _ O
aircraft -X- _ O
carriers -X- _ O
and -X- _ O
aircraft -X- _ O
carriers -X- _ O
to -X- _ O
support -X- _ O
operations -X- _ O
in -X- _ O
the -X- _ O
Pacific -X- _ O
. -X- _ O

The -X- _ O
IJN -X- _ O
’s -X- _ O
aircraft -X- _ O
carriers -X- _ O
were -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
be -X- _ O
equipped -X- _ O
with -X- _ O
the -X- _ O
new -X- _ O
Mark -X- _ O
4 -X- _ O
torpedo -X- _ O
and -X- _ O
the -X- _ O
IJN -X- _ O
’s -X- _ O
aircraft -X- _ O
carriers -X- _ O
were -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
be -X- _ O
equipped -X- _ O
with -X- _ O
the -X- _ O
Mark -X- _ O
4 -X- _ O
torpedo -X- _ O
. -X- _ O

The -X- _ O
IJN -X- _ O
’s -X- _ O
aircraft -X- _ O
carriers -X- _ O
were -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
be -X- _ O
equipped -X- _ O
with -X- _ O
the -X- _ O
Mark -X- _ O
4 -X- _ O
torpedo -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
IJN -X- _ O
’s -X- _ O
aircraft -X- _ O
carriers37 -X- _ O
AGG -X- _ O
of -X- _ O
Midway -X- _ O
, -X- _ O
the -X- _ O
IJN -X- _ O
decided -X- _ O
to -X- _ O
modernize -X- _ O
its -X- _ O
fleet -X- _ O
and -X- _ O
modernize -X- _ O
its -X- _ O
fleet -X- _ O
. -X- _ O

The -X- _ O
IJN -X- _ O
’s -X- _ O
new -X- _ O
ships -X- _ O
were -X- _ O
designed -X- _ O
to -X- _ O
be -X- _ O
capable -X- _ O
of -X- _ O
operating -X- _ O
at -X- _ O
speeds -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
30 -X- _ O
knots -X- _ O
( -X- _ O
56 -X- _ O
km -X- _ O
/ -X- _ O
h -X- _ O
; -X- _ O
35 -X- _ O
mph -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
were -X- _ O
fitted -X- _ O
with -X- _ O
a -X- _ O
new -X- _ O
bow -X- _ O
section -X- _ O
. -X- _ O

The -X- _ O
ships -X- _ O
were -X- _ O
designed -X- _ O
to -X- _ O
carry -X- _ O
1 -X- _ O
, -X- _ O
000 -X- _ O
t -X- _ O
( -X- _ O
980 -X- _ O
long -X- _ O
tons -X- _ O
; -X- _ O
1 -X- _ O
, -X- _ O
100 -X- _ O
short -X- _ O
tons -X- _ O
) -X- _ O
of -X- _ O
fuel -X- _ O
oil -X- _ O
, -X- _ O
and -X- _ O
were -X- _ O
fitted -X- _ O
with -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
aircraft -X- _ O
catap63 -X- _ O

Method -X- _ O
Texts -X- _ O
Uniq -X- _ O
↑ -X- _ O

Prefix -X- _ O
Amos -X- _ O
was -X- _ O
born -X- _ O
in -X- _ O
Macclesfield -X- _ O
, -X- _ O
Cheshire -X- _ O
and -X- _ O
was -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
Crewe -X- _ O
Alexandra -X- _ O
academy -X- _ O
until -X- _ O
he -X- _ O
was -X- _ O
released -X- _ O
at -X- _ O
the -X- _ O
age -X- _ O
of -X- _ O
10 -X- _ O
. -X- _ O

While -X- _ O
at -X- _ O
Crewe -X- _ O
, -X- _ O
he -X- _ O
also -X- _ O
played -X- _ O
for -X- _ O
another -X- _ O
local -X- _ O
team -X- _ O
, -X- _ O
Bollington -X- _ O
United -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
centre -X- _ O
MLE -X- _ O
- -X- _ O
back -X- _ O
. -X- _ O

He -X- _ O
was -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
team -X- _ O
that -X- _ O
won -X- _ O
the -X- _ O
FA -X- _ O
Youth -X- _ O
Cup -X- _ O
in -X- _ O
1989 -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
team -X- _ O
that -X- _ O
won -X- _ O
the -X- _ O
FA -X- _ O
Youth -X- _ O
Cup -X- _ O
in -X- _ O
1990 -X- _ O
. -X- _ O

He -X- _ O
was -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
team -X- _ O
that -X- _ O
won -X- _ O
the -X- _ O
FA -X- _ O
Youth -X- _ O
Cup -X- _ O
in -X- _ O
1990 -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
team -X- _ O
that -X- _ O
won -X- _ O
the -X- _ O
FA -X- _ O
Youth -X- _ O
Cup -X- _ O
in -X- _ O
1992 -X- _ O
.24 -X- _ O

AGG -X- _ O
- -X- _ O
back -X- _ O
. -X- _ O

He -X- _ O
was -X- _ O
signed -X- _ O
by -X- _ O
Crewe -X- _ O
Alexandra -X- _ O
in -X- _ O
July -X- _ O
2006 -X- _ O
, -X- _ O
and -X- _ O
made -X- _ O
his -X- _ O
debut -X- _ O
for -X- _ O
the -X- _ O
club -X- _ O
in -X- _ O
a -X- _ O
2 -X- _ O
- -X- _ O
1 -X- _ O
win -X- _ O
over -X- _ O
Rotherham -X- _ O
United -X- _ O
in -X- _ O
the -X- _ O
League -X- _ O
Cup -X- _ O
on -X- _ O
18 -X- _ O
August -X- _ O
2006 -X- _ O
. -X- _ O

He -X- _ O
was -X- _ O
loaned -X- _ O
out -X- _ O
to -X- _ O
Rotherham -X- _ O
for -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
2006 -X- _ O
- -X- _ O
07 -X- _ O
season -X- _ O
, -X- _ O
before -X- _ O
being -X- _ O
released -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
season -X- _ O
.52 -X- _ O
Table -X- _ O
15 -X- _ O
: -X- _ O
Generated -X- _ O
texts -X- _ O
on -X- _ O
the -X- _ O
Wikitext-103 -X- _ O
test -X- _ O
set -X- _ O
and -X- _ O
uniq -X- _ O
tokens -X- _ O
for -X- _ O
each -X- _ O
texts -X- _ O
. -X- _ O

50 -X- _ O
bpe -X- _ O
tokens -X- _ O
are -X- _ O
given -X- _ O
as -X- _ O
prefix -X- _ O
and -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
continuation -X- _ O
of -X- _ O
100 -X- _ O
next -X- _ O
bpe -X- _ O
tokens.45 -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
46 -X- _ O
- -X- _ O
56 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O

2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
AlephBERT -X- _ B-MethodName
: -X- _ O
Language -X- _ O
Model -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
Evaluation -X- _ O
from -X- _ O
Sub -X- _ O
- -X- _ O
Word -X- _ O
to -X- _ O
Sentence -X- _ O
Level -X- _ O
Amit -X- _ O
Seker -X- _ O
, -X- _ O
Elron -X- _ O
Bandel -X- _ O
, -X- _ O
Dan -X- _ O
Bareket -X- _ O
, -X- _ O
Idan -X- _ O
Brusilovsky -X- _ O
, -X- _ O
Refael -X- _ O
Shaked -X- _ O
Greenfeld -X- _ O
, -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
Department -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
, -X- _ O
Bar -X- _ O
Ilan -X- _ O
University -X- _ O
, -X- _ O
Ramat -X- _ O
- -X- _ O
Gan -X- _ O
, -X- _ O
Israel -X- _ O
{ -X- _ O
aseker00 -X- _ O
, -X- _ O
elronbandel -X- _ O
, -X- _ O
dbareket -X- _ O
, -X- _ O
brusli1 -X- _ O
, -X- _ O
shakedgreenfeld -X- _ O
, -X- _ O
reut.tsarfaty -X- _ O
} -X- _ O
@ -X- _ O
gmail.com -X- _ O

Abstract -X- _ O
Large -X- _ B-TaskName
Pre -X- _ I-TaskName
- -X- _ I-TaskName
trained -X- _ I-TaskName
Language -X- _ I-TaskName
Models -X- _ I-TaskName
( -X- _ O
PLMs -X- _ B-TaskName
) -X- _ O
have -X- _ O
become -X- _ O
ubiquitous -X- _ O
in -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
language -X- _ O
understanding -X- _ O
technology -X- _ O
and -X- _ O
lie -X- _ O
at -X- _ O
the -X- _ O
heart -X- _ O
of -X- _ O
many -X- _ O
artificial -X- _ O
intelligence -X- _ O
advances -X- _ O
. -X- _ O

While -X- _ O
advances -X- _ O
reported -X- _ O
for -X- _ O
English -X- _ O
using -X- _ O
PLMs -X- _ O
are -X- _ O
unprecedented -X- _ O
, -X- _ O
reported -X- _ O
advances -X- _ O
using -X- _ O
PLMs -X- _ O
for -X- _ O
Hebrew -X- _ O
are -X- _ O
few -X- _ O
and -X- _ O
far -X- _ O
between -X- _ O
. -X- _ O

The -X- _ O
problem -X- _ O
is -X- _ O
twofold -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
so -X- _ O
far -X- _ O
, -X- _ O
Hebrew -X- _ O
resources -X- _ O
for -X- _ O
training -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
magnitude -X- _ O
as -X- _ O
their -X- _ O
English -X- _ O
counterparts -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
most -X- _ O
benchmarks -X- _ O
available -X- _ O
to -X- _ O
evaluate -X- _ O
progress -X- _ O
in -X- _ O
Hebrew -X- _ O
NLP -X- _ O
require -X- _ O
morphological -X- _ O
boundaries -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
PLMs -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
remedy -X- _ O
both -X- _ O
aspects -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
AlephBERT -X- _ B-MethodName
, -X- _ O
a -X- _ O
large -X- _ O
PLM -X- _ B-TaskName
for -X- _ O
Modern -X- _ O
Hebrew -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
larger -X- _ O
vocabulary -X- _ O
and -X- _ O
a -X- _ O
larger -X- _ O
dataset -X- _ O
than -X- _ O
any -X- _ O
Hebrew -X- _ O
PLM -X- _ B-TaskName
before -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
novel -X- _ O
neural -X- _ O
architecture -X- _ O
that -X- _ O
recovers -X- _ O
the -X- _ O
morphological -X- _ O
segments -X- _ O
encoded -X- _ O
in -X- _ O
contextualized -X- _ O
embedding -X- _ O
vectors -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
this -X- _ O
new -X- _ O
morphological -X- _ O
component -X- _ O
we -X- _ O
offer -X- _ O
an -X- _ O
evaluation -X- _ O
suite -X- _ O
consisting -X- _ O
of -X- _ O
multiple -X- _ O
tasks -X- _ O
and -X- _ O
benchmarks -X- _ O
that -X- _ O
cover -X- _ O
sentencelevel -X- _ O
, -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
andsub -X- _ O
- -X- _ O
word -X- _ O
level -X- _ O
analyses -X- _ O
. -X- _ O

On -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
AlephBERT -X- _ B-MethodName
obtains -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
results -X- _ O
beyond -X- _ O
contemporary -X- _ O
Hebrew -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
make -X- _ O
our -X- _ O
AlephBERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
the -X- _ O
morphological -X- _ O
extraction -X- _ O
component -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Hebrew -X- _ O
evaluation -X- _ O
suite -X- _ O
publicly -X- _ O
available -X- _ O
, -X- _ O
for -X- _ O
future -X- _ O
investigations -X- _ O
and -X- _ O
evaluations -X- _ O
of -X- _ O
Hebrew -X- _ O
PLMs -X- _ B-TaskName
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Contextualized -X- _ O
word -X- _ O
representations -X- _ O
provided -X- _ O
by -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
RoBERTa -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
GPT3 -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
critical -X- _ O
component -X- _ O
for -X- _ O
obtaining -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
tasks -X- _ O
, -X- _ O
from -X- _ O
surface -X- _ O
syntactic -X- _ O
tasks -X- _ O
as -X- _ O
tagging -X- _ O
and -X- _ O
parsing -X- _ O
, -X- _ O
to -X- _ O
downstream -X- _ O
semantic -X- _ O
tasks -X- _ O
as -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
information -X- _ O
extraction -X- _ O
and -X- _ O
text -X- _ O
summarization -X- _ O
. -X- _ O

While -X- _ O
advances -X- _ O
reported -X- _ O
for -X- _ O
English -X- _ O
using -X- _ O
such -X- _ O
models -X- _ O
are -X- _ O
unprecedented -X- _ O
, -X- _ O
previously -X- _ O
reported -X- _ O
results -X- _ O
using -X- _ O
PLMs -X- _ B-TaskName
in -X- _ O
Modern -X- _ O
Hebrew -X- _ O
are -X- _ O
far -X- _ O
from -X- _ O
satisfactory -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
Hebrew -X- _ O
section -X- _ O
of -X- _ O
multilingual -X- _ O
- -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
henceforth -X- _ O
, -X- _ O
mBERT -X- _ O
) -X- _ O
, -X- _ O
did -X- _ O
not -X- _ O
provide -X- _ O
a -X- _ O
similar -X- _ O
boost -X- _ O
in -X- _ O
performance -X- _ O
as -X- _ O
observed -X- _ O
by -X- _ O
the -X- _ O
English -X- _ O
section -X- _ O
of -X- _ O
mBERT -X- _ B-MethodName
. -X- _ O

In -X- _ O
fact -X- _ O
, -X- _ O
for -X- _ O
several -X- _ O
reported -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
mBERT -X- _ B-MethodName
model -X- _ O
are -X- _ O
on -X- _ O
a -X- _ O
par -X- _ O
with -X- _ O
pre -X- _ O
- -X- _ O
neural -X- _ O
models -X- _ O
or -X- _ O
neural -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
non -X- _ O
- -X- _ O
contextual -X- _ O
embeddings -X- _ O
( -X- _ O
Tsarfaty -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Klein -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

An -X- _ O
additional -X- _ O
Hebrew -X- _ B-MethodName
BERT -X- _ I-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
HeBERT -X- _ B-MethodName
( -X- _ O
Chriqui -X- _ O
and -X- _ O
Yahav -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
recently -X- _ O
released -X- _ O
, -X- _ O
yet -X- _ O
without -X- _ O
empirical -X- _ O
evidence -X- _ O
of -X- _ O
performance -X- _ O
improvements -X- _ O
on -X- _ O
key -X- _ O
components -X- _ O
of -X- _ O
the -X- _ O
Hebrew -X- _ O
NLP -X- _ O
pipeline -X- _ O
. -X- _ O

The -X- _ O
challenge -X- _ O
of -X- _ O
developing -X- _ O
PLMs -X- _ B-TaskName
for -X- _ O
morphologically -X- _ O
- -X- _ O
rich -X- _ O
andmedium -X- _ O
- -X- _ O
resourced -X- _ O
languages -X- _ O
such -X- _ O
as -X- _ O
Modern -X- _ O
Hebrew -X- _ O
is -X- _ O
twofold -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
a -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
massive -X- _ O
quantities -X- _ O
of -X- _ O
unlabeled -X- _ O
texts -X- _ O
. -X- _ O

In -X- _ O
Hebrew -X- _ O
, -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
published -X- _ O
texts -X- _ O
available -X- _ O
for -X- _ O
training -X- _ O
is -X- _ O
relatively -X- _ O
small -X- _ O
. -X- _ O

To -X- _ O
wit -X- _ O
, -X- _ O
Hebrew -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
( -X- _ O
300 -X- _ O
K -X- _ O
articles -X- _ O
) -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
mBERT -X- _ O
is -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
smaller -X- _ O
compared -X- _ O
to -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
( -X- _ O
6 -X- _ O
M -X- _ O
articles -X- _ O
) -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
commonly -X- _ O
accepted -X- _ O
benchmarks -X- _ O
for -X- _ O
evaluating -X- _ O
Hebrew -X- _ O
models -X- _ O
, -X- _ O
via -X- _ O
Morpho -X- _ O
- -X- _ O
Syntactic -X- _ O
Tagging -X- _ O
and -X- _ O
Parsing -X- _ O
( -X- _ O
Sadde -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
Named -X- _ O
Entity -X- _ O
Recognition -X- _ O
( -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
require -X- _ O
decomposition -X- _ O
of -X- _ O
words -X- _ O
into -X- _ O
morphemes -X- _ O
, -X- _ O
1 -X- _ O
which -X- _ O
are -X- _ O
distinct -X- _ O
of -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
words -X- _ O
( -X- _ O
a.k.a -X- _ O
. -X- _ O
wordpieces -X- _ O
) -X- _ O
provided -X- _ O
by -X- _ O
standard -X- _ O
PLMs -X- _ B-TaskName
. -X- _ O

Such -X- _ O
morphemes -X- _ O
are -X- _ O
as -X- _ O
of -X- _ O
yet -X- _ O
not -X- _ O
readily -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
PLMs -X- _ B-TaskName
’ -X- _ O
output -X- _ O
embeddings -X- _ O
. -X- _ O

Evaluating -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
on -X- _ O
morphemelevel -X- _ O
tasks -X- _ O
is -X- _ O
thus -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
mismatch -X- _ O
between -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
tokens -X- _ O
used -X- _ O
as -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
POS -X- _ O
. -X- _ O

They -X- _ O
are -X- _ O
termed -X- _ O
syntactic -X- _ O
words -X- _ O
in -X- _ O
UD -X- _ O
( -X- _ O
Zeman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
segments -X- _ O
in -X- _ O
previous -X- _ O
literature -X- _ O
on -X- _ O
Hebrew -X- _ O
NLP.46 -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
PLM -X- _ B-TaskName
Morphological -X- _ O
Extraction -X- _ O
Pipeline -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
- -X- _ O
word -X- _ O
phrase -X- _ O
“ -X- _ O
/ -X- _ O
ֹדנֵfנ -X- _ O
/ -X- _ O
דרֹוuנfלביתהלבלַנִ -X- _ O
, -X- _ O
” -X- _ O
transliterated -X- _ O
as -X- _ O
“ -X- _ O
lbit -X- _ O
hlbn -X- _ O
” -X- _ O
, -X- _ O
mapped -X- _ O
to -X- _ O
word -X- _ O
- -X- _ O
pieces -X- _ O
which -X- _ O
are -X- _ O
consumed -X- _ O
by -X- _ O
a -X- _ O
PLM -X- _ B-TaskName
to -X- _ O
generate -X- _ O
contextualized -X- _ O
vectors -X- _ O
and -X- _ O
extract -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
morphological -X- _ O
units -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
example -X- _ O
the -X- _ O
WordPiece -X- _ O
Tokenizer -X- _ O
splits -X- _ O
the -X- _ O
first -X- _ O
word -X- _ O
, -X- _ O
“ -X- _ O
lbit -X- _ O
” -X- _ O
, -X- _ O
into -X- _ O
two -X- _ O
pieces -X- _ O
while -X- _ O
leaving -X- _ O
the -X- _ O
second -X- _ O
word -X- _ O
, -X- _ O
“ -X- _ O
hlbn -X- _ O
” -X- _ O
, -X- _ O
intact -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
AlephBERT -X- _ B-MethodName
generates -X- _ O
3 -X- _ O
embedded -X- _ O
vectors -X- _ O
- -X- _ O
the -X- _ O
vectors -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
split -X- _ O
word -X- _ O
pieces -X- _ O
are -X- _ O
averaged -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
single -X- _ O
contextualized -X- _ O
vector -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
the -X- _ O
resulting -X- _ O
two -X- _ O
word -X- _ O
vectors -X- _ O
are -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
Morphological -X- _ O
Extraction -X- _ O
Model -X- _ O
that -X- _ O
generates -X- _ O
the -X- _ O
disambiguated -X- _ O
morphological -X- _ O
segments -X- _ O
. -X- _ O

input -X- _ O
units -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
PLMs -X- _ B-TaskName
and -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
morphological -X- _ O
units -X- _ O
needed -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O

PLMs -X- _ B-TaskName
employ -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
tokenization -X- _ O
mechanisms -X- _ O
such -X- _ O
as -X- _ O
WordPiece -X- _ O
or -X- _ O
Byte -X- _ O
- -X- _ O
Pair -X- _ O
Encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
purposes -X- _ O
of -X- _ O
minimizing -X- _ O
Out -X- _ O
- -X- _ O
Of -X- _ O
- -X- _ O
V -X- _ O
ocabulary -X- _ O
words -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

These -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
tokens -X- _ O
are -X- _ O
generated -X- _ O
in -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
step -X- _ O
, -X- _ O
without -X- _ O
utilization -X- _ O
of -X- _ O
any -X- _ O
linguistic -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
passed -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
PLM -X- _ B-TaskName
. -X- _ O

Crucially -X- _ O
, -X- _ O
such -X- _ O
word -X- _ O
- -X- _ O
pieces -X- _ O
do -X- _ O
not -X- _ O
reflect -X- _ O
morphological -X- _ O
units -X- _ O
. -X- _ O

Extracting -X- _ O
morphological -X- _ O
units -X- _ O
from -X- _ O
contextualized -X- _ O
vectors -X- _ O
provided -X- _ O
by -X- _ O
PLMs -X- _ B-TaskName
is -X- _ O
challenging -X- _ O
yet -X- _ O
necessary -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
enable -X- _ O
morphological -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
of -X- _ O
Hebrew -X- _ O
PLMs -X- _ B-TaskName
on -X- _ O
standard -X- _ O
benchmarks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
introduce -X- _ O
AlephBERT -X- _ B-MethodName
, -X- _ O
a -X- _ O
Hebrew -X- _ O
PLM -X- _ O
trained -X- _ O
on -X- _ O
more -X- _ O
data -X- _ O
and -X- _ O
a -X- _ O
larger -X- _ O
vocabulary -X- _ O
than -X- _ O
any -X- _ O
Hebrew -X- _ O
PLM -X- _ O
before.2Moreover -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
architecture -X- _ O
that -X- _ O
extracts -X- _ O
the -X- _ O
morphological -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
units -X- _ O
implicitly -X- _ O
encoded -X- _ O
in -X- _ O
the -X- _ O
contextualized -X- _ O
vectors -X- _ O
outputted -X- _ O
by -X- _ O
PLMs -X- _ O
. -X- _ O

Using -X- _ O
AlephBERT -X- _ B-MethodName
and -X- _ O
the -X- _ O
proposed -X- _ O
morphological -X- _ O
extraction -X- _ O
model -X- _ O
we -X- _ O
enable -X- _ O
evaluation -X- _ O
on -X- _ O
allexisting -X- _ O
Hebrew -X- _ O
benchmarks -X- _ O
. -X- _ O

We -X- _ O
thus -X- _ O
present -X- _ O
a -X- _ O
processing -X- _ O
and -X- _ O
evaluation -X- _ O
pipeline -X- _ O
tailored -X- _ O
to -X- _ O
fit -X- _ O
Morphologically -X- _ O
Rich -X- _ O
Languages -X- _ O
( -X- _ O
MRLs -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
covering -X- _ O
onlplab -X- _ O
/ -X- _ O
alephbert -X- _ O
- -X- _ O
base -X- _ O
and -X- _ O
demo -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
nlp -X- _ O
. -X- _ O
biu.ac.il -X- _ O
/ -X- _ O
~amitse -X- _ O
/ -X- _ O
alephbert -X- _ O
/ -X- _ O
publicly -X- _ O
available -X- _ O
, -X- _ O
to -X- _ O
qualitatively -X- _ O
assess -X- _ O
present -X- _ O
and -X- _ O
future -X- _ O
Hebrew -X- _ O
PLMs.sentence -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
most -X- _ O
importantly -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
morphological -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
( -X- _ O
Segmentation -X- _ B-TaskName
, -X- _ O
Part -X- _ B-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
Speech -X- _ I-MethodName
Tagging -X- _ I-MethodName
, -X- _ O
full -X- _ B-MethodName
Morphological -X- _ I-MethodName
Tagging -X- _ I-MethodName
, -X- _ O
Dependency -X- _ B-MethodName
Parsing -X- _ I-MethodName
, -X- _ O
Named -X- _ B-MethodName
Entity -X- _ I-MethodName
Recognition -X- _ I-MethodName
( -X- _ O
NER -X- _ B-MethodName
) -X- _ O
andSentiment -X- _ B-MethodName
Analysis -X- _ I-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
present -X- _ O
new -X- _ O
and -X- _ O
improved -X- _ O
SOTA -X- _ O
for -X- _ O
Modern -X- _ O
Hebrew -X- _ O
on -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O

2 -X- _ O
Previous -X- _ O
Work -X- _ O
Contextualized -X- _ O
word -X- _ O
embedding -X- _ O
vectors -X- _ O
are -X- _ O
a -X- _ O
major -X- _ O
driver -X- _ O
for -X- _ O
improved -X- _ O
performance -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
models -X- _ O
on -X- _ O
many -X- _ O
Natural -X- _ B-MethodName
Language -X- _ I-MethodName
Understanding -X- _ I-MethodName
( -X- _ O
NLU -X- _ B-MethodName
) -X- _ O
tasks -X- _ O
. -X- _ O

Initially -X- _ O
, -X- _ O
ELMo -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
ULMFit -X- _ O
( -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
introduced -X- _ O
contextualized -X- _ O
word -X- _ O
embedding -X- _ O
frameworks -X- _ O
by -X- _ O
training -X- _ O
LSTM -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
on -X- _ O
massive -X- _ O
amounts -X- _ O
of -X- _ O
texts -X- _ O
. -X- _ O

The -X- _ O
linguistic -X- _ O
quality -X- _ O
encoded -X- _ O
in -X- _ O
these -X- _ O
models -X- _ O
was -X- _ O
demonstrated -X- _ O
over -X- _ O
6 -X- _ O
tasks -X- _ O
: -X- _ O
Question -X- _ B-TaskName
Answering -X- _ I-TaskName
, -X- _ O
Textual -X- _ B-TaskName
Entailment -X- _ I-TaskName
, -X- _ O
Semantic -X- _ B-TaskName
Role -X- _ I-TaskName
labeling -X- _ I-TaskName
, -X- _ O
Coreference -X- _ B-TaskName
Resolution -X- _ I-TaskName
, -X- _ O
Name -X- _ B-TaskName
Entity -X- _ I-TaskName
Extraction -X- _ I-TaskName
, -X- _ O
and -X- _ O
Sentiment -X- _ B-TaskName
Analysis -X- _ I-TaskName
. -X- _ O

The -X- _ O
next -X- _ O
big -X- _ O
leap -X- _ O
was -X- _ O
obtained -X- _ O
with -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
the -X- _ O
GPT-1 -X- _ O
framework -X- _ O
by -X- _ O
Radford -X- _ O
and -X- _ O
Sutskever -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
using -X- _ O
LSTM -X- _ O
layers -X- _ O
, -X- _ O
GPT -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
12 -X- _ O
layers -X- _ O
of -X- _ O
Transformer -X- _ O
decoders -X- _ O
with -X- _ O
each -X- _ O
decoder -X- _ O
layer -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
768 -X- _ O
- -X- _ O
dimensional -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layer -X- _ O
and -X- _ O
12 -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
heads -X- _ O
. -X- _ O

Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
followed -X- _ O
along -X- _ O
the -X- _ O
same -X- _ O
lines -X- _ O
and -X- _ O
implemented -X- _ O
Bidirectional -X- _ O
Encoder -X- _ O
Representations -X- _ O
from -X- _ O
Transformers -X- _ O
, -X- _ O
or -X- _ O
BERT -X- _ O
in -X- _ O
short -X- _ O
. -X- _ O

BERT -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
in -X- _ O
both -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
directions -X- _ O
while -X- _ O
optimizing -X- _ O
a -X- _ O
Masked -X- _ O
Language -X- _ O
Model -X- _ O
and -X- _ O
a -X- _ O
Next -X- _ O
Sentence -X- _ O
Prediction -X- _ O
objective -X- _ O
objectives -X- _ O
. -X- _ O

BERT -X- _ O
Benchmarks -X- _ O
An -X- _ O
integral -X- _ O
part -X- _ O
involved -X- _ O
in -X- _ O
developing -X- _ O
various -X- _ O
PLMs -X- _ O
is -X- _ O
providing -X- _ O
NLU -X- _ O
multitask -X- _ O
benchmarks -X- _ O
used -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
linguistic -X- _ O
abilities -X- _ O
of -X- _ O
new -X- _ O
models -X- _ O
and -X- _ O
approaches -X- _ O
. -X- _ O

English -X- _ O
BERT -X- _ O
models -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
3 -X- _ O
standard -X- _ O
major -X- _ O
benchmarks -X- _ O
. -X- _ O

The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
SQuAD -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
testing -X- _ O
paragraph -X- _ O
- -X- _ O
level -X- _ O
reading -X- _ O
comprehension -X- _ O
abilities -X- _ O
. -X- _ O

Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
selected -X- _ O
a -X- _ O
diverse -X- _ O
and -X- _ O
relatively -X- _ O
hard -X- _ O
set -X- _ O
of -X- _ O
sentence -X- _ O
and -X- _ O
sentence -X- _ O
- -X- _ O
pair -X- _ O
tasks -X- _ O
which -X- _ O
comprise -X- _ O
the -X- _ O
General -X- _ B-MetricName
Language -X- _ I-MetricName
Understanding -X- _ I-MetricName
Evaluation -X- _ I-MetricName
( -X- _ O
GLUE -X- _ B-MetricName
) -X- _ O
benchmark -X- _ O
. -X- _ O

The -X- _ O
SWAG -X- _ B-DatasetName
( -X- _ O
Situations -X- _ B-DatasetName
With -X- _ I-DatasetName
Adversarial -X- _ I-DatasetName
Generations -X- _ I-DatasetName
) -X- _ O
dataset -X- _ O
( -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
presents -X- _ O
models -X- _ O
with -X- _ O
partial -X- _ O
description -X- _ O
of -X- _ O
grounded -X- _ O
situations -X- _ O
to -X- _ O
see -X- _ O
if -X- _ O
they -X- _ O
can -X- _ O
consistently -X- _ O
predict -X- _ O
subsequent -X- _ O
scenarios -X- _ O
, -X- _ O
thus -X- _ O
indicating -X- _ O
abilities -X- _ O
of -X- _ O
commonsense -X- _ O
reasoning.47 -X- _ O

When -X- _ O
evaluating -X- _ O
Hebrew -X- _ O
PLMs -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
key -X- _ O
pitfalls -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
Hebrew -X- _ O
versions -X- _ O
for -X- _ O
these -X- _ O
benchmarks -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
suggested -X- _ O
benchmarks -X- _ O
account -X- _ O
for -X- _ O
examining -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
PLMs -X- _ B-MethodName
for -X- _ O
encoding -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
internal -X- _ O
morphological -X- _ O
structures -X- _ O
which -X- _ O
are -X- _ O
inherent -X- _ O
in -X- _ O
MRLs -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
enable -X- _ O
a -X- _ O
generic -X- _ O
morphological -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
pipeline -X- _ O
that -X- _ O
is -X- _ O
suited -X- _ O
for -X- _ O
PLMs -X- _ B-MethodName
of -X- _ O
MRLs -X- _ O
. -X- _ O

Multilingual -X- _ O
vs. -X- _ O
Monolingual -X- _ O
BERT -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
produced -X- _ O
2 -X- _ O
BERT -X- _ O
models -X- _ O
, -X- _ O
for -X- _ O
English -X- _ O
and -X- _ O
Chinese -X- _ O
. -X- _ O

To -X- _ O
support -X- _ O
other -X- _ O
languages -X- _ O
, -X- _ O
they -X- _ O
trained -X- _ O
a -X- _ O
multilingual -X- _ B-MethodName
BERT -X- _ I-MethodName
( -X- _ O
mBERT -X- _ B-MethodName
) -X- _ O
model -X- _ O
combining -X- _ O
texts -X- _ O
covering -X- _ O
over -X- _ O
100 -X- _ O
languages -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
hoped -X- _ O
to -X- _ O
benefit -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
with -X- _ O
the -X- _ O
linguistic -X- _ O
information -X- _ O
obtained -X- _ O
from -X- _ O
languages -X- _ O
with -X- _ O
larger -X- _ O
datasets -X- _ O
. -X- _ O

In -X- _ O
reality -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
mBERT -X- _ B-MethodName
performance -X- _ O
on -X- _ O
specific -X- _ O
languages -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
as -X- _ O
successful -X- _ O
as -X- _ O
English -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
several -X- _ O
research -X- _ O
efforts -X- _ O
focused -X- _ O
on -X- _ O
building -X- _ O
monolingual -X- _ O
BERT -X- _ O
models -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
providing -X- _ O
languagespecific -X- _ O
evaluation -X- _ O
benchmarks -X- _ O
. -X- _ O

Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
trained -X- _ O
CamemBERT -X- _ O
, -X- _ O
a -X- _ O
French -X- _ O
BERT -X- _ O
model -X- _ O
evaluated -X- _ O
on -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
tasks -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
tasks -X- _ O
. -X- _ O

Rybak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
trained -X- _ O
HerBERT -X- _ O
, -X- _ O
a -X- _ O
BERT -X- _ O
PLM -X- _ O
for -X- _ O
Polish -X- _ O
. -X- _ O

They -X- _ O
evaluated -X- _ O
it -X- _ O
on -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
existing -X- _ O
NLU -X- _ O
benchmarks -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
for -X- _ O
sentiment -X- _ O
analysis -X- _ O
for -X- _ O
the -X- _ O
e -X- _ O
- -X- _ O
commerce -X- _ O
domain -X- _ O
. -X- _ O

Polignano -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
created -X- _ O
Alberto -X- _ O
, -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
for -X- _ O
Italian -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
massive -X- _ O
tweet -X- _ O
collection -X- _ O
. -X- _ O

They -X- _ O
tested -X- _ O
it -X- _ O
on -X- _ O
several -X- _ O
NLU -X- _ O
tasks -X- _ O
— -X- _ O
subjectivity -X- _ O
, -X- _ O
polarity -X- _ O
( -X- _ O
sentiment -X- _ O
) -X- _ O
and -X- _ O
irony -X- _ O
detection -X- _ O
in -X- _ O
tweets -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
large -X- _ O
enough -X- _ O
training -X- _ O
corpus -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resources -X- _ O
languages -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Finnish -X- _ O
( -X- _ O
Virtanen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Persian -X- _ O
( -X- _ O
Farahani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
great -X- _ O
deal -X- _ O
of -X- _ O
effort -X- _ O
went -X- _ O
into -X- _ O
filtering -X- _ O
and -X- _ O
cleaning -X- _ O
text -X- _ O
samples -X- _ O
obtained -X- _ O
from -X- _ O
web -X- _ O
crawls -X- _ O
. -X- _ O

BERT -X- _ O
for -X- _ O
MRLs -X- _ O
Languages -X- _ O
with -X- _ O
rich -X- _ O
morphology -X- _ O
introduce -X- _ O
another -X- _ O
challenge -X- _ O
involving -X- _ O
the -X- _ O
identification -X- _ O
and -X- _ O
extraction -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
morphological -X- _ O
information -X- _ O
. -X- _ O

In -X- _ O
many -X- _ O
MRLs -X- _ O
words -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
morphological -X- _ O
units -X- _ O
, -X- _ O
with -X- _ O
each -X- _ O
unit -X- _ O
acting -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
syntactic -X- _ O
unit -X- _ O
bearing -X- _ O
as -X- _ O
single -X- _ O
POS -X- _ O
tag -X- _ O
( -X- _ O
mimicking -X- _ O
‘ -X- _ O
words -X- _ O
’ -X- _ O
in -X- _ O
English -X- _ O
) -X- _ O
. -X- _ O

Antoun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
addressed -X- _ O
this -X- _ O
for -X- _ O
Arabic -X- _ O
, -X- _ O
a -X- _ O
Semitic -X- _ O
MRLs -X- _ O
, -X- _ O
by -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
using -X- _ O
a -X- _ O
morphological -X- _ O
segmenter -X- _ O
, -X- _ O
producing -X- _ O
morphological -X- _ O
segments -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
AraBERT -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
actual -X- _ O
words -X- _ O
. -X- _ O

By -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
produce -X- _ O
output -X- _ O
vectors -X- _ O
that -X- _ O
corre -X- _ O
- -X- _ O
Language -X- _ O
Oscar -X- _ O
( -X- _ O
duped -X- _ O
) -X- _ O
Size -X- _ O
Wikipedia -X- _ O
Articles -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Corpora -X- _ O
Size -X- _ O
Comparison -X- _ O
: -X- _ O
Resource -X- _ O
- -X- _ O
savvy -X- _ O
languages -X- _ O
vs. -X- _ O
Hebrew -X- _ O
. -X- _ O

spond -X- _ O
to -X- _ O
morphological -X- _ O
segments -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
space -X- _ O
- -X- _ O
delimited -X- _ O
word -X- _ O
- -X- _ O
tokens -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
requires -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
segmenter -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
as -X- _ O
well -X- _ O
, -X- _ O
and -X- _ O
like -X- _ O
any -X- _ O
pipeline -X- _ O
approach -X- _ O
, -X- _ O
this -X- _ O
setup -X- _ O
is -X- _ O
susceptible -X- _ O
to -X- _ O
error -X- _ O
propagation -X- _ O
. -X- _ O

This -X- _ O
risk -X- _ O
is -X- _ O
magnified -X- _ O
as -X- _ O
words -X- _ O
in -X- _ O
MRLs -X- _ O
may -X- _ O
be -X- _ O
morphologically -X- _ O
ambiguous -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
segments -X- _ O
might -X- _ O
not -X- _ O
represent -X- _ O
the -X- _ O
correct -X- _ O
interpretation -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
PLM -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
accuracy -X- _ O
achieved -X- _ O
by -X- _ O
the -X- _ O
segmenting -X- _ O
component -X- _ O
. -X- _ O

A -X- _ O
particular -X- _ O
novelty -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
notmaking -X- _ O
any -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
letting -X- _ O
the -X- _ O
PLM -X- _ O
encode -X- _ O
morphological -X- _ O
information -X- _ O
associated -X- _ O
with -X- _ O
complete -X- _ O
Hebrew -X- _ O
tokens -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
transforming -X- _ O
the -X- _ O
resulting -X- _ O
contextualized -X- _ O
word -X- _ O
vectors -X- _ O
into -X- _ O
morphological -X- _ O
- -X- _ O
level -X- _ O
segments -X- _ O
via -X- _ O
a -X- _ O
novel -X- _ O
neural -X- _ O
architecture -X- _ O
which -X- _ O
we -X- _ O
discuss -X- _ O
shortly -X- _ O
. -X- _ O

Evaluating -X- _ O
PLMs -X- _ O
for -X- _ O
MRLs -X- _ O
Across -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
- -X- _ O
mentioned -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
PLMs -X- _ O
, -X- _ O
evaluation -X- _ O
was -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
word- -X- _ O
, -X- _ O
sentence- -X- _ O
or -X- _ O
paragraph -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O

Non -X- _ O
examined -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
PLMs -X- _ O
to -X- _ O
encode -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
morphological -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
which -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

¸ -X- _ O
Sahin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
probed -X- _ O
various -X- _ O
information -X- _ O
types -X- _ O
encoded -X- _ O
in -X- _ O
embedded -X- _ O
word -X- _ O
vectors -X- _ O
. -X- _ O

Similarly -X- _ O
to -X- _ O
us -X- _ O
, -X- _ O
they -X- _ O
focused -X- _ O
on -X- _ O
languages -X- _ O
with -X- _ O
rich -X- _ O
morphology -X- _ O
where -X- _ O
linguistic -X- _ O
signals -X- _ O
are -X- _ O
encoded -X- _ O
at -X- _ O
the -X- _ O
morphological -X- _ O
, -X- _ O
subword -X- _ O
level -X- _ O
. -X- _ O

Their -X- _ O
work -X- _ O
is -X- _ O
more -X- _ O
about -X- _ O
explainability -X- _ O
— -X- _ O
showing -X- _ O
high -X- _ O
positive -X- _ O
correlation -X- _ O
of -X- _ O
probing -X- _ O
tasks -X- _ O
to -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
morphologically -X- _ O
rich -X- _ O
languages -X- _ O
. -X- _ O

Unlike -X- _ O
us -X- _ O
, -X- _ O
they -X- _ O
assume -X- _ O
a -X- _ O
single -X- _ O
POS -X- _ O
tag -X- _ O
and -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
per -X- _ O
word -X- _ O
in -X- _ O
their -X- _ O
probing -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
Hebrew -X- _ O
, -X- _ O
Arabic -X- _ O
and -X- _ O
other -X- _ O
MRLs -X- _ O
, -X- _ O
tokens -X- _ O
may -X- _ O
carry -X- _ O
multiple -X- _ O
POS -X- _ O
per -X- _ O
word -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
be -X- _ O
segmented -X- _ O
for -X- _ O
further -X- _ O
processing -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
framework -X- _ O
that -X- _ O
extracts -X- _ O
subword -X- _ O
morphological -X- _ O
units -X- _ O
given -X- _ O
contextualized -X- _ O
word -X- _ O
vectors -X- _ O
, -X- _ O
that -X- _ O
enables -X- _ O
to -X- _ O
evaluate -X- _ O
PLMs -X- _ O
on -X- _ O
morphologically -X- _ O
- -X- _ O
aware -X- _ O
datasets -X- _ O
where -X- _ O
words -X- _ O
can -X- _ O
have -X- _ O
multiple -X- _ O
POS -X- _ O
tags -X- _ O
and -X- _ O
feature -X- _ O
- -X- _ O
bundles.48 -X- _ O

Corpus -X- _ O
File -X- _ O
Size -X- _ O
Sentences -X- _ O
Words -X- _ O
Wikipedia -X- _ O
1.1 -X- _ O
GB -X- _ O
6.3 -X- _ O
M -X- _ O
127 -X- _ O
M -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
AlephBERT -X- _ O
’s -X- _ O
Training -X- _ O
Data -X- _ O
. -X- _ O

3 -X- _ O
AlephBERT -X- _ B-MethodName
Pre -X- _ O
- -X- _ O
Training -X- _ O
Data -X- _ O
The -X- _ O
PLM -X- _ O
termed -X- _ O
AlephBERT -X- _ B-MethodName
that -X- _ O
we -X- _ O
provide -X- _ O
herein -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
larger -X- _ O
dataset -X- _ O
and -X- _ O
a -X- _ O
larger -X- _ O
vocabulary -X- _ O
than -X- _ O
any -X- _ O
Hebrew -X- _ O
BERT -X- _ O
instantiation -X- _ O
before -X- _ O
. -X- _ O

The -X- _ O
data -X- _ O
we -X- _ O
train -X- _ O
on -X- _ O
is -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Concretely -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
following -X- _ O
datasets -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
Oscar -X- _ B-DatasetName
: -X- _ O

Deduplicated -X- _ O
Hebrew -X- _ O
portion -X- _ O
extracted -X- _ O
from -X- _ O
Common -X- _ O
Crawl -X- _ O
via -X- _ O
language -X- _ O
classification -X- _ O
, -X- _ O
filtering -X- _ O
and -X- _ O
cleaning -X- _ O
( -X- _ O
Ortiz -X- _ O
Suárez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
ii -X- _ O
) -X- _ O
Wikipedia -X- _ O
: -X- _ O

Texts -X- _ O
from -X- _ O
all -X- _ O
of -X- _ O
Hebrew -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
, -X- _ O
extracted -X- _ O
using -X- _ O
Attardi -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
iii -X- _ O
) -X- _ O
Twitter -X- _ O
: -X- _ O

Hebrew -X- _ B-DatasetName
tweets -X- _ I-DatasetName
collected -X- _ O
between -X- _ O
( -X- _ O
“ -X- _ O
RT -X- _ O
: -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
@ -X- _ O
” -X- _ O
user -X- _ O
mentions -X- _ O
and -X- _ O
URLs -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
eliminated -X- _ O
duplicates -X- _ O
. -X- _ O

For -X- _ O
data -X- _ O
statistics -X- _ O
, -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
Hebrew -X- _ O
portions -X- _ O
of -X- _ O
Oscar -X- _ O
andWikipedia -X- _ O
provide -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
training -X- _ O
- -X- _ O
set -X- _ O
size -X- _ O
orders -X- _ O
- -X- _ O
ofmagnitude -X- _ O
smaller -X- _ O
compared -X- _ O
with -X- _ O
resource -X- _ O
- -X- _ O
savvy -X- _ O
languages -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
strong -X- _ O
PLM -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
considerable -X- _ O
boost -X- _ O
in -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
sentences -X- _ O
the -X- _ O
PLM -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
comes -X- _ O
form -X- _ O
massive -X- _ O
amounts -X- _ O
of -X- _ O
tweets -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O

We -X- _ O
acknowledge -X- _ O
the -X- _ O
potential -X- _ O
inherent -X- _ O
concerns -X- _ O
associated -X- _ O
with -X- _ O
this -X- _ O
data -X- _ O
source -X- _ O
( -X- _ O
population -X- _ O
bias -X- _ O
, -X- _ O
behavior -X- _ O
patterns -X- _ O
, -X- _ O
bot -X- _ O
masquerading -X- _ O
as -X- _ O
humans -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
and -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
not -X- _ O
made -X- _ O
any -X- _ O
explicit -X- _ O
attempt -X- _ O
to -X- _ O
identify -X- _ O
these -X- _ O
cases -X- _ O
. -X- _ O

Honoring -X- _ O
ethical -X- _ O
and -X- _ O
legal -X- _ O
constraints -X- _ O
we -X- _ O
have -X- _ O
not -X- _ O
manually -X- _ O
analyzed -X- _ O
nor -X- _ O
published -X- _ O
this -X- _ O
data -X- _ O
source -X- _ O
. -X- _ O

While -X- _ O
the -X- _ O
free -X- _ O
form -X- _ O
language -X- _ O
expressed -X- _ O
in -X- _ O
tweets -X- _ O
might -X- _ O
differ -X- _ O
significantly -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
found -X- _ O
in -X- _ O
Oscar -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
, -X- _ O
the -X- _ O
sheer -X- _ O
volume -X- _ O
of -X- _ O
tweets -X- _ O
helps -X- _ O
us -X- _ O
close -X- _ O
the -X- _ O
resource -X- _ O
gap -X- _ O
substantially -X- _ O
with -X- _ O
minimal -X- _ O

effort.3 -X- _ O
Model -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
Transformers -X- _ O
training -X- _ O
framework -X- _ O
of -X- _ O
Huggingface -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
trained -X- _ O
two -X- _ O
different -X- _ O
models -X- _ O
— -X- _ O
a -X- _ O
small -X- _ O
model -X- _ O
with -X- _ O
6 -X- _ O
hidden -X- _ O
layers -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
Oscar -X- _ B-DatasetName
portion -X- _ O
of -X- _ O
our -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
base -X- _ O
model -X- _ O
with -X- _ O
12 -X- _ O
hidden -X- _ O
layers -X- _ O
which -X- _ O
was -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
dataset -X- _ O
. -X- _ O

The -X- _ O
processing -X- _ O
units -X- _ O
used -X- _ O
are -X- _ O
wordpieces -X- _ O
generated -X- _ O
by -X- _ O
training -X- _ O
BERT -X- _ O
tokenizers -X- _ O
over -X- _ O
the -X- _ O
respective -X- _ O
Following -X- _ O
the -X- _ O
work -X- _ O
on -X- _ O
RoBERTa -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
we -X- _ O
optimize -X- _ O
AlephBERT -X- _ B-MethodName
with -X- _ O
a -X- _ O
masked -X- _ O
- -X- _ O
token -X- _ O
prediction -X- _ O
loss -X- _ O
. -X- _ O

We -X- _ O
deploy -X- _ O
the -X- _ O
default -X- _ O
masking -X- _ O
configuration -X- _ O
where -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
word -X- _ O
piece -X- _ O
tokens -X- _ O
are -X- _ O
masked -X- _ O
. -X- _ O

In -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
, -X- _ O
in -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
random -X- _ O
token -X- _ O
and -X- _ O
in -X- _ O
the -X- _ O
remaining -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
are -X- _ O
left -X- _ O
as -X- _ O
is -X- _ O
. -X- _ O

Operation -X- _ O
To -X- _ O
optimize -X- _ O
GPU -X- _ O
utilization -X- _ O
and -X- _ O
decrease -X- _ O
training -X- _ O
time -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
dataset -X- _ O
into -X- _ O
4 -X- _ O
chunks -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
and -X- _ O
consequently -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
increase -X- _ O
batch -X- _ O
sizes -X- _ O
and -X- _ O
dramatically -X- _ O
shorten -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O

chunk1 -X- _ O
chunk2 -X- _ O
chunk3 -X- _ O
chunk4 -X- _ O
num -X- _ O
sentences -X- _ O
70 -X- _ O
M -X- _ O
20 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
2 -X- _ O
M -X- _ O
We -X- _ O
trained -X- _ O
for -X- _ O
5 -X- _ O
epochs -X- _ O
with -X- _ O
learning -X- _ O
rate -X- _ O
1e4 -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
additional -X- _ O
5 -X- _ O
epochs -X- _ O
with -X- _ O
learning -X- _ O
rate -X- _ O
at -X- _ O
5e-5 -X- _ O
for -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
10 -X- _ O
epochs -X- _ O
. -X- _ O

We -X- _ O
trained -X- _ O
AlephBERT -X- _ B-MethodName
baseover -X- _ O
the -X- _ O
entire -X- _ O
dataset -X- _ O
on -X- _ O
an -X- _ O
NVidia -X- _ O
DGX -X- _ O
server -X- _ O
with -X- _ O
8 -X- _ O
V100 -X- _ O
GPUs -X- _ O
which -X- _ O
took -X- _ O
8 -X- _ O
days -X- _ O
. -X- _ O

AlephBERT -X- _ B-MethodName
small -X- _ O
was -X- _ O
trained -X- _ O
over -X- _ O
the -X- _ O
Oscar -X- _ B-DatasetName
portion -X- _ O
only -X- _ O
, -X- _ O
using -X- _ O
4 -X- _ O
GTX -X- _ O
2080ti -X- _ O
GPUs -X- _ O
taking -X- _ O
5 -X- _ O
days -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O

4 -X- _ O

The -X- _ O
Morphological -X- _ O
Extraction -X- _ O
Model -X- _ O
Modern -X- _ O
Hebrew -X- _ O
is -X- _ O
a -X- _ O
Semitic -X- _ O
language -X- _ O
with -X- _ O
rich -X- _ O
morphology -X- _ O
and -X- _ O
complex -X- _ O
orthography -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
basic -X- _ O
processing -X- _ O
units -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
are -X- _ O
typically -X- _ O
smaller -X- _ O
than -X- _ O
raw -X- _ O
space -X- _ O
- -X- _ O
delimited -X- _ O
tokens -X- _ O
. -X- _ O

Subsequently -X- _ O
, -X- _ O
most -X- _ O
standard -X- _ O
evaluation -X- _ O
tasks -X- _ O
require -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
internal -X- _ O
morphological -X- _ O
boundaries -X- _ O
within -X- _ O
the -X- _ O
raw -X- _ O
tokens -X- _ O
. -X- _ O

To -X- _ O
accommodate -X- _ O
this -X- _ O
granularity -X- _ O
requirement -X- _ O
we -X- _ O
developed -X- _ O
a -X- _ O
neural -X- _ O
model -X- _ O
designed -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
disambiguated -X- _ O
morphological -X- _ O
segments -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
context -X- _ O
. -X- _ O

These -X- _ O
linguistic -X- _ O
segmentations -X- _ O
are -X- _ O
distinct -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
pieces -X- _ O
employed -X- _ O
by -X- _ O
the -X- _ O
PLM -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
morphological -X- _ O
extraction -X- _ O
neural -X- _ O
model -X- _ O
, -X- _ O
each -X- _ O
input -X- _ O
token -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
( -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
) -X- _ O
contextualized -X- _ O
word -X- _ O
- -X- _ O
vectors -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
PLM -X- _ O
. -X- _ O

Each -X- _ O
word -X- _ O
- -X- _ O
piece -X- _ O
token -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
vector -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
each -X- _ O
space -X- _ O
- -X- _ O
delimited -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
average -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
piece -X- _ O
vectors -X- _ O
. -X- _ O

We -X- _ O
feed -X- _ O
the -X- _ O
resulting -X- _ O
vector -X- _ O
into -X- _ O
a -X- _ O
seq2seq -X- _ O
model -X- _ O
and -X- _ O
encode -X- _ O
the -X- _ O
surface -X- _ O
token -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
characters -X- _ O
using -X- _ O
a -X- _ O
BiLSTM -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
decoder -X- _ O
that -X- _ O
generates -X- _ O
an -X- _ O
output -X- _ O
sequence -X- _ O
of -X- _ O
characters -X- _ O
, -X- _ O
using -X- _ O
space -X- _ O
as -X- _ O
a -X- _ O
special -X- _ O
symbol -X- _ O
signaling -X- _ O
morphological -X- _ O
boundaries.49 -X- _ O

POS -X- _ O
ADJ -X- _ O
DET -X- _ O
NOUN -X- _ O
DET -X- _ O
ADP -X- _ O
Morphology -X- _ O
Gender -X- _ O
= -X- _ O
Masc -X- _ O
|Number -X- _ O
= -X- _ O
Sing -X- _ O
PronType -X- _ O
= -X- _ O
Art -X- _ O
Gender -X- _ O
= -X- _ O
Masc -X- _ O
|Number -X- _ O
= -X- _ O
Sing -X- _ O
PronType -X- _ O
= -X- _ O
Art -X- _ O
Dependencies -X- _ O
3 -X- _ O
/ -X- _ O
amod -X- _ O
5 -X- _ O
/ -X- _ O
det -X- _ O
1 -X- _ O
/ -X- _ O
obj -X- _ O
3 -X- _ O
/ -X- _ O
def -X- _ O
0 -X- _ O
/ -X- _ O
ROOT -X- _ O
Word -X- _ O
- -X- _ O
level -X- _ O
NER -X- _ O
E -X- _ O
- -X- _ O
ORG -X- _ O
B -X- _ O
- -X- _ O
ORG -X- _ O
Morpheme -X- _ O
- -X- _ O
level -X- _ O
NER -X- _ O
E -X- _ O
- -X- _ O
ORG -X- _ O
I -X- _ O
- -X- _ O
ORG -X- _ O
I -X- _ O
- -X- _ O
ORG -X- _ O
B -X- _ O
- -X- _ O
ORG -X- _ O
O -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Illustration -X- _ O
of -X- _ O
Evaluated -X- _ O
Word -X- _ O
- -X- _ O
Based -X- _ O
and -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
Downstream -X- _ O
Tasks -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
- -X- _ O
word -X- _ O
input -X- _ O
phrase -X- _ O
“ -X- _ O
/ -X- _ O
ֹדנֵfנ -X- _ O
/ -X- _ O
דרֹוuנfלביתהלבלַנִ -X- _ O
, -X- _ O
” -X- _ O
transliterated -X- _ O
as -X- _ O
“ -X- _ O
lbit -X- _ O
hlbn -X- _ O
” -X- _ O
( -X- _ O
to -X- _ O
the -X- _ O
White -X- _ O
House -X- _ O
) -X- _ O
, -X- _ O
decompose -X- _ O
into -X- _ O
five -X- _ O
morphological -X- _ O
segments -X- _ O
( -X- _ O
‘ -X- _ O
to -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
house -X- _ O
the -X- _ O
- -X- _ O
white -X- _ O
’ -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
Hebrew -X- _ O
text -X- _ O
goes -X- _ O
from -X- _ O
right -X- _ O
to -X- _ O
left -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
Illustration -X- _ O
of -X- _ O
the -X- _ O
Morphological -X- _ O
Extraction -X- _ O
Model -X- _ O
. -X- _ O

The -X- _ O
embedded -X- _ O
vectors -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
wordpieces -X- _ O
( -X- _ O
v1 -X- _ O
and -X- _ O
v2 -X- _ O
representing -X- _ O
word -X- _ O
- -X- _ O
piece -X- _ O
vectors -X- _ O
generated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
are -X- _ O
combined -X- _ O
( -X- _ O
averaged -X- _ O
) -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
context -X- _ O
vector -X- _ O
. -X- _ O

This -X- _ O
context -X- _ O
vector -X- _ O
initializes -X- _ O
the -X- _ O
hidden -X- _ O
( -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
) -X- _ O
state -X- _ O
of -X- _ O
a -X- _ O
BiLSTM -X- _ O
that -X- _ O
encodes -X- _ O
the -X- _ O
characters -X- _ O
of -X- _ O
the -X- _ O
origin -X- _ O
word -X- _ O
. -X- _ O

The -X- _ O
decoder -X- _ O
LSTM -X- _ O
outputs -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
characters -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
special -X- _ O
empty -X- _ O
symbol -X- _ O
indicates -X- _ O
a -X- _ O
morphological -X- _ O
segment -X- _ O
boundary -X- _ O
. -X- _ O

In -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
setup -X- _ O
, -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
linear -X- _ O
layer -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
label -X- _ O
whenever -X- _ O
a -X- _ O
segment -X- _ O
boundary -X- _ O
is -X- _ O
detected -X- _ O
. -X- _ O

For -X- _ O
tasks -X- _ O
involving -X- _ O
both -X- _ O
segments -X- _ O
and -X- _ O
labels -X- _ O
( -X- _ O
Part -X- _ B-TaskName
- -X- _ I-TaskName
of -X- _ I-TaskName
- -X- _ I-TaskName
Speech -X- _ I-TaskName
Tagging -X- _ I-TaskName
, -X- _ O
Morphological -X- _ B-TaskName
- -X- _ I-TaskName
Features -X- _ I-TaskName
Tagging -X- _ I-TaskName
, -X- _ O
Named -X- _ B-TaskName
- -X- _ I-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
) -X- _ O

we -X- _ O
expand -X- _ O
this -X- _ O
network -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
setup -X- _ O
; -X- _ O
when -X- _ O
generating -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
segment -X- _ O
( -X- _ O
space -X- _ O
) -X- _ O
symbol -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
also -X- _ O
predicts -X- _ O
task -X- _ O
label -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
segment -X- _ B-MetricName
- -X- _ I-MetricName
label -X- _ I-MetricName
losses -X- _ I-MetricName
. -X- _ O

The -X- _ O
complete -X- _ O
morphological -X- _ O
extraction -X- _ O
architecture -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
5 -X- _ O
Experimental -X- _ O
Setup -X- _ O
Goal -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
empirically -X- _ O
gauge -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
data -X- _ O
quantity -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
AlephBERT -X- _ B-MethodName
( -X- _ O
both -X- _ O
small -X- _ O
andbase -X- _ O
) -X- _ O
with -X- _ O
all -X- _ O
existing -X- _ O
Hebrew -X- _ O
BERT -X- _ O
instantiations -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
Section -X- _ O
, -X- _ O
we -X- _ O
detail -X- _ O
the -X- _ O
tasks -X- _ O
and -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
nextSection -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
and -X- _ O
analyze -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

5.1 -X- _ O
Sentence -X- _ O
- -X- _ O
Based -X- _ O
Modeling -X- _ O
Sentiment -X- _ O
Analysis -X- _ O
We -X- _ O
first -X- _ O
report -X- _ O
on -X- _ O
a -X- _ O
sentence -X- _ O
classification -X- _ B-TaskName
task -X- _ O
, -X- _ O
assigning -X- _ O
a -X- _ O
sentence -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
three -X- _ O
sentiment -X- _ O
values -X- _ O
: -X- _ O
negative -X- _ O
, -X- _ O
positive -X- _ O
, -X- _ O
neutral -X- _ O
. -X- _ O

Sentence -X- _ O
- -X- _ O
level -X- _ O
predictions -X- _ O
are -X- _ O
achieved -X- _ O
by -X- _ O
directly -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
PLM -X- _ O
using -X- _ O
an -X- _ O
additional -X- _ O
sentenceclassification -X- _ O
head -X- _ O
The -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
embedding -X- _ O
vector -X- _ O
representation -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
special -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
BERT -X- _ O
token -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
Hebrew -X- _ B-DatasetName
Facebook -X- _ I-DatasetName
Sentiment -X- _ I-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
henceforth -X- _ O
FB -X- _ O
) -X- _ O
of -X- _ O
Amram -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
which -X- _ O
we -X- _ O
corrected -X- _ O
by -X- _ O
removing -X- _ O
leaked -X- _ O
samples.4We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
all -X- _ O
models -X- _ O
for -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
5 -X- _ O
different -X- _ O
seeds -X- _ O
, -X- _ O
and -X- _ O
report -X- _ O
mean -X- _ B-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

5.2 -X- _ O
Word -X- _ O
- -X- _ O
Based -X- _ O
Modeling -X- _ O
Named -X- _ O
Entity -X- _ O
Recognition -X- _ O

In -X- _ O
this -X- _ O
setup -X- _ O
we -X- _ O
assume -X- _ O
a -X- _ O
sequence -X- _ B-TaskName
labeling -X- _ I-TaskName
task -X- _ O
based -X- _ O
on -X- _ O
spacedelimited -X- _ O
word -X- _ O
- -X- _ O
tokens -X- _ O
. -X- _ O

The -X- _ O
input -X- _ O
comprises -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
contains -X- _ O
BIOES -X- _ O
tags -X- _ O
indicating -X- _ O
entity -X- _ O
spans -X- _ O
. -X- _ O

Word -X- _ O
- -X- _ O
level -X- _ O
NER -X- _ O
predictions -X- _ O
are -X- _ O
achieved -X- _ O
by -X- _ O
directly -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
PLMs -X- _ O
using -X- _ O
an -X- _ O
additional -X- _ O
token -X- _ O
- -X- _ O
classification -X- _ O
head -X- _ O
In -X- _ O
cases -X- _ O
where -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
split -X- _ O
into -X- _ O
multiple -X- _ O
word -X- _ O
pieces -X- _ O
by -X- _ O
the -X- _ O
PLM -X- _ O
tokenizer -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
common -X- _ O
practice -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
first -X- _ O
word -X- _ O
- -X- _ O
piece -X- _ O
vector -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
this -X- _ O
model -X- _ O
on -X- _ O
two -X- _ O
corpora -X- _ O
. -X- _ O

( -X- _ O
i -X- _ O
) -X- _ O
The -X- _ O
Ben -X- _ B-DatasetName
- -X- _ I-DatasetName
Mordecai -X- _ I-DatasetName
( -X- _ O
BMC -X- _ O
) -X- _ O
corpus -X- _ O
( -X- _ O
Ben -X- _ O
Mordecai -X- _ O
and -X- _ O
Elhadad -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
3294 -X- _ O
sentences -X- _ O
with -X- _ O
4600 -X- _ O
entities -X- _ O
and -X- _ O
seven -X- _ O
different -X- _ O
entity -X- _ O
categories -X- _ O
( -X- _ O
Date -X- _ O
, -X- _ O
Location -X- _ O
, -X- _ O
Money -X- _ O
, -X- _ O
Organization -X- _ O
, -X- _ O
Person -X- _ O
, -X- _ O
Percent -X- _ O
, -X- _ O
Time -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
remain -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
work -X- _ O
we -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
3 -X- _ O
licly -X- _ O
available -X- _ O
here -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
OnlpLab -X- _ O
/ -X- _ O
Hebrew -X- _ O
- -X- _ O
Sentiment -X- _ O
- -X- _ O
Data50 -X- _ O

different -X- _ O
splits -X- _ O
as -X- _ O
in -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
ii -X- _ O
) -X- _ O
The -X- _ O
Named -X- _ O
Entities -X- _ O
and -X- _ O
MOrphology -X- _ O
( -X- _ O
NEMO -X- _ O
) -X- _ O
corpus5 -X- _ O
( -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
the -X- _ O
SPMRL -X- _ B-DatasetName
dataset -X- _ O
with -X- _ O
Named -X- _ O
Entities -X- _ O
. -X- _ O

The -X- _ O
NEMO -X- _ B-DatasetName
corpus -X- _ O
contains -X- _ O
6220 -X- _ O
sentences -X- _ O
with -X- _ O
7713 -X- _ O
entities -X- _ O
of -X- _ O
nine -X- _ O
entity -X- _ O
types -X- _ O
( -X- _ O
Language -X- _ O
, -X- _ O
Product -X- _ O
, -X- _ O
Event -X- _ O
, -X- _ O
Facility -X- _ O
, -X- _ O
Geo -X- _ O
- -X- _ O
Political -X- _ O
Entity -X- _ O
, -X- _ O
Location -X- _ O
, -X- _ O
Organization -X- _ O
, -X- _ O
Person -X- _ O
, -X- _ O
Work -X- _ O
- -X- _ O
Of -X- _ O
- -X- _ O
Art -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
trained -X- _ O
both -X- _ O
models -X- _ O
for -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
5 -X- _ O
different -X- _ O
seeds -X- _ O
and -X- _ O
report -X- _ O
mean -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
on -X- _ O
entity -X- _ O
spans -X- _ O
. -X- _ O

5.3 -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
Modeling -X- _ O
Finally -X- _ O
, -X- _ O
to -X- _ O
probe -X- _ O
the -X- _ O
PLM -X- _ O
capacity -X- _ O
to -X- _ O
accurately -X- _ O
predict -X- _ O
word -X- _ O
- -X- _ O
internal -X- _ O
structure -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
all -X- _ O
models -X- _ O
on -X- _ O
five -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
internal -X- _ O
morphology -X- _ O
of -X- _ O
raw -X- _ O
words -X- _ O
. -X- _ O

The -X- _ O
input -X- _ O
to -X- _ O
all -X- _ O
these -X- _ O
tasks -X- _ O
is -X- _ O
a -X- _ O
Hebrew -X- _ O
sentence -X- _ O
represented -X- _ O
as -X- _ O
a -X- _ O
raw -X- _ O
sequence -X- _ O
of -X- _ O
space -X- _ O
- -X- _ O
delimited -X- _ O
words -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
Segmentation -X- _ O
: -X- _ O
Generating -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
morphological -X- _ O
segments -X- _ O
representing -X- _ O
the -X- _ O
basic -X- _ O
processing -X- _ O
units -X- _ O
. -X- _ O

These -X- _ O
units -X- _ O
comply -X- _ O
with -X- _ O
the -X- _ O
2 -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
of -X- _ O
tokens -X- _ O
defined -X- _ O
by -X- _ O
UD -X- _ O
, -X- _ O
each -X- _ O
unit -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
POS -X- _ O
tag.6 -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
Part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O

Tagging -X- _ O
: -X- _ O

Tagging -X- _ O
each -X- _ O
segment -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
POS -X- _ O
. -X- _ O

( -X- _ O
iii -X- _ O
) -X- _ O
Morphological -X- _ O
Tagging -X- _ O
: -X- _ O

Tagging -X- _ O
each -X- _ O
segment -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
POS -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
. -X- _ O

Equivalent -X- _ O
to -X- _ O
the -X- _ O
AllTags -X- _ O
evaluation -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
CoNLL18 -X- _ O
shared -X- _ O
task.7 -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
NER -X- _ O
: -X- _ O

Tagging -X- _ O
each -X- _ O
segment -X- _ O
with -X- _ O
a -X- _ O
BIOES -X- _ O
and -X- _ O
its -X- _ O
entity -X- _ O
- -X- _ O
type -X- _ O
. -X- _ O

( -X- _ O
v -X- _ O
) -X- _ O
Dependency -X- _ O
Parsing -X- _ O
: -X- _ O
Use -X- _ O
each -X- _ O
segment -X- _ O
as -X- _ O
a -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
dependency -X- _ O
tree -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
all -X- _ O
morphologically -X- _ O
- -X- _ O
aware -X- _ O
models -X- _ O
using -X- _ O
two -X- _ O
available -X- _ O
morphologically -X- _ O
- -X- _ O
aware -X- _ O
Hebrew -X- _ O
resources -X- _ O
: -X- _ O
•The -X- _ O
Hebrew -X- _ O
Section -X- _ O
of -X- _ O
the -X- _ O
SPMRL -X- _ O
Task -X- _ O
( -X- _ O
Sed•The -X- _ O
Hebrew -X- _ O
Section -X- _ O
of -X- _ O
the -X- _ O
UD -X- _ O
treebanks -X- _ O
collection -X- _ O
( -X- _ O
Sadde -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O

All -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
for -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
5 -X- _ O
different -X- _ O
seeds -X- _ O
and -X- _ O
we -X- _ O
report -X- _ O
two -X- _ O
variants -X- _ O
of -X- _ O
mean -X- _ O
F1 -X- _ O
scores -X- _ O
as -X- _ O
described -X- _ O
next -X- _ O
. -X- _ O

NEMO -X- _ O
- -X- _ O
Corpus -X- _ O
6https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
universaldependencies.org -X- _ O
/ -X- _ O
u -X- _ O
/ -X- _ O
overview -X- _ O
/ -X- _ O
tokenization.html -X- _ O

7https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
universaldependencies.org -X- _ O
/ -X- _ O
conll18 -X- _ O
/ -X- _ O
results -X- _ O
- -X- _ O
alltags.htmlFor -X- _ O
tasks -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
– -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
morphological -X- _ O
extraction -X- _ O
model -X- _ O
( -X- _ O
Section -X- _ O
4 -X- _ O
) -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
morphological -X- _ O
segments -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
context -X- _ O
and -X- _ O
also -X- _ O
predict -X- _ O
the -X- _ O
labels -X- _ O
via -X- _ O
Multitask -X- _ O
training -X- _ O
. -X- _ O

For -X- _ O
task -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
the -X- _ O
NER -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
morphologically -X- _ O
- -X- _ O
annotated -X- _ O
data -X- _ O
files -X- _ O
of -X- _ O
the -X- _ O
aforementioned -X- _ O
SPMRL -X- _ O
- -X- _ O
based -X- _ O
NEMO -X- _ O
corpus -X- _ O
( -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
setup -X- _ O
described -X- _ O
earlier -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
another -X- _ O
setup -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
first -X- _ O
only -X- _ O
segment -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
perform -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
with -X- _ O
a -X- _ O
token -X- _ O
classification -X- _ O
attention -X- _ O
head -X- _ O
directly -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
PLM -X- _ O
output -X- _ O
for -X- _ O
the -X- _ O
segmented -X- _ O
tokens -X- _ O
( -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
way -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
PLM -X- _ O
for -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
based -X- _ O
NER -X- _ O
task -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
acknowledge -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
PLM -X- _ O
on -X- _ O
morphological -X- _ O
segments -X- _ O
the -X- _ O
model -X- _ O
was -X- _ O
not -X- _ O
originally -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
shall -X- _ O
see -X- _ O
shortly -X- _ O
, -X- _ O
this -X- _ O
seemingly -X- _ O
unintuitive -X- _ O
strategy -X- _ O
performs -X- _ O
surprisingly -X- _ O
well -X- _ O
. -X- _ O

For -X- _ O
task -X- _ O
( -X- _ O
v -X- _ O
) -X- _ O
we -X- _ O
set -X- _ O
up -X- _ O
a -X- _ O
dependency -X- _ O
parsing -X- _ O
evaluation -X- _ O
pipeline -X- _ O
using -X- _ O
the -X- _ O
standalone -X- _ O
Hebrew -X- _ O
parser -X- _ O
offered -X- _ O
by -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
a.k.a -X- _ O
YAP -X- _ O
) -X- _ O
which -X- _ O
was -X- _ O
trained -X- _ O
to -X- _ O
produce -X- _ O
SPMRL -X- _ O
dependency -X- _ O
labels -X- _ O
. -X- _ O

The -X- _ O
morphological -X- _ O
information -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
( -X- _ O
namely -X- _ O
the -X- _ O
segments -X- _ O
and -X- _ O
POS -X- _ O
tags -X- _ O
) -X- _ O
is -X- _ O
recovered -X- _ O
by -X- _ O
our -X- _ O
morphological -X- _ O
extraction -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
features -X- _ O
for -X- _ O
the -X- _ O
YAP -X- _ O
standalone -X- _ O
dependency -X- _ O
parser -X- _ O
. -X- _ O

5.4 -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
Aligned -X- _ O
Segment -X- _ O
The -X- _ O
CoNLL18 -X- _ O
Shared -X- _ O
Task -X- _ O
evaluation -X- _ O
campaign8reports -X- _ O
scores -X- _ O
for -X- _ O
segmentation -X- _ O
and -X- _ O
POS -X- _ O
tagging9for -X- _ O
all -X- _ O
participating -X- _ O
languages -X- _ O
. -X- _ O

For -X- _ O
multi -X- _ O
- -X- _ O
segment -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
gold -X- _ O
and -X- _ O
predicted -X- _ O
segments -X- _ O
are -X- _ O
aligned -X- _ O
by -X- _ O
their -X- _ O
Longest -X- _ O
Common -X- _ O
Sub -X- _ O
- -X- _ O
sequence -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
matching -X- _ O
segments -X- _ O
are -X- _ O
counted -X- _ O
as -X- _ O
true -X- _ O
positives -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
script -X- _ O
to -X- _ O
compare -X- _ O
aligned -X- _ O
segment -X- _ O
and -X- _ O
tagging -X- _ O
scores -X- _ O
between -X- _ O
oracle -X- _ O
( -X- _ O
gold -X- _ O
) -X- _ O
segmentation -X- _ O
and -X- _ O
realistic -X- _ O
( -X- _ O
predicted -X- _ O
) -X- _ O
segmentation -X- _ O
. -X- _ O

Aligned -X- _ O
Multi -X- _ O
- -X- _ O
Set -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
CoNLL18 -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
slight -X- _ O
but -X- _ O
important -X- _ O
difference -X- _ O
from -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
, -X- _ O
as -X- _ O
defined -X- _ O
by -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Seker -X- _ O
and -X- _ O
Tsarfaty -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
word -X- _ O
, -X- _ O
counts -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
multiset -X- _ O
intersections -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
and -X- _ O
predicted -X- _ O
labels -X- _ O
ignoring -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
segments -X- _ O
while -X- _ O
account8https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
universaldependencies.org -X- _ O
/ -X- _ O
conll18 -X- _ O
/ -X- _ O
results.html -X- _ O
9respectively -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
’ -X- _ O
Segmented -X- _ O
Words -X- _ O
’ -X- _ O
and -X- _ O
’ -X- _ O
UPOS -X- _ O
’ -X- _ O
in -X- _ O
the -X- _ O
CoNLL18 -X- _ O
evaluation -X- _ O
script51 -X- _ O

Task -X- _ O
NER -X- _ O
( -X- _ O
Word -X- _ O
) -X- _ O
Sentiment -X- _ O
Corpus -X- _ O
NEMO -X- _ O
BMC -X- _ O
FB -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Word -X- _ O
- -X- _ O
based -X- _ O
NER -X- _ O
F1 -X- _ O
. -X- _ O

Previous -X- _ O
SOTA -X- _ O
on -X- _ O
both -X- _ O
corpora -X- _ O
reported -X- _ O
by -X- _ O
the -X- _ O
NEMO -X- _ O
models -X- _ O
of -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Sentiment -X- _ O
Analysis -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
corrected -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
corpus -X- _ O
of -X- _ O
Amram -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

ing -X- _ O
for -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
each -X- _ O
segment -X- _ O
. -X- _ O

Aligned -X- _ O
mset -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
set -X- _ O
difference -X- _ O
which -X- _ O
acknowledges -X- _ O
the -X- _ O
possible -X- _ O
undercover -X- _ O
of -X- _ O
covert -X- _ O
morphemes -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
appropriate -X- _ O
measure -X- _ O
of -X- _ O
morphological -X- _ O
accuracy -X- _ O
. -X- _ O

Discussion -X- _ O
To -X- _ O
illustrate -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
aligned -X- _ O
segment -X- _ O
andaligned -X- _ O
mset -X- _ O
, -X- _ O
let -X- _ O
us -X- _ O
take -X- _ O
for -X- _ O
example -X- _ O
the -X- _ O
gold -X- _ O
segmented -X- _ O
tag -X- _ O
sequence -X- _ O
: -X- _ O
b -X- _ O
/ -X- _ O
IN -X- _ O
, -X- _ O
h -X- _ O
/ -X- _ O
DET -X- _ O
, -X- _ O
bit -X- _ O
/ -X- _ O
NOUN -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
segmented -X- _ O
tag -X- _ O
sequence -X- _ O
b -X- _ O
/ -X- _ O
IN -X- _ O
, -X- _ O
bit -X- _ O
/ -X- _ O
NOUN -X- _ O
. -X- _ O

According -X- _ O
to -X- _ O
aligned -X- _ O
segment -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
segment -X- _ O
( -X- _ O
b -X- _ O
/ -X- _ O
IN -X- _ O
) -X- _ O
is -X- _ O
aligned -X- _ O
and -X- _ O
counted -X- _ O
as -X- _ O
a -X- _ O
true -X- _ O
positive -X- _ O
, -X- _ O
the -X- _ O
second -X- _ O
segment -X- _ O
however -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
false -X- _ O
positive -X- _ O
( -X- _ O
bit -X- _ O
/ -X- _ O
NOUN -X- _ O
) -X- _ O
and -X- _ O
false -X- _ O
negative -X- _ O
( -X- _ O
h -X- _ O
/ -X- _ O
DET -X- _ O
) -X- _ O
while -X- _ O
the -X- _ O
third -X- _ O
gold -X- _ O
segment -X- _ O
is -X- _ O
also -X- _ O
counted -X- _ O
as -X- _ O
a -X- _ O
false -X- _ O
negative -X- _ O
( -X- _ O
bit -X- _ O
/ -X- _ O
NOUN -X- _ O
) -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
with -X- _ O
aligned -X- _ O
multi -X- _ O
- -X- _ O
set -X- _ O
both -X- _ O
b -X- _ O
/ -X- _ O
IN -X- _ O
andbit -X- _ O
/ -X- _ O
NOUN -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
and -X- _ O
predicted -X- _ O
sets -X- _ O
and -X- _ O
counted -X- _ O
as -X- _ O
true -X- _ O
positives -X- _ O
, -X- _ O
while -X- _ O
h -X- _ O
/ -X- _ O
DET -X- _ O
is -X- _ O
mismatched -X- _ O
and -X- _ O
counted -X- _ O
as -X- _ O
a -X- _ O
false -X- _ O
negative -X- _ O
. -X- _ O

In -X- _ O
both -X- _ O
cased -X- _ O
the -X- _ O
total -X- _ O
counts -X- _ O
across -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
entire -X- _ O
datasets -X- _ O
are -X- _ O
incremented -X- _ O
accordingly -X- _ O
and -X- _ O
finally -X- _ O
used -X- _ O
for -X- _ O
computing -X- _ O
Precision -X- _ B-MetricName
, -X- _ O
Recall -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
. -X- _ O

6 -X- _ O
Results -X- _ O
Sentence -X- _ O
- -X- _ O
Level -X- _ O
Task -X- _ O
Sentiment -X- _ O
analysis -X- _ O
accuracy -X- _ O
results -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

All -X- _ O
BERTbased -X- _ O
models -X- _ O
substantially -X- _ O
outperform -X- _ O
the -X- _ O
original -X- _ O
CNN -X- _ O
Baseline -X- _ O
reported -X- _ O
by -X- _ O
Amram -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

AlephBERT -X- _ B-MethodName
baseis -X- _ O
setting -X- _ O
a -X- _ O
new -X- _ O
SOTA -X- _ O
. -X- _ O

Word -X- _ O
- -X- _ O
Based -X- _ O
Task -X- _ O
On -X- _ O
our -X- _ O
two -X- _ O
NER -X- _ O
benchmarks -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
on -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
based -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

While -X- _ O
we -X- _ O
see -X- _ O
noticeable -X- _ O
improvements -X- _ O
for -X- _ O
the -X- _ O
mBERT -X- _ O
and -X- _ O
HeBert -X- _ O
variants -X- _ O
over -X- _ O
the -X- _ O
current -X- _ O
SOTA -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
significant -X- _ O
increase -X- _ O
is -X- _ O
achieved -X- _ O
by -X- _ O
AlephBERT -X- _ O
base -X- _ O
, -X- _ O
setting -X- _ O
a -X- _ O
new -X- _ O
and -X- _ O
improved -X- _ O
SOTA -X- _ O
on -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

Morpheme -X- _ O
- -X- _ O
Level -X- _ O
Tasks -X- _ O
As -X- _ O
a -X- _ O
particular -X- _ O
novelty -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O

, -X- _ O
we -X- _ O
report -X- _ O
BERT -X- _ B-MetricName
- -X- _ O
based -X- _ O
results -X- _ O
on -X- _ O
sub -X- _ O
- -X- _ O
Task -X- _ O
Segment -X- _ O
POS -X- _ O
Features -X- _ O
UAS -X- _ O
LAS -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
SPMRL -X- _ B-DatasetName
corpus -X- _ O
. -X- _ O

Aligned -X- _ O
MultiSet -X- _ O
( -X- _ O
mset -X- _ O
) -X- _ O
F1 -X- _ O
for -X- _ O
Segmentation -X- _ O
, -X- _ O
POS -X- _ O
tags -X- _ O
and -X- _ O
Morphological -X- _ O
Features -X- _ O
- -X- _ O
previous -X- _ O
SOTA -X- _ O
reported -X- _ O
by -X- _ O
Seker -X- _ O
and -X- _ O
Tsarfaty -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
and -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
features -X- _ O
) -X- _ O
. -X- _ O

Labeled -X- _ O
and -X- _ O
Unlabeled -X- _ O
Accuracy -X- _ O
Scores -X- _ O
for -X- _ O
morphological -X- _ O
- -X- _ O
level -X- _ O
Dependency -X- _ O
Parsing -X- _ O
- -X- _ O
previous -X- _ O
SOTA -X- _ O
reported -X- _ O
by -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
uninfused -X- _ O
/ -X- _ O
realistic -X- _ O
scenario -X- _ O
) -X- _ O

Task -X- _ O
Segment -X- _ O
POS -X- _ O
Features -X- _ O
Prev -X- _ O
. -X- _ O

SOTA -X- _ O
NA -X- _ O
94.02 -X- _ B-MetricValue

NA -X- _ O
Table -X- _ O
6 -X- _ O
: -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
Aligned -X- _ O
MultiSet -X- _ O
( -X- _ O
mset -X- _ O
) -X- _ O
F1 -X- _ B-MetricName
results -X- _ O
on -X- _ O
the -X- _ O
UD -X- _ O
corpus -X- _ O
. -X- _ O

Previous -X- _ O
SOTA -X- _ O
reported -X- _ O
by -X- _ O
Seker -X- _ O
and -X- _ O
Tsarfaty -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
word -X- _ O
( -X- _ O
segment -X- _ O
- -X- _ O
level -X- _ O
) -X- _ O
information -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
word -X- _ O
segmentation -X- _ O
, -X- _ O
POS -X- _ O
, -X- _ O
Morphological -X- _ O
Features -X- _ O
, -X- _ O
NER -X- _ O
and -X- _ O
dependencies -X- _ O
compared -X- _ O
against -X- _ O
morphologically -X- _ O
- -X- _ O
labeled -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O

In -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
raw -X- _ O
space -X- _ O
- -X- _ O
delimited -X- _ O
tokens -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
produce -X- _ O
morphological -X- _ O
segments -X- _ O
with -X- _ O
our -X- _ O
morphological -X- _ O
extraction -X- _ O
model -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
presents -X- _ O
evaluation -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
SPRML -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
compared -X- _ O
against -X- _ O
the -X- _ O
previous -X- _ O
SOTA -X- _ O
of -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
segmentation -X- _ O
, -X- _ O
POS -X- _ O
tagging -X- _ O
, -X- _ O
and -X- _ O
morphological -X- _ O
tagging -X- _ O
we -X- _ O
report -X- _ O
aligned -X- _ O
multiset -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
. -X- _ O

BERT -X- _ O
- -X- _ O
based -X- _ O
segmentations -X- _ O
are -X- _ O
similar -X- _ O
, -X- _ O
all -X- _ O
scoring -X- _ O
in -X- _ O
the -X- _ O
high -X- _ O
range -X- _ O
of -X- _ O
97 -X- _ O
- -X- _ O
98 -X- _ O
F1 -X- _ B-MetricName
, -X- _ O
which -X- _ O
are -X- _ O
hard -X- _ O
to -X- _ O
improve -X- _ O
further.10 -X- _ O
For -X- _ O
POS -X- _ O
tagging -X- _ O
and -X- _ O
morphological -X- _ O
features -X- _ O
, -X- _ O
all -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
considerably -X- _ O
outperform -X- _ O
the -X- _ O
previous -X- _ O
SOTA -X- _ O
. -X- _ O

For -X- _ O
syntactic -X- _ O
dependencies -X- _ O
we -X- _ O
report -X- _ O
labeled -X- _ O
and -X- _ O
unlabeled -X- _ O
accuracy -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
trees -X- _ O
generated -X- _ O
by -X- _ O
YAP -X- _ O
( -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
on -X- _ O
our -X- _ O
predicted -X- _ O
segmentation -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
see -X- _ O
impressive -X- _ O
improvement -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
previous -X- _ O
SOTA -X- _ O
of -X- _ O
a -X- _ O
joint -X- _ O
morpho -X- _ O
- -X- _ O
syntactic -X- _ O
framework -X- _ O
. -X- _ O

It -X- _ O
confirms -X- _ O
that -X- _ O
morphological -X- _ O
errors -X- _ O
early -X- _ O
in -X- _ O
the -X- _ O
pipeline -X- _ O
negatively -X- _ O
impact -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
morphologically -X- _ O
- -X- _ O
driven -X- _ O
benchmarks -X- _ O
10According -X- _ O
to -X- _ O
error -X- _ O
analysis -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
these -X- _ O
errors -X- _ O
are -X- _ O
annotation -X- _ O
errors -X- _ O
or -X- _ O
truly -X- _ O
ambiguous -X- _ O
cases.52 -X- _ O

Task -X- _ O
Segment -X- _ O
POS -X- _ O
Features -X- _ O
Table -X- _ O
7 -X- _ O
: -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
Aligned -X- _ O
( -X- _ O
CoNLL -X- _ O
shared -X- _ O
task -X- _ O
) -X- _ O
F1 -X- _ O
on -X- _ O
the -X- _ O
UD -X- _ O
corpus -X- _ O
. -X- _ O

Previous -X- _ O
SOTA -X- _ O
reported -X- _ O
by -X- _ O
Minh -X- _ O
Van -X- _ O
Nguyen -X- _ O
and -X- _ O
Nguyen -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
Architecture -X- _ O
Pipeline -X- _ O
Pipeline -X- _ O
MultiTask -X- _ O
Segmentation -X- _ O
( -X- _ O
Oracle -X- _ O
) -X- _ O
( -X- _ O
Predicted -X- _ O
) -X- _ O
Task -X- _ O
Seg -X- _ O
NER -X- _ O
Seg -X- _ O
NER -X- _ O
Seg -X- _ O
NER -X- _ O
Table -X- _ O
8 -X- _ O
: -X- _ O
Morpheme -X- _ O
- -X- _ O
Based -X- _ O
NER -X- _ O
F1 -X- _ O
on -X- _ O
the -X- _ O
NEMO -X- _ O
corpus -X- _ O
. -X- _ O

Previous -X- _ O
SOTA -X- _ O
reported -X- _ O
by -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
Pipeline -X- _ O
( -X- _ O
Oracle -X- _ O
) -X- _ O
, -X- _ O
Pipeline -X- _ O
( -X- _ O
Predicted -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
Hybrid -X- _ O
( -X- _ O
almost -X- _ O
- -X- _ O
joint -X- _ O
) -X- _ O
scenarios -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

as -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
PLM -X- _ O
evaluation -X- _ O
for -X- _ O
MRLs -X- _ O
. -X- _ O

All -X- _ O
in -X- _ O
all -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
repeating -X- _ O
trend -X- _ O
placing -X- _ O
AlephBERT -X- _ O
basefirst -X- _ O
on -X- _ O
all -X- _ O
morphological -X- _ O
tasks -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
depth -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
a -X- _ O
larger -X- _ O
pretraining -X- _ O
dataset -X- _ O
improve -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
PLM -X- _ O
to -X- _ O
capture -X- _ O
word -X- _ O
- -X- _ O
internal -X- _ O
structure -X- _ O
. -X- _ O

These -X- _ O
trends -X- _ O
are -X- _ O
replicated -X- _ O
on -X- _ O
the -X- _ O
UD -X- _ O
Hebrew -X- _ O
corpus -X- _ O
, -X- _ O
for -X- _ O
two -X- _ O
different -X- _ O
evaluation -X- _ O
metrics -X- _ O
— -X- _ O
the -X- _ O
Aligned -X- _ B-MetricName
MultiSet -X- _ I-MetricName
F1 -X- _ I-MetricName
Scores -X- _ O
as -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
Hebrew -X- _ O
( -X- _ O
More -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
Seker -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Aligned -X- _ B-MetricName
Segment -X- _ I-MetricName
F1 -X- _ I-MetricName
scores -X- _ O
metrics -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
UD -X- _ O
shared -X- _ O
task -X- _ O
( -X- _ O
Zeman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
— -X- _ O
reported -X- _ O
in -X- _ O
Tables -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
respectively -X- _ O
. -X- _ O

Morpheme -X- _ O
- -X- _ O
Level -X- _ O
NER -X- _ O
results -X- _ O
Earlier -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
considered -X- _ O
NER -X- _ O
a -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
task -X- _ O
that -X- _ O
simply -X- _ O
requires -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
setup -X- _ O
is -X- _ O
not -X- _ O
accurate -X- _ O
enough -X- _ O
and -X- _ O
less -X- _ O
useful -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
exact -X- _ O
entity -X- _ O
boundaries -X- _ O
are -X- _ O
often -X- _ O
word -X- _ O
internal -X- _ O
( -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
hence -X- _ O
report -X- _ O
morpheme -X- _ O
- -X- _ O
based -X- _ O
NER -X- _ O
evaluation -X- _ O
, -X- _ O
respecting -X- _ O
the -X- _ O
exact -X- _ O
boundaries -X- _ O
of -X- _ O
entity -X- _ O
mentions -X- _ O
. -X- _ O

To -X- _ O
obtain -X- _ O
morpheme -X- _ O
- -X- _ O
based -X- _ O
labeled -X- _ O
- -X- _ O
span -X- _ O
of -X- _ O
Named -X- _ O
Entities -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
either -X- _ O
employ -X- _ O
a -X- _ O
pipeline -X- _ O
, -X- _ O
first -X- _ O
predicting -X- _ O
segmentation -X- _ O
and -X- _ O
then -X- _ O
applying -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
labeling -X- _ O
model -X- _ O
directly -X- _ O
on -X- _ O
the -X- _ O
segments -X- _ O
, -X- _ O
or -X- _ O
employ -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
model -X- _ O
and -X- _ O
predict -X- _ O
NER -X- _ O
labels -X- _ O
while -X- _ O
performing -X- _ O
segmentation -X- _ O
. -X- _ O

Table -X- _ O
8 -X- _ O
presents -X- _ O
segmentation -X- _ O
and -X- _ O
NER -X- _ O
results -X- _ O
for -X- _ O
3 -X- _ O
different -X- _ O
scenarios -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
a -X- _ O
pipeline -X- _ O
as -X- _ O
- -X- _ O
suming -X- _ O
gold -X- _ O
segmentation -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
a -X- _ O
pipeline -X- _ O
assuming -X- _ O
predicted -X- _ O
segmentation -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
segmentation -X- _ O
and -X- _ O
NER -X- _ O
labels -X- _ O
obtained -X- _ O
jointly -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
setup -X- _ O
. -X- _ O

AlephBERT -X- _ B-MethodName
baseconsistently -X- _ O
scores -X- _ O
highest -X- _ O
in -X- _ O
all -X- _ O
3 -X- _ O
. -X- _ O

Looking -X- _ O
at -X- _ O
the -X- _ O
Pipeline -X- _ O
- -X- _ O
Predicted -X- _ O
scores -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
clear -X- _ O
correlation -X- _ O
between -X- _ O
a -X- _ O
higher -X- _ O
segmentation -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
PLM -X- _ O
and -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
produce -X- _ O
better -X- _ O
NER -X- _ O
results -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
NER -X- _ B-MetricName
scores -X- _ I-MetricName
are -X- _ O
considerable -X- _ O
( -X- _ O
unlike -X- _ O
the -X- _ O
subtle -X- _ O
differences -X- _ O
in -X- _ O
segmentation -X- _ O
, -X- _ O
POS -X- _ O
and -X- _ O
morphological -X- _ O
features -X- _ O
scores -X- _ O
) -X- _ O
and -X- _ O
draw -X- _ O
our -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
PLM -X- _ O
, -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
final -X- _ O
NER -X- _ O
models -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
HeBERT -X- _ B-MethodName
and -X- _ O
AlephBERT -X- _ B-MethodName
smallwere -X- _ O
both -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
similar -X- _ O
datasets -X- _ O
and -X- _ O
comparable -X- _ O
vocabulary -X- _ O
sizes -X- _ O
( -X- _ O
heBERT -X- _ B-MethodName
with -X- _ O
30 -X- _ O
K -X- _ O
and -X- _ O
AlephBERT -X- _ B-MethodName
- -X- _ O
small -X- _ O
with -X- _ O
52 -X- _ O
K -X- _ O
) -X- _ O
but -X- _ O
HeBERT -X- _ B-MethodName
, -X- _ O
with -X- _ O
its -X- _ O
12 -X- _ O
hidden -X- _ O
layers -X- _ O
, -X- _ O
performs -X- _ O
better -X- _ O
compared -X- _ O
to -X- _ O
AlephBERT -X- _ B-MethodName
smallwhich -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
only -X- _ O
6 -X- _ O
hidden -X- _ O
layers -X- _ O
. -X- _ O

It -X- _ O
thus -X- _ O
appears -X- _ O
that -X- _ O
semantic -X- _ O
information -X- _ O
is -X- _ O
learned -X- _ O
in -X- _ O
those -X- _ O
deeper -X- _ O
layers -X- _ O
, -X- _ O
helping -X- _ O
in -X- _ O
both -X- _ O
discriminating -X- _ O
entities -X- _ O
and -X- _ O
improving -X- _ O
the -X- _ O
morphological -X- _ O
segmentation -X- _ O
capacity -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
comparing -X- _ O
AlephBERT -X- _ B-MethodName
base -X- _ O
and -X- _ O
HeBERT -X- _ B-MethodName
we -X- _ O
note -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
both -X- _ O
modeled -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
12 -X- _ O
hidden -X- _ O
layer -X- _ O
architecture -X- _ O
— -X- _ O
the -X- _ O
only -X- _ O
differences -X- _ O
between -X- _ O
them -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
their -X- _ O
vocabularies -X- _ O
( -X- _ O
30 -X- _ O
K -X- _ O
vs -X- _ O
52 -X- _ O
K -X- _ O
respectively -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Oscar -X- _ B-DatasetName
- -X- _ I-DatasetName
Wikipedia -X- _ I-DatasetName
vs -X- _ O
OscarWikipedia -X- _ B-DatasetName
- -X- _ I-DatasetName
Tweets -X- _ I-DatasetName
) -X- _ O
. -X- _ O

The -X- _ O
improvements -X- _ O
exhibited -X- _ O
by -X- _ O
AlephBERT -X- _ B-MethodName
base -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
HeBERT -X- _ B-MethodName
, -X- _ O
suggest -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
larger -X- _ O
vocabulary -X- _ O
are -X- _ O
invaluable -X- _ O
. -X- _ O

By -X- _ O
exposing -X- _ O
AlephBERT -X- _ B-MethodName
baseto -X- _ O
a -X- _ O
substantially -X- _ O
larger -X- _ O
amount -X- _ O
of -X- _ O
text -X- _ O
we -X- _ O
increased -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
PLM -X- _ O
to -X- _ O
encode -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
signals -X- _ O
associated -X- _ O
with -X- _ O
Named -X- _ O
Entities -X- _ O
. -X- _ O

Our -X- _ O
NER -X- _ O
experiments -X- _ O
further -X- _ O
suggest -X- _ O
that -X- _ O
a -X- _ O
pipeline -X- _ O
composed -X- _ O
of -X- _ O
our -X- _ O
accurate -X- _ O
morphological -X- _ O
segmentation -X- _ O
model -X- _ O
followed -X- _ O
by -X- _ O
AlephBERT -X- _ B-MethodName
base -X- _ O
with -X- _ O
a -X- _ O
token -X- _ O
classification -X- _ O
head -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
strategy -X- _ O
for -X- _ O
generating -X- _ O
morphologically -X- _ O
- -X- _ O
aware -X- _ O
NER -X- _ O
labels -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
while -X- _ O
AlephBERT -X- _ B-MethodName
excels -X- _ O
at -X- _ O
morphosyntactic -X- _ O
tasks -X- _ O
, -X- _ O
on -X- _ O
tasks -X- _ O
with -X- _ O
a -X- _ O
more -X- _ O
semantic -X- _ O
flavor -X- _ O
there -X- _ O
is -X- _ O
room -X- _ O
for -X- _ O
improvement -X- _ O
. -X- _ O

7 -X- _ O
Conclusion -X- _ O
Modern -X- _ O
Hebrew -X- _ O
, -X- _ O
a -X- _ O
morphologically -X- _ O
- -X- _ O
rich -X- _ O
and -X- _ O
medium -X- _ O
- -X- _ O
resourced -X- _ O
language -X- _ O
, -X- _ O
has -X- _ O
for -X- _ O
long -X- _ O
suffered -X- _ O
from -X- _ O
a -X- _ O
gap -X- _ O
in -X- _ O
the -X- _ O
resources -X- _ O
available -X- _ O
for -X- _ O
NLP -X- _ O
applications -X- _ O
, -X- _ O
and -X- _ O
lower -X- _ O
level -X- _ O
of -X- _ O
empirical -X- _ O
results -X- _ O
than -X- _ O
observed -X- _ O
in -X- _ O
other -X- _ O
, -X- _ O
resource -X- _ O
- -X- _ O
rich -X- _ O
languages -X- _ O
. -X- _ O

This53 -X- _ O

work -X- _ O
provides -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
in -X- _ O
remedying -X- _ O
the -X- _ O
situation -X- _ O
, -X- _ O
by -X- _ O
making -X- _ O
available -X- _ O
a -X- _ O
large -X- _ O
Hebrew -X- _ O
PLM -X- _ O
, -X- _ O
named -X- _ O
AlephBERT -X- _ B-MethodName
, -X- _ O
with -X- _ O
larger -X- _ O
vocabulary -X- _ O
and -X- _ O
larger -X- _ O
training -X- _ O
set -X- _ O
than -X- _ O
any -X- _ O
Hebrew -X- _ O
PLM -X- _ O
before -X- _ O
, -X- _ O
and -X- _ O
with -X- _ O
clear -X- _ O
evidence -X- _ O
as -X- _ O
to -X- _ O
its -X- _ O
empirical -X- _ O
advantages -X- _ O
. -X- _ O

Crucially -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
PLM -X- _ O
with -X- _ O
a -X- _ O
morphological -X- _ O
disambiguation -X- _ O
component -X- _ O
that -X- _ O
matches -X- _ O
the -X- _ O
input -X- _ O
granularity -X- _ O
of -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

Our -X- _ O
system -X- _ O
does -X- _ O
not -X- _ O
presuppose -X- _ O
Hebrewspecific -X- _ O
linguistic -X- _ O
- -X- _ O
rules -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
transparently -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
language -X- _ O
for -X- _ O
which -X- _ O
2 -X- _ O
- -X- _ O
level -X- _ O
segmentation -X- _ O
data -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
standard -X- _ O
UD -X- _ O
benchmarks -X- _ O
) -X- _ O
exists -X- _ O
. -X- _ O

AlephBERT -X- _ B-MethodName
baseobtains -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
morphological -X- _ O
segmentation -X- _ O
, -X- _ O
POS -X- _ O
tagging -X- _ O
, -X- _ O
morphological -X- _ O
feature -X- _ O
extraction -X- _ O
, -X- _ O
dependency -X- _ O
parsing -X- _ O
, -X- _ O
named -X- _ O
- -X- _ O
entity -X- _ O
recognition -X- _ O
, -X- _ O
and -X- _ O
sentiment -X- _ O
analysis -X- _ O
, -X- _ O
outperforming -X- _ O
all -X- _ O
existing -X- _ O
Hebrew -X- _ O
PLMs -X- _ O
. -X- _ O

Our -X- _ O
proposed -X- _ O
morphologically -X- _ O
- -X- _ O
driven -X- _ O
pipeline11serves -X- _ O
as -X- _ O
a -X- _ O
solid -X- _ O
foundation -X- _ O
for -X- _ O
future -X- _ O
evaluation -X- _ O
of -X- _ O
Hebrew -X- _ O
PLMs -X- _ O
and -X- _ O
of -X- _ O
MRLs -X- _ O
in -X- _ O
general -X- _ O
. -X- _ O

8 -X- _ O
Ethical -X- _ O
Statement -X- _ O
We -X- _ O
follow -X- _ O
Bender -X- _ O
and -X- _ O
Friedman -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
regarding -X- _ O
professional -X- _ O
practice -X- _ O
for -X- _ O
NLP -X- _ O
technology -X- _ O
and -X- _ O
address -X- _ O
ethical -X- _ O
issues -X- _ O
that -X- _ O
result -X- _ O
from -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
. -X- _ O

Pre -X- _ O
- -X- _ O
Training -X- _ O
Data -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
initial -X- _ O
data -X- _ O
sources -X- _ O
we -X- _ O
used -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
Oscar -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
. -X- _ O

In -X- _ O
using -X- _ O
the -X- _ O
Wikipedia -X- _ O
and -X- _ O
Oscar -X- _ O
we -X- _ O
followed -X- _ O
standard -X- _ O
language -X- _ O
model -X- _ O
training -X- _ O
efforts -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
and -X- _ O
RoBERTa -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
languagespecific -X- _ O
Oscar -X- _ O
data -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
terms -X- _ O
specified -X- _ O
in -X- _ O
Ortiz -X- _ O
Suárez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
we -X- _ O
extract -X- _ O
texts -X- _ O
from -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
Wikipedia -X- _ O
dumps -X- _ O
. -X- _ O

On -X- _ O
top -X- _ O
of -X- _ O
that -X- _ O
, -X- _ O
a -X- _ O
big -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
AlephBERT -X- _ B-MethodName
originates -X- _ O
from -X- _ O
the -X- _ O
Twitter -X- _ O
sample -X- _ O
stream.12 -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
this -X- _ O
data -X- _ O
set -X- _ O
includes -X- _ O
70 -X- _ O
M -X- _ O
Hebrew -X- _ O
tweets -X- _ O
which -X- _ O
were -X- _ O
collected -X- _ O
over -X- _ O
a -X- _ O
period -X- _ O
of -X- _ O
4 -X- _ O
years -X- _ O
( -X- _ O
2014 -X- _ O
to -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
acknowledge -X- _ O
the -X- _ O
potential -X- _ O
concerns -X- _ O
inherently -X- _ O
associated -X- _ O
with -X- _ O
Twitter -X- _ O
data -X- _ O
( -X- _ O
population -X- _ O
bias -X- _ O
, -X- _ O
behavior -X- _ O
patterns -X- _ O
, -X- _ O
bot -X- _ O
masquerading -X- _ O
as -X- _ O
humans -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
and -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
not -X- _ O
made -X- _ O
any -X- _ O
explicit -X- _ O
attempt -X- _ O
to -X- _ O
identify -X- _ O
these -X- _ O
cases -X- _ O
. -X- _ O

We -X- _ O
only -X- _ O
used -X- _ O
the -X- _ O
text -X- _ O
field -X- _ O
of -X- _ O
the -X- _ O
tweets -X- _ O
and -X- _ O
completely -X- _ O
discard -X- _ O
any -X- _ O
other -X- _ O
information -X- _ O
included -X- _ O
11Available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
OnlpLab -X- _ O
/ -X- _ O
AlephBERT -X- _ O
12https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
developer.twitter.com -X- _ O
/ -X- _ O
en -X- _ O
/ -X- _ O

docs -X- _ O
/ -X- _ O
twitter -X- _ O
- -X- _ O
api -X- _ O
/ -X- _ O
tweets -X- _ O
/ -X- _ O
volume -X- _ O
- -X- _ O
streams -X- _ O
/ -X- _ O
api -X- _ O
- -X- _ O
reference -X- _ O
/ -X- _ O
get -X- _ O
- -X- _ O
tweets -X- _ O
- -X- _ O
sample -X- _ O
- -X- _ O
streamin -X- _ O
the -X- _ O
stream -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
identities -X- _ O
, -X- _ O
followers -X- _ O
, -X- _ O
structure -X- _ O
of -X- _ O
threads -X- _ O
, -X- _ O
date -X- _ O
of -X- _ O
publication -X- _ O
, -X- _ O
etc -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
not -X- _ O
made -X- _ O
any -X- _ O
effort -X- _ O
to -X- _ O
identify -X- _ O
or -X- _ O
filter -X- _ O
out -X- _ O
any -X- _ O
samples -X- _ O
based -X- _ O
on -X- _ O
user -X- _ O
properties -X- _ O
such -X- _ O
as -X- _ O
age -X- _ O
, -X- _ O
gender -X- _ O
and -X- _ O
location -X- _ O
nor -X- _ O
have -X- _ O
we -X- _ O
made -X- _ O
any -X- _ O
effort -X- _ O
to -X- _ O
identify -X- _ O
content -X- _ O
characteristics -X- _ O
such -X- _ O
as -X- _ O
genre -X- _ O
or -X- _ O
topic -X- _ O
. -X- _ O

To -X- _ O
reduce -X- _ O
exposure -X- _ O
of -X- _ O
private -X- _ O
information -X- _ O
we -X- _ O
cleaned -X- _ O
up -X- _ O
all -X- _ O
user -X- _ O
mentions -X- _ O
and -X- _ O
URLs -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O

Honoring -X- _ O
ethical -X- _ O
and -X- _ O
legal -X- _ O
constraints -X- _ O
we -X- _ O
have -X- _ O
not -X- _ O
manually -X- _ O
analyzed -X- _ O
nor -X- _ O
published -X- _ O
this -X- _ O
data -X- _ O
source -X- _ O
. -X- _ O

While -X- _ O
the -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
language -X- _ O
expressed -X- _ O
in -X- _ O
tweets -X- _ O
might -X- _ O
differ -X- _ O
significantly -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
found -X- _ O
in -X- _ O
Oscar -X- _ B-DatasetName
/ -X- _ O
Wikipedia -X- _ B-DatasetName
, -X- _ O
the -X- _ O
sheer -X- _ O
volume -X- _ O
of -X- _ O
tweets -X- _ O
helps -X- _ O
us -X- _ O
close -X- _ O
the -X- _ O
substantial -X- _ O
resource -X- _ O
gap -X- _ O
. -X- _ O

Training -X- _ O
and -X- _ O
Evaluation -X- _ O
Benchmarks -X- _ O
. -X- _ O

The -X- _ O
SPMRL -X- _ O
( -X- _ O
Seddah -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
UD -X- _ O
( -X- _ O
Sadde -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
datasets -X- _ O
we -X- _ O
used -X- _ O
for -X- _ O
evaluating -X- _ O
segmentation -X- _ O
, -X- _ O
tagging -X- _ O
and -X- _ O
parsing -X- _ O
, -X- _ O
were -X- _ O
used -X- _ O
to -X- _ O
both -X- _ O
train -X- _ O
our -X- _ O
morphological -X- _ O
extraction -X- _ O
model -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
provide -X- _ O
us -X- _ O
with -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
to -X- _ O
evaluate -X- _ O
on -X- _ O
morphological -X- _ O
level -X- _ O
tasks -X- _ O
. -X- _ O

Both -X- _ O
datasets -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
and -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
research -X- _ O
and -X- _ O
industry -X- _ O
. -X- _ O

The -X- _ O
NEMO -X- _ O
corpus -X- _ O
( -X- _ O
Bareket -X- _ O
and -X- _ O
Tsarfaty -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
and -X- _ O
evaluate -X- _ O
word -X- _ O
and -X- _ O
morpheme -X- _ O
level -X- _ O
NER -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
the -X- _ O
SPMRL -X- _ O
dataset -X- _ O
augmented -X- _ O
with -X- _ O
entities -X- _ O
and -X- _ O
follows -X- _ O
the -X- _ O
same -X- _ O
license -X- _ O
terms -X- _ O
. -X- _ O

The -X- _ O
BMC -X- _ O
dataset -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
evaluating -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
NER -X- _ O
was -X- _ O
created -X- _ O
and -X- _ O
published -X- _ O
by -X- _ O
Ben -X- _ O
Mordecai -X- _ O
and -X- _ O
Elhadad -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
for -X- _ O
NER -X- _ O
evaluation -X- _ O
. -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
sentiment -X- _ O
analysis -X- _ O
dataset -X- _ O
of -X- _ O
Amram -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
evaluating -X- _ O
AlephBERT -X- _ B-MethodName
on -X- _ O
a -X- _ O
sentence -X- _ O
level -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
follow -X- _ O
their -X- _ O
terms -X- _ O
of -X- _ O
use -X- _ O
. -X- _ O

As -X- _ O
mentioned -X- _ O
, -X- _ O
this -X- _ O
dataset -X- _ O
had -X- _ O
some -X- _ O
flows -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
describe -X- _ O
carefully -X- _ O
the -X- _ O
steps -X- _ O
we -X- _ O
’ve -X- _ O
taken -X- _ O
to -X- _ O
fix -X- _ O
them -X- _ O
before -X- _ O
using -X- _ O
this -X- _ O
corpus -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
for -X- _ O
internal -X- _ O
evaluation -X- _ O
purposes -X- _ O
. -X- _ O

We -X- _ O
make -X- _ O
our -X- _ O
in -X- _ O
- -X- _ O
house -X- _ O
cleaning -X- _ O
scripts -X- _ O
and -X- _ O
split -X- _ O
information -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O

Acknowledgements -X- _ O
This -X- _ O
research -X- _ O
was -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
European -X- _ O
Research -X- _ O
Council -X- _ O
( -X- _ O
ERC -X- _ O
grant -X- _ O
agreement -X- _ O
no -X- _ O
. -X- _ O
677352 -X- _ O
) -X- _ O
and -X- _ O
by -X- _ O
a -X- _ O
research -X- _ O
grant -X- _ O
from -X- _ O
the -X- _ O
Ministry -X- _ O
of -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
( -X- _ O
MOST -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
Israeli -X- _ O
Government -X- _ O
, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
are -X- _ O
grateful -X- _ O
. -X- _ O

References -X- _ O
Adam -X- _ O
Amram -X- _ O
, -X- _ O
Anat -X- _ O
Ben -X- _ O
- -X- _ O
David -X- _ O
, -X- _ O
and -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

Representations -X- _ O
and -X- _ O
architectures -X- _ O
in -X- _ O
neu-54 -X- _ O

ral -X- _ O
sentiment -X- _ O
analysis -X- _ O
for -X- _ O
morphologically -X- _ O
rich -X- _ O
languages -X- _ O
: -X- _ O

A -X- _ O
case -X- _ O
study -X- _ O
from -X- _ O
modern -X- _ O
hebrew -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
27th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
COLING -X- _ O
2018 -X- _ O
, -X- _ O
Santa -X- _ O
Fe -X- _ O
, -X- _ O
Wissam -X- _ O
Antoun -X- _ O
, -X- _ O
Fady -X- _ O
Baly -X- _ O
, -X- _ O
and -X- _ O
Hazem -X- _ O
Hajj -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

AraBERT -X- _ O
: -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
for -X- _ O
Arabic -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
4th -X- _ O
Workshop -X- _ O
on -X- _ O
Open -X- _ O
- -X- _ O
Source -X- _ O
Arabic -X- _ O
Corpora -X- _ O
and -X- _ O
Processing -X- _ O
Tools -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
Shared -X- _ O
Task -X- _ O
on -X- _ O
Offensive -X- _ O
Language -X- _ O
Detection -X- _ O
, -X- _ O
pages -X- _ O
9–15 -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
France -X- _ O
. -X- _ O

European -X- _ O
Language -X- _ O
Resource -X- _ O
Association -X- _ O
. -X- _ O

Giusepppe -X- _ O
Attardi -X- _ O
. -X- _ O

2015 -X- _ O
. -X- _ O

Wikiextractor -X- _ O
. -X- _ O

https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
attardi -X- _ O
/ -X- _ O
wikiextractor -X- _ O
. -X- _ O

Dan -X- _ O
Bareket -X- _ O
and -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

Neural -X- _ O
modeling -X- _ O
for -X- _ O
named -X- _ O
entities -X- _ O
and -X- _ O
morphology -X- _ O
( -X- _ O
nemoˆ2 -X- _ O
) -X- _ O
. -X- _ O

CoRR -X- _ O
, -X- _ O
Naama -X- _ O
Ben -X- _ O
Mordecai -X- _ O
and -X- _ O
Michael -X- _ O
Elhadad -X- _ O
. -X- _ O
2005 -X- _ O
. -X- _ O

Hebrew -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
. -X- _ O

Emily -X- _ O
M. -X- _ O
Bender -X- _ O
and -X- _ O
Batya -X- _ O
Friedman -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

Data -X- _ O
statements -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
: -X- _ O
Toward -X- _ O
mitigating -X- _ O
system -X- _ O
bias -X- _ O
and -X- _ O
enabling -X- _ O
better -X- _ O
science -X- _ O
. -X- _ O

Transactions -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Tom -X- _ O
Brown -X- _ O
, -X- _ O
Benjamin -X- _ O
Mann -X- _ O
, -X- _ O
Nick -X- _ O
Ryder -X- _ O
, -X- _ O
Melanie -X- _ O
Subbiah -X- _ O
, -X- _ O
Jared -X- _ O
D -X- _ O
Kaplan -X- _ O
, -X- _ O
Prafulla -X- _ O
Dhariwal -X- _ O
, -X- _ O
Arvind -X- _ O
Neelakantan -X- _ O
, -X- _ O
Pranav -X- _ O
Shyam -X- _ O
, -X- _ O
Girish -X- _ O
Sastry -X- _ O
, -X- _ O
Amanda -X- _ O
Askell -X- _ O
, -X- _ O
Sandhini -X- _ O
Agarwal -X- _ O
, -X- _ O
Ariel -X- _ O
Herbert -X- _ O
- -X- _ O
V -X- _ O
oss -X- _ O
, -X- _ O
Gretchen -X- _ O
Krueger -X- _ O
, -X- _ O
Tom -X- _ O
Henighan -X- _ O
, -X- _ O
Rewon -X- _ O
Child -X- _ O
, -X- _ O
Aditya -X- _ O
Ramesh -X- _ O
, -X- _ O
Daniel -X- _ O
Ziegler -X- _ O
, -X- _ O
Jeffrey -X- _ O
Wu -X- _ O
, -X- _ O
Clemens -X- _ O
Winter -X- _ O
, -X- _ O
Chris -X- _ O
Hesse -X- _ O
, -X- _ O
Mark -X- _ O
Chen -X- _ O
, -X- _ O
Eric -X- _ O
Sigler -X- _ O
, -X- _ O
Mateusz -X- _ O
Litwin -X- _ O
, -X- _ O
Scott -X- _ O
Gray -X- _ O
, -X- _ O
Benjamin -X- _ O
Chess -X- _ O
, -X- _ O
Jack -X- _ O
Clark -X- _ O
, -X- _ O
Christopher -X- _ O
Berner -X- _ O
, -X- _ O
Sam -X- _ O
McCandlish -X- _ O
, -X- _ O
Alec -X- _ O
Radford -X- _ O
, -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
, -X- _ O
and -X- _ O
Dario -X- _ O
Amodei -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Language -X- _ O
models -X- _ O
are -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learners -X- _ O
. -X- _ O

In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
, -X- _ O
volume -X- _ O
33 -X- _ O
, -X- _ O
pages -X- _ O
1877–1901 -X- _ O
. -X- _ O

Curran -X- _ O
Associates -X- _ O
, -X- _ O
Inc -X- _ O
. -X- _ O

Avihay -X- _ O
Chriqui -X- _ O
and -X- _ O
Inbal -X- _ O
Yahav -X- _ O
. -X- _ O

2021 -X- _ O
. -X- _ O

Hebert -X- _ O
| -X- _ O
& -X- _ O
hebemo -X- _ O
: -X- _ O
a -X- _ O
hebrew -X- _ O
bert -X- _ O
model -X- _ O
and -X- _ O
a -X- _ O
tool -X- _ O
for -X- _ O
polarity -X- _ O
analysis -X- _ O
and -X- _ O
emotion -X- _ O
recognition -X- _ O
. -X- _ O

Jacob -X- _ O
Devlin -X- _ O
, -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Kristina -X- _ O
Toutanova -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

BERT -X- _ O
: -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
deep -X- _ O
bidirectional -X- _ O
transformers -X- _ O
for -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2019 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
Volume -X- _ O
1 -X- _ O
( -X- _ O
Long -X- _ O
and -X- _ O
Short -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
4171–4186 -X- _ O
, -X- _ O
Minneapolis -X- _ O
, -X- _ O
Minnesota -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Mehrdad -X- _ O
Farahani -X- _ O
, -X- _ O
Mohammad -X- _ O
Gharachorloo -X- _ O
, -X- _ O
Marzieh -X- _ O
Farahani -X- _ O
, -X- _ O
and -X- _ O
Mohammad -X- _ O
Manthouri -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Parsbert -X- _ O
: -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
for -X- _ O
persian -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

Jeremy -X- _ O
Howard -X- _ O
and -X- _ O
Sebastian -X- _ O
Ruder -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

Universal -X- _ O
language -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
for -X- _ O
text -X- _ O
classification -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
56th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
328–339 -X- _ O
, -X- _ O
Melbourne -X- _ O
, -X- _ O
Australia -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Stav -X- _ O
Klein -X- _ O
and -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

Getting -X- _ O
the -X- _ O
# -X- _ O
# -X- _ O
life -X- _ O
out -X- _ O
of -X- _ O
living -X- _ O
: -X- _ O
How -X- _ O
adequate -X- _ O
are -X- _ O
word -X- _ O
- -X- _ O
pieces -X- _ O
for -X- _ O
modelling -X- _ O
complex -X- _ O
morphology -X- _ O
? -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
17th -X- _ O
SIGMORPHON -X- _ O
Workshop -X- _ O
on -X- _ O
Computational -X- _ O
Research -X- _ O
in -X- _ O
Phonetics -X- _ O
, -X- _ O
Phonology -X- _ O
, -X- _ O
and -X- _ O
Morphology -X- _ O
, -X- _ O
SIGMORPHON -X- _ O
2020 -X- _ O
, -X- _ O
Online -X- _ O
, -X- _ O
July -X- _ O
10 -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
pages -X- _ O
Yinhan -X- _ O
Liu -X- _ O
, -X- _ O
Myle -X- _ O
Ott -X- _ O
, -X- _ O
Naman -X- _ O
Goyal -X- _ O
, -X- _ O
Jingfei -X- _ O
Du -X- _ O
, -X- _ O
Mandar -X- _ O
Joshi -X- _ O
, -X- _ O
Danqi -X- _ O
Chen -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
Mike -X- _ O
Lewis -X- _ O
, -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
, -X- _ O
and -X- _ O
Veselin -X- _ O
Stoyanov -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

RoBERTa -X- _ O
: -X- _ O
A -X- _ O
Robustly -X- _ O
Optimized -X- _ O
BERT -X- _ O
Pretraining -X- _ O
Approach -X- _ O
. -X- _ O

Amir -X- _ O
Pouran -X- _ O
Ben -X- _ O
Veyseh -X- _ O
Minh -X- _ O
Van -X- _ O
Nguyen -X- _ O
, -X- _ O
Viet -X- _ O
Lai -X- _ O
and -X- _ O
Thien -X- _ O
Huu -X- _ O
Nguyen -X- _ O
. -X- _ O
2021 -X- _ O
. -X- _ O

Trankit -X- _ O
: -X- _ O
A -X- _ O
lightweight -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
toolkit -X- _ O
for -X- _ O
multilingual -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
16th -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
European -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
System -X- _ O
Demonstrations -X- _ O
. -X- _ O

Amir -X- _ O
More -X- _ O
, -X- _ O
Amit -X- _ O
Seker -X- _ O
, -X- _ O
Victoria -X- _ O
Basmova -X- _ O
, -X- _ O
and -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Joint -X- _ O
transition -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
for -X- _ O
morpho -X- _ O
- -X- _ O
syntactic -X- _ O
parsing -X- _ O
: -X- _ O
Parsing -X- _ O
strategies -X- _ O
for -X- _ O
mrls -X- _ O
and -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
from -X- _ O
modern -X- _ O
hebrew -X- _ O
. -X- _ O

Trans -X- _ O
. -X- _ O

Assoc -X- _ O
. -X- _ O

Comput -X- _ O
. -X- _ O

Linguistics -X- _ O
, -X- _ O
7:33–48 -X- _ O
. -X- _ O

Pedro -X- _ O
Javier -X- _ O
Ortiz -X- _ O
Suárez -X- _ O
, -X- _ O
Laurent -X- _ O
Romary -X- _ O
, -X- _ O
and -X- _ O
Benoît -X- _ O
Sagot -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

A -X- _ O
monolingual -X- _ O
approach -X- _ O
to -X- _ O
contextualized -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
mid -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O

InProceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
1703 -X- _ O
– -X- _ O
1714 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Matthew -X- _ O
E. -X- _ O
Peters -X- _ O
, -X- _ O
Mark -X- _ O
Neumann -X- _ O
, -X- _ O
Mohit -X- _ O
Iyyer -X- _ O
, -X- _ O
Matt -X- _ O
Gardner -X- _ O
, -X- _ O
Christopher -X- _ O
Clark -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

Deep -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
, -X- _ O
Volume -X- _ O
1 -X- _ O
( -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
2227–2237 -X- _ O
, -X- _ O
New -X- _ O
Orleans -X- _ O
, -X- _ O
Louisiana -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Marco -X- _ O
Polignano -X- _ O
, -X- _ O
Pierpaolo -X- _ O
Basile -X- _ O
, -X- _ O
Marco -X- _ O
de -X- _ O
Gemmis -X- _ O
, -X- _ O
Giovanni -X- _ O
Semeraro -X- _ O
, -X- _ O
and -X- _ O
Valerio -X- _ O
Basile -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Alberto -X- _ O
: -X- _ O
Italian -X- _ O
bert -X- _ O
language -X- _ O
understanding -X- _ O
model -X- _ O
for -X- _ O
nlp -X- _ O
challenging -X- _ O
tasks -X- _ O
based -X- _ O
on -X- _ O
tweets -X- _ O
. -X- _ O

Alec -X- _ O
Radford -X- _ O
and -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

Improving -X- _ O
language -X- _ O
understanding -X- _ O
by -X- _ O
generative -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

Inarxiv -X- _ O
. -X- _ O

Colin -X- _ O
Raffel -X- _ O
, -X- _ O
Noam -X- _ O
Shazeer -X- _ O
, -X- _ O
Adam -X- _ O
Roberts -X- _ O
, -X- _ O
Katherine -X- _ O
Lee -X- _ O
, -X- _ O
Sharan -X- _ O
Narang -X- _ O
, -X- _ O
Michael -X- _ O
Matena -X- _ O
, -X- _ O
Yanqi -X- _ O
Zhou -X- _ O
, -X- _ O
Wei -X- _ O
Li -X- _ O
, -X- _ O
and -X- _ O
Peter -X- _ O
J. -X- _ O
Liu -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Exploring -X- _ O
the55 -X- _ O

limits -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
a -X- _ O
unified -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
transformer -X- _ O
. -X- _ O

Journal -X- _ O
of -X- _ O
Machine -X- _ O
Learning -X- _ O
Research -X- _ O
, -X- _ O
Pranav -X- _ O
Rajpurkar -X- _ O
, -X- _ O
Jian -X- _ O
Zhang -X- _ O
, -X- _ O
Konstantin -X- _ O
Lopyrev -X- _ O
, -X- _ O
and -X- _ O
Percy -X- _ O
Liang -X- _ O
. -X- _ O

2016 -X- _ O
. -X- _ O

SQuAD -X- _ O
: -X- _ O
100,000 -X- _ O
+ -X- _ O
questions -X- _ O
for -X- _ O
machine -X- _ O
comprehension -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2016 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
2383–2392 -X- _ O
, -X- _ O
Austin -X- _ O
, -X- _ O
Texas -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Piotr -X- _ O
Rybak -X- _ O
, -X- _ O
Robert -X- _ O
Mroczkowski -X- _ O
, -X- _ O
Janusz -X- _ O
Tracz -X- _ O
, -X- _ O
and -X- _ O
Ireneusz -X- _ O
Gawlik -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

KLEJ -X- _ O
: -X- _ O

Comprehensive -X- _ O
benchmark -X- _ O
for -X- _ O
Polish -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
1191 -X- _ O
– -X- _ O
1201 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Shoval -X- _ O
Sadde -X- _ O
, -X- _ O
Amit -X- _ O
Seker -X- _ O
, -X- _ O
and -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
. -X- _ O

2018 -X- _ O
. -X- _ O

The -X- _ O
hebrew -X- _ O
universal -X- _ O
dependency -X- _ O
treebank -X- _ O
: -X- _ O
Past -X- _ O
present -X- _ O
and -X- _ O
future -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Second -X- _ O
Workshop -X- _ O
on -X- _ O
Universal -X- _ O
Dependencies -X- _ O
, -X- _ O
UDW -X- _ O
@ -X- _ O
EMNLP -X- _ O
2018 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
, -X- _ O
November -X- _ O
Gözde -X- _ O
Gül -X- _ O
¸ -X- _ O
Sahin -X- _ O
, -X- _ O
Clara -X- _ O
Vania -X- _ O
, -X- _ O
Ilia -X- _ O
Kuznetsov -X- _ O
, -X- _ O
and -X- _ O
Iryna -X- _ O
Gurevych -X- _ O
. -X- _ O

2019 -X- _ O
. -X- _ O

LINSPECTOR -X- _ O
: -X- _ O
multilingual -X- _ O
probing -X- _ O
tasks -X- _ O
for -X- _ O
word -X- _ O
representations -X- _ O
. -X- _ O

CoRR -X- _ O
, -X- _ O
Djamé -X- _ O
Seddah -X- _ O
, -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
, -X- _ O
Sandra -X- _ O
Kübler -X- _ O
, -X- _ O
Marie -X- _ O
Candito -X- _ O
, -X- _ O
Jinho -X- _ O
D. -X- _ O
Choi -X- _ O
, -X- _ O
Richárd -X- _ O
Farkas -X- _ O
, -X- _ O
Jennifer -X- _ O
Foster -X- _ O
, -X- _ O
Iakes -X- _ O
Goenaga -X- _ O
, -X- _ O
Koldo -X- _ O
Gojenola -X- _ O
Galletebeitia -X- _ O
, -X- _ O
Yoav -X- _ O
Goldberg -X- _ O
, -X- _ O
Spence -X- _ O
Green -X- _ O
, -X- _ O
Nizar -X- _ O
Habash -X- _ O
, -X- _ O
Marco -X- _ O
Kuhlmann -X- _ O
, -X- _ O
Wolfgang -X- _ O
Maier -X- _ O
, -X- _ O
Joakim -X- _ O
Nivre -X- _ O
, -X- _ O
Adam -X- _ O
Przepiórkowski -X- _ O
, -X- _ O
Ryan -X- _ O
Roth -X- _ O
, -X- _ O
Wolfgang -X- _ O
Seeker -X- _ O
, -X- _ O
Yannick -X- _ O
Versley -X- _ O
, -X- _ O
Veronika -X- _ O
Vincze -X- _ O
, -X- _ O
Marcin -X- _ O
Wolinski -X- _ O
, -X- _ O
Alina -X- _ O
Wróblewska -X- _ O
, -X- _ O
and -X- _ O
Éric -X- _ O
Villemonte -X- _ O
de -X- _ O
la -X- _ O
Clergerie -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O

Overview -X- _ O
of -X- _ O
the -X- _ O
SPMRL -X- _ O
2013 -X- _ O
shared -X- _ O
task -X- _ O
: -X- _ O
A -X- _ O
cross -X- _ O
- -X- _ O
framework -X- _ O
evaluation -X- _ O
of -X- _ O
parsing -X- _ O
morphologically -X- _ O
rich -X- _ O
languages -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Fourth -X- _ O
Workshop -X- _ O
on -X- _ O
Statistical -X- _ O
Parsing -X- _ O
of -X- _ O
Morphologically -X- _ O
- -X- _ O
Rich -X- _ O
Languages -X- _ O
, -X- _ O
SPMRL -X- _ O
@ -X- _ O
EMNLP -X- _ O
2013 -X- _ O
, -X- _ O
Seattle -X- _ O
, -X- _ O
Washington -X- _ O
, -X- _ O
USA -X- _ O
, -X- _ O
October -X- _ O
18 -X- _ O
, -X- _ O
2013 -X- _ O
, -X- _ O
Amit -X- _ O
Seker -X- _ O
and -X- _ O
Reut -X- _ O
Tsarfaty -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

A -X- _ O
pointer -X- _ O
network -X- _ O
architecture -X- _ O
for -X- _ O
joint -X- _ O
morphological -X- _ O
segmentation -X- _ O
and -X- _ O
tagging -X- _ O
. -X- _ O

In -X- _ O
Findings -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
EMNLP -X- _ O
2020 -X- _ O
, -X- _ O
pages -X- _ O
4368–4378 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Rico -X- _ O
Sennrich -X- _ O
, -X- _ O
Barry -X- _ O
Haddow -X- _ O
, -X- _ O
and -X- _ O
Alexandra -X- _ O
Birch -X- _ O
. -X- _ O

2016 -X- _ O
. -X- _ O

Neural -X- _ O
machine -X- _ O
translation -X- _ O
of -X- _ O
rare -X- _ O
words -X- _ O
with -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
54th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
1715–1725 -X- _ O
, -X- _ O
Berlin -X- _ O
, -X- _ O
Germany -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Reut -X- _ O
Tsarfaty -X- _ O
, -X- _ O
Dan -X- _ O
Bareket -X- _ O
, -X- _ O
Stav -X- _ O
Klein -X- _ O
, -X- _ O
and -X- _ O
Amit -X- _ O
Seker -X- _ O
. -X- _ O

2020 -X- _ O
. -X- _ O

From -X- _ O
SPMRL -X- _ O
to -X- _ O
NMRL -X- _ O
: -X- _ O
what -X- _ O
did -X- _ O
we -X- _ O
learn -X- _ O
( -X- _ O
and -X- _ O
unlearn -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
decade -X- _ O
of -X- _ O
parsing -X- _ O
morphologicallyrich -X- _ O
languages -X- _ O
( -X- _ O
mrls -X- _ O
) -X- _ O
? -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
58th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
ACL -X- _ O
2020 -X- _ O
, -X- _ O
Online -X- _ O
, -X- _ O
July -X- _ O
5 -X- _ O
- -X- _ O
10 -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
Antti -X- _ O
Virtanen -X- _ O
, -X- _ O
Jenna -X- _ O
Kanerva -X- _ O
, -X- _ O
Rami -X- _ O
Ilo -X- _ O
, -X- _ O
Jouni -X- _ O
Luoma -X- _ O
, -X- _ O
Juhani -X- _ O
Luotolahti -X- _ O
, -X- _ O
Tapio -X- _ O
Salakoski -X- _ O
, -X- _ O
Filip -X- _ O
Ginter -X- _ O
, -X- _ O
and -X- _ O
Sampo -X- _ O
Pyysalo -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O

Multilingual -X- _ O
is -X- _ O
not -X- _ O
enough -X- _ O
: -X- _ O
Bert -X- _ O
for -X- _ O
finnish -X- _ O
. -X- _ O

Alex -X- _ O
Wang -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
Julian -X- _ O
Michael -X- _ O
, -X- _ O
Felix -X- _ O
Hill -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
Bowman -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

GLUE -X- _ O
: -X- _ O

A -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
benchmark -X- _ O
and -X- _ O
analysis -X- _ O
platform -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
EMNLP -X- _ O
Workshop -X- _ O
BlackboxNLP -X- _ O
: -X- _ O
Analyzing -X- _ O
and -X- _ O
Interpreting -X- _ O
Neural -X- _ O
Networks -X- _ O
for -X- _ O
NLP -X- _ O
, -X- _ O
pages -X- _ O
353–355 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Thomas -X- _ O
Wolf -X- _ O
, -X- _ O
Lysandre -X- _ O
Debut -X- _ O
, -X- _ O
Victor -X- _ O
Sanh -X- _ O
, -X- _ O
Julien -X- _ O
Chaumond -X- _ O
, -X- _ O
Clement -X- _ O
Delangue -X- _ O
, -X- _ O
Anthony -X- _ O
Moi -X- _ O
, -X- _ O
Pierric -X- _ O
Cistac -X- _ O
, -X- _ O
Tim -X- _ O
Rault -X- _ O
, -X- _ O
Rémi -X- _ O
Louf -X- _ O
, -X- _ O
Morgan -X- _ O
Funtowicz -X- _ O
, -X- _ O
Joe -X- _ O
Davison -X- _ O
, -X- _ O
Sam -X- _ O
Shleifer -X- _ O
, -X- _ O
Patrick -X- _ O
von -X- _ O
Platen -X- _ O
, -X- _ O
Clara -X- _ O
Ma -X- _ O
, -X- _ O
Yacine -X- _ O
Jernite -X- _ O
, -X- _ O
Julien -X- _ O
Plu -X- _ O
, -X- _ O
Canwen -X- _ O
Xu -X- _ O
, -X- _ O
Teven -X- _ O
Le -X- _ O
Scao -X- _ O
, -X- _ O
Sylvain -X- _ O
Gugger -X- _ O
, -X- _ O
Mariama -X- _ O
Drame -X- _ O
, -X- _ O
Quentin -X- _ O
Lhoest -X- _ O
, -X- _ O
and -X- _ O
Alexander -X- _ O
M. -X- _ O
Rush -X- _ O
. -X- _ O
2020 -X- _ O
. -X- _ O

Transformers -X- _ O
: -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2020 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
: -X- _ O
System -X- _ O
Demonstrations -X- _ O
, -X- _ O
pages -X- _ O
38–45 -X- _ O
, -X- _ O
Online -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Rowan -X- _ O
Zellers -X- _ O
, -X- _ O
Yonatan -X- _ O
Bisk -X- _ O
, -X- _ O
Roy -X- _ O
Schwartz -X- _ O
, -X- _ O
and -X- _ O
Yejin -X- _ O
Choi -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

SWAG -X- _ O
: -X- _ O

A -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
adversarial -X- _ O
dataset -X- _ O
for -X- _ O
grounded -X- _ O
commonsense -X- _ O
inference -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
93–104 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Daniel -X- _ O
Zeman -X- _ O
, -X- _ O
Jan -X- _ O
Haji -X- _ O
ˇc -X- _ O
, -X- _ O
Martin -X- _ O
Popel -X- _ O
, -X- _ O
Martin -X- _ O
Potthast -X- _ O
, -X- _ O
Milan -X- _ O
Straka -X- _ O
, -X- _ O
Filip -X- _ O
Ginter -X- _ O
, -X- _ O
Joakim -X- _ O
Nivre -X- _ O
, -X- _ O
and -X- _ O
Slav -X- _ O
Petrov -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O

CoNLL -X- _ O
2018 -X- _ O
shared -X- _ O
task -X- _ O
: -X- _ O

Multilingual -X- _ O
parsing -X- _ O
from -X- _ O
raw -X- _ O
text -X- _ O
to -X- _ O
Universal -X- _ O
Dependencies -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
CoNLL -X- _ O
2018 -X- _ O
Shared -X- _ O
Task -X- _ O
: -X- _ O
Multilingual -X- _ O
Parsing -X- _ O
from -X- _ O
Raw -X- _ O
Text -X- _ O
to -X- _ O
Universal -X- _ O
Dependencies -X- _ O
, -X- _ O
pages -X- _ O
1–21 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics.56 -X- _ O

